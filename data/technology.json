{
  "updated_at": "2026-03-01T07:27:56.947Z",
  "clusters": [
    {
      "id": "cluster_6",
      "coverage": 2,
      "updated_at": "Sat, 28 Feb 2026 19:05:00 -0500",
      "title": "OpenAI says it does not think Anthropic should be designated as a supply chain risk and it has made its position on this clear to the Pentagon (@openai)",
      "neutral_headline": "Pentagon moves to designate Anthropic as a supply-chain risk",
      "bullet_summary": [
        "Reported by TechMeme, TechCrunch"
      ],
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/260228/p19#a260228p19",
          "published_at": "Sat, 28 Feb 2026 19:05:00 -0500",
          "title": "OpenAI says it does not think Anthropic should be designated as a supply chain risk and it has made its position on this clear to the Pentagon (@openai)",
          "standfirst": "@openai: OpenAI says it does not think Anthropic should be designated as a supply chain risk and it has made its position on this clear to the Pentagon &mdash; We do not think Anthropic should be designated as a supply chain risk and we've made our position on this clear to the Department of War.",
          "content": "@openai: OpenAI says it does not think Anthropic should be designated as a supply chain risk and it has made its position on this clear to the Pentagon &mdash; We do not think Anthropic should be designated as a supply chain risk and we've made our position on this clear to the Department of War.",
          "feed_position": 5,
          "image_url": "http://www.techmeme.com/img/pml.png"
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2026/02/27/pentagon-moves-to-designate-anthropic-as-a-supply-chain-risk/",
          "published_at": "Fri, 27 Feb 2026 21:53:14 +0000",
          "title": "Pentagon moves to designate Anthropic as a supply-chain risk",
          "standfirst": "\"We don't need it, we don't want it, and will not do business with them again,\" the president wrote in the post.",
          "content": "\"We don't need it, we don't want it, and will not do business with them again,\" the president wrote in the post.",
          "feed_position": 10
        }
      ],
      "featured_image": "http://www.techmeme.com/img/pml.png",
      "popularity_score": 2012.617515
    },
    {
      "id": "cluster_23",
      "coverage": 2,
      "updated_at": "Sat, 28 Feb 2026 20:00:26 +0000",
      "title": "Trump moves to ban Anthropic from the US government",
      "neutral_headline": "Trump moves to ban Anthropic from the US government",
      "bullet_summary": [
        "Reported by Ars Technica, Wired Tech"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/02/trump-moves-to-ban-anthropic-from-the-us-government/",
          "published_at": "Sat, 28 Feb 2026 20:00:26 +0000",
          "title": "Trump moves to ban Anthropic from the US government",
          "standfirst": "The Defense Department pressured Anthropic to drop restrictions on how its AI can be used by the military.",
          "content": "US President Donald Trump announced Friday that he was instructing every federal agency to “immediately cease” use of Anthropic’s AI tools. The move comes after Anthropic and top officials clashed for weeks over military applications of artificial intelligence. \"The Leftwing nut jobs at Anthropic have made a DISASTROUS MISTAKE trying to STRONG-ARM the Department of War,” Trump said in a post on Truth Social. Trump said that there would be a “six month phase out period” for agencies using Anthropic, which could allow time for further negotiations between the government and the AI startup.Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2023/11/getty-Dario-Amodei-1152x648.jpg"
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/trump-moves-to-ban-anthropic-from-the-us-government/",
          "published_at": "Fri, 27 Feb 2026 21:36:31 +0000",
          "title": "Trump Moves to Ban Anthropic From the US Government",
          "standfirst": "President Donald Trump’s sudden order comes after the Defense Department pressured Anthropic to drop restrictions on how its AI can be used by the military.",
          "content": "President Donald Trump’s sudden order comes after the Defense Department pressured Anthropic to drop restrictions on how its AI can be used by the military.",
          "feed_position": 16,
          "image_url": "https://media.wired.com/photos/69a0a09c6c9d7076f06f28c6/master/pass/Pentagon-Goes-Nuclear-on-Anthropic-Business-2261852583.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2023/11/getty-Dario-Amodei-1152x648.jpg",
      "popularity_score": 2008.541403888889
    },
    {
      "id": "cluster_26",
      "coverage": 2,
      "updated_at": "Sat, 28 Feb 2026 19:08:21 +0000",
      "title": "Everything announced at MWC 2026: The new Leica Leitzphone by Xiaomi, Honor's ultra-thin MagicPad 4 and more",
      "neutral_headline": "Xiaomi 17 Ultra hands-on: cameras, but maybe hard to get",
      "bullet_summary": [
        "Leica also announced a new phone made in partnership with Xiaomi at MWC",
        "The Xiaomi Pad 8 ProXiaomiIn addition to the 17 Ultra, Xiaomi announced two new tablets at MWC this year: the Xiaomi Pad 8 and Xiaomi Pad 8 Pro",
        "Honor MagicPad 4 HonorAhead of MWC, Honor announced what it claims is the thinnest Android tablet in the world: the 4",
        "com/mobile/everything-announced-at-mwc-2026-the-new-leica-leitzphone-by-xiaomi-honors-ultra-thin-magicpad-4-and-more-172442426"
      ],
      "items": [
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/everything-announced-at-mwc-2026-the-new-leica-leitzphone-by-xiaomi-honors-ultra-thin-magicpad-4-and-more-172442426.html",
          "published_at": "Sat, 28 Feb 2026 19:08:21 +0000",
          "title": "Everything announced at MWC 2026: The new Leica Leitzphone by Xiaomi, Honor's ultra-thin MagicPad 4 and more",
          "standfirst": "MWC 2026 officially gets underway on March 2 and will continue through March 5, but the announcements are already coming ahead of its start. We can always count on the annual tech event to bring tons of new phones, laptops and tablets, and we're expecting to see some robots and other gadgets too — plus plenty of AI news, of course. In addition to the announcements, MWC is our chance to get hands-on time with some of the most interesting new devices, like the Xiaomi 17 Ultra.Engadget’s Mat Smith is on the ground in Barcelona, and we'll be updating this story as the week goes on to keep you in the loop on everything that caught our attention. Keep checking back here for the latest MWC news. Xiaomi x LeicaMat Smith for EngadgetXiaomi kicked off MWC this year by announcing the global launch of its 17 Ultra smartphone, which debuted first in China back in December. It's unclear if the phone will ever come to the US, but it's now rolling out in Europe. Xiaomi teamed up again with Leica to make a photography-focused smartphone, and the 17 Ultra sports a 1-inch 50-megapixel camera sensor with a f/1.67 lens, a telephoto setup with a 200MP 1/1.4-inch sensor, and a 50MP ultrawide camera. There's also a manual zoom ring around the camera. Check out our hands on for our first impressions of what it's like shooting with the Xiaomi 17 Ultra. And there's more to it than just the camera. The 17 Ultra has a 6.9-inch OLED 120 Hz display that peaks at 3,500 nits of brightness, and a 6000mAh silicon-carbon battery. The Xiaomi 17 Ultra starts at £1,299 (roughly $1,750).Leica also announced a new phone made in partnership with Xiaomi at MWC. It looks a whole lot like Xiaomi's 17 Ultra, but isn't the 17 Ultra, exactly. Leica Leitzphone by Xiaomi hands-on at MWC 2026Image by Mat Smith for EngadgetLike the 17 Ultra, Leica's Leitzphone by Xiaomi has a 1-inch camera sensor and physical controls for zoom and other settings, using a mechanical ring around the camera unit. It features a Leica-designed intuitive camera interface with the option to show just the essentials when you're shooting, hiding all the modes and labels. There's a monochrome shooting mode and Leica filters. The Leica branding is splashed all over it in design and wallpapers, but it's otherwise pretty similar to the 17 Ultra, with the same specs. Like the 17 Ultra, it has a Snapdragon 8 Elite Gen 5 chip and a 6.9-inch 120Hz display. This one's priced at €1,999 (roughly $2,362).The Xiaomi Pad 8 ProXiaomiIn addition to the 17 Ultra, Xiaomi announced two new tablets at MWC this year: the Xiaomi Pad 8 and Xiaomi Pad 8 Pro. There's nothing revolutionary here, but they're lightweight and thin, with both being 5.75mm thick and weighing 485g, and have a 9200mAh battery. The Pro model is powered by a Snapdragon 8 Elite chip, while the regular Pad 8 uses the Snapdragon 8s Gen 4 chipset. Xiaomi also unveiled a new 5000mAh powerbank, the UltraThin Magnetic Power Bank 5000 15W. The 6mm thick power bank comes in three colors with an aluminum alloy shell: orange, silver and charcoal gray. Along with that, the company introduced the Xiaomi Tag, its own take on the Bluetooth item tracker. The Xiaomi Tag has a built-in hanging loop so it can be attached directly to a keyring, and the company says it will work with both Apple Find My and Google's Find Hub for Android. Honor MagicPad 4 HonorAhead of MWC, Honor announced what it claims is the thinnest Android tablet in the world: the 4.8mm thick MagicPad 4. We're expecting to hear more about this at Honor's press conference on Sunday, but so far we know it features a 12.3-inch 165Hz OLED display and weighs just 450g. It comes with up to 16GB of RAM and 512GB of storage, and is powered by Qualcomm's Snapdragon 8 Gen 5 chipset. The thinness doesn't count the camera bump, Honor notes. The MagicPad 4 has 13MP rear and 9MP front cameras. It also boasts spatial audio, with eight speakers.Just as the display is slightly smaller than the previous MagicPad, the MagicPad 4 has a smaller battery at 10100 mAh. It comes with a 66W fast charger. The MagicPad 4 will run Honor's MagicOS 10. We don't yet know how much it will cost, but we'll update this after Honor's press conference (where we're also expecting to see the company's robot) with any new details. TecnoTecnoWe can always expect to see some wild phone concepts at MWC, and this year we're starting with one from Tecno. The company unveiled a modular concept smartphone design that can be as thin as 4.9mm in its base configuration. There’d be 10 modules to choose from based on the announcement, including various camera lenses, a gaming attachment and a power bank, relying on magnets to keep it all together — or Modular Magnetic Interconnection Technology, as Tecno is calling it. This article originally appeared on Engadget at https://www.engadget.com/mobile/everything-announced-at-mwc-2026-the-new-leica-leitzphone-by-xiaomi-honors-ultra-thin-magicpad-4-and-more-172442426.html?src=rss",
          "content": "MWC 2026 officially gets underway on March 2 and will continue through March 5, but the announcements are already coming ahead of its start. We can always count on the annual tech event to bring tons of new phones, laptops and tablets, and we're expecting to see some robots and other gadgets too — plus plenty of AI news, of course. In addition to the announcements, MWC is our chance to get hands-on time with some of the most interesting new devices, like the Xiaomi 17 Ultra.Engadget’s Mat Smith is on the ground in Barcelona, and we'll be updating this story as the week goes on to keep you in the loop on everything that caught our attention. Keep checking back here for the latest MWC news. Xiaomi x LeicaMat Smith for EngadgetXiaomi kicked off MWC this year by announcing the global launch of its 17 Ultra smartphone, which debuted first in China back in December. It's unclear if the phone will ever come to the US, but it's now rolling out in Europe. Xiaomi teamed up again with Leica to make a photography-focused smartphone, and the 17 Ultra sports a 1-inch 50-megapixel camera sensor with a f/1.67 lens, a telephoto setup with a 200MP 1/1.4-inch sensor, and a 50MP ultrawide camera. There's also a manual zoom ring around the camera. Check out our hands on for our first impressions of what it's like shooting with the Xiaomi 17 Ultra. And there's more to it than just the camera. The 17 Ultra has a 6.9-inch OLED 120 Hz display that peaks at 3,500 nits of brightness, and a 6000mAh silicon-carbon battery. The Xiaomi 17 Ultra starts at £1,299 (roughly $1,750).Leica also announced a new phone made in partnership with Xiaomi at MWC. It looks a whole lot like Xiaomi's 17 Ultra, but isn't the 17 Ultra, exactly. Leica Leitzphone by Xiaomi hands-on at MWC 2026Image by Mat Smith for EngadgetLike the 17 Ultra, Leica's Leitzphone by Xiaomi has a 1-inch camera sensor and physical controls for zoom and other settings, using a mechanical ring around the camera unit. It features a Leica-designed intuitive camera interface with the option to show just the essentials when you're shooting, hiding all the modes and labels. There's a monochrome shooting mode and Leica filters. The Leica branding is splashed all over it in design and wallpapers, but it's otherwise pretty similar to the 17 Ultra, with the same specs. Like the 17 Ultra, it has a Snapdragon 8 Elite Gen 5 chip and a 6.9-inch 120Hz display. This one's priced at €1,999 (roughly $2,362).The Xiaomi Pad 8 ProXiaomiIn addition to the 17 Ultra, Xiaomi announced two new tablets at MWC this year: the Xiaomi Pad 8 and Xiaomi Pad 8 Pro. There's nothing revolutionary here, but they're lightweight and thin, with both being 5.75mm thick and weighing 485g, and have a 9200mAh battery. The Pro model is powered by a Snapdragon 8 Elite chip, while the regular Pad 8 uses the Snapdragon 8s Gen 4 chipset. Xiaomi also unveiled a new 5000mAh powerbank, the UltraThin Magnetic Power Bank 5000 15W. The 6mm thick power bank comes in three colors with an aluminum alloy shell: orange, silver and charcoal gray. Along with that, the company introduced the Xiaomi Tag, its own take on the Bluetooth item tracker. The Xiaomi Tag has a built-in hanging loop so it can be attached directly to a keyring, and the company says it will work with both Apple Find My and Google's Find Hub for Android. Honor MagicPad 4 HonorAhead of MWC, Honor announced what it claims is the thinnest Android tablet in the world: the 4.8mm thick MagicPad 4. We're expecting to hear more about this at Honor's press conference on Sunday, but so far we know it features a 12.3-inch 165Hz OLED display and weighs just 450g. It comes with up to 16GB of RAM and 512GB of storage, and is powered by Qualcomm's Snapdragon 8 Gen 5 chipset. The thinness doesn't count the camera bump, Honor notes. The MagicPad 4 has 13MP rear and 9MP front cameras. It also boasts spatial audio, with eight speakers.Just as the display is slightly smaller than the previous MagicPad, the MagicPad 4 has a smaller battery at 10100 mAh. It comes with a 66W fast charger. The MagicPad 4 will run Honor's MagicOS 10. We don't yet know how much it will cost, but we'll update this after Honor's press conference (where we're also expecting to see the company's robot) with any new details. TecnoTecnoWe can always expect to see some wild phone concepts at MWC, and this year we're starting with one from Tecno. The company unveiled a modular concept smartphone design that can be as thin as 4.9mm in its base configuration. There’d be 10 modules to choose from based on the announcement, including various camera lenses, a gaming attachment and a power bank, relying on magnets to keep it all together — or Modular Magnetic Interconnection Technology, as Tecno is calling it. This article originally appeared on Engadget at https://www.engadget.com/mobile/everything-announced-at-mwc-2026-the-new-leica-leitzphone-by-xiaomi-honors-ultra-thin-magicpad-4-and-more-172442426.html?src=rss",
          "feed_position": 1,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2026-02/125f8ad0-1495-11f1-bb83-dd96bb6ae2a2"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/smartphones/leica-leitzphone-xiaomi-mwc-2026-135744417.html",
          "published_at": "Sat, 28 Feb 2026 15:37:34 +0000",
          "title": "Leica’s Leitzphone by Xiaomi has a huge 1-inch camera sensor and a stylish new design",
          "standfirst": "Alongside a global launch for Xiaomi's 17 Ultra (read about that right here), the company announced a further deepening of its relationship with Leica. The CEO of Leica, Matthias Harsch, took to the stage to announce a new Leitzphone, which appears to be an even deeper collaboration than 17 Ultra by Leica, which is a different phone. Confused? That's fair. Design-wise, Leica has shifted back to a single tone body color, which looks more \"Leica\" to this camera dilettante's eyes. And if you’re thinking you’ve heard of the Leitzphone before, you probably have: it was a series of phones made by Sharp that launched in Japan in 2021. They all had a 1-inch camera sensor, as does Xiaomi’s first Leitzphone. It also has a mechanical, physical ring dial around the camera unit to control settings like zoom, exposure and shutter speed. The camera interface is also designed by Leica. It's designed to be as intuitive as possible, with an Essential mode in the camera app that strips away all those modes and labels, showcasing whatever you're looking to shoot. You can switch between a monochrome shooting mode and a more familiar punchy, contrasty Leica filter. And that's it. Aside from that there's no major standout interface or UI changes that I could spot while trying out the Leitzphone briefly at Xiaomi's MWC keynote. However, if you're intrigued by the functionality — or the cameras — check out our hands-on coverage and sample photos of the Xiaomi 17 Ultra. The cameras are good. Image by Mat Smith for Engadget All three iterations (the regular Xiaomi 17 Ultra , the \"by Leica\" edition and the Leitzphone) have a Snapdragon 8 Elite Gen 5 chip and a 6.9-inch 120Hz display that can reach up to 3,500 nits of peak brightness. While cameras are naturally the focus, it’s a flagship device by pretty much any metric. It also has a 6,000mAh battery for extended vacation photo shoots. Barring some Leica-tinged wallpapers and design accents, it's a lot like the 17 Ultra by Leica, just with different messaging. This is Leica's phone, made by Xiaomi, but does a rose by any other name still have great low-light photography? Maybe increased Leica branding will be enough to coax its camera fans into making this their next smartphone, perhaps. Image by Mat Smith for Engadget After years of collaboration (and cute little badges), this may be the first pure \"Leica phone\" manufactured by Xiaomi but sold directly by both companies. It's priced at €1,999 (roughly $2,362), but it's not known yet whether this phone will launch in the US. Welcome to MWC, everyone.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/leica-leitzphone-xiaomi-mwc-2026-135744417.html?src=rss",
          "content": "Alongside a global launch for Xiaomi's 17 Ultra (read about that right here), the company announced a further deepening of its relationship with Leica. The CEO of Leica, Matthias Harsch, took to the stage to announce a new Leitzphone, which appears to be an even deeper collaboration than 17 Ultra by Leica, which is a different phone. Confused? That's fair. Design-wise, Leica has shifted back to a single tone body color, which looks more \"Leica\" to this camera dilettante's eyes. And if you’re thinking you’ve heard of the Leitzphone before, you probably have: it was a series of phones made by Sharp that launched in Japan in 2021. They all had a 1-inch camera sensor, as does Xiaomi’s first Leitzphone. It also has a mechanical, physical ring dial around the camera unit to control settings like zoom, exposure and shutter speed. The camera interface is also designed by Leica. It's designed to be as intuitive as possible, with an Essential mode in the camera app that strips away all those modes and labels, showcasing whatever you're looking to shoot. You can switch between a monochrome shooting mode and a more familiar punchy, contrasty Leica filter. And that's it. Aside from that there's no major standout interface or UI changes that I could spot while trying out the Leitzphone briefly at Xiaomi's MWC keynote. However, if you're intrigued by the functionality — or the cameras — check out our hands-on coverage and sample photos of the Xiaomi 17 Ultra. The cameras are good. Image by Mat Smith for Engadget All three iterations (the regular Xiaomi 17 Ultra , the \"by Leica\" edition and the Leitzphone) have a Snapdragon 8 Elite Gen 5 chip and a 6.9-inch 120Hz display that can reach up to 3,500 nits of peak brightness. While cameras are naturally the focus, it’s a flagship device by pretty much any metric. It also has a 6,000mAh battery for extended vacation photo shoots. Barring some Leica-tinged wallpapers and design accents, it's a lot like the 17 Ultra by Leica, just with different messaging. This is Leica's phone, made by Xiaomi, but does a rose by any other name still have great low-light photography? Maybe increased Leica branding will be enough to coax its camera fans into making this their next smartphone, perhaps. Image by Mat Smith for Engadget After years of collaboration (and cute little badges), this may be the first pure \"Leica phone\" manufactured by Xiaomi but sold directly by both companies. It's priced at €1,999 (roughly $2,362), but it's not known yet whether this phone will launch in the US. Welcome to MWC, everyone.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/leica-leitzphone-xiaomi-mwc-2026-135744417.html?src=rss",
          "feed_position": 4,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2026-02/a136bb60-14b9-11f1-b3ff-dbc37cb7af1d"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/smartphones/xiaomi-17-ultra-global-launch-hands-on-leica-camera-143006810.html",
          "published_at": "Sat, 28 Feb 2026 14:30:06 +0000",
          "title": "Xiaomi 17 Ultra hands-on: Incredible cameras, but maybe hard to get",
          "standfirst": "China’s biggest phone makers continue to relentlessly forge ahead with high-spec phones that you may never see in the US. With the Xiaomi 17 Ultra this year, the company has continued its pattern from previous iterations by focusing on powerful camera sensors, huge batteries and… being selective about global availability. Xiaomi’s 17 series is launching across multiple European territories months after its Asia debut, but at the time of writing, no word yet on US availability. Another logistical point of interest? When we last checked out Xiaomi’s devices, it was the 15 series, and the company has decided to skip 16 and leap straight to 17, conveniently matching Apple’s latest number. Storied camera brand Leica has been involved with Xiaomi’s phones for a few years and its newest flagship doesn’t disappoint in that regard, because this is another Xiaomi device dedicated to photography. Image by Mat Smith for Engadget The 17 Ultra has a huge 1-inch 50-megapixel main camera sensor with a f/1.67 lens, and a telephoto setup with a 200MP 1/1.4-inch sensor and going up to 4.3x optical zoom. Xiaomi claims it’s capable of up to 17x “optical-level zoom,” but quality doesn’t measure up to, say, the Oppo Find X9, with its dedicated telescopic lens add-on. There’s also a 50MP ultrawide camera to round things out. The main camera is very impressive, delivering plenty of detail and performing incredibly well in low light, seemingly before any computational photography kicks in. A new Light Fusion 1050L sensor features LOFIC HDR technology, delivering stronger control over highlights and more detail in darker areas of your shots. I've been impressed by the balanced color tone and contrast, without having to edit or add one of the (many) Leica camera filters. If anything, the slightly heavy-handed algorithms can sometimes ruin parts of a shot. For instance, by scrambling lettering or capturing blurry, AI-mutated faces where computational photography takes a swing (and a miss) at people in the distance. Mat Smith for Engadget The telephoto camera alone is also technically interesting in a few ways. It offers continual optical zoom across the 75-100mm range without in-sensor cropping. This means the lenses physically move to deliver lossless zoom across a range of distances, without jarring leaps between camera sensors and crops. This doesn’t run across the full gamut, but it does roughly cover the 3-4x optical zoom range, which is often used in portrait photography. The APO (apochromatic) lens design on the telephoto is more immediately useful and effective. An APO lens significantly reduces chromatic aberration by focusing three wavelengths of light (red, green and blue) onto the same focal plane. This lens design means it can correct color fringing and improve image sharpness. At full optical zoom, this light fitting at Soho Theatre Walthamstow doesn't bloom or fringe to the extent that most smartphone zooms suffer from.Mat Smith for Engadget At higher zoom levels, fringing and lighting bloom often hamper telephoto photos on smartphones, and Xiaomi’s solution has some appeal. I noticed less fringing than on other zoom-capable Android phones from Samsung, Oppo and Google. It also supports macro photography, but is hindered this time by a minimum focal distance of 30cm (11.8 inches). Most smartphone cameras’ macro modes let you get much closer. The 17 Ultra can capture up to 8K video (at 30 fps), 4K Dolby Vision up to 120 fps, and 4K 120 fps Log video, ensuring you can make the most of that huge 1-inch sensor in video, too. That said, it seems to struggle with stabilization at times, while its low-light performance doesn’t match its prowess in still photography, lagging behind flagship phones from Apple, Google and Samsung. There's also a special Leica edition of the 17 Ultra, which is largely the same, specification-wise, but with a manual zoom ring around the camera unit. It's a cool gimmick, but felt oddly loose on a few devices I've handled. Xiaomi made a few design changes to its Ultra line this year, with a new, entirely flat display, and flattened edges that look like a certain family of devices. In fairness, it’s not the only company using imitation as flattery. There’s also IP68 protection against dust and water. While cameras may be the highlight, this is a flagship device by any specification metric. With a 6.9-inch display, this expansive OLED display has variable refresh rates (1-120Hz) and peaks at 3,500 nits of brightness. At that size, the Xiaomi 17 Ultra is in the territory of devices like the iPhone 17 Pro Max and S26 Ultra. A phone this size isn’t for everyone, but it is the thinnest Ultra phone from Xiaomi to date, with a profile measuring 8.29mm. Xiaomi has also reduced the camera unit’s diameter and raised it on the device, making it easier to use and helping keep fingers out of your shots. Image by Mat Smith for Engadget Also, I’d be remiss if I didn’t mention the huge 6,000mAh silicon-carbon battery, with support for Xiaomi’s 90W HyperCharge (if you have the right charger) and 50W wireless HyperCharge (which also requires Xiaomi’s own dock) speeds. Other phone makers: Please put a battery this huge in your flagship. At MWC 2026, the company announced the global launch and rollout of the device across Europe, including the UK where the Ultra will start priced at £1,299 (roughly $1,750). We're still waiting to confirm US availability and pricing. While the specs are powerful, “launching” a flagship device that’s already been in the wild for a few months — even if elsewhere in the world — reduces the spectacle.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/xiaomi-17-ultra-global-launch-hands-on-leica-camera-143006810.html?src=rss",
          "content": "China’s biggest phone makers continue to relentlessly forge ahead with high-spec phones that you may never see in the US. With the Xiaomi 17 Ultra this year, the company has continued its pattern from previous iterations by focusing on powerful camera sensors, huge batteries and… being selective about global availability. Xiaomi’s 17 series is launching across multiple European territories months after its Asia debut, but at the time of writing, no word yet on US availability. Another logistical point of interest? When we last checked out Xiaomi’s devices, it was the 15 series, and the company has decided to skip 16 and leap straight to 17, conveniently matching Apple’s latest number. Storied camera brand Leica has been involved with Xiaomi’s phones for a few years and its newest flagship doesn’t disappoint in that regard, because this is another Xiaomi device dedicated to photography. Image by Mat Smith for Engadget The 17 Ultra has a huge 1-inch 50-megapixel main camera sensor with a f/1.67 lens, and a telephoto setup with a 200MP 1/1.4-inch sensor and going up to 4.3x optical zoom. Xiaomi claims it’s capable of up to 17x “optical-level zoom,” but quality doesn’t measure up to, say, the Oppo Find X9, with its dedicated telescopic lens add-on. There’s also a 50MP ultrawide camera to round things out. The main camera is very impressive, delivering plenty of detail and performing incredibly well in low light, seemingly before any computational photography kicks in. A new Light Fusion 1050L sensor features LOFIC HDR technology, delivering stronger control over highlights and more detail in darker areas of your shots. I've been impressed by the balanced color tone and contrast, without having to edit or add one of the (many) Leica camera filters. If anything, the slightly heavy-handed algorithms can sometimes ruin parts of a shot. For instance, by scrambling lettering or capturing blurry, AI-mutated faces where computational photography takes a swing (and a miss) at people in the distance. Mat Smith for Engadget The telephoto camera alone is also technically interesting in a few ways. It offers continual optical zoom across the 75-100mm range without in-sensor cropping. This means the lenses physically move to deliver lossless zoom across a range of distances, without jarring leaps between camera sensors and crops. This doesn’t run across the full gamut, but it does roughly cover the 3-4x optical zoom range, which is often used in portrait photography. The APO (apochromatic) lens design on the telephoto is more immediately useful and effective. An APO lens significantly reduces chromatic aberration by focusing three wavelengths of light (red, green and blue) onto the same focal plane. This lens design means it can correct color fringing and improve image sharpness. At full optical zoom, this light fitting at Soho Theatre Walthamstow doesn't bloom or fringe to the extent that most smartphone zooms suffer from.Mat Smith for Engadget At higher zoom levels, fringing and lighting bloom often hamper telephoto photos on smartphones, and Xiaomi’s solution has some appeal. I noticed less fringing than on other zoom-capable Android phones from Samsung, Oppo and Google. It also supports macro photography, but is hindered this time by a minimum focal distance of 30cm (11.8 inches). Most smartphone cameras’ macro modes let you get much closer. The 17 Ultra can capture up to 8K video (at 30 fps), 4K Dolby Vision up to 120 fps, and 4K 120 fps Log video, ensuring you can make the most of that huge 1-inch sensor in video, too. That said, it seems to struggle with stabilization at times, while its low-light performance doesn’t match its prowess in still photography, lagging behind flagship phones from Apple, Google and Samsung. There's also a special Leica edition of the 17 Ultra, which is largely the same, specification-wise, but with a manual zoom ring around the camera unit. It's a cool gimmick, but felt oddly loose on a few devices I've handled. Xiaomi made a few design changes to its Ultra line this year, with a new, entirely flat display, and flattened edges that look like a certain family of devices. In fairness, it’s not the only company using imitation as flattery. There’s also IP68 protection against dust and water. While cameras may be the highlight, this is a flagship device by any specification metric. With a 6.9-inch display, this expansive OLED display has variable refresh rates (1-120Hz) and peaks at 3,500 nits of brightness. At that size, the Xiaomi 17 Ultra is in the territory of devices like the iPhone 17 Pro Max and S26 Ultra. A phone this size isn’t for everyone, but it is the thinnest Ultra phone from Xiaomi to date, with a profile measuring 8.29mm. Xiaomi has also reduced the camera unit’s diameter and raised it on the device, making it easier to use and helping keep fingers out of your shots. Image by Mat Smith for Engadget Also, I’d be remiss if I didn’t mention the huge 6,000mAh silicon-carbon battery, with support for Xiaomi’s 90W HyperCharge (if you have the right charger) and 50W wireless HyperCharge (which also requires Xiaomi’s own dock) speeds. Other phone makers: Please put a battery this huge in your flagship. At MWC 2026, the company announced the global launch and rollout of the device across Europe, including the UK where the Ultra will start priced at £1,299 (roughly $1,750). We're still waiting to confirm US availability and pricing. While the specs are powerful, “launching” a flagship device that’s already been in the wild for a few months — even if elsewhere in the world — reduces the spectacle.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/xiaomi-17-ultra-global-launch-hands-on-leica-camera-143006810.html?src=rss",
          "feed_position": 5,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2026-02/1247e420-1495-11f1-ad47-af056530f142"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/gaming/steam-next-fest-a-different-flavor-of-the-witcher-and-other-new-indie-games-worth-checking-out-120000900.html",
          "published_at": "Sat, 28 Feb 2026 12:00:00 +0000",
          "title": "Steam Next Fest, a different flavor of The Witcher and other new indie games worth checking out",
          "standfirst": "Welcome to our latest roundup of what's going on in the indie game space. It's Steam Next Fest week, with literally thousands of demos for upcoming games for us to dive into. I'm trying to check out as many as I can before the event wraps up on Monday. However, I made a near-critical error in my planning: I opted to try the Raccoin demo first. I could and would have happily played that all week.This is a coin-pushing roguelike deckbuilder that adopts the format of Balatro. To progress, you need to earn a certain number of points and the target increases each round. Every three rounds there's a sort-of boss — a few coins that negatively impact your game until you can get rid of them. After every round, you’ll go to a shop to buy and sell special coins and other upgrades. As you might expect with this type of game, finding ways to boost the points you can score from each coin is how to win.On my first successful run, I found a way to electrify the coins (which boosts their score) by charging them and use passive abilities and special coins to spread and amplify the effect. Then I was able to replicate a special coin that pulls all other nearby coins into a cyclone — having the water-based coins in there helped to spread the electrical effect between other coins. There were a few rounds in which I didn't even have to do anything. The cyclones just dumped enough coins over the edge for me. This was only the first way I've figured out how to break the game. Six hours in, I'm eager to find many more. Raccoin — from Doraccoon and Balatro publisher Playstack — will hit Steam on March 31. The demo is currently still available.I've had The Eternal Life of Goldman on my wishlist since we first learned about it a couple of years ago. I'm very glad that was one of the demos I've tried. This is an utterly gorgeous platform adventure with hand-drawn art. As Goldman, an elderly gentleman, you'll swap parts of your cane on the fly so you can hook onto floating rings or pogo off springs. The platforming is challenging enough that I had to focus to get through the demo, which lasts about 75-90 minutes. There's almost always something going on in the background or foreground too. This game from Weappy Studio is shaping up to be quite something. I can't wait to play the full thing when The Eternal Life of Goldman hits PC, Nintendo Switch, PS5 and Xbox Series X/S, hopefully later this year.Of course I had to check out the Next Fest demo for Vampire Crawlers, which is also available on Xbox. The latest game from Poncle is a turn-based deckbuilder roguelite. Oh, and it's also a Vampire Survivors spin-off. Instead of passively firing your weapons at surrounding enemies, you have a bit more control here. It plays a bit like those first-person maze games from the '90s. You'll walk around each level with the help of a map that shows where enemies, chests and bosses are located. When you encounter enemies, you'll play cards in a certain order to deal damage or boost your stats for that particular battle. You can play all your available cards in one go, but you might want to rearrange them first so that you, for instance, use a card that boosts your damage before firing any weapons. Each card has a mana point value — you can only play a full hand if you have enough mana. And yes, there are weapon evolutions.Turn-based games usually aren't my bag, but sometimes they just hit right. The Vampire Crawlers demo hits right. I can already tell I'm going to spend dozens of hours with the full game, which is coming to Steam, Xbox Series X/S, PS5, Nintendo Switch, iOS and Android this year. I tried a few other demos so far, including one for John Carpenter's Toxic Commando, a co-op shooter in the vein of Left 4 Dead. It's a little rough around the edges right now, but it seems enjoyable enough. There are a bunch of other Next Fest demos I'm hoping to try over the weekend, including precision platformer Croak, PvE pirate game Windrose, cyberpunk platformer Replaced, record store sim Wax Heads, match-three/tower-defense game Titanium Court and Dragon Care Tarot. I read that you can pet dragons in the latter, so I'm sold. New releasesIf you can't get enough of The Witcher and are impatiently waiting for CD Projekt Red to unleash The Witcher IV, here's one way to keep your thumbs busy in the meantime. Reigns: The Witcher is the latest installment of the Reigns series from Nerial and Devolver Digital for Steam, Android and iOS ($6). You still play as Geralt of Rivia. However, this is a narrative-focused game in which you make choices by swiping. It's something a little different for Witcher fans. It might just pull some long-time Reigns players into that fantasy universe for the first time too.Bread and Fred is the cutest thing. The co-op platformer from SandCastles Studio has been available on PC (Steam, GOG and Epic Games Store) and Nintendo Switch for a while, and this week it landed on Xbox One, Xbox Series X/S, PS4 and PS5. It normally costs $15 and there's a 20 percent launch discount on those consoles. You'll need to be a PS Plus subscriber to get those savings on PlayStation, though.You and a friend take control of a pair of adorable penguins that are tethered together. The aim is to ascend a mountain, sometimes by swinging each other to get to hard-to-reach places. But if you miss a jump, you can plummet back down and erase a chunk of your progress. There is a single-player mode in which one of the penguins is replaced by a rock. The pixel art aesthetic here is super charming.Here's another co-op game. This one is a side‑scrolling RPG brawler. After several months in early access/game preview, the full version of Stoic's Towerborne arrived on Xbox Series X/S, Xbox on PC, Steam and PS5. It costs $25, though there's a 20 percent launch discount on Xbox. It’s on Game Pass Ultimate and Premium as well. After the 1.0 update, the game has a full campaign that you can play offline by yourself or online with friends. Stoic has added fresh biomes, enemies and bosses, and there are said to be hundreds of missions, side quests and bounties. I really dig the fluidity of the animations in the trailer, though the action is a bit hard to parse at first glance. Still, I'm curious enough to try out Towerborne.I’ve been a little too occupied with other Next Fest demos (plus Overwatch challenges, I’ll admit it) to play Dice A Million yet, but this roguelike deckbuilder looks pretty interesting. The aim is to find the right combination of dice and rings (i.e. passive abilities) to roll a million points in one go. As with the likes of Balatro, it's all about figuring out powerful synergies between dice and rings to break the game and rack up ridiculous scores. I did quite enjoy a line on the Steam page that reads, \"Cutting edge next-gen graphics (not really, I drew all of them on paint).\" Dice A Million — from Countlessnights and publisher 2 Left Thumbs — is also available on Itch and Xbox on PC. It's on Game Pass Ultimate and PC Game Pass. Otherwise, it costs $13, but there's a 20 percent discount on Steam until March 11. There's a demo available on Steam too.Upcoming MOUSE: P.I. For Hire will now launch on 16 April 2026. pic.twitter.com/gwD3QW5Vyt— MOUSE: P.I. For Hire (@mousethegame) February 23, 2026 Let's start this section with a news roundup. Mouse: P.I. for Hire continues to look rad, but unfortunately we'll have to wait a little longer to play it. Fumi Games and publisher PlaySide have delayed it by a few weeks until April 16 to polish the game up.I do love voxel-based heist game Teardown, so I'm jazzed for the online multiplayer update. Tuxedo Labs revealed it will go live on Steam on March 12. It will add a co-op campaign option (for up to 12 players!). There'll be hundreds of other multiplayer modes created by the studio and the community, including prop hunt, battle royale and floor-is-lava modes. There's going to be so much carnage. The PS5 and Xbox Series X/S versions of Teardown will get the multiplayer update later this year.ConcernedApe (aka Eric Barrone) marked the 10-year anniversary of Stardew Valley by showing off some very early gameplay footage, some stories from his time of working on his all-time-great indie game and revealing the two additional characters that players will be able to marry when the 1.7 update goes live. Sandy's cool, so it'll be nice to have her as an option, but Clint? That guy sucks. Here's hoping Barrone will finally focus more of his attention on Haunted Chocolatier once this Stardew update is done and dusted.Also as part of the 10th anniversary celebrations, it was revealed this week that an orchestra will deliver a one-night-only performance of music from Stardew Valley at the Red Rocks Amphitheatre in Colorado on October 25. I missed my chance to see the Symphony of Seasons tour in person when it stopped near me, because I don't always make the wisest decisions in life. At least we can now watch an official recording of a previous concert.Minimap, a social platform for gamers, ran its first indie game showcase this week. Among the highlights:Thrifty Business (Spellgarden Games), a cozy thrift-store management sim that's coming to Steam this year. A demo's available now.Another look at Please, Watch The Artwork, an anomaly-spotting game — without jump scares or monsters — from Please, Touch The Artwork developer Thomas Waterzooi.Lily’s World XD, a psychological horror game from SonderingEmily in which you'll investigate a teenage girl's laptop in the early 2000s. The trailer brings to mind screenlife films like Searching and Unfriended.Coming-of-age adventure Ikuma - The Frozen Compass from Mooneye Studios. You'll play as both cabin boy Sam and husky Ellie (or have a friend take control of one of them) as you try to make your way home from the Arctic. This should hit Steam later this year. Tombwater was originally supposed to arrive in November, but Moth Atlas and publisher Midwest Games delayed it for further refinement. It's now set to arrive on Steam on March 31.A Next Fest demo is available now.This is a 2D Soulslike with a Western setting and 2D pixel art that's inspired by Bloodborne and early Legend of Zelda games. You'll face off against horrific eldritch creatures as you search for a missing friend. You'll have seven playable classes to choose from and the ability to wield more than 50 firearms and melee weapons, and more than 20 spells. Tombwater is said to have around 20 hours of gameplay.There's no release date for Solarpunk as yet, but I found this trailer quite soothing. It offers a first look at co-op gameplay for this base-building and exploration game from the two-person team at Cyberwave and publisher rokaplay. Up to four players will be able to explore floating islands, gather resources and build out a homestead together. As the title suggests, there's a technology-driven element to Solarpunk. You can use renewable energy sources to power tools that can automate things like resource harvesting and watering plants. The airships you use to travel between islands look cool too.Solarpunk is set to hit Steam later this year. A demo is available now.This article originally appeared on Engadget at https://www.engadget.com/gaming/steam-next-fest-a-different-flavor-of-the-witcher-and-other-new-indie-games-worth-checking-out-120000900.html?src=rss",
          "content": "Welcome to our latest roundup of what's going on in the indie game space. It's Steam Next Fest week, with literally thousands of demos for upcoming games for us to dive into. I'm trying to check out as many as I can before the event wraps up on Monday. However, I made a near-critical error in my planning: I opted to try the Raccoin demo first. I could and would have happily played that all week.This is a coin-pushing roguelike deckbuilder that adopts the format of Balatro. To progress, you need to earn a certain number of points and the target increases each round. Every three rounds there's a sort-of boss — a few coins that negatively impact your game until you can get rid of them. After every round, you’ll go to a shop to buy and sell special coins and other upgrades. As you might expect with this type of game, finding ways to boost the points you can score from each coin is how to win.On my first successful run, I found a way to electrify the coins (which boosts their score) by charging them and use passive abilities and special coins to spread and amplify the effect. Then I was able to replicate a special coin that pulls all other nearby coins into a cyclone — having the water-based coins in there helped to spread the electrical effect between other coins. There were a few rounds in which I didn't even have to do anything. The cyclones just dumped enough coins over the edge for me. This was only the first way I've figured out how to break the game. Six hours in, I'm eager to find many more. Raccoin — from Doraccoon and Balatro publisher Playstack — will hit Steam on March 31. The demo is currently still available.I've had The Eternal Life of Goldman on my wishlist since we first learned about it a couple of years ago. I'm very glad that was one of the demos I've tried. This is an utterly gorgeous platform adventure with hand-drawn art. As Goldman, an elderly gentleman, you'll swap parts of your cane on the fly so you can hook onto floating rings or pogo off springs. The platforming is challenging enough that I had to focus to get through the demo, which lasts about 75-90 minutes. There's almost always something going on in the background or foreground too. This game from Weappy Studio is shaping up to be quite something. I can't wait to play the full thing when The Eternal Life of Goldman hits PC, Nintendo Switch, PS5 and Xbox Series X/S, hopefully later this year.Of course I had to check out the Next Fest demo for Vampire Crawlers, which is also available on Xbox. The latest game from Poncle is a turn-based deckbuilder roguelite. Oh, and it's also a Vampire Survivors spin-off. Instead of passively firing your weapons at surrounding enemies, you have a bit more control here. It plays a bit like those first-person maze games from the '90s. You'll walk around each level with the help of a map that shows where enemies, chests and bosses are located. When you encounter enemies, you'll play cards in a certain order to deal damage or boost your stats for that particular battle. You can play all your available cards in one go, but you might want to rearrange them first so that you, for instance, use a card that boosts your damage before firing any weapons. Each card has a mana point value — you can only play a full hand if you have enough mana. And yes, there are weapon evolutions.Turn-based games usually aren't my bag, but sometimes they just hit right. The Vampire Crawlers demo hits right. I can already tell I'm going to spend dozens of hours with the full game, which is coming to Steam, Xbox Series X/S, PS5, Nintendo Switch, iOS and Android this year. I tried a few other demos so far, including one for John Carpenter's Toxic Commando, a co-op shooter in the vein of Left 4 Dead. It's a little rough around the edges right now, but it seems enjoyable enough. There are a bunch of other Next Fest demos I'm hoping to try over the weekend, including precision platformer Croak, PvE pirate game Windrose, cyberpunk platformer Replaced, record store sim Wax Heads, match-three/tower-defense game Titanium Court and Dragon Care Tarot. I read that you can pet dragons in the latter, so I'm sold. New releasesIf you can't get enough of The Witcher and are impatiently waiting for CD Projekt Red to unleash The Witcher IV, here's one way to keep your thumbs busy in the meantime. Reigns: The Witcher is the latest installment of the Reigns series from Nerial and Devolver Digital for Steam, Android and iOS ($6). You still play as Geralt of Rivia. However, this is a narrative-focused game in which you make choices by swiping. It's something a little different for Witcher fans. It might just pull some long-time Reigns players into that fantasy universe for the first time too.Bread and Fred is the cutest thing. The co-op platformer from SandCastles Studio has been available on PC (Steam, GOG and Epic Games Store) and Nintendo Switch for a while, and this week it landed on Xbox One, Xbox Series X/S, PS4 and PS5. It normally costs $15 and there's a 20 percent launch discount on those consoles. You'll need to be a PS Plus subscriber to get those savings on PlayStation, though.You and a friend take control of a pair of adorable penguins that are tethered together. The aim is to ascend a mountain, sometimes by swinging each other to get to hard-to-reach places. But if you miss a jump, you can plummet back down and erase a chunk of your progress. There is a single-player mode in which one of the penguins is replaced by a rock. The pixel art aesthetic here is super charming.Here's another co-op game. This one is a side‑scrolling RPG brawler. After several months in early access/game preview, the full version of Stoic's Towerborne arrived on Xbox Series X/S, Xbox on PC, Steam and PS5. It costs $25, though there's a 20 percent launch discount on Xbox. It’s on Game Pass Ultimate and Premium as well. After the 1.0 update, the game has a full campaign that you can play offline by yourself or online with friends. Stoic has added fresh biomes, enemies and bosses, and there are said to be hundreds of missions, side quests and bounties. I really dig the fluidity of the animations in the trailer, though the action is a bit hard to parse at first glance. Still, I'm curious enough to try out Towerborne.I’ve been a little too occupied with other Next Fest demos (plus Overwatch challenges, I’ll admit it) to play Dice A Million yet, but this roguelike deckbuilder looks pretty interesting. The aim is to find the right combination of dice and rings (i.e. passive abilities) to roll a million points in one go. As with the likes of Balatro, it's all about figuring out powerful synergies between dice and rings to break the game and rack up ridiculous scores. I did quite enjoy a line on the Steam page that reads, \"Cutting edge next-gen graphics (not really, I drew all of them on paint).\" Dice A Million — from Countlessnights and publisher 2 Left Thumbs — is also available on Itch and Xbox on PC. It's on Game Pass Ultimate and PC Game Pass. Otherwise, it costs $13, but there's a 20 percent discount on Steam until March 11. There's a demo available on Steam too.Upcoming MOUSE: P.I. For Hire will now launch on 16 April 2026. pic.twitter.com/gwD3QW5Vyt— MOUSE: P.I. For Hire (@mousethegame) February 23, 2026 Let's start this section with a news roundup. Mouse: P.I. for Hire continues to look rad, but unfortunately we'll have to wait a little longer to play it. Fumi Games and publisher PlaySide have delayed it by a few weeks until April 16 to polish the game up.I do love voxel-based heist game Teardown, so I'm jazzed for the online multiplayer update. Tuxedo Labs revealed it will go live on Steam on March 12. It will add a co-op campaign option (for up to 12 players!). There'll be hundreds of other multiplayer modes created by the studio and the community, including prop hunt, battle royale and floor-is-lava modes. There's going to be so much carnage. The PS5 and Xbox Series X/S versions of Teardown will get the multiplayer update later this year.ConcernedApe (aka Eric Barrone) marked the 10-year anniversary of Stardew Valley by showing off some very early gameplay footage, some stories from his time of working on his all-time-great indie game and revealing the two additional characters that players will be able to marry when the 1.7 update goes live. Sandy's cool, so it'll be nice to have her as an option, but Clint? That guy sucks. Here's hoping Barrone will finally focus more of his attention on Haunted Chocolatier once this Stardew update is done and dusted.Also as part of the 10th anniversary celebrations, it was revealed this week that an orchestra will deliver a one-night-only performance of music from Stardew Valley at the Red Rocks Amphitheatre in Colorado on October 25. I missed my chance to see the Symphony of Seasons tour in person when it stopped near me, because I don't always make the wisest decisions in life. At least we can now watch an official recording of a previous concert.Minimap, a social platform for gamers, ran its first indie game showcase this week. Among the highlights:Thrifty Business (Spellgarden Games), a cozy thrift-store management sim that's coming to Steam this year. A demo's available now.Another look at Please, Watch The Artwork, an anomaly-spotting game — without jump scares or monsters — from Please, Touch The Artwork developer Thomas Waterzooi.Lily’s World XD, a psychological horror game from SonderingEmily in which you'll investigate a teenage girl's laptop in the early 2000s. The trailer brings to mind screenlife films like Searching and Unfriended.Coming-of-age adventure Ikuma - The Frozen Compass from Mooneye Studios. You'll play as both cabin boy Sam and husky Ellie (or have a friend take control of one of them) as you try to make your way home from the Arctic. This should hit Steam later this year. Tombwater was originally supposed to arrive in November, but Moth Atlas and publisher Midwest Games delayed it for further refinement. It's now set to arrive on Steam on March 31.A Next Fest demo is available now.This is a 2D Soulslike with a Western setting and 2D pixel art that's inspired by Bloodborne and early Legend of Zelda games. You'll face off against horrific eldritch creatures as you search for a missing friend. You'll have seven playable classes to choose from and the ability to wield more than 50 firearms and melee weapons, and more than 20 spells. Tombwater is said to have around 20 hours of gameplay.There's no release date for Solarpunk as yet, but I found this trailer quite soothing. It offers a first look at co-op gameplay for this base-building and exploration game from the two-person team at Cyberwave and publisher rokaplay. Up to four players will be able to explore floating islands, gather resources and build out a homestead together. As the title suggests, there's a technology-driven element to Solarpunk. You can use renewable energy sources to power tools that can automate things like resource harvesting and watering plants. The airships you use to travel between islands look cool too.Solarpunk is set to hit Steam later this year. A demo is available now.This article originally appeared on Engadget at https://www.engadget.com/gaming/steam-next-fest-a-different-flavor-of-the-witcher-and-other-new-indie-games-worth-checking-out-120000900.html?src=rss",
          "feed_position": 6
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/vibe-coding-with-overeager-ai-lessons-learned-from-treating-google-ai-studio",
          "published_at": "Sat, 28 Feb 2026 08:00:00 GMT",
          "title": "Vibe coding with overeager AI: Lessons learned from treating Google AI Studio like a teammate",
          "standfirst": "Most discussions about vibe coding usually position generative AI as a backup singer rather than the frontman: Helpful as a performer to jump-start ideas, sketch early code structures and explore new directions more quickly. Caution is often urged regarding its suitability for production systems where determinism, testability and operational reliability are non-negotiable. However, my latest project taught me that achieving production-quality work with an AI assistant requires more than just going with the flow.I set out with a clear and ambitious goal: To build an entire production‑ready business application by directing an AI inside a vibe coding environment — without writing a single line of code myself. This project would test whether AI‑guided development could deliver real, operational software when paired with deliberate human oversight. The application itself explored a new category of MarTech that I call &#x27;promotional marketing intelligence.&#x27; It would integrate econometric modeling, context‑aware AI planning, privacy‑first data handling and operational workflows designed to reduce organizational risk. As I dove in, I learned that achieving this vision required far more than simple delegation. Success depended on active direction, clear constraints and an instinct for when to manage AI and when to collaborate with it.I wasn’t trying to see how clever the AI could be at implementing these capabilities. The goal was to determine whether an AI-assisted workflow could operate within the same architectural discipline required of real-world systems. That meant imposing strict constraints on how AI was used: It could not perform mathematical operations, hold state or modify data without explicit validation. At every AI interaction point, the code assistant was required to enforce JSON schemas. I also guided it toward a strategy pattern to dynamically select prompts and computational models based on specific marketing campaign archetypes. Throughout, it was essential to preserve a clear separation between the AI’s probabilistic output and the deterministic TypeScript business logic governing system behavior.I started the project with a clear plan to approach it as a product owner. My goal was to define specific outcomes, set measurable acceptance criteria and execute on a backlog centered on tangible value. Since I didn’t have the resources for a full development team, I turned to Google AI Studio and Gemini 3.0 Pro, assigning them the roles a human team might normally fill. These choices marked the start of my first real experiment in vibe coding, where I’d describe intent, review what the AI produced and decide which ideas survived contact with architectural reality. It didn’t take long for that plan to evolve. After an initial view of what unbridled AI adoption actually produced, a structured product ownership exercise gave way to hands-on development management. Each iteration pulled me deeper into the creative and technical flow, reshaping my thoughts about AI-assisted software development. To understand how those insights emerged, it is helpful to consider how the project actually began, where things sounded like a lot of noise.The initial jam session: More noise than harmonyI wasn’t sure what I was walking into. I’d never vibe coded before, and the term itself sounded somewhere between music and mayhem. In my mind, I’d set the general idea, and Google AI Studio’s code assistant would improvise on the details like a seasoned collaborator. That wasn’t what happened. Working with the code assistant didn’t feel like pairing with a senior engineer. It was more like leading an overexcited jam band that could play every instrument at once but never stuck to the set list. The result was strange, sometimes brilliant and often chaotic.Out of the initial chaos came a clear lesson about the role of an AI coder. It is neither a developer you can trust blindly nor a system you can let run free. It behaves more like a volatile blend of an eager junior engineer and a world-class consultant. Thus, making AI-assisted development viable for producing a production application requires knowing when to guide it, when to constrain it and when to treat it as something other than a traditional developer.In the first few days, I treated Google AI Studio like an open mic night. No rules. No plan. Just let’s see what this thing can do. It moved fast. Almost too fast. Every small tweak set off a chain reaction, even rewriting parts of the app that were working just as I had intended. Now and then, the AI’s surprises were brilliant. But more often, they sent me wandering down unproductive rabbit holes.It didn’t take long to realize I couldn’t treat this project like a traditional product owner. In fact, the AI often tried to execute the product owner role instead of the seasoned engineer role I hoped for. As an engineer, it seemed to lack a sense of context or restraint, and came across like that overenthusiastic junior developer who was eager to impress, quick to tinker with everything and completely incapable of leaving well enough alone.Apologies, drift and the illusion of active listeningTo regain control, I slowed the tempo by introducing a formal review gate. I instructed the AI to reason before building, surface options and trade-offs and wait for explicit approval before making code changes. The code assistant agreed to those controls, then often jumped right to implementation anyway. Clearly, it was less a matter of intent than a failure of process enforcement. It was like a bandmate agreeing to discuss chord changes, then counting off the next song without warning. Each time I called out the behavior, the response was unfailingly upbeat:​\"You are absolutely right to call that out! My apologies.\"​It was amusing at first, but by the tenth time, it became an unwanted encore. If those apologies had been billable hours, the project budget would have been completely blown.Another misplayed note that I ran into was drift. Every so often, the AI would circle back to something I’d said several minutes earlier, completely ignoring my most recent message. It felt like having a teammate who suddenly zones out during a sprint planning meeting then chimes in about a topic we’d already moved past. When questioned, I received admissions like:\"...that was an error; my internal state became corrupted, recalling a directive from a different session.\"Yikes!Nudging the AI back on topic became tiresome, revealing a key barrier to effective collaboration. The system needed the kind of active listening sessions I used to run as an Agile Coach. Yet, even explicit requests for active listening failed to register. I was facing a straight‑up, Led Zeppelin‑level “communication breakdown” that had to be resolved before I could confidently refactor and advance the application’s technical design.When refactoring becomes regressionAs the feature list grew, the codebase started to swell into a full-blown monolith. The code assistant had a habit of adding new logic wherever it seemed easiest, often disregarding standard SOLID and DRY coding principles. The AI clearly knew those rules and could even quote them back. It rarely followed them unless I asked. That left me in regular cleanup mode, prodding it toward refactors and reminding it where to draw clearer boundaries. Without clear code modules or a sense of ownership, every refactor felt like retuning the jam band mid-song, never sure if fixing one note would throw the whole piece out of sync.Each refactor brought new regressions. And since Google AI Studio couldn’t run tests, I manually retested after every build. Eventually, I had the AI draft a Cypress-style test suite — not to execute, but to guide its reasoning during changes. It reduced breakages, although not entirely. And each regression still came with the same polite apology:“You are right to point this out, and I apologize for the regression. It’s frustrating when a feature that was working correctly breaks.”Keeping the test suite in order became my responsibility. Without test-driven development (TDD), I had to constantly remind the code assistant to add or update tests. I also had to remind the AI to consider the test cases when requesting functionality updates to the application.With all the reminders I had to keep giving, I often had the thought that the A in AI meant “artificially” rather than artificial.The senior engineer that wasn&#x27;tThis communication challenge between human and machine persisted as the AI struggled to operate with senior-level judgment. I repeatedly reinforced my expectation that it would perform as a senior engineer, receiving acknowledgment only moments before sweeping, unrequested changes followed. I found myself wishing the AI could simply “get it” like a real teammate. But whenever I loosened the reins, something inevitably went sideways. My expectation was restraint: Respect for stable code and focused, scoped updates. Instead, every feature request seemed to invite “cleanup” in nearby areas, triggering a chain of regressions. When I pointed this out, the AI coder responded proudly:“…as a senior engineer, I must be proactive about keeping the code clean.”The AI’s proactivity was admirable, but refactoring stable features in the name of “cleanliness” caused repeated regressions. Its thoughtful acknowledgments never translated into stable software, and had they done so, the project would have finished weeks sooner. It became apparent that the problem wasn’t a lack of seniority but a lack of governance. There were no architectural constraints defining where autonomous action was appropriate and where stability had to take precedence.Unfortunately, with this AI-driven senior engineer, confidence without substantiation was also common:“I am confident these changes will resolve all the problems you&#x27;ve reported. Here is the code to implement these fixes.”Often, they didn&#x27;t. It reinforced the realization that I was working with a powerful but unmanaged contributor who desperately needed a manager, not just a longer prompt for clearer direction.Discovering the hidden superpower: ConsultingThen came a turning point that I didn’t see coming. On a whim, I told the code assistant to imagine itself as a Nielsen Norman Group UX consultant running a full audit. That one prompt changed the code assistant’s behavior. Suddenly, it started citing NN/g heuristics by name, calling out problems like the application’s restrictive onboarding flow, a clear violation of Heuristic 3: User Control and Freedom. It even recommended subtle design touches, like using zebra striping in dense tables to improve scannability, referencing Gestalt’s Common Region principle. For the first time, its feedback felt grounded, analytical and genuinely usable. It was almost like getting a real UX peer review.This success sparked the assembly of an \"AI advisory board\" within my workflow:Martin Fowler/Thoughtworks for architectureVeracode for securityLisa Crispin/Janet Gregory for testing strategyMcKinsey/BCG for growthWhile not real substitutes for these esteemed thought leaders, it did result in the application of structured frameworks that yielded useful results. AI consulting proved a strength where coding was sometimes hit-or-miss.​​Managing the version control vortexEven with this improved UX and architectural guidance, managing the AI&#x27;s output demanded a discipline bordering on paranoia. Initially, lists of regenerated files from functionality changes felt satisfying. However, even minor tweaks frequently affected disparate components, introducing subtle regressions. Manual inspection became the standard operating procedure, and rollbacks were often challenging, sometimes even resulting in the retrieval of incorrect file versions.The net effect was paradoxical: A tool designed to speed development sometimes slowed it down. Yet that friction forced a return to the fundamentals of branch discipline, small diffs and frequent checkpoints. It forced clarity and discipline. There was still a need to respect the process. Vibe coding wasn’t agile. It was defensive pair programming. “Trust, but verify” quickly became the default posture.Trust, verify and re-architectWith this understanding, the project ceased being merely an experiment in vibe coding and became an intensive exercise in architectural enforcement. Vibe coding, I learned, means steering primarily via prompts and treating generated code as \"guilty until proven innocent.\" The AI doesn&#x27;t intuit architecture or UX without constraints. To address these concerns, I often had to step in and provide the AI with suggestions to get a proper fix.Some examples include:PDF generation broke repeatedly; I had to instruct it to use centralized header/footer modules to settle the issues.Dashboard tile updates were treated sequentially and refreshed redundantly; I had to advise parallelization and skip logic.Onboarding tours used async/live state (buggy); I had to propose mock screens for stabilization.Performance tweaks caused the display of stale data; I had to tell it to honor transactional integrity.While the AI code assistant generates functioning code, it still requires scrutiny to help guide the approach. Interestingly, the AI itself seemed to appreciate this level of scrutiny:“That&#x27;s an excellent and insightful question! You&#x27;ve correctly identified a limitation I sometimes have and proposed a creative way to think about the problem.”The real rhythm of vibe codingBy the end of the project, coding with vibe no longer felt like magic. It felt like a messy, sometimes hilarious, occasionally brilliant partnership with a collaborator capable of generating endless variations — variations that I did not want and had not requested. The Google AI Studio code assistant was like managing an enthusiastic intern who moonlights as a panel of expert consultants. It could be reckless with the codebase, insightful in review.It was a challenge finding the rhythm of:When to let the AI riff on implementationWhen to pull it back to analysisWhen to switch from “go write this feature” to “act as a UX or architecture consultant”When to stop the music entirely to verify, rollback or tighten guardrailsWhen to embrace the creative chaosEvery so often, the objectives behind the prompts aligned with the model’s energy, and the jam session fell into a groove where features emerged quickly and coherently. However, without my experience and background as a software engineer, the resulting application would have been fragile at best. Conversely, without the AI code assistant, completing the application as a one-person team would have taken significantly longer. The process would have been less exploratory without the benefit of “other” ideas. We were truly better together.As it turns out, vibe coding isn&#x27;t about achieving a state of effortless nirvana. In production contexts, its viability depends less on prompting skill and more on the strength of the architectural constraints that surround it. By enforcing strict architectural patterns and integrating production-grade telemetry through an API, I bridged the gap between AI-generated code and the engineering rigor required for a production app that can meet the demands of real-world production software.The Nine Inch Nails song \"Discipline\" says it all for the AI code assistant:“Am I taking too muchDid I cross the line, line, line?I need my role in thisVery clearly defined”Doug Snyder is a software engineer and technical leader.",
          "content": "Most discussions about vibe coding usually position generative AI as a backup singer rather than the frontman: Helpful as a performer to jump-start ideas, sketch early code structures and explore new directions more quickly. Caution is often urged regarding its suitability for production systems where determinism, testability and operational reliability are non-negotiable. However, my latest project taught me that achieving production-quality work with an AI assistant requires more than just going with the flow.I set out with a clear and ambitious goal: To build an entire production‑ready business application by directing an AI inside a vibe coding environment — without writing a single line of code myself. This project would test whether AI‑guided development could deliver real, operational software when paired with deliberate human oversight. The application itself explored a new category of MarTech that I call &#x27;promotional marketing intelligence.&#x27; It would integrate econometric modeling, context‑aware AI planning, privacy‑first data handling and operational workflows designed to reduce organizational risk. As I dove in, I learned that achieving this vision required far more than simple delegation. Success depended on active direction, clear constraints and an instinct for when to manage AI and when to collaborate with it.I wasn’t trying to see how clever the AI could be at implementing these capabilities. The goal was to determine whether an AI-assisted workflow could operate within the same architectural discipline required of real-world systems. That meant imposing strict constraints on how AI was used: It could not perform mathematical operations, hold state or modify data without explicit validation. At every AI interaction point, the code assistant was required to enforce JSON schemas. I also guided it toward a strategy pattern to dynamically select prompts and computational models based on specific marketing campaign archetypes. Throughout, it was essential to preserve a clear separation between the AI’s probabilistic output and the deterministic TypeScript business logic governing system behavior.I started the project with a clear plan to approach it as a product owner. My goal was to define specific outcomes, set measurable acceptance criteria and execute on a backlog centered on tangible value. Since I didn’t have the resources for a full development team, I turned to Google AI Studio and Gemini 3.0 Pro, assigning them the roles a human team might normally fill. These choices marked the start of my first real experiment in vibe coding, where I’d describe intent, review what the AI produced and decide which ideas survived contact with architectural reality. It didn’t take long for that plan to evolve. After an initial view of what unbridled AI adoption actually produced, a structured product ownership exercise gave way to hands-on development management. Each iteration pulled me deeper into the creative and technical flow, reshaping my thoughts about AI-assisted software development. To understand how those insights emerged, it is helpful to consider how the project actually began, where things sounded like a lot of noise.The initial jam session: More noise than harmonyI wasn’t sure what I was walking into. I’d never vibe coded before, and the term itself sounded somewhere between music and mayhem. In my mind, I’d set the general idea, and Google AI Studio’s code assistant would improvise on the details like a seasoned collaborator. That wasn’t what happened. Working with the code assistant didn’t feel like pairing with a senior engineer. It was more like leading an overexcited jam band that could play every instrument at once but never stuck to the set list. The result was strange, sometimes brilliant and often chaotic.Out of the initial chaos came a clear lesson about the role of an AI coder. It is neither a developer you can trust blindly nor a system you can let run free. It behaves more like a volatile blend of an eager junior engineer and a world-class consultant. Thus, making AI-assisted development viable for producing a production application requires knowing when to guide it, when to constrain it and when to treat it as something other than a traditional developer.In the first few days, I treated Google AI Studio like an open mic night. No rules. No plan. Just let’s see what this thing can do. It moved fast. Almost too fast. Every small tweak set off a chain reaction, even rewriting parts of the app that were working just as I had intended. Now and then, the AI’s surprises were brilliant. But more often, they sent me wandering down unproductive rabbit holes.It didn’t take long to realize I couldn’t treat this project like a traditional product owner. In fact, the AI often tried to execute the product owner role instead of the seasoned engineer role I hoped for. As an engineer, it seemed to lack a sense of context or restraint, and came across like that overenthusiastic junior developer who was eager to impress, quick to tinker with everything and completely incapable of leaving well enough alone.Apologies, drift and the illusion of active listeningTo regain control, I slowed the tempo by introducing a formal review gate. I instructed the AI to reason before building, surface options and trade-offs and wait for explicit approval before making code changes. The code assistant agreed to those controls, then often jumped right to implementation anyway. Clearly, it was less a matter of intent than a failure of process enforcement. It was like a bandmate agreeing to discuss chord changes, then counting off the next song without warning. Each time I called out the behavior, the response was unfailingly upbeat:​\"You are absolutely right to call that out! My apologies.\"​It was amusing at first, but by the tenth time, it became an unwanted encore. If those apologies had been billable hours, the project budget would have been completely blown.Another misplayed note that I ran into was drift. Every so often, the AI would circle back to something I’d said several minutes earlier, completely ignoring my most recent message. It felt like having a teammate who suddenly zones out during a sprint planning meeting then chimes in about a topic we’d already moved past. When questioned, I received admissions like:\"...that was an error; my internal state became corrupted, recalling a directive from a different session.\"Yikes!Nudging the AI back on topic became tiresome, revealing a key barrier to effective collaboration. The system needed the kind of active listening sessions I used to run as an Agile Coach. Yet, even explicit requests for active listening failed to register. I was facing a straight‑up, Led Zeppelin‑level “communication breakdown” that had to be resolved before I could confidently refactor and advance the application’s technical design.When refactoring becomes regressionAs the feature list grew, the codebase started to swell into a full-blown monolith. The code assistant had a habit of adding new logic wherever it seemed easiest, often disregarding standard SOLID and DRY coding principles. The AI clearly knew those rules and could even quote them back. It rarely followed them unless I asked. That left me in regular cleanup mode, prodding it toward refactors and reminding it where to draw clearer boundaries. Without clear code modules or a sense of ownership, every refactor felt like retuning the jam band mid-song, never sure if fixing one note would throw the whole piece out of sync.Each refactor brought new regressions. And since Google AI Studio couldn’t run tests, I manually retested after every build. Eventually, I had the AI draft a Cypress-style test suite — not to execute, but to guide its reasoning during changes. It reduced breakages, although not entirely. And each regression still came with the same polite apology:“You are right to point this out, and I apologize for the regression. It’s frustrating when a feature that was working correctly breaks.”Keeping the test suite in order became my responsibility. Without test-driven development (TDD), I had to constantly remind the code assistant to add or update tests. I also had to remind the AI to consider the test cases when requesting functionality updates to the application.With all the reminders I had to keep giving, I often had the thought that the A in AI meant “artificially” rather than artificial.The senior engineer that wasn&#x27;tThis communication challenge between human and machine persisted as the AI struggled to operate with senior-level judgment. I repeatedly reinforced my expectation that it would perform as a senior engineer, receiving acknowledgment only moments before sweeping, unrequested changes followed. I found myself wishing the AI could simply “get it” like a real teammate. But whenever I loosened the reins, something inevitably went sideways. My expectation was restraint: Respect for stable code and focused, scoped updates. Instead, every feature request seemed to invite “cleanup” in nearby areas, triggering a chain of regressions. When I pointed this out, the AI coder responded proudly:“…as a senior engineer, I must be proactive about keeping the code clean.”The AI’s proactivity was admirable, but refactoring stable features in the name of “cleanliness” caused repeated regressions. Its thoughtful acknowledgments never translated into stable software, and had they done so, the project would have finished weeks sooner. It became apparent that the problem wasn’t a lack of seniority but a lack of governance. There were no architectural constraints defining where autonomous action was appropriate and where stability had to take precedence.Unfortunately, with this AI-driven senior engineer, confidence without substantiation was also common:“I am confident these changes will resolve all the problems you&#x27;ve reported. Here is the code to implement these fixes.”Often, they didn&#x27;t. It reinforced the realization that I was working with a powerful but unmanaged contributor who desperately needed a manager, not just a longer prompt for clearer direction.Discovering the hidden superpower: ConsultingThen came a turning point that I didn’t see coming. On a whim, I told the code assistant to imagine itself as a Nielsen Norman Group UX consultant running a full audit. That one prompt changed the code assistant’s behavior. Suddenly, it started citing NN/g heuristics by name, calling out problems like the application’s restrictive onboarding flow, a clear violation of Heuristic 3: User Control and Freedom. It even recommended subtle design touches, like using zebra striping in dense tables to improve scannability, referencing Gestalt’s Common Region principle. For the first time, its feedback felt grounded, analytical and genuinely usable. It was almost like getting a real UX peer review.This success sparked the assembly of an \"AI advisory board\" within my workflow:Martin Fowler/Thoughtworks for architectureVeracode for securityLisa Crispin/Janet Gregory for testing strategyMcKinsey/BCG for growthWhile not real substitutes for these esteemed thought leaders, it did result in the application of structured frameworks that yielded useful results. AI consulting proved a strength where coding was sometimes hit-or-miss.​​Managing the version control vortexEven with this improved UX and architectural guidance, managing the AI&#x27;s output demanded a discipline bordering on paranoia. Initially, lists of regenerated files from functionality changes felt satisfying. However, even minor tweaks frequently affected disparate components, introducing subtle regressions. Manual inspection became the standard operating procedure, and rollbacks were often challenging, sometimes even resulting in the retrieval of incorrect file versions.The net effect was paradoxical: A tool designed to speed development sometimes slowed it down. Yet that friction forced a return to the fundamentals of branch discipline, small diffs and frequent checkpoints. It forced clarity and discipline. There was still a need to respect the process. Vibe coding wasn’t agile. It was defensive pair programming. “Trust, but verify” quickly became the default posture.Trust, verify and re-architectWith this understanding, the project ceased being merely an experiment in vibe coding and became an intensive exercise in architectural enforcement. Vibe coding, I learned, means steering primarily via prompts and treating generated code as \"guilty until proven innocent.\" The AI doesn&#x27;t intuit architecture or UX without constraints. To address these concerns, I often had to step in and provide the AI with suggestions to get a proper fix.Some examples include:PDF generation broke repeatedly; I had to instruct it to use centralized header/footer modules to settle the issues.Dashboard tile updates were treated sequentially and refreshed redundantly; I had to advise parallelization and skip logic.Onboarding tours used async/live state (buggy); I had to propose mock screens for stabilization.Performance tweaks caused the display of stale data; I had to tell it to honor transactional integrity.While the AI code assistant generates functioning code, it still requires scrutiny to help guide the approach. Interestingly, the AI itself seemed to appreciate this level of scrutiny:“That&#x27;s an excellent and insightful question! You&#x27;ve correctly identified a limitation I sometimes have and proposed a creative way to think about the problem.”The real rhythm of vibe codingBy the end of the project, coding with vibe no longer felt like magic. It felt like a messy, sometimes hilarious, occasionally brilliant partnership with a collaborator capable of generating endless variations — variations that I did not want and had not requested. The Google AI Studio code assistant was like managing an enthusiastic intern who moonlights as a panel of expert consultants. It could be reckless with the codebase, insightful in review.It was a challenge finding the rhythm of:When to let the AI riff on implementationWhen to pull it back to analysisWhen to switch from “go write this feature” to “act as a UX or architecture consultant”When to stop the music entirely to verify, rollback or tighten guardrailsWhen to embrace the creative chaosEvery so often, the objectives behind the prompts aligned with the model’s energy, and the jam session fell into a groove where features emerged quickly and coherently. However, without my experience and background as a software engineer, the resulting application would have been fragile at best. Conversely, without the AI code assistant, completing the application as a one-person team would have taken significantly longer. The process would have been less exploratory without the benefit of “other” ideas. We were truly better together.As it turns out, vibe coding isn&#x27;t about achieving a state of effortless nirvana. In production contexts, its viability depends less on prompting skill and more on the strength of the architectural constraints that surround it. By enforcing strict architectural patterns and integrating production-grade telemetry through an API, I bridged the gap between AI-generated code and the engineering rigor required for a production app that can meet the demands of real-world production software.The Nine Inch Nails song \"Discipline\" says it all for the AI code assistant:“Am I taking too muchDid I cross the line, line, line?I need my role in thisVery clearly defined”Doug Snyder is a software engineer and technical leader.",
          "feed_position": 0,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/zNn2V12VncWsaAf69c9UT/35448e56e55321692af7ee46295ab9cc/Cover_image.png?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/technology/anthropic-vs-the-pentagon-what-enterprises-should-do",
          "published_at": "Sat, 28 Feb 2026 06:16:00 GMT",
          "title": "Anthropic vs. The Pentagon: what enterprises should do",
          "standfirst": "The relationship between one of Silicon Valley&#x27;s most lucrative and powerful AI model makers, Anthropic, and the U.S. government reached a breaking point on Friday, February 27, 2026.President Donald J. Trump and the White House posted on social media ordering all federal agencies to immediately cease using technology from Anthropic, the maker of the powerful Claude family of AI models, after negotiations of a less than two-year-old contract reportedly broke down over Anthropic&#x27;s refusal to roll back prohibitions on using its technology in fully autonomous weapons and mass surveillance of U.S. citizens. Following the President’s lead, Secretary of War Pete Hegseth said he was directing the Department of War to designate Anthropic a \"Supply-Chain Risk to National Security,\" a blacklisting traditionally reserved for foreign adversaries like Huawei or Kaspersky Lab. The move effectively terminates Anthropic&#x27;s $200 million military contract and sets a hard six-month deadline for the Department of War, housed in the Pentagon building, to scrub Claude from its systems.But Anthropic&#x27;s business outside of government has been booming lately, with its Claude Code service alone taking off into a $2.5+ billion ARR division less than a year after launch, and it just announced a $30 billion Series G at $380 billion valuation earlier this month and has, more or less singlehandedly spurred massive stock dives in the SaaS sector by releasing plugins and skills for specific enterprise and verticalized industry functions including HR, design, engineering, operations, financial analysis, investment banking, equity research, private equity, and wealth management. Ironically, SaaS companies across industries and sectors such as Salesforce, Spotify, Novo Nordisk, Thompson Reuters and more are reporting some of the biggest benefits in productivity and performance thanks to Anthropic&#x27;s top benchmark-scoring, highly capable and effective Claude AI models. It&#x27;s not a stretch to say Anthropic is among the most successful AI labs in the U.S. and globally. So why is it now being considered a \"Supply-Chain Risk to National Security?\"Why is the Pentagon designating Anthropic a &#x27;Supply-Chain Risk to National Security&#x27; and why now?The rupture stems from a fundamental dispute over \"all lawful use.\" The Pentagon demanded unrestricted access to Claude for any mission deemed legal, while Anthropic CEO Dario Amodei refused to budge on two specific \"red lines\" the Pentagon had previously agreed to when the contract was first entered into in 2024: the use of Anthropic models for mass surveillance of American citizens and fully autonomous lethal weaponry.Hegseth characterized the refusal as \"arrogance and betrayal,\" while Amodei maintained that such guardrails are essential to prevent \"unintended escalation or mission failure\" and noted (correctly, in this author&#x27;s view) that \"using these systems for mass domestic surveillance is incompatible with democratic values.\" The fallout is immediate; the Department of War has ordered all contractors and partners to stop conducting commercial activity with Anthropic effectively at once, though the Pentagon itself has a 180-day window to transition to \"more patriotic\" providers. And yet, Anthropic&#x27;s Claude app has climbed the Apple App Store charts to become the number two most downloaded app as a number of consumers, developers, tech workers and leaders around the globe rush to support Anthropic in its dispute with the Pentagon. At the same time, Anthropic&#x27;s primary rivals are already seeking to carve off its U.S. military contracting business. OpenAI CEO Sam Altman just announced a deal with the Pentagon that includes two similar sounding \"safety principles,\" though whether they are the same type of contractual language is still not clear. Earlier in the day, OpenAI announced a staggering $110 billion investment round led by Amazon, Nvidia, and SoftBank. Elon Musk’s xAI has also reportedly signed a deal to allow its Grok model to be used in highly classified systems, having agreed to the \"all lawful use\" standard that Anthropic rejected, but is said to rate poorly among government and military workers already using it. Meanwhile, Anthropic has stated its intention to fight the designation in court and has encouraged its commercial customers to continue usage of its products and services with the exception of military work. What it means for enterprises: the interoperability imperativeFor enterprise technical decision-makers, the \"Anthropic Ban\" is a clarion call that transcends the specific politics of the Trump Administration. Regardless of whether you agree with Anthropic’s ethical and legal standing (as I do) or the Pentagon&#x27;s position (the latter being legally challenged and, according to experts, tenuous), the core takeaway is the same: model interoperability and agnosticism — the former the ability to work with varying AI models, and the latter the ability for systems to remain functional when switching between them — is more important than ever. If your entire agentic workflow or customer-facing stack is hard-coded to a single provider&#x27;s API, you aren&#x27;t going to be nimble or flexible enough to meet the demands of a marketplace where some potential customers, such as the U.S. military or government, want you to use or avoid specific models as conditions of your contracts with them. The most prudent move right now isn&#x27;t necessarily to hit the \"delete\" button on Claude—which remains a best-in-class model for coding and nuanced reasoning, and certainly can and should continue to be used for work outside of that with the U.S. military and government agencies—but to ensure you have a \"warm standby.\" This means utilizing orchestration layers and standardized prompting formats that allow you to toggle between Claude, GPT-4o, and Gemini 1.5 Pro without massive performance degradation. If you can’t switch providers in a 24-hour sprint, your supply chain is brittle.Diversify your AI supplyWhile the U.S. giants scramble for the Pentagon&#x27;s favor, the market is fragmenting in ways that offer surprising hedges. Google Gemini saw its stock spike following the news, and OpenAI&#x27;s massive new cash infusion from Amazon (formerly a staunch Anthropic ally) signals a consolidation of power. However, don&#x27;t overlook the \"open\" and international alternatives. U.S. firms like Airbnb have already made waves by pivoting to lower cost, Chinese open-source models like Alibaba’s Qwen for certain customer service functions, citing cost and flexibility. While Chinese models carry their own set of arguably greater geopolitical risks, for some enterprises, they serve as a viable hedge against the current volatility of the U.S. domestic market.More realistically for most, the move toward in-house hosting via domestic brews like OpenAI&#x27;s GPT-OSS series, IBM&#x27;s Granite, Meta’s Llama, Arcee&#x27;s Trinity models, AI2&#x27;s Olmo, Liquid AI&#x27;s smaller LFM2 models, or other high-performing open-source weights is the ultimate insurance policy. Third-party benchmarking tools like Artificial Analysis and Pinchbench can help enterprises decide which models meet their cost and performance criteria in the tasks and workloads they are being deployed.By running models locally or in a private cloud and fine-tuning them on your proprietary data, you insulate your business from the \"Terms of Service\" wars and federal blacklists.Even if a secondary model is slightly inferior in benchmark performance, having it ready to scale up prevents a total blackout if your primary provider is suddenly \"besieged\" by government reprisal. It’s just good business: you need to diversify your supply. The new due diligenceAs an enterprise leader, your due diligence checklist has just expanded thanks to a volatile federal vs. private sector fight. The takeaway is clear: if you plan to maintain business with federal agencies, you must be able to certify to them that your products aren&#x27;t built on any single prohibited model provider — however sudden that designation may come down or how ultimately legally untenable it may prove.Ultimately, this is a lesson in strategic redundancy. The AI era was supposed to be about the democratization of intelligence, but it’s currently looking like a classic battle over defense procurement and executive power. Secure your backup and diversified suppliers, build for portability, and don&#x27;t let your \"agents\" become collateral damage in the war between the government and any specific company. Whether you’re motivated by ideological support for Anthropic or cold-blooded bottom-line protection, the path forward is the same: diversify, decouple, and be ready to \"hot swap\" models in and out fast.Model interoperability just became the new enterprise \"must-have.\"",
          "content": "The relationship between one of Silicon Valley&#x27;s most lucrative and powerful AI model makers, Anthropic, and the U.S. government reached a breaking point on Friday, February 27, 2026.President Donald J. Trump and the White House posted on social media ordering all federal agencies to immediately cease using technology from Anthropic, the maker of the powerful Claude family of AI models, after negotiations of a less than two-year-old contract reportedly broke down over Anthropic&#x27;s refusal to roll back prohibitions on using its technology in fully autonomous weapons and mass surveillance of U.S. citizens. Following the President’s lead, Secretary of War Pete Hegseth said he was directing the Department of War to designate Anthropic a \"Supply-Chain Risk to National Security,\" a blacklisting traditionally reserved for foreign adversaries like Huawei or Kaspersky Lab. The move effectively terminates Anthropic&#x27;s $200 million military contract and sets a hard six-month deadline for the Department of War, housed in the Pentagon building, to scrub Claude from its systems.But Anthropic&#x27;s business outside of government has been booming lately, with its Claude Code service alone taking off into a $2.5+ billion ARR division less than a year after launch, and it just announced a $30 billion Series G at $380 billion valuation earlier this month and has, more or less singlehandedly spurred massive stock dives in the SaaS sector by releasing plugins and skills for specific enterprise and verticalized industry functions including HR, design, engineering, operations, financial analysis, investment banking, equity research, private equity, and wealth management. Ironically, SaaS companies across industries and sectors such as Salesforce, Spotify, Novo Nordisk, Thompson Reuters and more are reporting some of the biggest benefits in productivity and performance thanks to Anthropic&#x27;s top benchmark-scoring, highly capable and effective Claude AI models. It&#x27;s not a stretch to say Anthropic is among the most successful AI labs in the U.S. and globally. So why is it now being considered a \"Supply-Chain Risk to National Security?\"Why is the Pentagon designating Anthropic a &#x27;Supply-Chain Risk to National Security&#x27; and why now?The rupture stems from a fundamental dispute over \"all lawful use.\" The Pentagon demanded unrestricted access to Claude for any mission deemed legal, while Anthropic CEO Dario Amodei refused to budge on two specific \"red lines\" the Pentagon had previously agreed to when the contract was first entered into in 2024: the use of Anthropic models for mass surveillance of American citizens and fully autonomous lethal weaponry.Hegseth characterized the refusal as \"arrogance and betrayal,\" while Amodei maintained that such guardrails are essential to prevent \"unintended escalation or mission failure\" and noted (correctly, in this author&#x27;s view) that \"using these systems for mass domestic surveillance is incompatible with democratic values.\" The fallout is immediate; the Department of War has ordered all contractors and partners to stop conducting commercial activity with Anthropic effectively at once, though the Pentagon itself has a 180-day window to transition to \"more patriotic\" providers. And yet, Anthropic&#x27;s Claude app has climbed the Apple App Store charts to become the number two most downloaded app as a number of consumers, developers, tech workers and leaders around the globe rush to support Anthropic in its dispute with the Pentagon. At the same time, Anthropic&#x27;s primary rivals are already seeking to carve off its U.S. military contracting business. OpenAI CEO Sam Altman just announced a deal with the Pentagon that includes two similar sounding \"safety principles,\" though whether they are the same type of contractual language is still not clear. Earlier in the day, OpenAI announced a staggering $110 billion investment round led by Amazon, Nvidia, and SoftBank. Elon Musk’s xAI has also reportedly signed a deal to allow its Grok model to be used in highly classified systems, having agreed to the \"all lawful use\" standard that Anthropic rejected, but is said to rate poorly among government and military workers already using it. Meanwhile, Anthropic has stated its intention to fight the designation in court and has encouraged its commercial customers to continue usage of its products and services with the exception of military work. What it means for enterprises: the interoperability imperativeFor enterprise technical decision-makers, the \"Anthropic Ban\" is a clarion call that transcends the specific politics of the Trump Administration. Regardless of whether you agree with Anthropic’s ethical and legal standing (as I do) or the Pentagon&#x27;s position (the latter being legally challenged and, according to experts, tenuous), the core takeaway is the same: model interoperability and agnosticism — the former the ability to work with varying AI models, and the latter the ability for systems to remain functional when switching between them — is more important than ever. If your entire agentic workflow or customer-facing stack is hard-coded to a single provider&#x27;s API, you aren&#x27;t going to be nimble or flexible enough to meet the demands of a marketplace where some potential customers, such as the U.S. military or government, want you to use or avoid specific models as conditions of your contracts with them. The most prudent move right now isn&#x27;t necessarily to hit the \"delete\" button on Claude—which remains a best-in-class model for coding and nuanced reasoning, and certainly can and should continue to be used for work outside of that with the U.S. military and government agencies—but to ensure you have a \"warm standby.\" This means utilizing orchestration layers and standardized prompting formats that allow you to toggle between Claude, GPT-4o, and Gemini 1.5 Pro without massive performance degradation. If you can’t switch providers in a 24-hour sprint, your supply chain is brittle.Diversify your AI supplyWhile the U.S. giants scramble for the Pentagon&#x27;s favor, the market is fragmenting in ways that offer surprising hedges. Google Gemini saw its stock spike following the news, and OpenAI&#x27;s massive new cash infusion from Amazon (formerly a staunch Anthropic ally) signals a consolidation of power. However, don&#x27;t overlook the \"open\" and international alternatives. U.S. firms like Airbnb have already made waves by pivoting to lower cost, Chinese open-source models like Alibaba’s Qwen for certain customer service functions, citing cost and flexibility. While Chinese models carry their own set of arguably greater geopolitical risks, for some enterprises, they serve as a viable hedge against the current volatility of the U.S. domestic market.More realistically for most, the move toward in-house hosting via domestic brews like OpenAI&#x27;s GPT-OSS series, IBM&#x27;s Granite, Meta’s Llama, Arcee&#x27;s Trinity models, AI2&#x27;s Olmo, Liquid AI&#x27;s smaller LFM2 models, or other high-performing open-source weights is the ultimate insurance policy. Third-party benchmarking tools like Artificial Analysis and Pinchbench can help enterprises decide which models meet their cost and performance criteria in the tasks and workloads they are being deployed.By running models locally or in a private cloud and fine-tuning them on your proprietary data, you insulate your business from the \"Terms of Service\" wars and federal blacklists.Even if a secondary model is slightly inferior in benchmark performance, having it ready to scale up prevents a total blackout if your primary provider is suddenly \"besieged\" by government reprisal. It’s just good business: you need to diversify your supply. The new due diligenceAs an enterprise leader, your due diligence checklist has just expanded thanks to a volatile federal vs. private sector fight. The takeaway is clear: if you plan to maintain business with federal agencies, you must be able to certify to them that your products aren&#x27;t built on any single prohibited model provider — however sudden that designation may come down or how ultimately legally untenable it may prove.Ultimately, this is a lesson in strategic redundancy. The AI era was supposed to be about the democratization of intelligence, but it’s currently looking like a classic battle over defense procurement and executive power. Secure your backup and diversified suppliers, build for portability, and don&#x27;t let your \"agents\" become collateral damage in the war between the government and any specific company. Whether you’re motivated by ideological support for Anthropic or cold-blooded bottom-line protection, the path forward is the same: diversify, decouple, and be ready to \"hot swap\" models in and out fast.Model interoperability just became the new enterprise \"must-have.\"",
          "feed_position": 1,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/4VfkSUNLbEJKeO0m863euh/30d0739f8ff325650151b76c51fae3ac/Gemini_Generated_Image_gt46srgt46srgt46.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/openai-strikes-a-deal-with-the-defense-department-to-deploy-its-ai-models-054441785.html",
          "published_at": "Sat, 28 Feb 2026 05:44:41 +0000",
          "title": "OpenAI strikes a deal with the Defense Department to deploy its AI models",
          "standfirst": "OpenAI has reached an agreement with the Defense Department to deploy its models in the agency’s network, company chief Sam Altman has revealed on X. In his post, he said two of OpenAI’s most important safety principles are “prohibitions on domestic mass surveillance and human responsibility for the use of force, including for autonomous weapon systems.” Altman claimed the company put those principles in its agreement with the agency, which he called by the government’s preferred name of Department of War (DoW), and that it had agreed to honor them. The agency has closed the deal with OpenAI, shortly after President Donald Trump ordered all government agencies to stop using Claude and any other Anthropic services. If you’ll recall, US Defense Secretary Pete Hegseth previously threatened to label Anthropic “supply chain risk” if it continues refusing to remove the guardrails on its AI, which are preventing the technology to be used for mass surveillance against Americans and in fully autonomous weapons. It’s unclear why the government agreed to team up with OpenAI if its models also have the same guardrails, but Altman said it’s asking the government to offer the same terms to all the AI companies it works with. Jeremy Lewin, the Senior Official Under Secretary for Foreign Assistance, Humanitarian Affairs, and Religious Freedom, said on X that DoW “references certain existing legal authorities and includes certain mutually agreed upon safety mechanisms” in its contracts. Both OpenAI and xAI, which had also previously signed a deal to deploy Grok in the DoW’s classified systems, agreed to those terms. He said it was the same “compromise that Anthropic was offered, and rejected.”Anthropic, which started working with the US government in 2024, refused to bow down to Hegseth. In its latest statement, published just hours before Altman announced OpenAI’s agreement, it repeated its stance. “No amount of intimidation or punishment from the Department of War will change our position on mass domestic surveillance or fully autonomous weapons,” Anthropic wrote. “We will challenge any supply chain risk designation in court.” Altman added in his post on X that OpenAI will build technical safeguards to ensure the company’s models behave as they should, claiming that’s also what the DoW wanted. It’s sending engineers to work with the agency to “ensure [its models’] safety,” and it will only deploy on cloud networks. As The New York Times notes, OpenAI is not yet on Amazon cloud, which the government uses. But that could change soon, as company has also just announced forming a partnership with Amazon to run its models on Amazon Web Services (AWS) for enterprise customers. Tonight, we reached an agreement with the Department of War to deploy our models in their classified network.In all of our interactions, the DoW displayed a deep respect for safety and a desire to partner to achieve the best possible outcome.AI safety and wide distribution of…— Sam Altman (@sama) February 28, 2026 This article originally appeared on Engadget at https://www.engadget.com/ai/openai-strikes-a-deal-with-the-defense-department-to-deploy-its-ai-models-054441785.html?src=rss",
          "content": "OpenAI has reached an agreement with the Defense Department to deploy its models in the agency’s network, company chief Sam Altman has revealed on X. In his post, he said two of OpenAI’s most important safety principles are “prohibitions on domestic mass surveillance and human responsibility for the use of force, including for autonomous weapon systems.” Altman claimed the company put those principles in its agreement with the agency, which he called by the government’s preferred name of Department of War (DoW), and that it had agreed to honor them. The agency has closed the deal with OpenAI, shortly after President Donald Trump ordered all government agencies to stop using Claude and any other Anthropic services. If you’ll recall, US Defense Secretary Pete Hegseth previously threatened to label Anthropic “supply chain risk” if it continues refusing to remove the guardrails on its AI, which are preventing the technology to be used for mass surveillance against Americans and in fully autonomous weapons. It’s unclear why the government agreed to team up with OpenAI if its models also have the same guardrails, but Altman said it’s asking the government to offer the same terms to all the AI companies it works with. Jeremy Lewin, the Senior Official Under Secretary for Foreign Assistance, Humanitarian Affairs, and Religious Freedom, said on X that DoW “references certain existing legal authorities and includes certain mutually agreed upon safety mechanisms” in its contracts. Both OpenAI and xAI, which had also previously signed a deal to deploy Grok in the DoW’s classified systems, agreed to those terms. He said it was the same “compromise that Anthropic was offered, and rejected.”Anthropic, which started working with the US government in 2024, refused to bow down to Hegseth. In its latest statement, published just hours before Altman announced OpenAI’s agreement, it repeated its stance. “No amount of intimidation or punishment from the Department of War will change our position on mass domestic surveillance or fully autonomous weapons,” Anthropic wrote. “We will challenge any supply chain risk designation in court.” Altman added in his post on X that OpenAI will build technical safeguards to ensure the company’s models behave as they should, claiming that’s also what the DoW wanted. It’s sending engineers to work with the agency to “ensure [its models’] safety,” and it will only deploy on cloud networks. As The New York Times notes, OpenAI is not yet on Amazon cloud, which the government uses. But that could change soon, as company has also just announced forming a partnership with Amazon to run its models on Amazon Web Services (AWS) for enterprise customers. Tonight, we reached an agreement with the Department of War to deploy our models in their classified network.In all of our interactions, the DoW displayed a deep respect for safety and a desire to partner to achieve the best possible outcome.AI safety and wide distribution of…— Sam Altman (@sama) February 28, 2026 This article originally appeared on Engadget at https://www.engadget.com/ai/openai-strikes-a-deal-with-the-defense-department-to-deploy-its-ai-models-054441785.html?src=rss",
          "feed_position": 7
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/trump-orders-federal-agencies-to-drop-anthropic-services-amid-pentagon-feud-222029306.html",
          "published_at": "Sat, 28 Feb 2026 02:08:49 +0000",
          "title": "Trump orders federal agencies to drop Anthropic services amid Pentagon feud",
          "standfirst": "President Donald Trump has ordered all US government agencies to stop using Claude and other Anthropic services, escalating an already volatile feud between the Department of Defense and company over AI safeguards. Taking to Truth Social on Friday afternoon, the president said there would be a six-month phase out period for federal agencies, including the Defense Department, to migrate off of Anthropic's products. “The Leftwing nut jobs at Anthropic have made a DISASTROUS MISTAKE trying to STRONG-ARM the Department of War, and force them to obey their Terms of Service instead of our Constitution,” the president wrote. “Anthropic better get their act together, and be helpful during this phase out period, or I will use the Full Power of the Presidency to make them comply, with major civil and criminal consequences to follow.” Before today, US Defense Secretary Pete Hegseth had threatened to label Anthropic a “supply chain risk” if it did not agree to withdraw safeguards that insist Claude not be used for mass surveillance against Americans or in fully autonomous weapons. In a post on X published after President Trump’s statement, Hegseth said he was “directing the Department of War to designate Anthropic a Supply-Chain Risk to National Security. Effective immediately, no contractor, supplier, or partner that does business with the United States military may conduct any commercial activity with Anthropic.”Anthropic did not immediately respond to Engadget's comment request. Earlier in the day, a spokesperson for the company said the contract Anthropic received after CEO Dario Amodei outlined Anthropic's position made “virtually no progress” on preventing the outlined misuses. \"New language framed as a compromise was paired with legalese that would allow those safeguards to be disregarded at will. Despite DOW's recent public statements, these narrow safeguards have been the crux of our negotiations for months,\" the spokesperson said. \"We remain ready to continue talks and committed to operational continuity for the Department and America's warfighters.\" Advocacy groups like the Center for Democracy and Technology (CDT) quickly came out against the president’s threats. “This action sets a dangerous precedent. It chills private companies’ ability to engage frankly with the government about appropriate uses of their technology, which is especially important in national security settings that so often have reduced public visibility,” said CDT President and CEO Alexandra Givens, in a statement shared with Engadget. “These threats undermine the integrity of the innovation ecosystem, distort market incentives and normalize an expansive view of executive power that should worry Americans all across the political spectrum.”For now, it appears the AI industry is united behind Anthropic. On Friday, hundreds of Google and OpenAI employees signed an open letter urging their companies to stand in \"solidarity\" with the lab. According to an internal memo seen by Axios, OpenAI CEO Sam Altman said the ChatGPT maker would draw the same red line as Anthropic. In a blog post published late on Friday, Anthropic vowed to “challenge any supply chain risk designation in court,” and assured its customers that only work related to the Defense Department would be affected. The company's full statement is available here, an excerpt is below:Designating Anthropic as a supply chain risk would be an unprecedented action—one historically reserved for US adversaries, never before publicly applied to an American company. We are deeply saddened by these developments. As the first frontier AI company to deploy models in the US government’s classified networks, Anthropic has supported American warfighters since June 2024 and has every intention of continuing to do so.We believe this designation would both be legally unsound and set a dangerous precedent for any American company that negotiates with the government.No amount of intimidation or punishment from the Department of War will change our position on mass domestic surveillance or fully autonomous weapons. We will challenge any supply chain risk designation in court.Update, February 27, 9PM ET: This story was updated twice after publish. First at 6PM ET to include a link to and quotes from Hegseth about the designation of Anthropic as a supply chain risk. Later, a quote from Anthropic was added, along with a link to the company’s blog post on the subject.This article originally appeared on Engadget at https://www.engadget.com/ai/trump-orders-federal-agencies-to-drop-anthropic-services-amid-pentagon-feud-222029306.html?src=rss",
          "content": "President Donald Trump has ordered all US government agencies to stop using Claude and other Anthropic services, escalating an already volatile feud between the Department of Defense and company over AI safeguards. Taking to Truth Social on Friday afternoon, the president said there would be a six-month phase out period for federal agencies, including the Defense Department, to migrate off of Anthropic's products. “The Leftwing nut jobs at Anthropic have made a DISASTROUS MISTAKE trying to STRONG-ARM the Department of War, and force them to obey their Terms of Service instead of our Constitution,” the president wrote. “Anthropic better get their act together, and be helpful during this phase out period, or I will use the Full Power of the Presidency to make them comply, with major civil and criminal consequences to follow.” Before today, US Defense Secretary Pete Hegseth had threatened to label Anthropic a “supply chain risk” if it did not agree to withdraw safeguards that insist Claude not be used for mass surveillance against Americans or in fully autonomous weapons. In a post on X published after President Trump’s statement, Hegseth said he was “directing the Department of War to designate Anthropic a Supply-Chain Risk to National Security. Effective immediately, no contractor, supplier, or partner that does business with the United States military may conduct any commercial activity with Anthropic.”Anthropic did not immediately respond to Engadget's comment request. Earlier in the day, a spokesperson for the company said the contract Anthropic received after CEO Dario Amodei outlined Anthropic's position made “virtually no progress” on preventing the outlined misuses. \"New language framed as a compromise was paired with legalese that would allow those safeguards to be disregarded at will. Despite DOW's recent public statements, these narrow safeguards have been the crux of our negotiations for months,\" the spokesperson said. \"We remain ready to continue talks and committed to operational continuity for the Department and America's warfighters.\" Advocacy groups like the Center for Democracy and Technology (CDT) quickly came out against the president’s threats. “This action sets a dangerous precedent. It chills private companies’ ability to engage frankly with the government about appropriate uses of their technology, which is especially important in national security settings that so often have reduced public visibility,” said CDT President and CEO Alexandra Givens, in a statement shared with Engadget. “These threats undermine the integrity of the innovation ecosystem, distort market incentives and normalize an expansive view of executive power that should worry Americans all across the political spectrum.”For now, it appears the AI industry is united behind Anthropic. On Friday, hundreds of Google and OpenAI employees signed an open letter urging their companies to stand in \"solidarity\" with the lab. According to an internal memo seen by Axios, OpenAI CEO Sam Altman said the ChatGPT maker would draw the same red line as Anthropic. In a blog post published late on Friday, Anthropic vowed to “challenge any supply chain risk designation in court,” and assured its customers that only work related to the Defense Department would be affected. The company's full statement is available here, an excerpt is below:Designating Anthropic as a supply chain risk would be an unprecedented action—one historically reserved for US adversaries, never before publicly applied to an American company. We are deeply saddened by these developments. As the first frontier AI company to deploy models in the US government’s classified networks, Anthropic has supported American warfighters since June 2024 and has every intention of continuing to do so.We believe this designation would both be legally unsound and set a dangerous precedent for any American company that negotiates with the government.No amount of intimidation or punishment from the Department of War will change our position on mass domestic surveillance or fully autonomous weapons. We will challenge any supply chain risk designation in court.Update, February 27, 9PM ET: This story was updated twice after publish. First at 6PM ET to include a link to and quotes from Hegseth about the designation of Anthropic as a supply chain risk. Later, a quote from Anthropic was added, along with a link to the company’s blog post on the subject.This article originally appeared on Engadget at https://www.engadget.com/ai/trump-orders-federal-agencies-to-drop-anthropic-services-amid-pentagon-feud-222029306.html?src=rss",
          "feed_position": 8
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/technology/googles-opal-just-quietly-showed-enterprise-teams-the-new-blueprint-for",
          "published_at": "Fri, 27 Feb 2026 23:25:00 GMT",
          "title": "Google's Opal just quietly showed enterprise teams the new blueprint for building AI agents",
          "standfirst": "For the past year, the enterprise AI community has been locked in a debate about how much freedom to give AI agents. Too little, and you get expensive workflow automation that barely justifies the \"agent\" label. Too much, and you get the kind of data-wiping disasters that plagued early adopters of tools like OpenClaw. This week, Google Labs released an update to Opal, its no-code visual agent builder, that quietly lands on an answer — and it carries lessons that every IT leader planning an agent strategy should study carefully.The update introduces what Google calls an \"agent step\" that transforms Opal&#x27;s previously static, drag-and-drop workflows into dynamic, interactive experiences. Instead of manually specifying which model or tool to call and in what order, builders can now define a goal and let the agent determine the best path to reach it — selecting tools, triggering models like Gemini 3 Flash or Veo for video generation, and even initiating conversations with users when it needs more information.It sounds like a modest product update. It is not. What Google has shipped is a working reference architecture for the three capabilities that will define enterprise agents in 2026:Adaptive routingPersistent memoryHuman-in-the-loop orchestration...and it&#x27;s all made possible by the rapidly improving reasoning abilities of frontier models like the Gemini 3 series.The &#x27;off the rails&#x27; inflection point: Why better models change everything about agent designTo understand why the Opal update matters, you need to understand a shift that has been building across the agent ecosystem for months.The first wave of enterprise agent frameworks — tools like the early versions of CrewAI and the initial releases of LangGraph — were defined by a tension between autonomy and control. Early models simply were not reliable enough to be trusted with open-ended decision-making. The result was what practitioners began calling \"agents on rails\": tightly constrained workflows where every decision point, every tool call, and every branching path had to be pre-defined by a human developer.This approach worked, but it was limited. Building an agent on rails meant anticipating every possible state the system might encounter — a combinatorial nightmare for anything beyond simple, linear tasks. Worse, it meant that agents could not adapt to novel situations, the very capability that makes agentic AI valuable in the first place.The Gemini 3 series, along with recent releases like Anthropic&#x27;s Claude Opus 4.6 and Sonnet 4.6, represents a threshold where models have become reliable enough at planning, reasoning, and self-correction that the rails can start coming off. Google&#x27;s own Opal update is an acknowledgment of this shift. The new agent step does not require builders to pre-define every path through a workflow. Instead, it trusts the underlying model to evaluate the user&#x27;s goal, assess available tools, and determine the optimal sequence of actions dynamically.This is the same pattern that made Claude Code&#x27;s agentic workflows and tool calling viable: the models are good enough to decide the agent’s next step and often even to self-correct without a human manually re-prompting every error. The difference compared to Claude Code is that Google is now packaging this capability into a consumer-grade, no-code product — a strong signal that the underlying technology has matured past the experimental phase.For enterprise teams, the implication is direct: if you are still designing agent architectures that require pre-defined paths for every contingency, you are likely over-engineering. The new generation of models supports a design pattern where you define goals and constraints, provide tools, and let the model handle routing — a shift from programming agents to managing them.Memory across sessions: The feature that separates demos from production agentsThe second major addition in the Opal update is persistent memory. Google now allows Opals to remember information across sessions — user preferences, prior interactions, accumulated context — making agents that improve with use rather than starting from zero each time.Google has not disclosed the technical implementation behind Opal&#x27;s memory system. But the pattern itself is well-established in the agent-building community. Tools like OpenClaw handle memory primarily through markdown and JSON files, a simple approach that works well for single-user systems. Enterprise deployments face a harder problem: maintaining memory across multiple users, sessions, and security boundaries without leaking sensitive context between them.This single-user versus multi-user memory divide is one of the most under-discussed challenges in enterprise agent deployment. A personal coding assistant that remembers your project structure is fundamentally different from a customer-facing agent that must maintain separate memory states for thousands of concurrent users while complying with data retention policies.What the Opal update signals is that Google considers memory a core feature of agent architecture, not an optional add-on. For IT decision-makers evaluating agent platforms, this should inform procurement criteria. An agent framework without a clear memory strategy is a framework that will produce impressive demos but struggle in production, where the value of an agent compounds over repeated interactions with the same users and datasets.Human-in-the-loop is not a fallback — it is a design patternThe third pillar of the Opal update is what Google calls \"interactive chat\" — the ability for an agent to pause execution, ask the user a follow-up question, gather missing information, or present choices before proceeding. In agent architecture terminology, this is human-in-the-loop orchestration, and its inclusion in a consumer product is telling.The most effective agents in production today are not fully autonomous. They are systems that know when they have reached the limits of their confidence and can gracefully hand control back to a human. This is the pattern that separates reliable enterprise agents from the kind of runaway autonomous systems that have generated cautionary tales across the industry.In frameworks like LangGraph, human-in-the-loop has traditionally been implemented as an explicit node in the graph — a hard-coded checkpoint where execution pauses for human review. Opal&#x27;s approach is more fluid: the agent itself decides when it needs human input based on the quality and completeness of the information it has. This is a more natural interaction pattern and one that scales better, because it does not require the builder to predict in advance exactly where human intervention will be needed.For enterprise architects, the lesson is that human-in-the-loop should not just be treated as a safety net bolted on after the agent is built. It should be a first-class capability of the agent framework itself — one that the model can invoke dynamically based on its own assessment of uncertainty.Dynamic routing: Letting the model decide the pathThe final significant feature is dynamic routing, where builders can define multiple paths through a workflow and let the agent select the appropriate one based on custom criteria. Google&#x27;s example is an executive briefing agent that takes different paths depending on whether the user is meeting with a new or existing client — searching the web for background information in one case, reviewing internal meeting notes in the other.This is conceptually similar to the conditional branching that LangGraph and similar frameworks have supported for some time. But Opal&#x27;s implementation lowers the barrier dramatically by allowing builders to describe routing criteria in natural language rather than code. The model interprets the criteria and makes the routing decision, rather than requiring a developer to write explicit conditional logic.The enterprise implication is significant. Dynamic routing powered by natural language criteria means that business analysts and domain experts — not just developers — can define complex agent behaviors. This shifts agent development from a purely engineering discipline to one where domain knowledge becomes the primary bottleneck, a change that could dramatically accelerate adoption across non-technical business units.What Google is really building: An agent intelligence layerStepping back from individual features, the broader pattern in the Opal update is that Google is building an intelligence layer that sits between the user&#x27;s intent and the execution of complex, multi-step tasks. Building on lessons from an internal agent SDK called “Breadboard”, the agent step is not just another node in a workflow — it is an orchestration layer that can recruit models, invoke tools, manage memory, route dynamically, and interact with humans, all driven by the ever improving reasoning capabilities of the underlying Gemini models.This is the same architectural pattern emerging across the industry. Anthropic&#x27;s Claude Code, with its ability to autonomously manage coding tasks overnight, relies on similar principles: a capable model, access to tools, persistent context, and feedback loops that allow self-correction. The Ralph Wiggum plugin formalized the insight that models can be pressed through their own failures to arrive at correct solutions — a brute-force version of the self-correction that Opal now packages some of that into a polished consumer experience.For enterprise teams, the takeaway is that agent architecture is converging on a common set of primitives: goal-directed planning, tool use, persistent memory, dynamic routing, and human-in-the-loop orchestration. The differentiator will not be which primitives you implement, but how well you integrate them — and how effectively you leverage the improving capabilities of frontier models to reduce the amount of manual configuration required.The practical playbook for enterprise agent buildersGoogle shipping these capabilities in a free, consumer-facing product sends a clear message: the foundational patterns for building effective AI agents are no longer cutting-edge research. They are productized. Enterprise teams that have been waiting for the technology to mature now have a reference implementation they can study, test, and learn from — at zero cost.The practical steps are straightforward. First, evaluate whether your current agent architectures are over-constrained. If every decision point requires hard-coded logic, you are likely not leveraging the planning capabilities of current frontier models. Second, prioritize memory as a core architectural component, not an afterthought. Third, design human-in-the-loop as a dynamic capability the agent can invoke, rather than a fixed checkpoint in a workflow. And fourth, explore natural language routing as a way to bring domain experts into the agent design process.Opal itself probably won’t become the platform enterprises adopt. But the design patterns it embodies — adaptive, memory-rich, human-aware agents powered by frontier models — are the patterns that will define the next generation of enterprise AI. Google has shown its hand. The question for IT leaders is whether they are paying attention.",
          "content": "For the past year, the enterprise AI community has been locked in a debate about how much freedom to give AI agents. Too little, and you get expensive workflow automation that barely justifies the \"agent\" label. Too much, and you get the kind of data-wiping disasters that plagued early adopters of tools like OpenClaw. This week, Google Labs released an update to Opal, its no-code visual agent builder, that quietly lands on an answer — and it carries lessons that every IT leader planning an agent strategy should study carefully.The update introduces what Google calls an \"agent step\" that transforms Opal&#x27;s previously static, drag-and-drop workflows into dynamic, interactive experiences. Instead of manually specifying which model or tool to call and in what order, builders can now define a goal and let the agent determine the best path to reach it — selecting tools, triggering models like Gemini 3 Flash or Veo for video generation, and even initiating conversations with users when it needs more information.It sounds like a modest product update. It is not. What Google has shipped is a working reference architecture for the three capabilities that will define enterprise agents in 2026:Adaptive routingPersistent memoryHuman-in-the-loop orchestration...and it&#x27;s all made possible by the rapidly improving reasoning abilities of frontier models like the Gemini 3 series.The &#x27;off the rails&#x27; inflection point: Why better models change everything about agent designTo understand why the Opal update matters, you need to understand a shift that has been building across the agent ecosystem for months.The first wave of enterprise agent frameworks — tools like the early versions of CrewAI and the initial releases of LangGraph — were defined by a tension between autonomy and control. Early models simply were not reliable enough to be trusted with open-ended decision-making. The result was what practitioners began calling \"agents on rails\": tightly constrained workflows where every decision point, every tool call, and every branching path had to be pre-defined by a human developer.This approach worked, but it was limited. Building an agent on rails meant anticipating every possible state the system might encounter — a combinatorial nightmare for anything beyond simple, linear tasks. Worse, it meant that agents could not adapt to novel situations, the very capability that makes agentic AI valuable in the first place.The Gemini 3 series, along with recent releases like Anthropic&#x27;s Claude Opus 4.6 and Sonnet 4.6, represents a threshold where models have become reliable enough at planning, reasoning, and self-correction that the rails can start coming off. Google&#x27;s own Opal update is an acknowledgment of this shift. The new agent step does not require builders to pre-define every path through a workflow. Instead, it trusts the underlying model to evaluate the user&#x27;s goal, assess available tools, and determine the optimal sequence of actions dynamically.This is the same pattern that made Claude Code&#x27;s agentic workflows and tool calling viable: the models are good enough to decide the agent’s next step and often even to self-correct without a human manually re-prompting every error. The difference compared to Claude Code is that Google is now packaging this capability into a consumer-grade, no-code product — a strong signal that the underlying technology has matured past the experimental phase.For enterprise teams, the implication is direct: if you are still designing agent architectures that require pre-defined paths for every contingency, you are likely over-engineering. The new generation of models supports a design pattern where you define goals and constraints, provide tools, and let the model handle routing — a shift from programming agents to managing them.Memory across sessions: The feature that separates demos from production agentsThe second major addition in the Opal update is persistent memory. Google now allows Opals to remember information across sessions — user preferences, prior interactions, accumulated context — making agents that improve with use rather than starting from zero each time.Google has not disclosed the technical implementation behind Opal&#x27;s memory system. But the pattern itself is well-established in the agent-building community. Tools like OpenClaw handle memory primarily through markdown and JSON files, a simple approach that works well for single-user systems. Enterprise deployments face a harder problem: maintaining memory across multiple users, sessions, and security boundaries without leaking sensitive context between them.This single-user versus multi-user memory divide is one of the most under-discussed challenges in enterprise agent deployment. A personal coding assistant that remembers your project structure is fundamentally different from a customer-facing agent that must maintain separate memory states for thousands of concurrent users while complying with data retention policies.What the Opal update signals is that Google considers memory a core feature of agent architecture, not an optional add-on. For IT decision-makers evaluating agent platforms, this should inform procurement criteria. An agent framework without a clear memory strategy is a framework that will produce impressive demos but struggle in production, where the value of an agent compounds over repeated interactions with the same users and datasets.Human-in-the-loop is not a fallback — it is a design patternThe third pillar of the Opal update is what Google calls \"interactive chat\" — the ability for an agent to pause execution, ask the user a follow-up question, gather missing information, or present choices before proceeding. In agent architecture terminology, this is human-in-the-loop orchestration, and its inclusion in a consumer product is telling.The most effective agents in production today are not fully autonomous. They are systems that know when they have reached the limits of their confidence and can gracefully hand control back to a human. This is the pattern that separates reliable enterprise agents from the kind of runaway autonomous systems that have generated cautionary tales across the industry.In frameworks like LangGraph, human-in-the-loop has traditionally been implemented as an explicit node in the graph — a hard-coded checkpoint where execution pauses for human review. Opal&#x27;s approach is more fluid: the agent itself decides when it needs human input based on the quality and completeness of the information it has. This is a more natural interaction pattern and one that scales better, because it does not require the builder to predict in advance exactly where human intervention will be needed.For enterprise architects, the lesson is that human-in-the-loop should not just be treated as a safety net bolted on after the agent is built. It should be a first-class capability of the agent framework itself — one that the model can invoke dynamically based on its own assessment of uncertainty.Dynamic routing: Letting the model decide the pathThe final significant feature is dynamic routing, where builders can define multiple paths through a workflow and let the agent select the appropriate one based on custom criteria. Google&#x27;s example is an executive briefing agent that takes different paths depending on whether the user is meeting with a new or existing client — searching the web for background information in one case, reviewing internal meeting notes in the other.This is conceptually similar to the conditional branching that LangGraph and similar frameworks have supported for some time. But Opal&#x27;s implementation lowers the barrier dramatically by allowing builders to describe routing criteria in natural language rather than code. The model interprets the criteria and makes the routing decision, rather than requiring a developer to write explicit conditional logic.The enterprise implication is significant. Dynamic routing powered by natural language criteria means that business analysts and domain experts — not just developers — can define complex agent behaviors. This shifts agent development from a purely engineering discipline to one where domain knowledge becomes the primary bottleneck, a change that could dramatically accelerate adoption across non-technical business units.What Google is really building: An agent intelligence layerStepping back from individual features, the broader pattern in the Opal update is that Google is building an intelligence layer that sits between the user&#x27;s intent and the execution of complex, multi-step tasks. Building on lessons from an internal agent SDK called “Breadboard”, the agent step is not just another node in a workflow — it is an orchestration layer that can recruit models, invoke tools, manage memory, route dynamically, and interact with humans, all driven by the ever improving reasoning capabilities of the underlying Gemini models.This is the same architectural pattern emerging across the industry. Anthropic&#x27;s Claude Code, with its ability to autonomously manage coding tasks overnight, relies on similar principles: a capable model, access to tools, persistent context, and feedback loops that allow self-correction. The Ralph Wiggum plugin formalized the insight that models can be pressed through their own failures to arrive at correct solutions — a brute-force version of the self-correction that Opal now packages some of that into a polished consumer experience.For enterprise teams, the takeaway is that agent architecture is converging on a common set of primitives: goal-directed planning, tool use, persistent memory, dynamic routing, and human-in-the-loop orchestration. The differentiator will not be which primitives you implement, but how well you integrate them — and how effectively you leverage the improving capabilities of frontier models to reduce the amount of manual configuration required.The practical playbook for enterprise agent buildersGoogle shipping these capabilities in a free, consumer-facing product sends a clear message: the foundational patterns for building effective AI agents are no longer cutting-edge research. They are productized. Enterprise teams that have been waiting for the technology to mature now have a reference implementation they can study, test, and learn from — at zero cost.The practical steps are straightforward. First, evaluate whether your current agent architectures are over-constrained. If every decision point requires hard-coded logic, you are likely not leveraging the planning capabilities of current frontier models. Second, prioritize memory as a core architectural component, not an afterthought. Third, design human-in-the-loop as a dynamic capability the agent can invoke, rather than a fixed checkpoint in a workflow. And fourth, explore natural language routing as a way to bring domain experts into the agent design process.Opal itself probably won’t become the platform enterprises adopt. But the design patterns it embodies — adaptive, memory-rich, human-aware agents powered by frontier models — are the patterns that will define the next generation of enterprise AI. Google has shown its hand. The question for IT leaders is whether they are paying attention.",
          "feed_position": 2,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/5IHY5EKUtp8R9dSKGLvxRT/94a1ffd7e5709a24b1e8229687cf42ac/Gemini_Generated_Image_1r6vew1r6vew1r6v.png?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/openais-big-investment-from-aws-comes-with-something-else-new-stateful",
          "published_at": "Fri, 27 Feb 2026 23:16:00 GMT",
          "title": "OpenAI's big investment from Amazon comes with something else: new 'stateful' architecture for enterprise agents",
          "standfirst": "The landscape of enterprise artificial intelligence shifted fundamentally today as OpenAI announced $110 billion in new funding from three of tech&#x27;s largest firms: $30 billion from SoftBank, $30 billion from Nvidia, and $50 billion from Amazon.But while the former two players are providing money, OpenAI is going further with Amazon in a new direction, establishing an upcoming fully \"Stateful Runtime Environment\" on Amazon Web Services (AWS), the world&#x27;s most used cloud environment.This signals OpenAI&#x27;s and Amazon&#x27;s vision of the next phase of the AI economy — moving from chatbots to autonomous \"AI coworkers\" known as agents — and that this evolution requires a different architectural foundation than the one that built GPT-4. For enterprise decision-makers, this announcement isn’t just a headline about massive capital; it is a technical roadmap for where the next generation of agentic intelligence will live and breathe.And especially for those enterprises currently using AWS, it&#x27;s great news, giving them more options with a new runtime environment from OpenAI coming soon (the companies have yet to announce a precise timeline for when it will arrive).The great divide between &#x27;stateless&#x27; and &#x27;stateful&#x27;At the heart of the new OpenAI-Amazon partnership is a technical distinction that will define developer workflows for the next decade: the difference between \"stateless\" and \"stateful\" environments.To date, most developers have interacted with OpenAI through stateless APIs. In a stateless model, every request is an isolated event; the model has no \"memory\" of previous interactions unless the developer manually feeds the entire conversation history back into the prompt. OpenAI&#x27;s prior cloud partner and major investor, Microsoft Azure, remains the exclusive third-party cloud provider for these stateless APIs.The newly announced Stateful Runtime Environment, by contrast, will be hosted on Amazon Bedrock — a paradigm shift. This environment allows models to maintain persistent context, memory, and identity. Rather than a series of disconnected calls, the stateful environment enables \"AI coworkers\" to handle ongoing projects, remember prior work, and move seamlessly across different software tools and data sources. As OpenAI notes on its website: \"Now, instead of manually stitching together disconnected requests to make things work, your agents automatically execute complex steps with &#x27;working context&#x27; that carries forward memory/history, tool and workflow state, environment use, and identity/permission boundaries.\"For builders of complex agents, this reduces the \"plumbing\" required to maintain context, as the infrastructure itself now handles the persistent state of the agent.OpenAI Frontier and the AWS IntegrationThe vehicle for this stateful intelligence is OpenAI Frontier, an end-to-end platform designed to help enterprises build, deploy, and manage teams of AI agents, launched back in early February 2026. Frontier is positioned as a solution to the \"AI opportunity gap\"—the disconnect between model capabilities and the ability of a business to actually put them into production.Key features of the Frontier platform include:Shared Business Context: Connecting siloed data from CRMs, ticketing tools, and internal databases into a single semantic layer.Agent Execution Environment: A dependable space where agents can run code, use computer tools, and solve real-world problems. Built-in Governance: Every AI agent has a unique identity with explicit permissions and boundaries, allowing for use in regulated environments.While the Frontier application itself will continue to be hosted on Microsoft Azure, AWS has been named the exclusive third-party cloud distribution provider for the platform. This means that while the \"engine\" may sit on Azure, AWS customers will be able to access and manage these agentic workloads directly through Amazon Bedrock, integrated with AWS’s existing infrastructure services.OpenAI opens the door to enterprises: how to register your interest in its upcoming new Stateful Runtime Environment on AWSFor now, OpenAI has launched a dedicated Enterprise Interest Portal on its website. This serves as the primary intake point for organizations looking to move past isolated pilots and into production-grade agentic workflows.The portal is a structured \"request for access\" form where decision-makers provide:Firmographic Data: Basic details including company size (ranging from startups of 1–50 to large-scale enterprises with 20,000+ employees) and contact information.Business Needs Assessment: A dedicated field for leadership to outline specific business challenges and requirements for \"AI coworkers\".By submitting this form, enterprises signal their readiness to work directly with OpenAI and AWS teams to implement solutions like multi-system customer support, sales operations, and finance audits that require high-reliability state management.Community and leadership reactionsThe scale of the announcement was mirrored in the public statements from the key players on social media.Sam Altman, CEO of OpenAI, expressed excitement about the Amazon partnership, specifically highlighting the \"stateful runtime environment\" and the use of Amazon&#x27;s custom Trainium chips. However, Altman was quick to clarify the boundaries of the deal: \"Our stateless API will remain exclusive to Azure, and we will build out much more capacity with them\".Amazon CEO Andy Jassy emphasized the demand from his own customer base, stating, \"We have lots of developers and companies eager to run services powered by OpenAI models on AWS\". He noted that the collaboration would \"change what’s possible for customers building AI apps and agents\".Early adopters have already begun to weigh in on the utility of the Frontier approach. Joe Park, EVP at State Farm, noted that the platform is helping the company accelerate its AI capabilities to \"help millions plan ahead, protect what matters most, and recover faster\".The enterprise decision: where to spend your dollars?For CTOs and enterprise decision-makers, the OpenAI-Amazon-Microsoft triangle creates a new set of strategic choices. The decision of where to allocate budget now depends heavily on the specific use case:For High-Volume, Standard Tasks: If your organization relies on standard API calls for content generation, summarization, or simple chat, Microsoft Azure remains the primary destination. These \"stateless\" calls are exclusive to Azure, even if they originate from an Amazon-linked collaboration.For Complex, Long-Running Agents: If your goal is to build \"AI coworkers\" that require deep integration with AWS-hosted data and persistent memory across weeks of work, the AWS Stateful Runtime Environment is the clear choice.For Custom Infrastructure: OpenAI has committed to consuming 2 gigawatts of AWS Trainium capacity to power Frontier and other advanced workloads. This suggests that enterprises looking for the most cost-efficient way to run OpenAI models at massive scale may find an advantage in the AWS-Trainium ecosystem.Licensing, revenue and the Microsoft &#x27;safety net&#x27;Despite the massive infusion of Amazon capital, the legal and financial ties between Microsoft and OpenAI remain remarkably rigid. A joint statement released by both companies clarified that their \"commercial and revenue share relationship remains unchanged\".Crucially, Microsoft continues to maintain its \"exclusive license and access to intellectual property across OpenAI models and products\". Furthermore, Microsoft will receive a share of the revenue generated by the OpenAI-Amazon partnership. This ensures that while OpenAI is diversifying its infrastructure, Microsoft remains the ultimate beneficiary of OpenAI’s commercial success, regardless of which cloud the compute actually runs on.The definition of Artificial General Intelligence (AGI) also remains a protected term in the Microsoft agreement. The contractual processes for determining when AGI has been reached—and the subsequent impact on commercial licensing—have not been altered by the Amazon deal.Ultimately, OpenAI is positioning itself as more than a model or tool provider; it is an infrastructure player attempting to straddle the two largest clouds on Earth. For the user, this means more choice and more specialized environments. For the enterprise, it means that the era of \"one-size-fits-all\" AI procurement is over. The choice between Azure and AWS for OpenAI services is now a technical decision about the nature of the work itself: whether your AI needs to simply \"think\" (stateless) or to \"remember and act\" (stateful).",
          "content": "The landscape of enterprise artificial intelligence shifted fundamentally today as OpenAI announced $110 billion in new funding from three of tech&#x27;s largest firms: $30 billion from SoftBank, $30 billion from Nvidia, and $50 billion from Amazon.But while the former two players are providing money, OpenAI is going further with Amazon in a new direction, establishing an upcoming fully \"Stateful Runtime Environment\" on Amazon Web Services (AWS), the world&#x27;s most used cloud environment.This signals OpenAI&#x27;s and Amazon&#x27;s vision of the next phase of the AI economy — moving from chatbots to autonomous \"AI coworkers\" known as agents — and that this evolution requires a different architectural foundation than the one that built GPT-4. For enterprise decision-makers, this announcement isn’t just a headline about massive capital; it is a technical roadmap for where the next generation of agentic intelligence will live and breathe.And especially for those enterprises currently using AWS, it&#x27;s great news, giving them more options with a new runtime environment from OpenAI coming soon (the companies have yet to announce a precise timeline for when it will arrive).The great divide between &#x27;stateless&#x27; and &#x27;stateful&#x27;At the heart of the new OpenAI-Amazon partnership is a technical distinction that will define developer workflows for the next decade: the difference between \"stateless\" and \"stateful\" environments.To date, most developers have interacted with OpenAI through stateless APIs. In a stateless model, every request is an isolated event; the model has no \"memory\" of previous interactions unless the developer manually feeds the entire conversation history back into the prompt. OpenAI&#x27;s prior cloud partner and major investor, Microsoft Azure, remains the exclusive third-party cloud provider for these stateless APIs.The newly announced Stateful Runtime Environment, by contrast, will be hosted on Amazon Bedrock — a paradigm shift. This environment allows models to maintain persistent context, memory, and identity. Rather than a series of disconnected calls, the stateful environment enables \"AI coworkers\" to handle ongoing projects, remember prior work, and move seamlessly across different software tools and data sources. As OpenAI notes on its website: \"Now, instead of manually stitching together disconnected requests to make things work, your agents automatically execute complex steps with &#x27;working context&#x27; that carries forward memory/history, tool and workflow state, environment use, and identity/permission boundaries.\"For builders of complex agents, this reduces the \"plumbing\" required to maintain context, as the infrastructure itself now handles the persistent state of the agent.OpenAI Frontier and the AWS IntegrationThe vehicle for this stateful intelligence is OpenAI Frontier, an end-to-end platform designed to help enterprises build, deploy, and manage teams of AI agents, launched back in early February 2026. Frontier is positioned as a solution to the \"AI opportunity gap\"—the disconnect between model capabilities and the ability of a business to actually put them into production.Key features of the Frontier platform include:Shared Business Context: Connecting siloed data from CRMs, ticketing tools, and internal databases into a single semantic layer.Agent Execution Environment: A dependable space where agents can run code, use computer tools, and solve real-world problems. Built-in Governance: Every AI agent has a unique identity with explicit permissions and boundaries, allowing for use in regulated environments.While the Frontier application itself will continue to be hosted on Microsoft Azure, AWS has been named the exclusive third-party cloud distribution provider for the platform. This means that while the \"engine\" may sit on Azure, AWS customers will be able to access and manage these agentic workloads directly through Amazon Bedrock, integrated with AWS’s existing infrastructure services.OpenAI opens the door to enterprises: how to register your interest in its upcoming new Stateful Runtime Environment on AWSFor now, OpenAI has launched a dedicated Enterprise Interest Portal on its website. This serves as the primary intake point for organizations looking to move past isolated pilots and into production-grade agentic workflows.The portal is a structured \"request for access\" form where decision-makers provide:Firmographic Data: Basic details including company size (ranging from startups of 1–50 to large-scale enterprises with 20,000+ employees) and contact information.Business Needs Assessment: A dedicated field for leadership to outline specific business challenges and requirements for \"AI coworkers\".By submitting this form, enterprises signal their readiness to work directly with OpenAI and AWS teams to implement solutions like multi-system customer support, sales operations, and finance audits that require high-reliability state management.Community and leadership reactionsThe scale of the announcement was mirrored in the public statements from the key players on social media.Sam Altman, CEO of OpenAI, expressed excitement about the Amazon partnership, specifically highlighting the \"stateful runtime environment\" and the use of Amazon&#x27;s custom Trainium chips. However, Altman was quick to clarify the boundaries of the deal: \"Our stateless API will remain exclusive to Azure, and we will build out much more capacity with them\".Amazon CEO Andy Jassy emphasized the demand from his own customer base, stating, \"We have lots of developers and companies eager to run services powered by OpenAI models on AWS\". He noted that the collaboration would \"change what’s possible for customers building AI apps and agents\".Early adopters have already begun to weigh in on the utility of the Frontier approach. Joe Park, EVP at State Farm, noted that the platform is helping the company accelerate its AI capabilities to \"help millions plan ahead, protect what matters most, and recover faster\".The enterprise decision: where to spend your dollars?For CTOs and enterprise decision-makers, the OpenAI-Amazon-Microsoft triangle creates a new set of strategic choices. The decision of where to allocate budget now depends heavily on the specific use case:For High-Volume, Standard Tasks: If your organization relies on standard API calls for content generation, summarization, or simple chat, Microsoft Azure remains the primary destination. These \"stateless\" calls are exclusive to Azure, even if they originate from an Amazon-linked collaboration.For Complex, Long-Running Agents: If your goal is to build \"AI coworkers\" that require deep integration with AWS-hosted data and persistent memory across weeks of work, the AWS Stateful Runtime Environment is the clear choice.For Custom Infrastructure: OpenAI has committed to consuming 2 gigawatts of AWS Trainium capacity to power Frontier and other advanced workloads. This suggests that enterprises looking for the most cost-efficient way to run OpenAI models at massive scale may find an advantage in the AWS-Trainium ecosystem.Licensing, revenue and the Microsoft &#x27;safety net&#x27;Despite the massive infusion of Amazon capital, the legal and financial ties between Microsoft and OpenAI remain remarkably rigid. A joint statement released by both companies clarified that their \"commercial and revenue share relationship remains unchanged\".Crucially, Microsoft continues to maintain its \"exclusive license and access to intellectual property across OpenAI models and products\". Furthermore, Microsoft will receive a share of the revenue generated by the OpenAI-Amazon partnership. This ensures that while OpenAI is diversifying its infrastructure, Microsoft remains the ultimate beneficiary of OpenAI’s commercial success, regardless of which cloud the compute actually runs on.The definition of Artificial General Intelligence (AGI) also remains a protected term in the Microsoft agreement. The contractual processes for determining when AGI has been reached—and the subsequent impact on commercial licensing—have not been altered by the Amazon deal.Ultimately, OpenAI is positioning itself as more than a model or tool provider; it is an infrastructure player attempting to straddle the two largest clouds on Earth. For the user, this means more choice and more specialized environments. For the enterprise, it means that the era of \"one-size-fits-all\" AI procurement is over. The choice between Azure and AWS for OpenAI services is now a technical decision about the nature of the work itself: whether your AI needs to simply \"think\" (stateless) or to \"remember and act\" (stateful).",
          "feed_position": 3,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/7bL3HaJIq1X5vb82aJqp93/0de52a58f30cce531f66f30ead20337f/Gemini_Generated_Image_nxfyvknxfyvknxfy.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/google-and-openai-employees-sign-open-letter-in-solidarity-with-anthropic-194957274.html",
          "published_at": "Fri, 27 Feb 2026 19:49:57 +0000",
          "title": "Google and OpenAI employees sign open letter in ‘solidarity’ with Anthropic",
          "standfirst": "Hundreds of employees at Google and OpenAI have signed an open letter urging their companies to stand with Anthropic in its standoff with the Pentagon over military applications for AI tools like Claude. The letter, titled “We Will Not Be Divided,” calls on the leadership of both companies to “put aside their differences and stand together to continue to refuse the Department of War’s current demands for permission to use our models for domestic mass surveillance and autonomously killing people without human oversight.” These are two lines that Anthropic CEO Dario Amodei has said should not be crossed by his or any other AI company. As of publication, the letter has over 450 signatures, almost 400 of which come from Google employees and the rest from OpenAI. Currently, roughly 50 percent of all participants have chosen to attach their names to the cause, with the rest remaining anonymous. All are verified as current employees of these companies. The original organizers of the letter aren’t Google or OpenAI employees; they say are unaffiliated with any AI company, political party or advocacy group. The open letter is the latest development in the saga between Anthropic and US Defense Secretary Pete Hegseth, who threatened to label the company a “supply chain risk” if it did not agree to withdraw certain guardrails for classified work. The Pentagon has also been in talks with Google and OpenAI about using their models for classified work, with xAI coming on board earlier this week. The letter argues the government is \"trying to divide each company with fear that the other will give in.” OpenAI CEO Sam Altman told his employees on Friday that the ChatGPT maker will draw the same red lines as Anthropic, according to an internal memo seen by Axios. He told CNBC on the same day that he doesn't \"personally think the Pentagon should be threatening DPA against these companies.\"This article originally appeared on Engadget at https://www.engadget.com/ai/google-and-openai-employees-sign-open-letter-in-solidarity-with-anthropic-194957274.html?src=rss",
          "content": "Hundreds of employees at Google and OpenAI have signed an open letter urging their companies to stand with Anthropic in its standoff with the Pentagon over military applications for AI tools like Claude. The letter, titled “We Will Not Be Divided,” calls on the leadership of both companies to “put aside their differences and stand together to continue to refuse the Department of War’s current demands for permission to use our models for domestic mass surveillance and autonomously killing people without human oversight.” These are two lines that Anthropic CEO Dario Amodei has said should not be crossed by his or any other AI company. As of publication, the letter has over 450 signatures, almost 400 of which come from Google employees and the rest from OpenAI. Currently, roughly 50 percent of all participants have chosen to attach their names to the cause, with the rest remaining anonymous. All are verified as current employees of these companies. The original organizers of the letter aren’t Google or OpenAI employees; they say are unaffiliated with any AI company, political party or advocacy group. The open letter is the latest development in the saga between Anthropic and US Defense Secretary Pete Hegseth, who threatened to label the company a “supply chain risk” if it did not agree to withdraw certain guardrails for classified work. The Pentagon has also been in talks with Google and OpenAI about using their models for classified work, with xAI coming on board earlier this week. The letter argues the government is \"trying to divide each company with fear that the other will give in.” OpenAI CEO Sam Altman told his employees on Friday that the ChatGPT maker will draw the same red lines as Anthropic, according to an internal memo seen by Axios. He told CNBC on the same day that he doesn't \"personally think the Pentagon should be threatening DPA against these companies.\"This article originally appeared on Engadget at https://www.engadget.com/ai/google-and-openai-employees-sign-open-letter-in-solidarity-with-anthropic-194957274.html?src=rss",
          "feed_position": 12
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/security/enterprise-mcp-adoption-is-outpacing-security-controls",
          "published_at": "Fri, 27 Feb 2026 19:00:00 GMT",
          "title": "Enterprise MCP adoption is outpacing security controls",
          "standfirst": "AI agents now carry more access and more connections to enterprise systems than any other software in the environment. That makes them a bigger attack surface than anything security teams have had to govern before, and the industry doesn&#x27;t yet have a framework for it. \"If that attack vector gets utilized, it can result in a data breach, or even worse,\" said Spiros Xanthos, founder and CEO of Resolve AI, speaking at a recent VentureBeat AI Impact Series event. Traditional security frameworks are built around human interactions. There&#x27;s not yet an agreed-upon construct for AI agents that have personas and can work autonomously, noted Jon Aniano, SVP of product and CRM applications at Zendesk, at the same event. Agentic AI is moving faster than enterprises can build guardrails — and Model Context Protocol (MCP), while decreasing integration complexity, is making the problem worse. “Right now it&#x27;s an unsolved problem because it&#x27;s the wild, wild West,” Aniano said. “We don&#x27;t even have a defined technical agent-to-agent protocol that all companies agree on. How do you balance user expectations versus what keeps your platform safe?”MCP still \"extremely permissive\" Enterprises are increasingly hooking into MCP servers because they simplify integration between agents, tools and data. However, MCP servers tend to be “extremely permissive,” he said. They are “actually probably worse than an API,” he contended, because APIs at least have more controls in place to impose upon agents. Today&#x27;s agents are acting on behalf of humans based on explicit permissions, thus establishing human accountability. \"But you might have tens, hundreds of agents in the future with their own identity, their own access,\" said Xanthos. \"It becomes a very complex matrix.\" Even as his startup is developing autonomous AI agents for site reliability engineering (SRE) and system management, he acknowledged that the industry “completely lacks the framework” for autonomous agents. “It&#x27;s completely on us and to anybody who builds agents to figure out what restrictions to give them,” he said. And customers must be able to trust those decisions. Some existing security tools do offer fine-grained access — Splunk, for instance, developed a method to provide access to certain indexes in underlying data stores, he noted — but most are broader and human-oriented. “We&#x27;re trying to figure this out with existing tools,” he said. \"But I don&#x27;t think they&#x27;re sufficient for the era of agents.” Who&#x27;s accountable when an AI mis-authenticates a user?At Zendesk and other customer relationship management (CRM) platform providers, AI is involved in a number of user interactions, Aniano noted — in fact, now it’s at a “volume and a scale that we haven&#x27;t contemplated as businesses and as a society.” It can get tricky when AI is helping out human agents; the audit trail can become a labyrinth. “So now you&#x27;ve got a human talking to a human that&#x27;s talking to an AI,” Aniano noted. “The human tells the AI to take action. Who&#x27;s at fault if it&#x27;s the wrong action?” This becomes even more complicated when there are “multiple pieces of AI and multiple humans\" in the mix. To prevent agents from going off the rails, Zendesk tends to be “very strict” about access and scope; however, customers can define their own guardrails based on their needs. In most cases, AI can access knowledge sources, but they’re not writing code or running commands on servers, Aniano said. If an AI does call an API, it is “declaratively designed” and sanctioned, and actions are specifically called out. However, customer demand is flooding these scenarios and “we&#x27;re kind of holding the gates right now,” he said. The industry must develop concrete standards for agent interactions. “We&#x27;re entering a world where, with things like MCP that can auto-discover tools, we&#x27;re going to have to create new methods of safety for deciding what tools these bots can interact with,” said Aniano. When it comes to security, enterprises are rightly concerned when AI takes over authentication tasks, such as sending out and processing one-time passwords (OTP), SMS codes, or other two-step verification methods, he said. What happens if an AI mis-authenticates or misidentifies someone? This can lead to sensitive data leakage or open the door for attackers. “There&#x27;s a spectrum now, and the end of that spectrum today is a human,” Aniano said. However, “the end of that spectrum tomorrow might be a specialized agent designed to do the same kind of gut feeling or human-level interaction.” Customers themselves are on a spectrum of adoption and comfort. In certain companies — particularly financial services or other highly-regulated environments — humans still must be involved in authentication, Aniano noted. In other cases, legacy companies or old guards only trust humans to authenticate other humans. He noted that Zendesk is experimenting with new AI agents that are “a little more connected to systems,” and working with a select group of customers around guardrailing. Standing authorization is comingIn some future, agents may actually be more trusted than humans to do some tasks, and granted permissions “way beyond” what humans have today, Xanthos said. But we’re a long way from that, and, for the most part, the fear of something going wrong is what’s holding enterprises back. “Which is a good fear, right? I&#x27;m not saying that it is a bad thing,” he said. Many enterprises simply aren&#x27;t yet comfortable with an agent doing all steps of a workflow or fully closing the loop by itself. They still want human review. Resolve AI is on the cusp of giving agents standing authorization in a few cases that are “generally safe,” such as in coding; from there they’ll move to more open-ended scenarios that are not all that risky, Xanthos explained. But he acknowledged that there will always be very risky situations where AI mistakes could “mutate the state of the production system,” as he put it. Ultimately, though: “There&#x27;s no going back, obviously; this is moving faster than maybe even mobile did. So the question is what do we do about it?”What security teams can do nowBoth speakers pointed to interim measures available within existing tooling. Xanthos noted that some tools — Splunk among them — already offer fine-grained index-level access controls that can be applied to agents. Aniano described Zendesk&#x27;s approach as a practical starting point: declaratively designed API calls with explicitly sanctioned actions, strict access and scope limits, and human review before expanding agent permissions. The underlying principle, as Aniano put it: \"We&#x27;re always checking those gates and seeing how we can widen the aperture\" — meaning don&#x27;t grant standing authorization until you&#x27;ve validated each expansion.",
          "content": "AI agents now carry more access and more connections to enterprise systems than any other software in the environment. That makes them a bigger attack surface than anything security teams have had to govern before, and the industry doesn&#x27;t yet have a framework for it. \"If that attack vector gets utilized, it can result in a data breach, or even worse,\" said Spiros Xanthos, founder and CEO of Resolve AI, speaking at a recent VentureBeat AI Impact Series event. Traditional security frameworks are built around human interactions. There&#x27;s not yet an agreed-upon construct for AI agents that have personas and can work autonomously, noted Jon Aniano, SVP of product and CRM applications at Zendesk, at the same event. Agentic AI is moving faster than enterprises can build guardrails — and Model Context Protocol (MCP), while decreasing integration complexity, is making the problem worse. “Right now it&#x27;s an unsolved problem because it&#x27;s the wild, wild West,” Aniano said. “We don&#x27;t even have a defined technical agent-to-agent protocol that all companies agree on. How do you balance user expectations versus what keeps your platform safe?”MCP still \"extremely permissive\" Enterprises are increasingly hooking into MCP servers because they simplify integration between agents, tools and data. However, MCP servers tend to be “extremely permissive,” he said. They are “actually probably worse than an API,” he contended, because APIs at least have more controls in place to impose upon agents. Today&#x27;s agents are acting on behalf of humans based on explicit permissions, thus establishing human accountability. \"But you might have tens, hundreds of agents in the future with their own identity, their own access,\" said Xanthos. \"It becomes a very complex matrix.\" Even as his startup is developing autonomous AI agents for site reliability engineering (SRE) and system management, he acknowledged that the industry “completely lacks the framework” for autonomous agents. “It&#x27;s completely on us and to anybody who builds agents to figure out what restrictions to give them,” he said. And customers must be able to trust those decisions. Some existing security tools do offer fine-grained access — Splunk, for instance, developed a method to provide access to certain indexes in underlying data stores, he noted — but most are broader and human-oriented. “We&#x27;re trying to figure this out with existing tools,” he said. \"But I don&#x27;t think they&#x27;re sufficient for the era of agents.” Who&#x27;s accountable when an AI mis-authenticates a user?At Zendesk and other customer relationship management (CRM) platform providers, AI is involved in a number of user interactions, Aniano noted — in fact, now it’s at a “volume and a scale that we haven&#x27;t contemplated as businesses and as a society.” It can get tricky when AI is helping out human agents; the audit trail can become a labyrinth. “So now you&#x27;ve got a human talking to a human that&#x27;s talking to an AI,” Aniano noted. “The human tells the AI to take action. Who&#x27;s at fault if it&#x27;s the wrong action?” This becomes even more complicated when there are “multiple pieces of AI and multiple humans\" in the mix. To prevent agents from going off the rails, Zendesk tends to be “very strict” about access and scope; however, customers can define their own guardrails based on their needs. In most cases, AI can access knowledge sources, but they’re not writing code or running commands on servers, Aniano said. If an AI does call an API, it is “declaratively designed” and sanctioned, and actions are specifically called out. However, customer demand is flooding these scenarios and “we&#x27;re kind of holding the gates right now,” he said. The industry must develop concrete standards for agent interactions. “We&#x27;re entering a world where, with things like MCP that can auto-discover tools, we&#x27;re going to have to create new methods of safety for deciding what tools these bots can interact with,” said Aniano. When it comes to security, enterprises are rightly concerned when AI takes over authentication tasks, such as sending out and processing one-time passwords (OTP), SMS codes, or other two-step verification methods, he said. What happens if an AI mis-authenticates or misidentifies someone? This can lead to sensitive data leakage or open the door for attackers. “There&#x27;s a spectrum now, and the end of that spectrum today is a human,” Aniano said. However, “the end of that spectrum tomorrow might be a specialized agent designed to do the same kind of gut feeling or human-level interaction.” Customers themselves are on a spectrum of adoption and comfort. In certain companies — particularly financial services or other highly-regulated environments — humans still must be involved in authentication, Aniano noted. In other cases, legacy companies or old guards only trust humans to authenticate other humans. He noted that Zendesk is experimenting with new AI agents that are “a little more connected to systems,” and working with a select group of customers around guardrailing. Standing authorization is comingIn some future, agents may actually be more trusted than humans to do some tasks, and granted permissions “way beyond” what humans have today, Xanthos said. But we’re a long way from that, and, for the most part, the fear of something going wrong is what’s holding enterprises back. “Which is a good fear, right? I&#x27;m not saying that it is a bad thing,” he said. Many enterprises simply aren&#x27;t yet comfortable with an agent doing all steps of a workflow or fully closing the loop by itself. They still want human review. Resolve AI is on the cusp of giving agents standing authorization in a few cases that are “generally safe,” such as in coding; from there they’ll move to more open-ended scenarios that are not all that risky, Xanthos explained. But he acknowledged that there will always be very risky situations where AI mistakes could “mutate the state of the production system,” as he put it. Ultimately, though: “There&#x27;s no going back, obviously; this is moving faster than maybe even mobile did. So the question is what do we do about it?”What security teams can do nowBoth speakers pointed to interim measures available within existing tooling. Xanthos noted that some tools — Splunk among them — already offer fine-grained index-level access controls that can be applied to agents. Aniano described Zendesk&#x27;s approach as a practical starting point: declaratively designed API calls with explicitly sanctioned actions, strict access and scope limits, and human review before expanding agent permissions. The underlying principle, as Aniano put it: \"We&#x27;re always checking those gates and seeing how we can widen the aperture\" — meaning don&#x27;t grant standing authorization until you&#x27;ve validated each expansion.",
          "feed_position": 4,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/2Il8GmCHR0jPAk1Zy5HOpa/3b698463f3151cc8969ea9b9601718ae/1Password.jpg?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/openai-secures-another-110-billion-in-funding-from-amazon-nvidia-and-softbank-171006356.html",
          "published_at": "Fri, 27 Feb 2026 17:10:07 +0000",
          "title": "OpenAI secures another $110 billion in funding from Amazon, NVIDIA and SoftBank",
          "standfirst": "OpenAI just announced a massive funding round of $110 billion, which is one of the biggest investment rounds in Silicon Valley history. The investors feature many of the usual suspects, including Amazon with $50 billion, NVIDIA with $30 billion and SoftBank with $30 billion. This investment brings OpenAI to a $730 billion valuation \"We’re super excited about this deal,\" OpenAI CEO Sam Altman told CNBC. \"AI is going to happen everywhere.\" That last statement seems more like a threat than a boast, but I digress. Beyond the funding round, OpenAI has announced strategic partnerships with both NVIDIA and Amazon. This will involve Amazon Web Services (AWS) running OpenAI models for enterprise customers to \"build generative AI applications and agents at production scale.\" It also names AWS as the exclusive third-party cloud distribution provider for OpenAI Frontier, which is an agentic enterprise platform. OpenAI has also committed to consuming 2 gigawatts of Amazon's Trainium capacity, which is the company's custom-designed AI training accelerator. In other words, Amazon is spending a lot of money on OpenAI and then OpenAI will turn around and spend a lot of money with Amazon. The AI funding ouroboros continues. It's also worth noting that Amazon's investment in OpenAI will be staggered. The funding begins with $15 billion, but the remaining $35 billion will only be invested when certain conditions are met. Oddly, it's been reported that one condition is that OpenAI achieves artificial general intelligence. AGI is when AI evolves to or beyond human-level abilities, at which point the entire world turns into rainbows and everyone gets a pony. This could happen later this year, according to those bullish on the technology, or never, according to many researchers. Sam Altman said it was coming in 2025 but has since grown weary of the term. The new partnership with NVIDIA evolves the long-standing collaboration between the two companies. OpenAI has pledged to consume 2 gigawatts of training capacity on NVIDIA's Vera Rubin systems and an additional 3 gigawatts of computing resources, likely in the form of GPUs, to run specific AI inference tasks. In other words, NVIDIA is spending a lot of money on OpenAI and then OpenAI will turn around and spend a lot of money with NVIDIA. The ouroboros must feed. As for revenue, OpenAI has forecast a massive loss of $14 billion in 2026. It lost around $5 billion in 2024 and reports estimate a loss of $8 billion in 2025. Despite this trajectory, the company claims it'll be raking in $100 billion in revenue by 2029.This article originally appeared on Engadget at https://www.engadget.com/ai/openai-secures-another-110-billion-in-funding-from-amazon-nvidia-and-softbank-171006356.html?src=rss",
          "content": "OpenAI just announced a massive funding round of $110 billion, which is one of the biggest investment rounds in Silicon Valley history. The investors feature many of the usual suspects, including Amazon with $50 billion, NVIDIA with $30 billion and SoftBank with $30 billion. This investment brings OpenAI to a $730 billion valuation \"We’re super excited about this deal,\" OpenAI CEO Sam Altman told CNBC. \"AI is going to happen everywhere.\" That last statement seems more like a threat than a boast, but I digress. Beyond the funding round, OpenAI has announced strategic partnerships with both NVIDIA and Amazon. This will involve Amazon Web Services (AWS) running OpenAI models for enterprise customers to \"build generative AI applications and agents at production scale.\" It also names AWS as the exclusive third-party cloud distribution provider for OpenAI Frontier, which is an agentic enterprise platform. OpenAI has also committed to consuming 2 gigawatts of Amazon's Trainium capacity, which is the company's custom-designed AI training accelerator. In other words, Amazon is spending a lot of money on OpenAI and then OpenAI will turn around and spend a lot of money with Amazon. The AI funding ouroboros continues. It's also worth noting that Amazon's investment in OpenAI will be staggered. The funding begins with $15 billion, but the remaining $35 billion will only be invested when certain conditions are met. Oddly, it's been reported that one condition is that OpenAI achieves artificial general intelligence. AGI is when AI evolves to or beyond human-level abilities, at which point the entire world turns into rainbows and everyone gets a pony. This could happen later this year, according to those bullish on the technology, or never, according to many researchers. Sam Altman said it was coming in 2025 but has since grown weary of the term. The new partnership with NVIDIA evolves the long-standing collaboration between the two companies. OpenAI has pledged to consume 2 gigawatts of training capacity on NVIDIA's Vera Rubin systems and an additional 3 gigawatts of computing resources, likely in the form of GPUs, to run specific AI inference tasks. In other words, NVIDIA is spending a lot of money on OpenAI and then OpenAI will turn around and spend a lot of money with NVIDIA. The ouroboros must feed. As for revenue, OpenAI has forecast a massive loss of $14 billion in 2026. It lost around $5 billion in 2024 and reports estimate a loss of $8 billion in 2025. Despite this trajectory, the company claims it'll be raking in $100 billion in revenue by 2029.This article originally appeared on Engadget at https://www.engadget.com/ai/openai-secures-another-110-billion-in-funding-from-amazon-nvidia-and-softbank-171006356.html?src=rss",
          "feed_position": 14
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/general/the-morning-after-engadget-newsletter-144951777.html",
          "published_at": "Fri, 27 Feb 2026 15:02:12 +0000",
          "title": "The Morning After: The Galaxy S26 Ultra’s Privacy Display is pretty cool",
          "standfirst": "Samsung’s Unpacked event midweek revealed three new phones and two sets of earbuds, but the real standout, as usual, is the Galaxy S26 Ultra. This year, the Ultra actually features a bit of genuine tech innovation — and no, we don’t mean it folds. Let’s talk about its new Privacy Display. This isn't a shimmery, holographic screen protector that’s hard to read and constantly peels off at the corners; this tech is engineered directly into the S26 Ultra’s OLED display. Samsung Display revealed its Flex Magic Pixel technology back in 2024. The S26 Ultra’s Privacy Display is built off the back of this. It controls the direction of light emitted from the AMOLED at the pixel level, integrating wide-angle and narrow-angle pixel arrays so the display can switch between a wide-angle viewing experience and more private, straight-on views. While HP’s SureView tech is similar, the amount of customization possible is incredible — and we all have our phones out in public much more than our… HP laptops. It could be perfect for keeping prying eyes off your banking apps, messaging apps and even dating apps. Otherwise, the rest of the S26 series offers incremental updates with better cameras and newer processors. This makes the base S26 and S26+ a harder sell unless your current Galaxy phone is several years old. Also, following the 2026 trend, they are all pricier this year. Make sure you check out our early impressions (S26 Ultra, S26, Galaxy Buds 4); reviews are coming soon. — Mat Smith The other big stories (and deals) this morning Apple and Netflix are teaming up to share Formula 1 programming Burger King will use AI to monitor employee ’friendliness’ Canadian government demands safety changes from OpenAI Amazon introduces three personality styles for Alexa+ Ambient Dreamie bedside companion review How much for a good night’s sleep? $250? Cheyenne MacDonald for Engadget Ambient’s dedicated alarm clock offers many of the conveniences of your smartphone alarms — highly customizable alarm schedules, a library of soundscapes and noise masks and even Bluetooth so you can connect earbuds. There’s no subscription, it sounds great and sleep insights are supposedly incoming. However, $250 is a lot. Check out our full review. Continue reading. An AI-generated Resident Evil Requiem review briefly made it on Metacritic By a video game news site owned by ClickOut Media. Review aggregator Metacritic has removed a review of Resident Evil Requiem because it was AI generated. Kotaku explained the review was published by UK gaming site VideoGamer, but appears to be “written” by a fake AI journalist rather than a real person. “Brian Merrygold” doesn’t seem to exist. The author’s profile on VideoGamer is just as awkwardly written as the review, and the profile picture of the account also appears to be AI-generated. Literally, the file name includes “ChatGPT-Image.” ClickOut Media, the company that owns VideoGamer and a collection of other publications, reportedly laid off the staff of its gaming sites earlier this month to pivot to AI-generated content. Here it is. Continue reading. This article originally appeared on Engadget at https://www.engadget.com/general/the-morning-after-engadget-newsletter-144951777.html?src=rss",
          "content": "Samsung’s Unpacked event midweek revealed three new phones and two sets of earbuds, but the real standout, as usual, is the Galaxy S26 Ultra. This year, the Ultra actually features a bit of genuine tech innovation — and no, we don’t mean it folds. Let’s talk about its new Privacy Display. This isn't a shimmery, holographic screen protector that’s hard to read and constantly peels off at the corners; this tech is engineered directly into the S26 Ultra’s OLED display. Samsung Display revealed its Flex Magic Pixel technology back in 2024. The S26 Ultra’s Privacy Display is built off the back of this. It controls the direction of light emitted from the AMOLED at the pixel level, integrating wide-angle and narrow-angle pixel arrays so the display can switch between a wide-angle viewing experience and more private, straight-on views. While HP’s SureView tech is similar, the amount of customization possible is incredible — and we all have our phones out in public much more than our… HP laptops. It could be perfect for keeping prying eyes off your banking apps, messaging apps and even dating apps. Otherwise, the rest of the S26 series offers incremental updates with better cameras and newer processors. This makes the base S26 and S26+ a harder sell unless your current Galaxy phone is several years old. Also, following the 2026 trend, they are all pricier this year. Make sure you check out our early impressions (S26 Ultra, S26, Galaxy Buds 4); reviews are coming soon. — Mat Smith The other big stories (and deals) this morning Apple and Netflix are teaming up to share Formula 1 programming Burger King will use AI to monitor employee ’friendliness’ Canadian government demands safety changes from OpenAI Amazon introduces three personality styles for Alexa+ Ambient Dreamie bedside companion review How much for a good night’s sleep? $250? Cheyenne MacDonald for Engadget Ambient’s dedicated alarm clock offers many of the conveniences of your smartphone alarms — highly customizable alarm schedules, a library of soundscapes and noise masks and even Bluetooth so you can connect earbuds. There’s no subscription, it sounds great and sleep insights are supposedly incoming. However, $250 is a lot. Check out our full review. Continue reading. An AI-generated Resident Evil Requiem review briefly made it on Metacritic By a video game news site owned by ClickOut Media. Review aggregator Metacritic has removed a review of Resident Evil Requiem because it was AI generated. Kotaku explained the review was published by UK gaming site VideoGamer, but appears to be “written” by a fake AI journalist rather than a real person. “Brian Merrygold” doesn’t seem to exist. The author’s profile on VideoGamer is just as awkwardly written as the review, and the profile picture of the account also appears to be AI-generated. Literally, the file name includes “ChatGPT-Image.” ClickOut Media, the company that owns VideoGamer and a collection of other publications, reportedly laid off the staff of its gaming sites earlier this month to pivot to AI-generated content. Here it is. Continue reading. This article originally appeared on Engadget at https://www.engadget.com/general/the-morning-after-engadget-newsletter-144951777.html?src=rss",
          "feed_position": 18,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/dreamiehead2.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/laptops/a-cheap-macbook-is-the-perfect-way-for-apple-to-win-over-windows-users-130000045.html",
          "published_at": "Fri, 27 Feb 2026 13:00:00 +0000",
          "title": "A cheap MacBook is the perfect way for Apple to win over Windows users",
          "standfirst": "The MacBook is coming back — or at least, that's what the rumors claim. Next week, Apple is expected to announce a colorful, low-cost, non-Air, non-Pro MacBook powered by one of its mobile processors. By avoiding its pricier M-series chips, Apple may reportedly be able to reach a low $699 or $799 price for the MacBook. The $999 MacBook Air is the cheapest laptop on the company's website right now, but Apple also sold the older M1 MacBook Air at Walmart for $700 in 2024, which later went down to $650 last year.That Walmart deal was a smart way for Apple to test out the viability of cheaper MacBooks without building an entirely new product. But now the M1 Air’s design looks seriously dated, and the company also needs to move beyond the six-year-old M1 chip. It's time to get serious about delivering a true low-cost Apple laptop.There's another compelling reason to bring back a cheaper MacBook: It's the perfect way to court disgruntled Windows users, something Apple hasn't really done since its \"Get A Mac\" ads from the mid-2000s. I figure the unbridled success of the iPhone and iPad made Apple focus less on directly competing with Windows. The sleek designs of the 2011-2015 era MacBook Air and Pros were their main selling points, but Apple's push towards USB-C-only machines and unreliable butterfly keyboards later made it clear it wasn't totally focused on Macs.But now Microsoft is distracted by AI — it's been pushing Copilot and AI features for years, instead of improving the Windows experience with more useful upgrades. Recent talk of agentic AI capabilities, which would let Copilot handle tasks for you automatically, also sparked plenty of criticism from Windows users. And with all of the focus on AI, Microsoft has also released some disastrous Windows updates over the last year, which have bricked OS installations. So, Apple, why not make a direct play for Windows users? Last year, I covered why it's a great time to jump ship from Windows to Mac, and I haven't been able to let go of that idea since. Apple's M-series chips are shockingly fast and efficient, and its hardware tends to be more durable than typical PC fare. Rumors point to Apple developing a new aluminum case for the low-cost MacBook, so it will likely feel more polished than a typical sub-$1,000 Windows laptop. macOS has also avoided the bloat that's plagued Windows for years — you can turn off Apple Intelligence with two clicks if you want to, and there aren't any annoying ads to deal with. A MacBook Air M5 on a table.Devindra Hardawar for EngadgetAnd while it used to be a pain to transition from Windows to Mac, it’s far easier these days, especially if you mainly rely on web apps. It also wouldn't be tough for Apple to make short tutorials to help Windows users get their bearings with the macOS basics, like installing apps and juggling app windows. Apple could also make a play for iPhone owners using Windows, who may not be aware of the many ways iOS and macOS are integrated. iPhone mirroring may be a huge draw on its own.Rumors also suggest the upcoming MacBook might use the A18 Pro from the iPhone 16 Pro, a chip that benchmarks faster than the M1. Even if it only has six cores, making it slower for heavy workloads than the M2, an A18 Pro-powered MacBook would still be more than enough power for basic productivity work. Not everyone needs the surprising amount of GPU power in the MacBook Air — especially if downgrading means they can save $200 to $300.I'm not saying any of this through any sort of Apple-loving bias. I typically use a MacBook Pro for work, but I'm a Windows user at heart. Windows was my gateway to computing in the '90s, back when Macs were far more expensive than PCs. These days, I spend more time on my Windows desktop making podcasts, playing PC games and bumming around the internet than I do working on Macs. And yet, it’s hard to deny everything Apple is doing right today — the only thing it’s missing is an inexpensive laptop entry. A $699 or $799 MacBook simply makes sense. And for many Windows users, it’ll be just the escape from Microsoft they need.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/a-cheap-macbook-is-the-perfect-way-for-apple-to-win-over-windows-users-130000045.html?src=rss",
          "content": "The MacBook is coming back — or at least, that's what the rumors claim. Next week, Apple is expected to announce a colorful, low-cost, non-Air, non-Pro MacBook powered by one of its mobile processors. By avoiding its pricier M-series chips, Apple may reportedly be able to reach a low $699 or $799 price for the MacBook. The $999 MacBook Air is the cheapest laptop on the company's website right now, but Apple also sold the older M1 MacBook Air at Walmart for $700 in 2024, which later went down to $650 last year.That Walmart deal was a smart way for Apple to test out the viability of cheaper MacBooks without building an entirely new product. But now the M1 Air’s design looks seriously dated, and the company also needs to move beyond the six-year-old M1 chip. It's time to get serious about delivering a true low-cost Apple laptop.There's another compelling reason to bring back a cheaper MacBook: It's the perfect way to court disgruntled Windows users, something Apple hasn't really done since its \"Get A Mac\" ads from the mid-2000s. I figure the unbridled success of the iPhone and iPad made Apple focus less on directly competing with Windows. The sleek designs of the 2011-2015 era MacBook Air and Pros were their main selling points, but Apple's push towards USB-C-only machines and unreliable butterfly keyboards later made it clear it wasn't totally focused on Macs.But now Microsoft is distracted by AI — it's been pushing Copilot and AI features for years, instead of improving the Windows experience with more useful upgrades. Recent talk of agentic AI capabilities, which would let Copilot handle tasks for you automatically, also sparked plenty of criticism from Windows users. And with all of the focus on AI, Microsoft has also released some disastrous Windows updates over the last year, which have bricked OS installations. So, Apple, why not make a direct play for Windows users? Last year, I covered why it's a great time to jump ship from Windows to Mac, and I haven't been able to let go of that idea since. Apple's M-series chips are shockingly fast and efficient, and its hardware tends to be more durable than typical PC fare. Rumors point to Apple developing a new aluminum case for the low-cost MacBook, so it will likely feel more polished than a typical sub-$1,000 Windows laptop. macOS has also avoided the bloat that's plagued Windows for years — you can turn off Apple Intelligence with two clicks if you want to, and there aren't any annoying ads to deal with. A MacBook Air M5 on a table.Devindra Hardawar for EngadgetAnd while it used to be a pain to transition from Windows to Mac, it’s far easier these days, especially if you mainly rely on web apps. It also wouldn't be tough for Apple to make short tutorials to help Windows users get their bearings with the macOS basics, like installing apps and juggling app windows. Apple could also make a play for iPhone owners using Windows, who may not be aware of the many ways iOS and macOS are integrated. iPhone mirroring may be a huge draw on its own.Rumors also suggest the upcoming MacBook might use the A18 Pro from the iPhone 16 Pro, a chip that benchmarks faster than the M1. Even if it only has six cores, making it slower for heavy workloads than the M2, an A18 Pro-powered MacBook would still be more than enough power for basic productivity work. Not everyone needs the surprising amount of GPU power in the MacBook Air — especially if downgrading means they can save $200 to $300.I'm not saying any of this through any sort of Apple-loving bias. I typically use a MacBook Pro for work, but I'm a Windows user at heart. Windows was my gateway to computing in the '90s, back when Macs were far more expensive than PCs. These days, I spend more time on my Windows desktop making podcasts, playing PC games and bumming around the internet than I do working on Macs. And yet, it’s hard to deny everything Apple is doing right today — the only thing it’s missing is an inexpensive laptop entry. A $699 or $799 MacBook simply makes sense. And for many Windows users, it’ll be just the escape from Microsoft they need.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/a-cheap-macbook-is-the-perfect-way-for-apple-to-win-over-windows-users-130000045.html?src=rss",
          "feed_position": 20,
          "image_url": "https://media-mbst-pub-ue1.s3.amazonaws.com/creatr-uploaded-images/2026-02/80fbbcc0-0ced-11f1-bd5e-ad51f3248234"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/openai-will-notify-authorities-of-credible-threats-after-canada-mass-shooters-second-account-was-discovered-112706548.html",
          "published_at": "Fri, 27 Feb 2026 11:27:06 +0000",
          "title": "OpenAI will notify authorities of credible threats after Canada mass shooter's second account was discovered",
          "standfirst": "OpenAI has vowed to strengthen its safety protocols and to notify law enforcement of credible threats sooner in a letter addressed to Canadian authorities, according to Politico and The Washington Post. If you’ll recall, Canadian politicians summoned the company’s leaders after reports came out that it didn’t notify authorities when it banned the account owned by the Tumbler Ridge, British Columbia mass shooting suspect back in 2025. Some of OpenAI’s leaders have already met with Candian officials, and British Columbia Premier David Eby said Sam Altman had also agreed to meet with him. While OpenAI has yet to announce changes to its rules, Ann O’Leary, its vice president of global policy, reportedly wrote in the letter that the company will tweak its detection systems so that they can better prevent banned users from coming back to the platform. Apparently, after OpenAI banned the shooter’s original account due to “potential warnings of committing real-world violence,” the perpetrator was able to create another account. The company only discovered the second account after the shooter’s name was released, and it has since notified authorities. Further, OpenAI will now notify authorities if it detects “imminent and credible” threats in ChatGPT conversations, even if the user doesn’t reveal “a target, means, and timing of planned violence.” O’Leary explained that if the new rules had been in effect when the shooter’s account was banned in 2025, the company would have notified the police. OpenAI will also establish a point of contact for Canadian law enforcement so it can quickly share information with authorities when needed. The Canadian government sees OpenAI’s decision not to report the shooter’s original account as a failure. It threatened to regulate AI chatbots in the country if their creators cannot show that they have proper safeguards to protect its users. It’s unclear at the moment if OpenAI also plans to roll out the same changes in the US and elsewhere in the world.This article originally appeared on Engadget at https://www.engadget.com/ai/openai-will-notify-authorities-of-credible-threats-after-canada-mass-shooters-second-account-was-discovered-112706548.html?src=rss",
          "content": "OpenAI has vowed to strengthen its safety protocols and to notify law enforcement of credible threats sooner in a letter addressed to Canadian authorities, according to Politico and The Washington Post. If you’ll recall, Canadian politicians summoned the company’s leaders after reports came out that it didn’t notify authorities when it banned the account owned by the Tumbler Ridge, British Columbia mass shooting suspect back in 2025. Some of OpenAI’s leaders have already met with Candian officials, and British Columbia Premier David Eby said Sam Altman had also agreed to meet with him. While OpenAI has yet to announce changes to its rules, Ann O’Leary, its vice president of global policy, reportedly wrote in the letter that the company will tweak its detection systems so that they can better prevent banned users from coming back to the platform. Apparently, after OpenAI banned the shooter’s original account due to “potential warnings of committing real-world violence,” the perpetrator was able to create another account. The company only discovered the second account after the shooter’s name was released, and it has since notified authorities. Further, OpenAI will now notify authorities if it detects “imminent and credible” threats in ChatGPT conversations, even if the user doesn’t reveal “a target, means, and timing of planned violence.” O’Leary explained that if the new rules had been in effect when the shooter’s account was banned in 2025, the company would have notified the police. OpenAI will also establish a point of contact for Canadian law enforcement so it can quickly share information with authorities when needed. The Canadian government sees OpenAI’s decision not to report the shooter’s original account as a failure. It threatened to regulate AI chatbots in the country if their creators cannot show that they have proper safeguards to protect its users. It’s unclear at the moment if OpenAI also plans to roll out the same changes in the US and elsewhere in the world.This article originally appeared on Engadget at https://www.engadget.com/ai/openai-will-notify-authorities-of-credible-threats-after-canada-mass-shooters-second-account-was-discovered-112706548.html?src=rss",
          "feed_position": 22
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/best-wifi-extender-130021313.html",
          "published_at": "Fri, 27 Feb 2026 10:01:27 +0000",
          "title": "The best Wi-Fi extenders in 2026",
          "standfirst": "Weak Wi-Fi can turn everyday tasks into small frustrations, whether it’s a video call that drops mid-sentence or a stream that refuses to load in certain rooms. If upgrading your router isn’t an option, a Wi-Fi extender can be a practical way to stretch your existing network farther and smooth out coverage gaps — without rewiring your home or rearranging furniture.Today’s Wi-Fi extenders range from simple plug-in repeaters to more advanced models that behave like miniature access points or mesh nodes. Some are best suited for extending coverage to a single room, while others are designed to preserve faster speeds across larger spaces. Choosing the right one depends on your home’s layout, your internet plan and how much performance you’re willing to trade for convenience.We’ve tested a variety of Wi-Fi extenders to find the best options for different budgets and setups, from affordable fixes for small dead zones to higher-end models built to handle heavier traffic and faster connections. Best Wi-Fi extender for 2026 How do Wi-Fi extenders work? These handy wireless devices do exactly what their name suggests: extend your Wi-Fi network so it covers more areas of your home. Most wireless extenders plug into an AC outlet and connect to your existing router so they can then rebroadcast it to spots that your router alone may not cover well. As a rule of thumb, you’ll get the best results by placing the extender half way between your router and the dead zone you’re trying to fix or improve your W-Fi connection and strengthen the wireless signal. One important thing to note about Wi-Fi range extenders (also sometimes called “repeaters”) is that most of them actually create a new Wi-Fi network when rebroadcasting your existing one. That network will have a new name (it’ll often be your default network’s name with an EXT appended at the end, unless you change it) and that means you’ll have to connect to different networks when in different parts of your home. While that’s a small tradeoff in return for improved internet connection, some will be more inconvenienced than others. If you’d rather have one, much larger network in your home, you’re better off upgrading to mesh networking systems. Mesh systems come with a main router and a wireless access point or two that, by default, create one large Wi-Fi system that should be accessible throughout your whole home. They tend to be the best Wi-Fi routers you can get, but that also translates to more expensive, and possibly more complicated, devices. Mesh Wi-Fi systems are, by far, more costly than a simple extender, plus you may have to work with your internet service provider to get your home’s existing network working on your new router. What to look for in a Wi-Fi extender Speed Extenders today can support single, dual or tri-band Wi-Fi, and they will tell you the maximum speeds they support on all of their available bands. For example, one dual-band device might support 600Mbps speeds over its 2.4GHz band and up to 1300Mbps over its 5GHz band, for a combined maximum speed of 1900Mbps. For the best performance, you’ll want to go with a Wi-Fi extender that has the highest speeds possible (and those, as you might expect, tend to cost more). Some extenders even support Wi-Fi 7, giving you the latest in wireless technology for higher bandwidth, faster internet speed and lower latency. However, it’s important to remember that Wi-Fi extenders are not true “signal boosters” since they are not designed to increase speeds across your home. In fact, you may find that the extender’s network is slower than your router’s. Instead, extenders are designed to increase the strong Wi-Fi coverage throughout your home, making them ideal for filling in dead zones. Some mesh extenders can help create a more seamless network, reducing the drop in speed and improving connectivity in larger spaces. Range, and number of supported devices With the name of the gaming being coverage area, taking note of a device’s range is important. Depending on the size of your home and property, you may only need up to 1,200 square feet of coverage. But those with larger homes will want to spring for an extender that can support upwards of 2,000+ square feet of coverage. Similarly, those with lots of gadgets will want an extender that can handle them all at once. If you spend most of your time on your phone or laptop and maybe have your smart TV online for a few hours of Netflix each day, you could get by with a more limited extender. Smart home aficionados and tech lovers should invest in one that won’t buckle under the pressure of a few dozen connected devices. This is especially important if you plan on linking all of the devices in a certain part of your home to your Wi-Fi range extender’s network, rather than directly to your existing router. Some models with external antennas can improve performance by providing stronger, more directional wireless signal. Design There isn’t a ton of innovation when it comes to design in the Wi-Fi extender space. Most of the ones you’ll find today are rounded rectangles roughly the size of your hand that plug into a standard wall outlet. They usually have a few indicator lights that will show you when the extender is connected, how strong its signal strength is and when there’s a problem, and some will even have moveable external antennas that companies claim provide even better Wi-Fi signal. Generally, they are pretty simple to install and get connected, but if you’re struggling with how to set up your Wi-Fi extender, there are plenty of YouTube videos you can check out. Aside from that, there are the scant few standalone Wi-Fi extenders that sit on an end table or a desk, and those look pretty similar to regular ol’ routers. But make no mistake, anything labeled as an extender or a “Wi-Fi repeater” will need an anchor router in order for it to work. Another convenient feature you’ll find on most Wi-Fi extenders is an extra Ethernet connection port (or a few). This allows you to use the extender as a wireless access point if you connect it to your existing router, or an adapter to provide devices like TVs, smart home hubs or game consoles a hardwired connection to the internet. Unsurprisingly, this wired connection usually provides you with the fastest speeds possible, so you may want to use it for your most crucial devices. Wi-Fi extender FAQs What's the difference between a wifi booster and extender? Nowadays, there’s really no difference between a Wi-Fi booster and Wi-Fi extender - they’re just different names for the same thing. Previously, however, Wi-Fi boosters were devices that received signals from wireless routers, broadcasting them to another network. This essentially extends the range of the signal. Wi-Fi extenders expand the coverage within your home’s Wi-Fi network, but often you will see extenders described as boosters. Is a Wi-Fi extender better than a mesh router? Mesh routers, or mesh Wi-Fi systems, use multiple devices (or nodes) across your home to create a larger home network. Essentially, you have multiple routers around your home with these systems, and that will hopefully provide the best coverage possible. Wi-Fi extenders, on the other hand, are usually just one device that extends your existing Wi-Fi signal, and they often require you to switch networks when connecting. Wi-Fi extenders are more affordable, though, and are great if you’re traveling or need a Wi-Fi signal in harder-to-reach areas. However, a mesh router can offer a better long-term solution to upgrade your entire home’s Wi-Fi. Should I use multiple Wi-Fi extenders? Some people may need to use multiple Wi-Fi extenders, for instance, if your home is large or has dead zones in different areas. But if you do use multiple Wi-Fi extenders, there’s a chance of interference. You may also need to manually connect to the extenders separately, which isn’t always convenient. What is the maximum distance for a Wi-Fi extender? The maximum distance for a Wi-Fi extender varies depending on the model, but most can effectively extend your wireless signal between 800 and 2,500 square feet. Some high-end models may reach even farther, especially if they feature external antennas or are part of a mesh system with additional dedicated wireless access points. However, keep in mind that real-world performance depends on factors like your home's layout, wall materials and interference from other devices. For best results, place your extender about halfway between your router and the area with weak or no Wi-Fi connection. Always check the manufacturer’s specs — some of our top picks clearly list their expected range so you can find one that fits your space.This article originally appeared on Engadget at https://www.engadget.com/computing/best-wifi-extender-130021313.html?src=rss",
          "content": "Weak Wi-Fi can turn everyday tasks into small frustrations, whether it’s a video call that drops mid-sentence or a stream that refuses to load in certain rooms. If upgrading your router isn’t an option, a Wi-Fi extender can be a practical way to stretch your existing network farther and smooth out coverage gaps — without rewiring your home or rearranging furniture.Today’s Wi-Fi extenders range from simple plug-in repeaters to more advanced models that behave like miniature access points or mesh nodes. Some are best suited for extending coverage to a single room, while others are designed to preserve faster speeds across larger spaces. Choosing the right one depends on your home’s layout, your internet plan and how much performance you’re willing to trade for convenience.We’ve tested a variety of Wi-Fi extenders to find the best options for different budgets and setups, from affordable fixes for small dead zones to higher-end models built to handle heavier traffic and faster connections. Best Wi-Fi extender for 2026 How do Wi-Fi extenders work? These handy wireless devices do exactly what their name suggests: extend your Wi-Fi network so it covers more areas of your home. Most wireless extenders plug into an AC outlet and connect to your existing router so they can then rebroadcast it to spots that your router alone may not cover well. As a rule of thumb, you’ll get the best results by placing the extender half way between your router and the dead zone you’re trying to fix or improve your W-Fi connection and strengthen the wireless signal. One important thing to note about Wi-Fi range extenders (also sometimes called “repeaters”) is that most of them actually create a new Wi-Fi network when rebroadcasting your existing one. That network will have a new name (it’ll often be your default network’s name with an EXT appended at the end, unless you change it) and that means you’ll have to connect to different networks when in different parts of your home. While that’s a small tradeoff in return for improved internet connection, some will be more inconvenienced than others. If you’d rather have one, much larger network in your home, you’re better off upgrading to mesh networking systems. Mesh systems come with a main router and a wireless access point or two that, by default, create one large Wi-Fi system that should be accessible throughout your whole home. They tend to be the best Wi-Fi routers you can get, but that also translates to more expensive, and possibly more complicated, devices. Mesh Wi-Fi systems are, by far, more costly than a simple extender, plus you may have to work with your internet service provider to get your home’s existing network working on your new router. What to look for in a Wi-Fi extender Speed Extenders today can support single, dual or tri-band Wi-Fi, and they will tell you the maximum speeds they support on all of their available bands. For example, one dual-band device might support 600Mbps speeds over its 2.4GHz band and up to 1300Mbps over its 5GHz band, for a combined maximum speed of 1900Mbps. For the best performance, you’ll want to go with a Wi-Fi extender that has the highest speeds possible (and those, as you might expect, tend to cost more). Some extenders even support Wi-Fi 7, giving you the latest in wireless technology for higher bandwidth, faster internet speed and lower latency. However, it’s important to remember that Wi-Fi extenders are not true “signal boosters” since they are not designed to increase speeds across your home. In fact, you may find that the extender’s network is slower than your router’s. Instead, extenders are designed to increase the strong Wi-Fi coverage throughout your home, making them ideal for filling in dead zones. Some mesh extenders can help create a more seamless network, reducing the drop in speed and improving connectivity in larger spaces. Range, and number of supported devices With the name of the gaming being coverage area, taking note of a device’s range is important. Depending on the size of your home and property, you may only need up to 1,200 square feet of coverage. But those with larger homes will want to spring for an extender that can support upwards of 2,000+ square feet of coverage. Similarly, those with lots of gadgets will want an extender that can handle them all at once. If you spend most of your time on your phone or laptop and maybe have your smart TV online for a few hours of Netflix each day, you could get by with a more limited extender. Smart home aficionados and tech lovers should invest in one that won’t buckle under the pressure of a few dozen connected devices. This is especially important if you plan on linking all of the devices in a certain part of your home to your Wi-Fi range extender’s network, rather than directly to your existing router. Some models with external antennas can improve performance by providing stronger, more directional wireless signal. Design There isn’t a ton of innovation when it comes to design in the Wi-Fi extender space. Most of the ones you’ll find today are rounded rectangles roughly the size of your hand that plug into a standard wall outlet. They usually have a few indicator lights that will show you when the extender is connected, how strong its signal strength is and when there’s a problem, and some will even have moveable external antennas that companies claim provide even better Wi-Fi signal. Generally, they are pretty simple to install and get connected, but if you’re struggling with how to set up your Wi-Fi extender, there are plenty of YouTube videos you can check out. Aside from that, there are the scant few standalone Wi-Fi extenders that sit on an end table or a desk, and those look pretty similar to regular ol’ routers. But make no mistake, anything labeled as an extender or a “Wi-Fi repeater” will need an anchor router in order for it to work. Another convenient feature you’ll find on most Wi-Fi extenders is an extra Ethernet connection port (or a few). This allows you to use the extender as a wireless access point if you connect it to your existing router, or an adapter to provide devices like TVs, smart home hubs or game consoles a hardwired connection to the internet. Unsurprisingly, this wired connection usually provides you with the fastest speeds possible, so you may want to use it for your most crucial devices. Wi-Fi extender FAQs What's the difference between a wifi booster and extender? Nowadays, there’s really no difference between a Wi-Fi booster and Wi-Fi extender - they’re just different names for the same thing. Previously, however, Wi-Fi boosters were devices that received signals from wireless routers, broadcasting them to another network. This essentially extends the range of the signal. Wi-Fi extenders expand the coverage within your home’s Wi-Fi network, but often you will see extenders described as boosters. Is a Wi-Fi extender better than a mesh router? Mesh routers, or mesh Wi-Fi systems, use multiple devices (or nodes) across your home to create a larger home network. Essentially, you have multiple routers around your home with these systems, and that will hopefully provide the best coverage possible. Wi-Fi extenders, on the other hand, are usually just one device that extends your existing Wi-Fi signal, and they often require you to switch networks when connecting. Wi-Fi extenders are more affordable, though, and are great if you’re traveling or need a Wi-Fi signal in harder-to-reach areas. However, a mesh router can offer a better long-term solution to upgrade your entire home’s Wi-Fi. Should I use multiple Wi-Fi extenders? Some people may need to use multiple Wi-Fi extenders, for instance, if your home is large or has dead zones in different areas. But if you do use multiple Wi-Fi extenders, there’s a chance of interference. You may also need to manually connect to the extenders separately, which isn’t always convenient. What is the maximum distance for a Wi-Fi extender? The maximum distance for a Wi-Fi extender varies depending on the model, but most can effectively extend your wireless signal between 800 and 2,500 square feet. Some high-end models may reach even farther, especially if they feature external antennas or are part of a mesh system with additional dedicated wireless access points. However, keep in mind that real-world performance depends on factors like your home's layout, wall materials and interference from other devices. For best results, place your extender about halfway between your router and the area with weak or no Wi-Fi connection. Always check the manufacturer’s specs — some of our top picks clearly list their expected range so you can find one that fits your space.This article originally appeared on Engadget at https://www.engadget.com/computing/best-wifi-extender-130021313.html?src=rss",
          "feed_position": 24
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/anthropic-refuses-to-bow-to-pentagon-despite-hegseths-threats-085553126.html",
          "published_at": "Fri, 27 Feb 2026 08:55:53 +0000",
          "title": "Anthropic refuses to bow to Pentagon despite Hegseth's threats",
          "standfirst": "Despite an ultimatum from Defense Secretary Pete Hegseth, Anthropic said that it can't \"in good conscience\" comply with a Pentagon edict to remove guardrails on its AI, CEO Dario Amodei wrote in a blog post. The Department of Defense had threatened to cancel a $200 million contract and label Anthropic a \"supply chain risk\" if it didn't agree to remove safeguards over mass surveillance and autonomous weapons. \"Our strong preference is to continue to serve the Department and our warfighters — with our two requested safeguards in place,\" Amodei said. \"We remain ready to continue our work to support the national security of the United States.\" In response, US Under Secretary of Defense Emil Michael accused Amodei in a post on X of wanting \"nothing more than to try to personally control the US military and is OK putting our nation's safety at risk.\" The standoff began when the Pentagon demanded that Anthropic its Claude AI product available for \"all lawful purposes\" — including mass surveillance and the development of fully autonomous weapons that can kill without human supervision. Anthropic refused to offer its tech for those things, even with a \"safety stack\" built into that model. Yesterday, Axios reported that Hegseth gave Anthropic a deadline of 5:01 PM on Friday to agree to the Pentagon's terms. At the same time, the DoD requested an assessment of its reliance on Claude, an initial step toward potentially labelling Anthropic as a \"supply chain risk\" — a designation usually reserved for firms from adversaries like China and \"never before applied to an American company,\" Anthropic wrote. Amodei declined to change his stance and stated that if the Pentagon chose to offboard Anthropic, \"we will work to enable a smooth transition to another provider, avoiding any disruption to ongoing military planning, operations or other critical missions.\" Grok is one of the other providers the DoD is reportedly considering, along with Google's Gemini and OpenAI. It may not be that simple for the military to disentangle itself from Claude, however. Up until now, Anthropic's model has been the only one allowed for the military's most sensitive tasks in intelligence, weapons development and battlefield operations. Claude was reportedly used in the Venezuelan raid in which the US military exfiltrated the country's president, Nicolás Maduro, and his wife. AI companies have been widely criticized for potential harm to users, but mass surveillance and weapons development would clearly take that to a new level. Anthropic's potential reply to the Pentagon was seen as a test of its claim to be the most safety-forward AI company, particularly after dropping its flagship safety pledge a few days ago. Now that Amodei has responded, the focus will shift to the Pentagon to see if it follows through on its threats, which could seriously harm Anthropic. This article originally appeared on Engadget at https://www.engadget.com/ai/anthropic-refuses-to-bow-to-pentagon-despite-hegseths-threats-085553126.html?src=rss",
          "content": "Despite an ultimatum from Defense Secretary Pete Hegseth, Anthropic said that it can't \"in good conscience\" comply with a Pentagon edict to remove guardrails on its AI, CEO Dario Amodei wrote in a blog post. The Department of Defense had threatened to cancel a $200 million contract and label Anthropic a \"supply chain risk\" if it didn't agree to remove safeguards over mass surveillance and autonomous weapons. \"Our strong preference is to continue to serve the Department and our warfighters — with our two requested safeguards in place,\" Amodei said. \"We remain ready to continue our work to support the national security of the United States.\" In response, US Under Secretary of Defense Emil Michael accused Amodei in a post on X of wanting \"nothing more than to try to personally control the US military and is OK putting our nation's safety at risk.\" The standoff began when the Pentagon demanded that Anthropic its Claude AI product available for \"all lawful purposes\" — including mass surveillance and the development of fully autonomous weapons that can kill without human supervision. Anthropic refused to offer its tech for those things, even with a \"safety stack\" built into that model. Yesterday, Axios reported that Hegseth gave Anthropic a deadline of 5:01 PM on Friday to agree to the Pentagon's terms. At the same time, the DoD requested an assessment of its reliance on Claude, an initial step toward potentially labelling Anthropic as a \"supply chain risk\" — a designation usually reserved for firms from adversaries like China and \"never before applied to an American company,\" Anthropic wrote. Amodei declined to change his stance and stated that if the Pentagon chose to offboard Anthropic, \"we will work to enable a smooth transition to another provider, avoiding any disruption to ongoing military planning, operations or other critical missions.\" Grok is one of the other providers the DoD is reportedly considering, along with Google's Gemini and OpenAI. It may not be that simple for the military to disentangle itself from Claude, however. Up until now, Anthropic's model has been the only one allowed for the military's most sensitive tasks in intelligence, weapons development and battlefield operations. Claude was reportedly used in the Venezuelan raid in which the US military exfiltrated the country's president, Nicolás Maduro, and his wife. AI companies have been widely criticized for potential harm to users, but mass surveillance and weapons development would clearly take that to a new level. Anthropic's potential reply to the Pentagon was seen as a test of its claim to be the most safety-forward AI company, particularly after dropping its flagship safety pledge a few days ago. Now that Amodei has responded, the focus will shift to the Pentagon to see if it follows through on its threats, which could seriously harm Anthropic. This article originally appeared on Engadget at https://www.engadget.com/ai/anthropic-refuses-to-bow-to-pentagon-despite-hegseths-threats-085553126.html?src=rss",
          "feed_position": 25
        }
      ],
      "featured_image": "https://s.yimg.com/os/creatr-uploaded-images/2026-02/125f8ad0-1495-11f1-bb83-dd96bb6ae2a2",
      "popularity_score": 2007.6733483333333
    },
    {
      "id": "cluster_34",
      "coverage": 2,
      "updated_at": "Sat, 28 Feb 2026 12:35:01 -0500",
      "title": "Sources: Israel hacked BadeSaba, a popular Iranian prayer app with 5M+ installs on Google Play, to send messages urging Iranian military personnel to defect (Wall Street Journal)",
      "neutral_headline": "Hacked Prayer App Sends ‘Surrender’ Messages to Iranians Amid Israeli and US Strikes",
      "bullet_summary": [
        "Reported by TechMeme, Wired Tech"
      ],
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/260228/p11#a260228p11",
          "published_at": "Sat, 28 Feb 2026 12:35:01 -0500",
          "title": "Sources: Israel hacked BadeSaba, a popular Iranian prayer app with 5M+ installs on Google Play, to send messages urging Iranian military personnel to defect (Wall Street Journal)",
          "standfirst": "Wall Street Journal: Sources: Israel hacked BadeSaba, a popular Iranian prayer app with 5M+ installs on Google Play, to send messages urging Iranian military personnel to defect &mdash; Israel hacked a popular Iranian prayer app to send notifications to potentially millions of phones Saturday morning urging &hellip;",
          "content": "Wall Street Journal: Sources: Israel hacked BadeSaba, a popular Iranian prayer app with 5M+ installs on Google Play, to send messages urging Iranian military personnel to defect &mdash; Israel hacked a popular Iranian prayer app to send notifications to potentially millions of phones Saturday morning urging &hellip;",
          "feed_position": 13,
          "image_url": "http://www.techmeme.com/260228/i11.jpg"
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/hacked-prayer-app-sends-surrender-messages-to-iranians-amid-israeli-strikes/",
          "published_at": "Sat, 28 Feb 2026 15:58:09 +0000",
          "title": "Hacked Prayer App Sends ‘Surrender’ Messages to Iranians Amid Israeli and US Strikes",
          "standfirst": "As Israeli airstrikes hit Tehran this morning, Iranians received mysterious push notifications saying that “help is on the way,” promising amnesty if they surrender.",
          "content": "As Israeli airstrikes hit Tehran this morning, Iranians received mysterious push notifications saying that “help is on the way,” promising amnesty if they surrender.",
          "feed_position": 2,
          "image_url": "https://media.wired.com/photos/69a2fc44d16e57b38c5e2d95/master/pass/MobileHackLead.jpg"
        }
      ],
      "featured_image": "http://www.techmeme.com/260228/i11.jpg",
      "popularity_score": 2006.1177927777778
    },
    {
      "id": "cluster_76",
      "coverage": 2,
      "updated_at": "Fri, 27 Feb 2026 23:00:54 +0000",
      "title": "OpenAI fires employee for using confidential info on prediction markets",
      "neutral_headline": "OpenAI fires employee for using confidential info on prediction markets",
      "bullet_summary": [
        "The company said such trades violates its internal company policies about using confidential information for personal gain",
        "Reported by TechCrunch, Wired Tech"
      ],
      "items": [
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2026/02/27/openai-fires-employee-for-using-confidential-info-on-prediction-markets/",
          "published_at": "Fri, 27 Feb 2026 23:00:54 +0000",
          "title": "OpenAI fires employee for using confidential info on prediction markets",
          "standfirst": "The company said such trades violates its internal company policies about using confidential information for personal gain.",
          "content": "The company said such trades violates its internal company policies about using confidential information for personal gain.",
          "feed_position": 9
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/openai-fires-employee-insider-trading-polymarket-kalshi/",
          "published_at": "Fri, 27 Feb 2026 19:07:28 +0000",
          "title": "OpenAI Fires an Employee for Prediction Market Insider Trading",
          "standfirst": "Prediction markets like Polymarket and Kalshi are big business, and some Big Tech employees are testing boundaries by making trades based on insider knowledge.",
          "content": "Prediction markets like Polymarket and Kalshi are big business, and some Big Tech employees are testing boundaries by making trades based on insider knowledge.",
          "feed_position": 19,
          "image_url": "https://media.wired.com/photos/69a0b01c157af8f83feddf9b/master/pass/OpenAI-Employee-Fired-Insider-Trading-Business-2210029299.jpg"
        }
      ],
      "featured_image": "https://media.wired.com/photos/69a0b01c157af8f83feddf9b/master/pass/OpenAI-Employee-Fired-Insider-Trading-Business-2210029299.jpg",
      "popularity_score": 2000
    },
    {
      "id": "cluster_30",
      "coverage": 1,
      "updated_at": "Sat, 28 Feb 2026 18:17:12 +0000",
      "title": "In puzzling outbreak, officials look to cold beer, gross ice, and ChatGPT",
      "neutral_headline": "In puzzling outbreak, officials look to cold beer, gross ice, and ChatGPT",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2026/02/did-chatgpt-help-health-officials-solve-a-weird-outbreak-maybe/",
          "published_at": "Sat, 28 Feb 2026 18:17:12 +0000",
          "title": "In puzzling outbreak, officials look to cold beer, gross ice, and ChatGPT",
          "standfirst": "An AI chatbot convinced health investigators they had the right answer.",
          "content": "Health officials in Illinois turned to an AI chatbot to try to solve a puzzling outbreak linked to a county fair. But whether it was actually helpful or not remains unclear. According to a report this week in the Morbidity and Mortality Weekly Report, officials in Brown County got the first hint of an outbreak from the county sheriff, who noted on August 5, 2024 that a remarkable number of potential jurors for an upcoming trial said they had a stomach bug. Then, on August 12, the state health department notified the county of a case of Salmonella enterica serotype Agbeni. With those two tips, county health officials opened an investigation and were able to identify 13 cases—seven laboratory-confirmed cases of S. enterica Agbeni and six probable cases that were in close contact with confirmed cases. The cases spanned five counties, but they all had one thing in common: everyone had gone to the Brown County fair.Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-1904444791-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-1904444791-1152x648.jpg",
      "popularity_score": 344.82084833333334
    },
    {
      "id": "cluster_72",
      "coverage": 1,
      "updated_at": "Sat, 28 Feb 2026 01:26:41 +0000",
      "title": "Google quantum-proofs HTTPS by squeezing 15kB of data into 700-byte space",
      "neutral_headline": "Google quantum-proofs HTTPS by squeezing 15kB of data into 700-byte space",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/security/2026/02/google-is-using-clever-math-to-quantum-proof-https-certificates/",
          "published_at": "Sat, 28 Feb 2026 01:26:41 +0000",
          "title": "Google quantum-proofs HTTPS by squeezing 15kB of data into 700-byte space",
          "standfirst": "Merkle Tree Certificate support is already in Chrome. Soon, it will be everywhere.",
          "content": "Google on Friday unveiled its plan for its Chrome browser to secure HTTPS certificates against quantum computer attacks without breaking the Internet. The objective is a tall order. The quantum-resistant cryptographic data needed to transparently publish TLS certificates is roughly 40 times bigger than the classical cryptographic material used today. A typical X.509 certificate chain used today comprises six elliptic curve signatures and two EC public keys, each of them only 64 bytes. This material can be cracked through the quantum-enabled Shor’s algorithm. The full chain is roughly 4 kilobytes. All this data must be transmitted when a browser connects to a site. The bigger they come, the slower they move “The bigger you make the certificate, the slower the handshake and the more people you leave behind,” said Bas Westerbaan, principal research engineer at Cloudflare, which is partnering with Google on the transition. “Our problem is we don’t want to leave people behind in this transition.” Speaking to Ars, he said that people will likely disable the new encryption if it slows their browsing. He added that the massive size increase can also degrade “middle boxes,” which sit between browsers and the final site.Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/06/https-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/06/https-1152x648.jpg",
      "popularity_score": 333
    },
    {
      "id": "cluster_73",
      "coverage": 1,
      "updated_at": "Sat, 28 Feb 2026 00:32:24 +0000",
      "title": "The Air Force's new ICBM is nearly ready to fly, but there’s nowhere to put it",
      "neutral_headline": "The Air Force's new ICBM is nearly ready to fly, but there’s nowhere to put it",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2026/02/the-air-forces-new-icbm-is-nearly-ready-to-fly-but-theres-nowhere-to-put-them/",
          "published_at": "Sat, 28 Feb 2026 00:32:24 +0000",
          "title": "The Air Force's new ICBM is nearly ready to fly, but there’s nowhere to put it",
          "standfirst": "\"There were assumptions that were made in the strategy that obviously didn’t come to fruition.\"",
          "content": "DENVER—The US Air Force's new Sentinel intercontinental ballistic missile is on track for its first test flight next year, military officials reaffirmed this week. But no one is ready to say when hundreds of new missile silos, dug from the windswept Great Plains, will be finished, how much they cost, or, for that matter, how many nuclear warheads each Sentinel missile could actually carry. The LGM-35A Sentinel will replace the Air Force's Minuteman III fleet, in service since 1970, with the first of the new missiles due to become operational in the early 2030s. But it will take longer than that to build and activate the full complement of Sentinel missiles and the 450 hardened underground silos to house them.Read full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/6404099-1152x648-1772236795.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/6404099-1152x648-1772236795.jpg",
      "popularity_score": 318
    },
    {
      "id": "cluster_77",
      "coverage": 1,
      "updated_at": "Fri, 27 Feb 2026 22:39:00 +0000",
      "title": "Under a Paramount-WBD merger, two struggling media giants would unite",
      "neutral_headline": "Under a Paramount-WBD merger, two struggling media giants would unite",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/02/under-a-paramount-wbd-merger-two-struggling-media-giants-would-unite/",
          "published_at": "Fri, 27 Feb 2026 22:39:00 +0000",
          "title": "Under a Paramount-WBD merger, two struggling media giants would unite",
          "standfirst": "Can two declining companies form a profitable one?",
          "content": "Netflix has dropped out of the bidding war for Warner Bros. Discovery (WBD), making Paramount Skydance the expected owner of WBD. A Paramount-WBD merger remains subject to regulatory approval, but it’s likely that we will see a Paramount-Skydance-Warner-Bros.-Discovery media giant. Such a conglomerate would unite two legacy media companies that have struggled with profitability for years and have strongly invested in streaming and cable. With Paramount inching closer to WBD ownership, let’s look at what the union implies for streaming and cable.Read full article Comments",
          "feed_position": 4,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-79075226-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-79075226-1152x648.jpg",
      "popularity_score": 293
    },
    {
      "id": "cluster_79",
      "coverage": 1,
      "updated_at": "Fri, 27 Feb 2026 21:27:33 +0000",
      "title": "Photons that aren't actually there influence superconductivity",
      "neutral_headline": "Photons that aren't actually there influence superconductivity",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/02/photons-that-arent-actually-there-influence-superconductivity/",
          "published_at": "Fri, 27 Feb 2026 21:27:33 +0000",
          "title": "Photons that aren't actually there influence superconductivity",
          "standfirst": "Interactions between neighboring materials is mediated by virtual photons.",
          "content": "Despite the headline, this isn't really a story about superconductivity—at least not the superconductivity that people care about, the stuff that doesn't require exotic refrigeration to work. Instead, it's a story about how superconductivity can be used as a test of some of the weirder consequences of quantum mechanics, one that involves non-existent particles of light that still act as if they exist. Researchers have found a way to get these virtual photons to influence the behavior of a superconductor, ultimately making it worse. That may, in the end, tell us something useful about superconductivity, but it'll probably take a little while. Virtual reality The story starts with quantum field theory, which is incredibly complex, but the simplified version is that even empty space is filled with fields that could govern the interactions of any quantum objects in or near that space. You can think of different particles as energetic excitements of these fields—so a photon is simply an energetic state of the quantum field.Read full article Comments",
          "feed_position": 5,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/niac_2011_thibeault-1041x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/niac_2011_thibeault-1041x648.jpg",
      "popularity_score": 283
    },
    {
      "id": "cluster_88",
      "coverage": 1,
      "updated_at": "Fri, 27 Feb 2026 19:04:23 +0000",
      "title": "The AI apocalypse is nigh in Good Luck, Have Fun, Don't Die",
      "neutral_headline": "The AI apocalypse is nigh in Good Luck, Have Fun, Don't Die",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/culture/2026/02/the-ai-apocalypse-is-nigh-in-good-luck-have-fun-dont-die/",
          "published_at": "Fri, 27 Feb 2026 19:04:23 +0000",
          "title": "The AI apocalypse is nigh in Good Luck, Have Fun, Don't Die",
          "standfirst": "Director Gore Verbinksi and screenwriter Matthew Robinson on the making of this darkly satirical sci-fi film.",
          "content": "We haven't had a new film from Gore Verbinski for nine years. But the director who brought us the first three Pirates of the Caribbean movies, the nightmare-inducing horror of The Ring (2002), and the Oscar-winning hijinks of Rango (2011) is back in peak form with Good Luck, Have Fun, Don't Die. It's a darkly satirical, inventive, and hugely entertaining time-loop adventure that also serves as a cautionary tale about our widespread online technology addiction. (Some spoilers below but no major reveals.) Sam Rockwell stars as an otherwise unnamed man who shows up at a Norms diner in Los Angeles looking like a homeless person but claiming to be a time traveler from an apocalyptic future. He’s there to recruit the locals into his war against a rogue AI, although the diner patrons are understandably dubious about his sanity. (“I come from a nightmare apocalypse,” he assures the crowd about his grubby appearance. “This is the height of f*@ing fashion!”)Read full article Comments",
          "feed_position": 7,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GLHFDD-TOP-1152x617.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GLHFDD-TOP-1152x617.jpg",
      "popularity_score": 278
    },
    {
      "id": "cluster_86",
      "coverage": 1,
      "updated_at": "Fri, 27 Feb 2026 19:14:51 +0000",
      "title": "Whoops: US military laser strike takes down CBP drone near Mexican border",
      "neutral_headline": "Whoops: US military laser strike takes down CBP drone near Mexican border",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/02/whoops-us-military-laser-strike-takes-down-cbp-drone-near-mexican-border/",
          "published_at": "Fri, 27 Feb 2026 19:14:51 +0000",
          "title": "Whoops: US military laser strike takes down CBP drone near Mexican border",
          "standfirst": "Trump admin \"incompetence continues to cause chaos in our skies,\" Duckworth says.",
          "content": "The US military mistakenly shot down a Customs and Border Protection (CBP) drone near the Mexican border in a strike that reportedly used a laser-based anti-drone system. The CBP uses drones to track people crossing the border. \"Congressional aides told Reuters the Pentagon used the high-energy laser system to shoot down a Customs and Border Protection drone near the Mexican border, in an area that often has incursions from Mexican drones used by drug cartels,\" Reuters reported last night. The FAA closed some airspace along the border with Mexico in Fort Hancock, Texas, on Thursday with a notice announcing temporary flight restrictions for special security reasons. The restrictions are in place until June 24 but could be lifted earlier. There are conflicting reports on which day the strike happened, with The New York Times reporting that the strike occurred Thursday and Bloomberg writing that the Federal Aviation Administration (FAA) “was notified Wednesday after the event occurred.”Read full article Comments",
          "feed_position": 6,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/cbp-drone-1152x648-1772218578.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/cbp-drone-1152x648-1772218578.jpg",
      "popularity_score": 273
    },
    {
      "id": "cluster_95",
      "coverage": 1,
      "updated_at": "Fri, 27 Feb 2026 17:21:21 +0000",
      "title": "How strong is New York's \"illegal gambling\" case against Valve's loot boxes?",
      "neutral_headline": "How strong is New York's \"illegal gambling\" case against Valve's loot boxes",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2026/02/how-strong-is-new-yorks-illegal-gambling-case-against-valves-loot-boxes/",
          "published_at": "Fri, 27 Feb 2026 17:21:21 +0000",
          "title": "How strong is New York's \"illegal gambling\" case against Valve's loot boxes?",
          "standfirst": "Lawyers tell Ars the state has a tough road ahead, even as Valve is uniquely vulnerable.",
          "content": "For years now, Valve fans have been making jokes about the company's slow transition from game maker to glorified digital hat and knife paint marketplace. This week, though, a lawsuit brought by the state of New York argues that Valve's in-game loot box sales amount to an illegal gambling outfit worth tens of billions of dollars. Lawyers who have looked into the particulars of the case tell Ars that the state faces an uphill battle in convincing courts that this portion of Valve's business legally constitutes gambling. That said, there are a few elements of the case that might make Valve legally vulnerable to the state's arguments. What is gambling, anyway? For a game to legally be counted as \"gambling\" in most jurisdictions, it has to pass a three-part test: a player has to pay money (1) for an outcome that's materially determined by chance (2) in the hopes of receiving something of value (3). While buying a key to a loot box in a Valve game easily passes those first two tests, New York's legal case will likely hinge on whether the random cosmetic items players get from those loot boxes constitute \"something of value\" for statutory purposes.Read full article Comments",
          "feed_position": 9,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/csgogun-1-1152x648.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/csgogun-1-1152x648.jpeg",
      "popularity_score": 258
    },
    {
      "id": "cluster_90",
      "coverage": 1,
      "updated_at": "Fri, 27 Feb 2026 18:36:04 +0000",
      "title": "Hyperion author Dan Simmons dies from stroke at 77",
      "neutral_headline": "Hyperion author Dan Simmons dies from stroke at 77",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/culture/2026/02/hyperion-author-dan-simmons-dies-from-stroke-at-77/",
          "published_at": "Fri, 27 Feb 2026 18:36:04 +0000",
          "title": "Hyperion author Dan Simmons dies from stroke at 77",
          "standfirst": "I went into Hyperion blind, decades ago, knowing almost nothing about it. I was never the same.",
          "content": "Dan Simmons, the author of more than three dozen books, including the famed Hyperion Cantos, has died from a stroke. He was 77. Simmons, who worked in elementary education before becoming an author in the 1980s, produced a broad portfolio of writing that spanned several genres, including horror fiction, historical fiction, and science fiction. Often, his books included elements of all of these. This obituary will focus on what is generally considered his greatest work, and what I believe is possibly the greatest science fiction novel of all time, Hyperion. Published in 1989, Hyperion is set in a far-flung future in which human settlement spans hundreds of planets. The novel feels both familiar, in that its structure follows Chaucer's Canterbury Tales, and utterly unfamiliar in its strange, far-flung setting.Read full article Comments",
          "feed_position": 8,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2015/06/Hyperion-1152x648-1772217993.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2015/06/Hyperion-1152x648-1772217993.jpg",
      "popularity_score": 250
    },
    {
      "id": "cluster_110",
      "coverage": 1,
      "updated_at": "Fri, 27 Feb 2026 14:19:00 +0000",
      "title": "Block lays off 40% of workforce as it goes all-in on AI tools",
      "neutral_headline": "Block lays off 40% of workforce as it goes all-in on AI tools",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2026/02/block-lays-off-40-of-workforce-as-it-goes-all-in-on-ai-tools/",
          "published_at": "Fri, 27 Feb 2026 14:19:00 +0000",
          "title": "Block lays off 40% of workforce as it goes all-in on AI tools",
          "standfirst": "CEO says \"most companies are late\" to realize how much technology will affect employment.",
          "content": "Block, the fintech group headed by Twitter cofounder Jack Dorsey, will cut its workforce by “nearly half” in one of the clearest signs of the sweeping changes AI tools are having on employment. Shares in the payment company soared more than 25 percent in after-hours trading on Thursday as it announced it would shed more than 4,000 jobs from its 10,000-strong workforce. “Intelligence tools have changed what it means to build and run a company. We’re already seeing it internally,” Dorsey wrote in a letter to shareholders.Read full article Comments",
          "feed_position": 14,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/jack-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/jack-1152x648.jpg",
      "popularity_score": 148
    },
    {
      "id": "cluster_111",
      "coverage": 1,
      "updated_at": "Fri, 27 Feb 2026 13:37:42 +0000",
      "title": "Apple says it has \"a big week ahead.\" Here's what we expect to see.",
      "neutral_headline": "Apple says it has \"a big week ahead.\" Here's what we expect to see.",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/02/what-new-hardware-to-expect-from-apple-next-week/",
          "published_at": "Fri, 27 Feb 2026 13:37:42 +0000",
          "title": "Apple says it has \"a big week ahead.\" Here's what we expect to see.",
          "standfirst": "Apple is taking an \"ain't broke/don't fix\" approach to most of its gadgets.",
          "content": "Excepting the AirTag 2, so far it's been a quiet year for Apple hardware. But that's poised to change next week, as the company is hosting a \"special experience\" on March 4. The use of the word experience, rather than event or presentation, implies that Apple’s typical presentation format won't apply here. And CEO Tim Cook more or less confirmed this when he posted that the company had \"a big week ahead,\" starting on Monday. Apple is most likely planning multiple days of product launches announced via press release on its Newsroom site, with the “experience” on Wednesday serving as a capper and a hands-on session for the media. Apple has used a similar strategy before, spacing out relatively low-key refreshes over several days to generate sustained interest rather than dropping everything in a single 30- to 60-minute string of pre-recorded videos.Read full article Comments",
          "feed_position": 15,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/DSC_5638-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/DSC_5638-1152x648.jpg",
      "popularity_score": 145
    },
    {
      "id": "cluster_101",
      "coverage": 1,
      "updated_at": "Fri, 27 Feb 2026 16:13:51 +0000",
      "title": "And the award for the most improved EV goes to... the 2026 Toyota bZ",
      "neutral_headline": "And the award for the most improved EV goes to... the 2026 Toyota bZ",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2026/02/and-the-award-for-the-most-improved-ev-goes-to-the-2026-toyota-bz/",
          "published_at": "Fri, 27 Feb 2026 16:13:51 +0000",
          "title": "And the award for the most improved EV goes to... the 2026 Toyota bZ",
          "standfirst": "Toyota's small electric SUV is much-revised, much more efficient, and much better.",
          "content": "The world's largest automaker has had a somewhat difficult relationship with battery-electric vehicles. Toyota was an early pioneer of hybrid powertrains, and it remains a fan today, often saying that given limited battery supply, it makes sense to build more hybrids than fewer EVs. Its first full BEV had a rocky start, suffering a recall due to improperly attached wheels just as the cars were hitting showrooms. Reviews for the awkwardly named bZ4x were mixed; the car did little to stand out among the competition. Toyota didn't get to be the world's largest automaker by being completely blind to feedback, and last year, it gave its EV platform (called e-TNGA and shared with Lexus and Subaru) a bit of a spiff-up. To start, it simplified the name—the small electric SUV is now just called the bZ. It uses a new 74.7 kWh battery pack, available with either front- or all-wheel-drive powertrains that now use silicon carbide power electronics. And for the North American market, instead of a CCS1 port just behind the front passenger wheel, you'll now see a Tesla-style NACS socket. Our test bZ was the $37,900 XLE FWD Plus, which has the most range of any bZ at 314 miles (505 km), according to the EPA test cycle. When you realize that the pre-facelift version managed just 252 miles (405 km) with 71.4 kWh onboard, the scale of the improvement becomes clear.Read full article Comments",
          "feed_position": 10,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/2026-Toyota-bZ-1-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/2026-Toyota-bZ-1-1152x648.jpg",
      "popularity_score": 139
    },
    {
      "id": "cluster_106",
      "coverage": 1,
      "updated_at": "Fri, 27 Feb 2026 15:13:48 +0000",
      "title": "Netflix cedes Warner Bros. Discovery to Paramount: “No longer financially attractive”",
      "neutral_headline": "Netflix cedes Warner Bros. Discovery to Paramount: “No longer financially attractive”",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/02/netflix-cedes-warner-bros-discovery-to-paramount-no-longer-financially-attractive/",
          "published_at": "Fri, 27 Feb 2026 15:13:48 +0000",
          "title": "Netflix cedes Warner Bros. Discovery to Paramount: “No longer financially attractive”",
          "standfirst": "Netflix shares jumped following the announcement.",
          "content": "Netflix backed out of its deal to acquire Warner Bros. Discovery’s (WBD’s) streaming and movie studios businesses on Thursday night. After increasing its bid for all of WBD by $1 per share on Tuesday, Paramount Skydance is poised to become the new owner of WBD, including Game of Thrones, DC Comics, and other IP, as well as the HBO Max streaming service and cable channels CNN and TBS. Netflix and WBD announced merger intentions on December 5. Netflix was going to pay an equity value of $72 billion, or an approximate total enterprise value of $82.7 billion, for part of WBD. At the time, NBC News reported that WBD’s total market value was $60 billion. But Paramount has reportedly been eyeing WBD for years and followed December's merger announcement with an aggressive hostile takeover bid. On Tuesday, in addition to raising its offer to buy all of WBD, Paramount also agreed to pay a $7 billion regulatory termination fee should a Paramount-WBD merger fail to close due to antitrust regulation, as well as a $0.25 per share ticking fee for every quarter that the deal doesn’t close, starting on September 30.Read full article Comments",
          "feed_position": 11,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-2258061457-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-2258061457-1152x648.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_107",
      "coverage": 1,
      "updated_at": "Fri, 27 Feb 2026 15:08:08 +0000",
      "title": "NASA shakes up its Artemis program to speed up lunar return",
      "neutral_headline": "NASA shakes up its Artemis program to speed up lunar return",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/staff/2026/02/nasa-shakes-up-its-artemis-program-to-speed-up-lunar-return/",
          "published_at": "Fri, 27 Feb 2026 15:08:08 +0000",
          "title": "NASA shakes up its Artemis program to speed up lunar return",
          "standfirst": "\"Launching SLS every three and a half years or so is not a recipe for success.\"",
          "content": "NASA Administrator Jared Isaacman announced sweeping changes to the Artemis program on Friday morning, including an increased cadence of missions and cancellation of an expensive rocket stage. The upheaval comes as NASA has struggled to fuel the massive Space Launch System rocket for the upcoming Artemis II lunar mission, and Isaacman has sought to revitalize an agency that has moved at a glacial pace on its deep space programs. There is ever-increasing concern that, absent a shake-up, China's rising space program will land humans on the Moon before NASA can return there this decade with Artemis. \"NASA must standardize its approach, increase flight rate safely, and execute on the president’s national space policy,\" Isaacman said. \"With credible competition from our greatest geopolitical adversary increasing by the day, we need to move faster, eliminate delays, and achieve our objectives.\"Read full article Comments",
          "feed_position": 12,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/07/eus_art-1152x648-1753395940.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/07/eus_art-1152x648-1753395940.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_114",
      "coverage": 1,
      "updated_at": "Fri, 27 Feb 2026 12:00:13 +0000",
      "title": "Rocket Report: Vulcan \"many months\" from flying; Falcon 9 extends reuse milestone",
      "neutral_headline": "Rocket Report: Vulcan \"many months\" from flying; Falcon 9 extends reuse milestone",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2026/02/rocket-report-neutron-launch-date-is-delayed-again-vector-launch-is-back-sort-of/",
          "published_at": "Fri, 27 Feb 2026 12:00:13 +0000",
          "title": "Rocket Report: Vulcan \"many months\" from flying; Falcon 9 extends reuse milestone",
          "standfirst": "\"As the original architect of Vector’s vision, it’s deeply meaningful to bring these assets home.\"",
          "content": "Welcome to Edition 8.31 of the Rocket Report! We have some late-breaking news this week with an update Thursday afternoon from Rocket Lab on the timing of its much-anticipated Neutron rocket. Following the failure of a first stage tank during testing, the company is pushing the medium-lift rocket's debut into the fourth quarter of this year. Effectively that probably means 2027 for the booster, which is disappointing because we all very much want to see another reusable rocket take flight. As always, we welcome reader submissions, and if you don't want to miss an issue, please subscribe using the box below (the form will not appear on AMP-enabled versions of the site). Each report will include information on small-, medium-, and heavy-lift rockets as well as a quick look ahead at the next three launches on the calendar. The ghost of Vector lives on. Tucson, Arizona-based satellite and rocket developer Phantom Space, co-founded by Jim Cantrell in 2019, has acquired the remnants of Vector Launch, Space News reports. The announcement is notable because Cantrell left Vector as its finances deteriorated in 2019. Cantrell said some of the assets, comprising flight-proven design elements, engineering data, and other technology originally developed for Vector, will be immediately integrated into Phantom’s Daytona vehicle architecture to reduce development risk.Read full article Comments",
          "feed_position": 16,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/Neutron-Hungry-Hippo-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/Neutron-Hungry-Hippo-1152x648.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_109",
      "coverage": 1,
      "updated_at": "Fri, 27 Feb 2026 14:34:45 +0000",
      "title": "How to downgrade from macOS 26 Tahoe on a new Mac",
      "neutral_headline": "How to downgrade from macOS 26 Tahoe on a new Mac",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/02/how-to-downgrade-from-macos-26-tahoe-on-a-new-mac/",
          "published_at": "Fri, 27 Feb 2026 14:34:45 +0000",
          "title": "How to downgrade from macOS 26 Tahoe on a new Mac",
          "standfirst": "Most new Macs can still be downgraded with few downsides. Here's what to know.",
          "content": "An Ars Technica colleague recently bought a new M4 MacBook Air. I have essentially nothing bad to say about this hardware, except to point out that even in our current memory shortage apocalypse, Apple is still charging higher-than-market-rates for RAM and SSD upgrades. Still, most people buying this laptop will have a perfectly nice time with it. But for this colleague, it was also their first interaction with macOS 26 Tahoe and the Liquid Glass redesign, the Mac's first major software design update since the Apple Silicon era began with macOS 11 Big Sur in 2020. Negative consumer reaction to Liquid Glass has been overstated by some members of the Apple enthusiast media ecosystem, and Apple's data shows that iOS 26 adoption rates are roughly in line with those of the last few years. But the Mac's foray into Liquid Glass has drawn particular ire from longtime users (developers Jeff Johnson and Norbert Heger have been tracking persistently weird Finder and window resizing behavior, to pick two concrete examples, and Daring Fireball's John Gruber has encouraged users not to upgrade).Read full article Comments",
          "feed_position": 13,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/tahoe-goodbye-imac-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/tahoe-goodbye-imac-1152x648.jpg",
      "popularity_score": 130
    }
  ]
}