{
  "updated_at": "2025-10-28T07:13:53.720Z",
  "clusters": [
    {
      "id": "cluster_0",
      "coverage": 2,
      "updated_at": "Tue, 28 Oct 2025 07:00:37 +0000",
      "title": "The best wireless headphones for 2025: Bluetooth options for every budget",
      "neutral_headline": "Best Wireless Headphones for 2025 Announced",
      "bullet_summary": [
        "It can be found on Hugging Face, GitHub and ModelScope, as well as through MiniMax&#x27;s API here",
        "It supports OpenAI and Anthropic API standards, as well, making it easy for customers of said proprietary AI startups to shift out their models to MiniMax&#x27;s API, if they want",
        "Strong Showing in Artificial Analysis’ Intelligence IndexThe model’s overall intelligence profile is confirmed in the latest Artificial Analysis Intelligence Index v3",
        "For enterprise users, this consistency indicates a reliable model foundation suitable for integration into software engineering, customer support, or knowledge automation systems"
      ],
      "items": [
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/audio/headphones/best-headphones-wireless-bluetooth-120543205.html",
          "published_at": "Tue, 28 Oct 2025 07:00:37 +0000",
          "title": "The best wireless headphones for 2025: Bluetooth options for every budget",
          "standfirst": "Wireless headphones have come a long way from the bulky designs of the past. Today’s models are lighter, smarter and packed with features that make them useful for everything from travel to long workdays at your desk. Many offer strong noise cancellation, quick pairing and reliable battery life — all of which makes them an easy upgrade if you want more freedom from your devices.Of course, not every listener has the same needs. Some people want portability, which is why our guide to the best earbuds is worth a look, while others want something more specialized like the best gaming headsets or the best budget earbuds. But if you’re after over-ear headphones that focus on comfort and immersive sound, this roundup of the best wireless headphones highlights the top choices we’ve tested. Table of contents Best wireless headphones for 2025 How to choose the best wireless headphones for you How we test over-ear headphones Other wireless headphones we tested Wireless headphones FAQs Best wireless headphones for 2025 How to choose the best wireless headphones for you When it comes to shopping for a good pair of wireless headphones, the first thing you’ll need to decide on is wear style. Do you prefer on-ear or over-ear headphones? For the purposes of our buyer’s guide, we focus on the over-ear style as that’s what most noise-canceling headphones are nowadays. Sure, you can find on-ear models with ANC, but over-ear designs are much more effective at blocking sound. Speaking of noise cancellation, you’ll want to determine early on if you even want that. If you frequently crank up the beats in noisy environments, you’ll want to not only make sure it’s there, but also make sure it’s good, preferably with adaptive ANC. If you plan to use your new headphones in quieter spaces, skipping ANC can save you some money. The next area to consider is features. We recommend trying to get the most bang for your buck, but as you’re shopping around you should determine which items are must-haves and what you can live without. And don’t take basic things like automatic pausing and Bluetooth multipoint connectivity for granted, as not all companies include them. We also suggest reading reviews to see how well a company’s more advanced features work. This will help you decide if those are something you’re willing to (likely) pay extra for. Keep an eye on better battery life estimates to avoid disappointment, as some manufacturers promise more hours than real-world testing delivers. And don’t be easily swayed by lofty promises about call quality without verifying them. Sound can be subjective, so we recommend trying before you buy if at all possible. We understand this isn’t easy at a time when we’re doing most of our shopping online. But trying on a set of headphones and listening to them for a few minutes can save you from an expensive case of buyer’s remorse. We also recommend paying attention to things like Spatial Audio, Dolby Atmos, 360 Reality Audio and other immersive formats. Not all headphones support them, so you’ll want to make sure a perspective pair does if that sort of thing excites you. If you plan to use your headphones for other media besides music, checking for latency is also a must — some delay can impact playback for things like movies or games, even if most true wireless headphones now offer minimal lag. How we test over-ear headphones The primary way we test wireless headphones is to wear them as much as possible. We prefer to do this over a one- to two-week period, but sometimes embargoes don’t allow it. During this time, we listen to a mix of music and podcasts, while also using the earbuds to take both voice and video calls. Since battery life for headphones can be 30 hours or more, we drain the battery with looping music and the volume set at a comfortable level (usually around 75 percent). Due to the longer battery estimates, we’ll typically power the headphones off several times and leave them during a review. This simulates real-world use and keeps us from having to constantly monitor the process for over 24 straight hours. To judge the best Bluetooth headphones, we focus on higher-quality audio by listening to a variety of genres and paying close attention to how each style sounds. We also test at both low and high volumes to check for consistency in the tuning. To assess the quality of phone calls, we’ll record audio samples with the headphones’ microphones as well as have third parties call us. When it comes to features, we do a thorough review of companion apps, testing each feature as we work through the software. Any holdovers from previous models are double checked for improvements or regression. If the headphones we’re testing are an updated version of a previous model, we’ll spend time getting reacquainted with the older set. Ditto for the closest competition for each new set of headphones that we review. Other wireless headphones we tested AirPods Max Apple’s AirPods Max are premium, well-designed over-ear headphones that incorporate all of the best features you find on standard AirPods: solid noise cancelation, spatial audio and easy Siri access. However, their $550 starting price makes them almost prohibitively expensive, even for Apple users. There are better options available at lower prices, but if you can pick up the AirPods Max at a steep discount, they might be worthwhile for the biggest Apple fans among us. Dyson On-Trac The On-Trac headphones have an almost infinitely customizable design, and that’s what’s most unique about them. The sound profile offers some nice detail, but lacks dynamic range overall. ANC is average at best and there aren’t any advanced features that will make your life easier. Well, except for the hearing health monitor which is actually handy. All told, that’s not a lot in a set of $500 headphones. Sonos Ace The Sonos Ace is an excellent debut for the company’s first headphones. The combination of refined design, great sound quality and home theater tricks creates a unique formula. However, ANC performance is just okay and key functionality is still in the works for many users. Sony ULT Wear If most headphones don’t have the level of bass you desire, the ULT Wear is an option to consider. The low-end thump isn’t for everyone, but there are also plenty of handy features and a refined look to make the $200 set more compelling than many in this price range. Sony WH-CH720N While the WH-CH720N are a great affordable option, we prefer the Audio-Technica in the budget category. Sony’s cans are lightweight with good sound quality, but ANC struggles at times and they’re made with a lot of plastic. Beats Studio Pro The Studio Pro lacks basic features like automatic pausing, and multipoint connectivity is only available on Android. Moreover, they’re not very comfortable for people with larger heads. Overall sound quality is improved, though, and voice performance on calls is well above average. Bose QuietComfort Ultra headphones Bose’s latest flagship model has a lot to offer, but its trademark Immersive Audio feature can be inconsistent across different types of music. There’s still world-class ANC, excellent comfort and a clearer transparency mode, but for the price, the non-Ultra model is a better choice right now. Master & Dynamic MH40 (2nd gen) The MH40 are a great set of headphones if you favor crisp, clear and natural sound that isn’t overly tuned. This pair showcases the company’s affinity for leather and metal too, but limited customization and short battery life for non-ANC cans kept this set from making the cut. Bowers & Wilkins Px8 The company’s trademark pristine sound is on display here, but the Px8 are more expensive and not nearly as comfortable as the Px7 S2. Wireless headphones FAQs How can you tell the quality of wireless headphones? I typically look at three factors: design, sound quality and features. In terms of design, I’m usually looking to see if the build quality of the headphones feels cheap and plasticky. Plenty of companies use plastic, but they can do so in a way that doesn’t look or feel like budget models. For sound quality, I want to hear a nice, even tuning where highs, mids and lows are all well represented. No overly boomy bass or scooped out mids. I also want good clarity where you can pick up fine details and an open, immersive soundstage. Features is typically a distant third, but if a company doesn’t cover basic functionality (automatic pausing, transparency mode, multipoint Bluetooth, etc.) it can be an indication of overall quality. How do I choose the best quality wireless headphones? “Best” can be pretty subjective, but I always recommend going to a place where you can listen to the headphones you’re thinking about buying before you commit. Sometimes this isn’t possible, so you’ll want to check return policies. I also recommend doing some research to determine what your priorities are in a new set. Are you an audiophile who wants the best sound quality? Is powerful active noise cancellation (ANC) the most important? Would you rather have conveniences like automatic pausing? Which brand has the best wireless headphones? Sony consistently tops our list with its 1000X line. This is mostly due to the combination of sound quality, ANC performance and the truckload of features these headphones pack in. I’ll be the first to tell you that there are better sounding options and other companies, like Bose, offer more effective noise cancellation. But when you add everything up, no one comes close to the full slate of tools Sony puts in its premium headphone line. Do expensive wireless headphones sound better? Exorbitant price tags don’t mean better audio quality. Bowers & Wilkins’ headphones are on the high end for wireless noise-canceling models and they sound amazing. However, Audio-Technica’s M50xBT2 is much more affordable and doesn’t have ANC, but these headphones have a warm, natural sound profile that I find very inviting. At the end of the day, it will come down to personal preference, but you don’t need to spend a lot to find great headphones.This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/best-headphones-wireless-bluetooth-120543205.html?src=rss",
          "content": "Wireless headphones have come a long way from the bulky designs of the past. Today’s models are lighter, smarter and packed with features that make them useful for everything from travel to long workdays at your desk. Many offer strong noise cancellation, quick pairing and reliable battery life — all of which makes them an easy upgrade if you want more freedom from your devices.Of course, not every listener has the same needs. Some people want portability, which is why our guide to the best earbuds is worth a look, while others want something more specialized like the best gaming headsets or the best budget earbuds. But if you’re after over-ear headphones that focus on comfort and immersive sound, this roundup of the best wireless headphones highlights the top choices we’ve tested. Table of contents Best wireless headphones for 2025 How to choose the best wireless headphones for you How we test over-ear headphones Other wireless headphones we tested Wireless headphones FAQs Best wireless headphones for 2025 How to choose the best wireless headphones for you When it comes to shopping for a good pair of wireless headphones, the first thing you’ll need to decide on is wear style. Do you prefer on-ear or over-ear headphones? For the purposes of our buyer’s guide, we focus on the over-ear style as that’s what most noise-canceling headphones are nowadays. Sure, you can find on-ear models with ANC, but over-ear designs are much more effective at blocking sound. Speaking of noise cancellation, you’ll want to determine early on if you even want that. If you frequently crank up the beats in noisy environments, you’ll want to not only make sure it’s there, but also make sure it’s good, preferably with adaptive ANC. If you plan to use your new headphones in quieter spaces, skipping ANC can save you some money. The next area to consider is features. We recommend trying to get the most bang for your buck, but as you’re shopping around you should determine which items are must-haves and what you can live without. And don’t take basic things like automatic pausing and Bluetooth multipoint connectivity for granted, as not all companies include them. We also suggest reading reviews to see how well a company’s more advanced features work. This will help you decide if those are something you’re willing to (likely) pay extra for. Keep an eye on better battery life estimates to avoid disappointment, as some manufacturers promise more hours than real-world testing delivers. And don’t be easily swayed by lofty promises about call quality without verifying them. Sound can be subjective, so we recommend trying before you buy if at all possible. We understand this isn’t easy at a time when we’re doing most of our shopping online. But trying on a set of headphones and listening to them for a few minutes can save you from an expensive case of buyer’s remorse. We also recommend paying attention to things like Spatial Audio, Dolby Atmos, 360 Reality Audio and other immersive formats. Not all headphones support them, so you’ll want to make sure a perspective pair does if that sort of thing excites you. If you plan to use your headphones for other media besides music, checking for latency is also a must — some delay can impact playback for things like movies or games, even if most true wireless headphones now offer minimal lag. How we test over-ear headphones The primary way we test wireless headphones is to wear them as much as possible. We prefer to do this over a one- to two-week period, but sometimes embargoes don’t allow it. During this time, we listen to a mix of music and podcasts, while also using the earbuds to take both voice and video calls. Since battery life for headphones can be 30 hours or more, we drain the battery with looping music and the volume set at a comfortable level (usually around 75 percent). Due to the longer battery estimates, we’ll typically power the headphones off several times and leave them during a review. This simulates real-world use and keeps us from having to constantly monitor the process for over 24 straight hours. To judge the best Bluetooth headphones, we focus on higher-quality audio by listening to a variety of genres and paying close attention to how each style sounds. We also test at both low and high volumes to check for consistency in the tuning. To assess the quality of phone calls, we’ll record audio samples with the headphones’ microphones as well as have third parties call us. When it comes to features, we do a thorough review of companion apps, testing each feature as we work through the software. Any holdovers from previous models are double checked for improvements or regression. If the headphones we’re testing are an updated version of a previous model, we’ll spend time getting reacquainted with the older set. Ditto for the closest competition for each new set of headphones that we review. Other wireless headphones we tested AirPods Max Apple’s AirPods Max are premium, well-designed over-ear headphones that incorporate all of the best features you find on standard AirPods: solid noise cancelation, spatial audio and easy Siri access. However, their $550 starting price makes them almost prohibitively expensive, even for Apple users. There are better options available at lower prices, but if you can pick up the AirPods Max at a steep discount, they might be worthwhile for the biggest Apple fans among us. Dyson On-Trac The On-Trac headphones have an almost infinitely customizable design, and that’s what’s most unique about them. The sound profile offers some nice detail, but lacks dynamic range overall. ANC is average at best and there aren’t any advanced features that will make your life easier. Well, except for the hearing health monitor which is actually handy. All told, that’s not a lot in a set of $500 headphones. Sonos Ace The Sonos Ace is an excellent debut for the company’s first headphones. The combination of refined design, great sound quality and home theater tricks creates a unique formula. However, ANC performance is just okay and key functionality is still in the works for many users. Sony ULT Wear If most headphones don’t have the level of bass you desire, the ULT Wear is an option to consider. The low-end thump isn’t for everyone, but there are also plenty of handy features and a refined look to make the $200 set more compelling than many in this price range. Sony WH-CH720N While the WH-CH720N are a great affordable option, we prefer the Audio-Technica in the budget category. Sony’s cans are lightweight with good sound quality, but ANC struggles at times and they’re made with a lot of plastic. Beats Studio Pro The Studio Pro lacks basic features like automatic pausing, and multipoint connectivity is only available on Android. Moreover, they’re not very comfortable for people with larger heads. Overall sound quality is improved, though, and voice performance on calls is well above average. Bose QuietComfort Ultra headphones Bose’s latest flagship model has a lot to offer, but its trademark Immersive Audio feature can be inconsistent across different types of music. There’s still world-class ANC, excellent comfort and a clearer transparency mode, but for the price, the non-Ultra model is a better choice right now. Master & Dynamic MH40 (2nd gen) The MH40 are a great set of headphones if you favor crisp, clear and natural sound that isn’t overly tuned. This pair showcases the company’s affinity for leather and metal too, but limited customization and short battery life for non-ANC cans kept this set from making the cut. Bowers & Wilkins Px8 The company’s trademark pristine sound is on display here, but the Px8 are more expensive and not nearly as comfortable as the Px7 S2. Wireless headphones FAQs How can you tell the quality of wireless headphones? I typically look at three factors: design, sound quality and features. In terms of design, I’m usually looking to see if the build quality of the headphones feels cheap and plasticky. Plenty of companies use plastic, but they can do so in a way that doesn’t look or feel like budget models. For sound quality, I want to hear a nice, even tuning where highs, mids and lows are all well represented. No overly boomy bass or scooped out mids. I also want good clarity where you can pick up fine details and an open, immersive soundstage. Features is typically a distant third, but if a company doesn’t cover basic functionality (automatic pausing, transparency mode, multipoint Bluetooth, etc.) it can be an indication of overall quality. How do I choose the best quality wireless headphones? “Best” can be pretty subjective, but I always recommend going to a place where you can listen to the headphones you’re thinking about buying before you commit. Sometimes this isn’t possible, so you’ll want to check return policies. I also recommend doing some research to determine what your priorities are in a new set. Are you an audiophile who wants the best sound quality? Is powerful active noise cancellation (ANC) the most important? Would you rather have conveniences like automatic pausing? Which brand has the best wireless headphones? Sony consistently tops our list with its 1000X line. This is mostly due to the combination of sound quality, ANC performance and the truckload of features these headphones pack in. I’ll be the first to tell you that there are better sounding options and other companies, like Bose, offer more effective noise cancellation. But when you add everything up, no one comes close to the full slate of tools Sony puts in its premium headphone line. Do expensive wireless headphones sound better? Exorbitant price tags don’t mean better audio quality. Bowers & Wilkins’ headphones are on the high end for wireless noise-canceling models and they sound amazing. However, Audio-Technica’s M50xBT2 is much more affordable and doesn’t have ANC, but these headphones have a warm, natural sound profile that I find very inviting. At the end of the day, it will come down to personal preference, but you don’t need to spend a lot to find great headphones.This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/best-headphones-wireless-bluetooth-120543205.html?src=rss",
          "feed_position": 0
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/minimax-m2-is-the-new-king-of-open-source-llms-especially-for-agentic-tool",
          "published_at": "Mon, 27 Oct 2025 19:01:00 GMT",
          "title": "MiniMax-M2 is the new king of open source LLMs (especially for agentic tool calling)",
          "standfirst": "Watch out, DeepSeek and Qwen! There&#x27;s a new king of open source large language models (LLMs), especially when it comes to something enterprises are increasingly valuing: agentic tool use — that is, the ability to go off and use other software capabilities like web search or bespoke applications — without much human guidance. That model is none other than MiniMax-M2, the latest LLM from the Chinese startup of the same name. And in a big win for enterprises globally, the model is available under a permissive, enterprise-friendly MIT License, meaning it is made available freely for developers to take, deploy, retrain, and use how they see fit — even for commercial purposes. It can be found on Hugging Face, GitHub and ModelScope, as well as through MiniMax&#x27;s API here. It supports OpenAI and Anthropic API standards, as well, making it easy for customers of said proprietary AI startups to shift out their models to MiniMax&#x27;s API, if they want.According to independent evaluations by Artificial Analysis, a third-party generative AI model benchmarking and research organization, M2 now ranks first among all open-weight systems worldwide on the Intelligence Index—a composite measure of reasoning, coding, and task-execution performance. In agentic benchmarks that measure how well a model can plan, execute, and use external tools—skills that power coding assistants and autonomous agents—MiniMax’s own reported results, following the Artificial Analysis methodology, show τ²-Bench 77.2, BrowseComp 44.0, and FinSearchComp-global 65.5. These scores place it at or near the level of top proprietary systems like GPT-5 (thinking) and Claude Sonnet 4.5, making MiniMax-M2 the highest-performing open model yet released for real-world agentic and tool-calling tasks.What It Means For Enterprises and the AI RaceBuilt around an efficient Mixture-of-Experts (MoE) architecture, MiniMax-M2 delivers high-end capability for agentic and developer workflows while remaining practical for enterprise deployment.For technical decision-makers, the release marks an important turning point for open models in business settings. MiniMax-M2 combines frontier-level reasoning with a manageable activation footprint—just 10 billion active parameters out of 230 billion total. This design enables enterprises to operate advanced reasoning and automation workloads on fewer GPUs, achieving near-state-of-the-art results without the infrastructure demands or licensing costs associated with proprietary frontier systems.Artificial Analysis’ data show that MiniMax-M2’s strengths go beyond raw intelligence scores. The model leads or closely trails top proprietary systems such as GPT-5 (thinking) and Claude Sonnet 4.5 across benchmarks for end-to-end coding, reasoning, and agentic tool use. Its performance in τ²-Bench, SWE-Bench, and BrowseComp indicates particular advantages for organizations that depend on AI systems capable of planning, executing, and verifying complex workflows—key functions for agentic and developer tools inside enterprise environments.As LLM engineer Pierre-Carl Langlais aka Alexander Doria posted on X: \"MiniMax [is] making a case for mastering the technology end-to-end to get actual agentic automation.\"Compact Design, Scalable PerformanceMiniMax-M2’s technical architecture is a sparse Mixture-of-Experts model with 230 billion total parameters and 10 billion active per inference. This configuration significantly reduces latency and compute requirements while maintaining broad general intelligence. The design allows for responsive agent loops—compile–run–test or browse–retrieve–cite cycles—that execute faster and more predictably than denser models.For enterprise technology teams, this means easier scaling, lower cloud costs, and reduced deployment friction. According to Artificial Analysis, the model can be served efficiently on as few as four NVIDIA H100 GPUs at FP8 precision, a setup well within reach for mid-size organizations or departmental AI clusters.Benchmark Leadership Across Agentic and Coding WorkflowsMiniMax’s benchmark suite highlights strong real-world performance across developer and agent environments. The figure below, released with the model, compares MiniMax-M2 (in red) with several leading proprietary and open models, including GPT-5 (thinking), Claude Sonnet 4.5, Gemini 2.5 Pro, and DeepSeek-V3.2.MiniMax-M2 achieves top or near-top performance in many categories:SWE-bench Verified: 69.4 — close to GPT-5’s 74.9ArtifactsBench: 66.8 — above Claude Sonnet 4.5 and DeepSeek-V3.2τ²-Bench: 77.2 — approaching GPT-5’s 80.1GAIA (text only): 75.7 — surpassing DeepSeek-V3.2BrowseComp: 44.0 — notably stronger than other open modelsFinSearchComp-global: 65.5 — best among tested open-weight systemsThese results show MiniMax-M2’s capability in executing complex, tool-augmented tasks across multiple languages and environments—skills increasingly relevant for automated support, R&D, and data analysis inside enterprises.Strong Showing in Artificial Analysis’ Intelligence IndexThe model’s overall intelligence profile is confirmed in the latest Artificial Analysis Intelligence Index v3.0, which aggregates performance across ten reasoning benchmarks including MMLU-Pro, GPQA Diamond, AIME 2025, IFBench, and τ²-Bench Telecom.MiniMax-M2 scored 61 points, ranking as the highest open-weight model globally and following closely behind GPT-5 (high) and Grok 4. Artificial Analysis highlighted the model’s balance between technical accuracy, reasoning depth, and applied intelligence across domains. For enterprise users, this consistency indicates a reliable model foundation suitable for integration into software engineering, customer support, or knowledge automation systems.Designed for Developers and Agentic SystemsMiniMax engineered M2 for end-to-end developer workflows, enabling multi-file code edits, automated testing, and regression repair directly within integrated development environments or CI/CD pipelines. The model also excels in agentic planning—handling tasks that combine web search, command execution, and API calls while maintaining reasoning traceability.These capabilities make MiniMax-M2 especially valuable for enterprises exploring autonomous developer agents, data analysis assistants, or AI-augmented operational tools. Benchmarks such as Terminal-Bench and BrowseComp demonstrate the model’s ability to adapt to incomplete data and recover gracefully from intermediate errors, improving reliability in production settings.Interleaved Thinking and Structured Tool UseA distinctive aspect of MiniMax-M2 is its interleaved thinking format, which maintains visible reasoning traces between <think>...</think> tags.This enables the model to plan and verify steps across multiple exchanges, a critical feature for agentic reasoning. MiniMax advises retaining these segments when passing conversation history to preserve the model’s logic and continuity.The company also provides a Tool Calling Guide on Hugging Face, detailing how developers can connect external tools and APIs via structured XML-style calls. This functionality allows MiniMax-M2 to serve as the reasoning core for larger agent frameworks, executing dynamic tasks such as search, retrieval, and computation through external functions.Open Source Access and Enterprise Deployment OptionsEnterprises can access the model through the MiniMax Open Platform API and MiniMax Agent interface (a web chat similar to ChatGPT), both currently free for a limited time.MiniMax recommends SGLang and vLLM for efficient serving, each offering day-one support for the model’s unique interleaved reasoning and tool-calling structure. Deployment guides and parameter configurations are available through MiniMax’s documentation.Cost Efficiency and Token EconomicsAs Artificial Analysis noted, MiniMax’s API pricing is set at $0.30 per million input tokens and $1.20 per million output tokens, among the most competitive in the open-model ecosystem. ProviderModel (doc link)Input $/1MOutput $/1MNotesMiniMaxMiniMax-M2$0.30$1.20Listed under “Chat Completion v2” for M2. OpenAIGPT-5$1.25$10.00Flagship model pricing on OpenAI’s API pricing page. OpenAIGPT-5 mini$0.25$2.00Cheaper tier for well-defined tasks. AnthropicClaude Sonnet 4.5$3.00$15.00Anthropic’s current per-MTok list; long-context (>200K input) uses a premium tier. GoogleGemini 2.5 Flash (Preview)$0.30$2.50Prices include “thinking tokens”; page also lists cheaper Flash-Lite and 2.0 tiers. xAIGrok-4 Fast (reasoning)$0.20$0.50“Fast” tier; xAI also lists Grok-4 at $3 / $15. DeepSeekDeepSeek-V3.2 (chat)$0.28$0.42Cache-hit input is $0.028; table shows per-model details. Qwen (Alibaba)qwen-flash (Model Studio)from $0.022from $0.216Tiered by input size (≤128K, ≤256K, ≤1M tokens); listed “Input price / Output price per 1M”. CohereCommand R+ (Aug 2024)$2.50$10.00First-party pricing page also lists Command R ($0.50 / $1.50) and others. Notes & caveats (for readers):Prices are USD per million tokens and can change; check linked pages for updates and region/endpoint nuances (e.g., Anthropic long-context >200K input, Google Live API variants, cache discounts). Vendors may bill extra for server-side tools (web search, code execution) or offer batch/context-cache discounts. While the model produces longer, more explicit reasoning traces, its sparse activation and optimized compute design help maintain a favorable cost-performance balance—an advantage for teams deploying interactive agents or high-volume automation systems.Background on MiniMax — an Emerging Chinese PowerhouseMiniMax has quickly become one of the most closely watched names in China’s fast-rising AI sector. Backed by Alibaba and Tencent, the company moved from relative obscurity to international recognition within a year—first through breakthroughs in AI video generation, then through a series of open-weight large language models (LLMs) aimed squarely at developers and enterprises.The company first captured global attention in late 2024 with its AI video generation tool, “video-01,” which demonstrated the ability to create dynamic, cinematic scenes in seconds. VentureBeat described how the model’s launch sparked widespread interest after online creators began sharing lifelike, AI-generated footage—most memorably, a viral clip of a Star Wars lightsaber duel that drew millions of views in under two days. CEO Yan Junjie emphasized that the system outperformed leading Western tools in generating human movement and expression, an area where video AIs often struggle. The product, later commercialized through MiniMax’s Hailuo platform, showcased the startup’s technical confidence and creative reach, helping to establish China as a serious contender in generative video technology.By early 2025, MiniMax had turned its attention to long-context language modeling, unveiling the MiniMax-01 series, including MiniMax-Text-01 and MiniMax-VL-01. These open-weight models introduced an unprecedented 4-million-token context window, doubling the reach of Google’s Gemini 1.5 Pro and dwarfing OpenAI’s GPT-4o by more than twentyfold. The company continued its rapid cadence with the MiniMax-M1 release in June 2025, a model focused on long-context reasoning and reinforcement learning efficiency. M1 extended context capacity to 1 million tokens and introduced a hybrid Mixture-of-Experts design trained using a custom reinforcement-learning algorithm known as CISPO. Remarkably, VentureBeat reported that MiniMax trained M1 at a total cost of about $534,700, roughly one-tenth of DeepSeek’s R1 and far below the multimillion-dollar budgets typical for frontier-scale models. For enterprises and technical teams, MiniMax’s trajectory signals the arrival of a new generation of cost-efficient, open-weight models designed for real-world deployment. Its open licensing—ranging from Apache 2.0 to MIT—gives businesses freedom to customize, self-host, and fine-tune without vendor lock-in or compliance restrictions. Features such as structured function calling, long-context retention, and high-efficiency attention architectures directly address the needs of engineering groups managing multi-step reasoning systems and data-intensive pipelines.As MiniMax continues to expand its lineup, the company has emerged as a key global innovator in open-weight AI, combining ambitious research with pragmatic engineering. Open-Weight Leadership and Industry ContextThe release of MiniMax-M2 reinforces the growing leadership of Chinese AI research groups in open-weight model development. Following earlier contributions from DeepSeek, Alibaba’s Qwen series, and Moonshot AI, MiniMax’s entry continues the trend toward open, efficient systems designed for real-world use. Artificial Analysis observed that MiniMax-M2 exemplifies a broader shift in focus toward agentic capability and reinforcement-learning refinement, prioritizing controllable reasoning and real utility over raw model size.For enterprises, this means access to a state-of-the-art open model that can be audited, fine-tuned, and deployed internally with full transparency. By pairing strong benchmark performance with open licensing and efficient scaling, MiniMaxAI positions MiniMax-M2 as a practical foundation for intelligent systems that think, act, and assist with traceable logic—making it one of the most enterprise-ready open AI models available today.",
          "content": "Watch out, DeepSeek and Qwen! There&#x27;s a new king of open source large language models (LLMs), especially when it comes to something enterprises are increasingly valuing: agentic tool use — that is, the ability to go off and use other software capabilities like web search or bespoke applications — without much human guidance. That model is none other than MiniMax-M2, the latest LLM from the Chinese startup of the same name. And in a big win for enterprises globally, the model is available under a permissive, enterprise-friendly MIT License, meaning it is made available freely for developers to take, deploy, retrain, and use how they see fit — even for commercial purposes. It can be found on Hugging Face, GitHub and ModelScope, as well as through MiniMax&#x27;s API here. It supports OpenAI and Anthropic API standards, as well, making it easy for customers of said proprietary AI startups to shift out their models to MiniMax&#x27;s API, if they want.According to independent evaluations by Artificial Analysis, a third-party generative AI model benchmarking and research organization, M2 now ranks first among all open-weight systems worldwide on the Intelligence Index—a composite measure of reasoning, coding, and task-execution performance. In agentic benchmarks that measure how well a model can plan, execute, and use external tools—skills that power coding assistants and autonomous agents—MiniMax’s own reported results, following the Artificial Analysis methodology, show τ²-Bench 77.2, BrowseComp 44.0, and FinSearchComp-global 65.5. These scores place it at or near the level of top proprietary systems like GPT-5 (thinking) and Claude Sonnet 4.5, making MiniMax-M2 the highest-performing open model yet released for real-world agentic and tool-calling tasks.What It Means For Enterprises and the AI RaceBuilt around an efficient Mixture-of-Experts (MoE) architecture, MiniMax-M2 delivers high-end capability for agentic and developer workflows while remaining practical for enterprise deployment.For technical decision-makers, the release marks an important turning point for open models in business settings. MiniMax-M2 combines frontier-level reasoning with a manageable activation footprint—just 10 billion active parameters out of 230 billion total. This design enables enterprises to operate advanced reasoning and automation workloads on fewer GPUs, achieving near-state-of-the-art results without the infrastructure demands or licensing costs associated with proprietary frontier systems.Artificial Analysis’ data show that MiniMax-M2’s strengths go beyond raw intelligence scores. The model leads or closely trails top proprietary systems such as GPT-5 (thinking) and Claude Sonnet 4.5 across benchmarks for end-to-end coding, reasoning, and agentic tool use. Its performance in τ²-Bench, SWE-Bench, and BrowseComp indicates particular advantages for organizations that depend on AI systems capable of planning, executing, and verifying complex workflows—key functions for agentic and developer tools inside enterprise environments.As LLM engineer Pierre-Carl Langlais aka Alexander Doria posted on X: \"MiniMax [is] making a case for mastering the technology end-to-end to get actual agentic automation.\"Compact Design, Scalable PerformanceMiniMax-M2’s technical architecture is a sparse Mixture-of-Experts model with 230 billion total parameters and 10 billion active per inference. This configuration significantly reduces latency and compute requirements while maintaining broad general intelligence. The design allows for responsive agent loops—compile–run–test or browse–retrieve–cite cycles—that execute faster and more predictably than denser models.For enterprise technology teams, this means easier scaling, lower cloud costs, and reduced deployment friction. According to Artificial Analysis, the model can be served efficiently on as few as four NVIDIA H100 GPUs at FP8 precision, a setup well within reach for mid-size organizations or departmental AI clusters.Benchmark Leadership Across Agentic and Coding WorkflowsMiniMax’s benchmark suite highlights strong real-world performance across developer and agent environments. The figure below, released with the model, compares MiniMax-M2 (in red) with several leading proprietary and open models, including GPT-5 (thinking), Claude Sonnet 4.5, Gemini 2.5 Pro, and DeepSeek-V3.2.MiniMax-M2 achieves top or near-top performance in many categories:SWE-bench Verified: 69.4 — close to GPT-5’s 74.9ArtifactsBench: 66.8 — above Claude Sonnet 4.5 and DeepSeek-V3.2τ²-Bench: 77.2 — approaching GPT-5’s 80.1GAIA (text only): 75.7 — surpassing DeepSeek-V3.2BrowseComp: 44.0 — notably stronger than other open modelsFinSearchComp-global: 65.5 — best among tested open-weight systemsThese results show MiniMax-M2’s capability in executing complex, tool-augmented tasks across multiple languages and environments—skills increasingly relevant for automated support, R&D, and data analysis inside enterprises.Strong Showing in Artificial Analysis’ Intelligence IndexThe model’s overall intelligence profile is confirmed in the latest Artificial Analysis Intelligence Index v3.0, which aggregates performance across ten reasoning benchmarks including MMLU-Pro, GPQA Diamond, AIME 2025, IFBench, and τ²-Bench Telecom.MiniMax-M2 scored 61 points, ranking as the highest open-weight model globally and following closely behind GPT-5 (high) and Grok 4. Artificial Analysis highlighted the model’s balance between technical accuracy, reasoning depth, and applied intelligence across domains. For enterprise users, this consistency indicates a reliable model foundation suitable for integration into software engineering, customer support, or knowledge automation systems.Designed for Developers and Agentic SystemsMiniMax engineered M2 for end-to-end developer workflows, enabling multi-file code edits, automated testing, and regression repair directly within integrated development environments or CI/CD pipelines. The model also excels in agentic planning—handling tasks that combine web search, command execution, and API calls while maintaining reasoning traceability.These capabilities make MiniMax-M2 especially valuable for enterprises exploring autonomous developer agents, data analysis assistants, or AI-augmented operational tools. Benchmarks such as Terminal-Bench and BrowseComp demonstrate the model’s ability to adapt to incomplete data and recover gracefully from intermediate errors, improving reliability in production settings.Interleaved Thinking and Structured Tool UseA distinctive aspect of MiniMax-M2 is its interleaved thinking format, which maintains visible reasoning traces between <think>...</think> tags.This enables the model to plan and verify steps across multiple exchanges, a critical feature for agentic reasoning. MiniMax advises retaining these segments when passing conversation history to preserve the model’s logic and continuity.The company also provides a Tool Calling Guide on Hugging Face, detailing how developers can connect external tools and APIs via structured XML-style calls. This functionality allows MiniMax-M2 to serve as the reasoning core for larger agent frameworks, executing dynamic tasks such as search, retrieval, and computation through external functions.Open Source Access and Enterprise Deployment OptionsEnterprises can access the model through the MiniMax Open Platform API and MiniMax Agent interface (a web chat similar to ChatGPT), both currently free for a limited time.MiniMax recommends SGLang and vLLM for efficient serving, each offering day-one support for the model’s unique interleaved reasoning and tool-calling structure. Deployment guides and parameter configurations are available through MiniMax’s documentation.Cost Efficiency and Token EconomicsAs Artificial Analysis noted, MiniMax’s API pricing is set at $0.30 per million input tokens and $1.20 per million output tokens, among the most competitive in the open-model ecosystem. ProviderModel (doc link)Input $/1MOutput $/1MNotesMiniMaxMiniMax-M2$0.30$1.20Listed under “Chat Completion v2” for M2. OpenAIGPT-5$1.25$10.00Flagship model pricing on OpenAI’s API pricing page. OpenAIGPT-5 mini$0.25$2.00Cheaper tier for well-defined tasks. AnthropicClaude Sonnet 4.5$3.00$15.00Anthropic’s current per-MTok list; long-context (>200K input) uses a premium tier. GoogleGemini 2.5 Flash (Preview)$0.30$2.50Prices include “thinking tokens”; page also lists cheaper Flash-Lite and 2.0 tiers. xAIGrok-4 Fast (reasoning)$0.20$0.50“Fast” tier; xAI also lists Grok-4 at $3 / $15. DeepSeekDeepSeek-V3.2 (chat)$0.28$0.42Cache-hit input is $0.028; table shows per-model details. Qwen (Alibaba)qwen-flash (Model Studio)from $0.022from $0.216Tiered by input size (≤128K, ≤256K, ≤1M tokens); listed “Input price / Output price per 1M”. CohereCommand R+ (Aug 2024)$2.50$10.00First-party pricing page also lists Command R ($0.50 / $1.50) and others. Notes & caveats (for readers):Prices are USD per million tokens and can change; check linked pages for updates and region/endpoint nuances (e.g., Anthropic long-context >200K input, Google Live API variants, cache discounts). Vendors may bill extra for server-side tools (web search, code execution) or offer batch/context-cache discounts. While the model produces longer, more explicit reasoning traces, its sparse activation and optimized compute design help maintain a favorable cost-performance balance—an advantage for teams deploying interactive agents or high-volume automation systems.Background on MiniMax — an Emerging Chinese PowerhouseMiniMax has quickly become one of the most closely watched names in China’s fast-rising AI sector. Backed by Alibaba and Tencent, the company moved from relative obscurity to international recognition within a year—first through breakthroughs in AI video generation, then through a series of open-weight large language models (LLMs) aimed squarely at developers and enterprises.The company first captured global attention in late 2024 with its AI video generation tool, “video-01,” which demonstrated the ability to create dynamic, cinematic scenes in seconds. VentureBeat described how the model’s launch sparked widespread interest after online creators began sharing lifelike, AI-generated footage—most memorably, a viral clip of a Star Wars lightsaber duel that drew millions of views in under two days. CEO Yan Junjie emphasized that the system outperformed leading Western tools in generating human movement and expression, an area where video AIs often struggle. The product, later commercialized through MiniMax’s Hailuo platform, showcased the startup’s technical confidence and creative reach, helping to establish China as a serious contender in generative video technology.By early 2025, MiniMax had turned its attention to long-context language modeling, unveiling the MiniMax-01 series, including MiniMax-Text-01 and MiniMax-VL-01. These open-weight models introduced an unprecedented 4-million-token context window, doubling the reach of Google’s Gemini 1.5 Pro and dwarfing OpenAI’s GPT-4o by more than twentyfold. The company continued its rapid cadence with the MiniMax-M1 release in June 2025, a model focused on long-context reasoning and reinforcement learning efficiency. M1 extended context capacity to 1 million tokens and introduced a hybrid Mixture-of-Experts design trained using a custom reinforcement-learning algorithm known as CISPO. Remarkably, VentureBeat reported that MiniMax trained M1 at a total cost of about $534,700, roughly one-tenth of DeepSeek’s R1 and far below the multimillion-dollar budgets typical for frontier-scale models. For enterprises and technical teams, MiniMax’s trajectory signals the arrival of a new generation of cost-efficient, open-weight models designed for real-world deployment. Its open licensing—ranging from Apache 2.0 to MIT—gives businesses freedom to customize, self-host, and fine-tune without vendor lock-in or compliance restrictions. Features such as structured function calling, long-context retention, and high-efficiency attention architectures directly address the needs of engineering groups managing multi-step reasoning systems and data-intensive pipelines.As MiniMax continues to expand its lineup, the company has emerged as a key global innovator in open-weight AI, combining ambitious research with pragmatic engineering. Open-Weight Leadership and Industry ContextThe release of MiniMax-M2 reinforces the growing leadership of Chinese AI research groups in open-weight model development. Following earlier contributions from DeepSeek, Alibaba’s Qwen series, and Moonshot AI, MiniMax’s entry continues the trend toward open, efficient systems designed for real-world use. Artificial Analysis observed that MiniMax-M2 exemplifies a broader shift in focus toward agentic capability and reinforcement-learning refinement, prioritizing controllable reasoning and real utility over raw model size.For enterprises, this means access to a state-of-the-art open model that can be audited, fine-tuned, and deployed internally with full transparency. By pairing strong benchmark performance with open licensing and efficient scaling, MiniMaxAI positions MiniMax-M2 as a practical foundation for intelligent systems that think, act, and assist with traceable logic—making it one of the most enterprise-ready open AI models available today.",
          "feed_position": 0,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/5ooQmDHIK8joIBWGcWySzH/e0d4c547081630465c4b8862570d0fd1/cfr0z3n_extremely_small_tiny_figurine_of_a_humanoid_robot_weari_47d6d5f6-f57a-4685-b6aa-d28c2657eef8.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/entertainment/streaming/how-to-cancel-your-peacock-subscription-160047090.html",
          "published_at": "Mon, 27 Oct 2025 16:00:47 +0000",
          "title": "How to cancel your Peacock subscription",
          "standfirst": "It happened again. Peacock just raised subscription prices for its Premium and Premium Plus plans. This is the third price increase in as many years. If your bank account is feeling the pain, or if you're just looking to streamline your entertainment options, you may decide it's time to take a break from NBC's flagship platform. Here's everything you need to know about canceling your Peacock subscription. How to cancel via web The simplest way to end your Peacock Premium service is if you're being billed directly by the company. You can follow the same steps in a web or mobile browser. Log in to your Peacock Premium or Premium Plus account. Click on the Profile icon. Select Account or Plans & Payments. Click on Cancel Plan. Follow the prompts to confirm the cancellation. That's pretty simple, but things get a bit more complicated if you're not in a direct-billing situation. How to cancel via third-party provider Like most modern streaming platforms, Peacock has partnerships with third-party providers like Apple and Amazon. This lets users sign up for the service through an entirely separate platform, like Prime Video. Cancelling has to also go through this third party. The general idea here is to sign into that account and find somewhere to manage billing and subscriptions, looking for Peacock. Here are specific steps for some of the more common providers. Cancel via Apple Go to the Settings app on your iPhone or iPad. Tap on your name at the top of the screen and tap Subscriptions. Select your Peacock subscription to manage and make changes. Cancel via Amazon Go to Amazon Memberships and Subscriptions using a web browser. Sign in to your Amazon account. Navigate to your Peacock subscription and select Cancel Subscription. Cancel via Google Play Go to the Google Play store using a web browser. Confirm that you’re signed in to your Google account. On the top right, click your Google account icon and select Payment & Subscriptions. Click the Subscriptions tab and select your Peacock subscription. Click Manage and select Cancel subscription. Cancel via Roku On your Roku TV, highlight Peacock. Press the star (*) button. Select Manage Subscriptions. Look for Peacock and hit Cancel. How to cancel a promotional subscription Peacock is often given away by internet providers like Comcast and phone carriers, among others. These plans often start free, but that goes away after a year or so. Check the fine print to see when your gifted subscription will run out, as you'll begin getting charged the usual rate. The best way to cancel these subscriptions is via the entity that offered it in the first place. This means you'll have to call up Xfinity or Spectrum directly. A customer representative should be able to handle the cancellation. Can I pause a Peacock subscription? No, Peacock doesn't currently offer the ability to pause a subscription. The best way to effectively \"pause\" a subscription is to cancel via one of the aforementioned methods and then resubscribe at a later date. What happens after you cancel? Cancelling a Peacock subscription doesn't immediately end your service. There are no partial refunds given, so you'll have full access to the account until the next payment date. At that point, the service will revert to the free tier. This means that if you change your mind before the next pay period, it's really easy to get things going again. Just look for a Restart Subscription button somewhere on the Account page. Like most modern tech services, cancelling doesn't erase any of your data. The subscription reverts to the free tier and will live on. To permanently close an account, you have to manually fill out a request via the Privacy Web Form in the Account page. This will lead you to a website to close the account.This article originally appeared on Engadget at https://www.engadget.com/entertainment/streaming/how-to-cancel-your-peacock-subscription-160047090.html?src=rss",
          "content": "It happened again. Peacock just raised subscription prices for its Premium and Premium Plus plans. This is the third price increase in as many years. If your bank account is feeling the pain, or if you're just looking to streamline your entertainment options, you may decide it's time to take a break from NBC's flagship platform. Here's everything you need to know about canceling your Peacock subscription. How to cancel via web The simplest way to end your Peacock Premium service is if you're being billed directly by the company. You can follow the same steps in a web or mobile browser. Log in to your Peacock Premium or Premium Plus account. Click on the Profile icon. Select Account or Plans & Payments. Click on Cancel Plan. Follow the prompts to confirm the cancellation. That's pretty simple, but things get a bit more complicated if you're not in a direct-billing situation. How to cancel via third-party provider Like most modern streaming platforms, Peacock has partnerships with third-party providers like Apple and Amazon. This lets users sign up for the service through an entirely separate platform, like Prime Video. Cancelling has to also go through this third party. The general idea here is to sign into that account and find somewhere to manage billing and subscriptions, looking for Peacock. Here are specific steps for some of the more common providers. Cancel via Apple Go to the Settings app on your iPhone or iPad. Tap on your name at the top of the screen and tap Subscriptions. Select your Peacock subscription to manage and make changes. Cancel via Amazon Go to Amazon Memberships and Subscriptions using a web browser. Sign in to your Amazon account. Navigate to your Peacock subscription and select Cancel Subscription. Cancel via Google Play Go to the Google Play store using a web browser. Confirm that you’re signed in to your Google account. On the top right, click your Google account icon and select Payment & Subscriptions. Click the Subscriptions tab and select your Peacock subscription. Click Manage and select Cancel subscription. Cancel via Roku On your Roku TV, highlight Peacock. Press the star (*) button. Select Manage Subscriptions. Look for Peacock and hit Cancel. How to cancel a promotional subscription Peacock is often given away by internet providers like Comcast and phone carriers, among others. These plans often start free, but that goes away after a year or so. Check the fine print to see when your gifted subscription will run out, as you'll begin getting charged the usual rate. The best way to cancel these subscriptions is via the entity that offered it in the first place. This means you'll have to call up Xfinity or Spectrum directly. A customer representative should be able to handle the cancellation. Can I pause a Peacock subscription? No, Peacock doesn't currently offer the ability to pause a subscription. The best way to effectively \"pause\" a subscription is to cancel via one of the aforementioned methods and then resubscribe at a later date. What happens after you cancel? Cancelling a Peacock subscription doesn't immediately end your service. There are no partial refunds given, so you'll have full access to the account until the next payment date. At that point, the service will revert to the free tier. This means that if you change your mind before the next pay period, it's really easy to get things going again. Just look for a Restart Subscription button somewhere on the Account page. Like most modern tech services, cancelling doesn't erase any of your data. The subscription reverts to the free tier and will live on. To permanently close an account, you have to manually fill out a request via the Privacy Web Form in the Account page. This will lead you to a website to close the account.This article originally appeared on Engadget at https://www.engadget.com/entertainment/streaming/how-to-cancel-your-peacock-subscription-160047090.html?src=rss",
          "feed_position": 9
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/anthropic-rolls-out-claude-ai-for-finance-integrates-with-excel-to-rival",
          "published_at": "Mon, 27 Oct 2025 16:00:00 GMT",
          "title": "Anthropic rolls out Claude AI for finance, integrates with Excel to rival Microsoft Copilot",
          "standfirst": "Anthropic is making its most aggressive push yet into the trillion-dollar financial services industry, unveiling a suite of tools that embed its Claude AI assistant directly into Microsoft Excel and connect it to real-time market data from some of the world&#x27;s most influential financial information providers.The San Francisco-based AI startup announced Monday it is releasing Claude for Excel, allowing financial analysts to interact with the AI system directly within their spreadsheets — the quintessential tool of modern finance. Beyond Excel, select Claude models are also being made available in Microsoft Copilot Studio and Researcher agent, expanding the integration across Microsoft&#x27;s enterprise AI ecosystem. The integration marks a significant escalation in Anthropic&#x27;s campaign to position itself as the AI platform of choice for banks, asset managers, and insurance companies, markets where precision and regulatory compliance matter far more than creative flair.The expansion comes just three months after Anthropic launched its Financial Analysis Solution in July, and it signals the company&#x27;s determination to capture market share in an industry projected to spend $97 billion on AI by 2027, up from $35 billion in 2023.More importantly, it positions Anthropic to compete directly with Microsoft — ironically, its partner in this Excel integration — which has its own Copilot AI assistant embedded across its Office suite, and with OpenAI, which counts Microsoft as its largest investor.Why Excel has become the new battleground for AI in financeThe decision to build directly into Excel is hardly accidental. Excel remains the lingua franca of finance, the digital workspace where analysts spend countless hours constructing financial models, running valuations, and stress-testing assumptions. By embedding Claude into this environment, Anthropic is meeting financial professionals exactly where they work rather than asking them to toggle between applications.Claude for Excel allows users to work with the AI in a sidebar where it can read, analyze, modify, and create new Excel workbooks while providing full transparency about the actions it takes by tracking and explaining changes and letting users navigate directly to referenced cells.This transparency feature addresses one of the most persistent anxieties around AI in finance: the \"black box\" problem. When billions of dollars ride on a financial model&#x27;s output, analysts need to understand not just the answer but how the AI arrived at it. By showing its work at the cell level, Anthropic is attempting to build the trust necessary for widespread adoption in an industry where careers and fortunes can turn on a misplaced decimal point.The technical implementation is sophisticated. Claude can discuss how spreadsheets work, modify them while preserving formula dependencies — a notoriously complex task — debug cell formulas, populate templates with new data, or build entirely new spreadsheets from scratch. This isn&#x27;t merely a chatbot that answers questions about your data; it&#x27;s a collaborative tool that can actively manipulate the models that drive investment decisions worth trillions of dollars.How Anthropic is building data moats around its financial AI platformPerhaps more significant than the Excel integration is Anthropic&#x27;s expansion of its connector ecosystem, which now links Claude to live market data and proprietary research from financial information giants. The company added six major new data partnerships spanning the entire spectrum of financial information that professional investors rely upon.Aiera now provides Claude with real-time earnings call transcripts and summaries of investor events like shareholder meetings, presentations, and conferences. The Aiera connector also enables a data feed from Third Bridge, which gives Claude access to a library of insights interviews, company intelligence, and industry analysis from experts and former executives. Chronograph gives private equity investors operational and financial information for portfolio monitoring and conducting due diligence, including performance metrics, valuations, and fund-level data.Egnyte enables Claude to securely search permitted data for internal data rooms, investment documents, and approved financial models while maintaining governed access controls. LSEG, the London Stock Exchange Group, connects Claude to live market data including fixed income pricing, equities, foreign exchange rates, macroeconomic indicators, and analysts&#x27; estimates of other important financial metrics. Moody&#x27;s provides access to proprietary credit ratings, research, and company data covering ownership, financials, and news on more than 600 million public and private companies, supporting work and research in compliance, credit analysis, and business development. MT Newswires provides Claude with access to the latest global multi-asset class news on financial markets and economies.These partnerships amount to a land grab for the informational infrastructure that powers modern finance. Previously announced in July, Anthropic had already secured integrations with S&P Capital IQ, Daloopa, Morningstar, FactSet, PitchBook, Snowflake, and Databricks. Together, these connectors give Claude access to virtually every category of financial data an analyst might need: fundamental company data, market prices, credit assessments, private company intelligence, alternative data, and breaking news.This matters because the quality of AI outputs depends entirely on the quality of inputs. Generic large language models trained on public internet data simply cannot compete with systems that have direct pipelines to Bloomberg-quality financial information. By securing these partnerships, Anthropic is building moats around its financial services offering that competitors will find difficult to replicate.The strategic calculus here is clear: Anthropic is betting that domain-specific AI systems with privileged access to proprietary data will outcompete general-purpose AI assistants. It&#x27;s a direct challenge to the \"one AI to rule them all\" approach favored by some competitors.Pre-configured workflows target the daily grind of Wall Street analystsThe third pillar of Anthropic&#x27;s announcement involves six new \"Agent Skills\" — pre-configured workflows for common financial tasks. These skills are Anthropic&#x27;s attempt to productize the workflows of entry-level and mid-level financial analysts, professionals who spend their days building models, processing due diligence documents, and writing research reports. Anthropic has designed skills specifically to automate these time-consuming tasks.The new skills include building discounted cash flow models complete with full free cash flow projections, weighted average cost of capital calculations, scenario toggles, and sensitivity tables. There&#x27;s comparable company analysis featuring valuation multiples and operating metrics that can be easily refreshed with updated data. Claude can now process data room documents into Excel spreadsheets populated with financial information, customer lists, and contract terms. It can create company teasers and profiles for pitch books and buyer lists, perform earnings analyses that use quarterly transcripts and financials to extract important metrics, guidance changes, and management commentary, and produce initiating coverage reports with industry analysis, company deep dives, and valuation frameworks.It&#x27;s worth noting that Anthropic&#x27;s Sonnet 4.5 model now tops the Finance Agent benchmark from Vals AI at 55.3% accuracy, a metric designed to test AI systems on tasks expected of entry-level financial analysts. A 55% accuracy rate might sound underwhelming, but it is state-of-the-art performance and highlights both the promise and limitations of AI in finance. The technology can clearly handle sophisticated analytical tasks, but it&#x27;s not yet reliable enough to operate autonomously without human oversight — a reality that may actually reassure both regulators and the analysts whose jobs might otherwise be at risk.The Agent Skills approach is particularly clever because it packages AI capabilities in terms that financial institutions already understand. Rather than selling generic \"AI assistance,\" Anthropic is offering solutions to specific, well-defined problems: \"You need a DCF model? We have a skill for that. You need to analyze earnings calls? We have a skill for that too.\"Trillion-dollar clients are already seeing massive productivity gainsAnthropic&#x27;s financial services strategy appears to be gaining traction with exactly the kind of marquee clients that matter in enterprise sales. The company counts among its clients AIA Labs at Bridgewater, Commonwealth Bank of Australia, American International Group, and Norges Bank Investment Management — Norway&#x27;s $1.6 trillion sovereign wealth fund, one of the world&#x27;s largest institutional investors.NBIM CEO Nicolai Tangen reported achieving approximately 20% productivity gains, equivalent to 213,000 hours, with portfolio managers and risk departments now able to \"seamlessly query our Snowflake data warehouse and analyze earnings calls with unprecedented efficiency.\"At AIG, CEO Peter Zaffino said the partnership has \"compressed the timeline to review business by more than 5x in our early rollouts while simultaneously improving our data accuracy from 75% to over 90%.\" If these numbers hold across broader deployments, the productivity implications for the financial services industry are staggering.These aren&#x27;t pilot programs or proof-of-concept deployments; they&#x27;re production implementations at institutions managing trillions of dollars in assets and making underwriting decisions that affect millions of customers. Their public endorsements provide the social proof that typically drives enterprise adoption in conservative industries.Regulatory uncertainty creates both opportunity and risk for AI deploymentYet Anthropic&#x27;s financial services ambitions unfold against a backdrop of heightened regulatory scrutiny and shifting enforcement priorities. In 2023, the Consumer Financial Protection Bureau released guidance requiring lenders to \"use specific and accurate reasons when taking adverse actions against consumers\" involving AI, and issued additional guidance requiring regulated entities to \"evaluate their underwriting models for bias\" and \"evaluate automated collateral-valuation and appraisal processes in ways that minimize bias.\"However, according to a Brookings Institution analysis, these measures have since been revoked with work stopped or eliminated at the current downsized CFPB under the current administration, creating regulatory uncertainty. The pendulum has swung from the Biden administration&#x27;s cautious approach, exemplified by an executive order on safe AI development, toward the Trump administration&#x27;s \"America&#x27;s AI Action Plan,\" which seeks to \"cement U.S. dominance in artificial intelligence\" through deregulation.This regulatory flux creates both opportunities and risks. Financial institutions eager to deploy AI now face less prescriptive federal oversight, potentially accelerating adoption. But the absence of clear guardrails also exposes them to potential liability if AI systems produce discriminatory outcomes, particularly in lending and underwriting.The Massachusetts Attorney General recently reached a $2.5 million settlement with student loan company Earnest Operations, alleging that its use of AI models resulted in \"disparate impact in approval rates and loan terms, specifically disadvantaging Black and Hispanic applicants.\" Such cases will likely multiply as AI deployment grows, creating a patchwork of state-level enforcement even as federal oversight recedes.Anthropic appears acutely aware of these risks. In an interview with Banking Dive, Jonathan Pelosi, Anthropic&#x27;s global head of industry for financial services, emphasized that Claude requires a \"human in the loop.\" The platform, he said, is not intended for autonomous financial decision-making or to provide stock recommendations that users follow blindly. During client onboarding, Pelosi told the publication, Anthropic focuses on training and understanding model limitations, putting guardrails in place so people treat Claude as a helpful technology rather than a replacement for human judgment.Competition heats up as every major tech company targets finance AIAnthropic&#x27;s financial services push comes as AI competition intensifies across the enterprise. OpenAI, Microsoft, Google, and numerous startups are all vying for position in what may become one of AI&#x27;s most lucrative verticals. Goldman Sachs introduced a generative AI assistant to its bankers, traders, and asset managers in January, signaling that major banks may build their own capabilities rather than rely exclusively on third-party providers.The emergence of domain-specific AI models like BloombergGPT — trained specifically on financial data — suggests the market may fragment between generalized AI assistants and specialized tools. Anthropic&#x27;s strategy appears to stake out a middle ground: general-purpose models, since Claude was not trained exclusively on financial data, enhanced with financial-specific tooling, data access, and workflows.The company&#x27;s partnership strategy with implementation consultancies including Deloitte, KPMG, PwC, Slalom, TribeAI, and Turing is equally critical. These firms serve as force multipliers, embedding Anthropic&#x27;s technology into their own service offerings and providing the change management expertise that financial institutions need to successfully adopt AI at scale.CFOs worry about AI hallucinations and cascading errorsThe broader question is whether AI tools like Claude will genuinely transform financial services productivity or merely shift work around. The PYMNTS Intelligence report \"The Agentic Trust Gap\" found that chief financial officers remain hesitant about AI agents, with \"nagging concern\" about hallucinations where \"an AI agent can go off script and expose firms to cascading payment errors and other inaccuracies.\"\"For finance leaders, the message is stark: Harness AI&#x27;s momentum now, but build the guardrails before the next quarterly call—or risk owning the fallout,\" the report warned.A 2025 KPMG report found that 70% of board members have developed responsible use policies for employees, with other popular initiatives including implementing a recognized AI risk and governance framework, developing ethical guidelines and training programs for AI developers, and conducting regular AI use audits.The financial services industry faces a delicate balancing act: move too slowly and risk competitive disadvantage as rivals achieve productivity gains; move too quickly and risk operational failures, regulatory penalties, or reputational damage. Speaking at the Evident AI Symposium in New York last week, Ian Glasner, HSBC&#x27;s group head of emerging technology, innovation and ventures, struck an optimistic tone about the sector&#x27;s readiness for AI adoption. \"As an industry, we are very well prepared to manage risk,\" he said, according to CIO Dive. \"Let&#x27;s not overcomplicate this. We just need to be focused on the business use case and the value associated.\"Anthropic&#x27;s latest moves suggest the company sees financial services as a beachhead market where AI&#x27;s value proposition is clear, customers have deep pockets, and the technical requirements play to Claude&#x27;s strengths in reasoning and accuracy. By building Excel integration, securing data partnerships, and pre-packaging common workflows, Anthropic is reducing the friction that typically slows enterprise AI adoption.The $61.5 billion valuation the company commanded in its March fundraising round — up from roughly $16 billion a year earlier — suggests investors believe this strategy will work. But the real test will come as these tools move from pilot programs to production deployments across thousands of analysts and billions of dollars in transactions.Financial services may prove to be AI&#x27;s most demanding proving ground: an industry where mistakes are costly, regulation is stringent, and trust is everything. If Claude can successfully navigate the spreadsheet cells and data feeds of Wall Street without hallucinating a decimal point in the wrong direction, Anthropic will have accomplished something far more valuable than winning another benchmark test. It will have proven that AI can be trusted with the money.",
          "content": "Anthropic is making its most aggressive push yet into the trillion-dollar financial services industry, unveiling a suite of tools that embed its Claude AI assistant directly into Microsoft Excel and connect it to real-time market data from some of the world&#x27;s most influential financial information providers.The San Francisco-based AI startup announced Monday it is releasing Claude for Excel, allowing financial analysts to interact with the AI system directly within their spreadsheets — the quintessential tool of modern finance. Beyond Excel, select Claude models are also being made available in Microsoft Copilot Studio and Researcher agent, expanding the integration across Microsoft&#x27;s enterprise AI ecosystem. The integration marks a significant escalation in Anthropic&#x27;s campaign to position itself as the AI platform of choice for banks, asset managers, and insurance companies, markets where precision and regulatory compliance matter far more than creative flair.The expansion comes just three months after Anthropic launched its Financial Analysis Solution in July, and it signals the company&#x27;s determination to capture market share in an industry projected to spend $97 billion on AI by 2027, up from $35 billion in 2023.More importantly, it positions Anthropic to compete directly with Microsoft — ironically, its partner in this Excel integration — which has its own Copilot AI assistant embedded across its Office suite, and with OpenAI, which counts Microsoft as its largest investor.Why Excel has become the new battleground for AI in financeThe decision to build directly into Excel is hardly accidental. Excel remains the lingua franca of finance, the digital workspace where analysts spend countless hours constructing financial models, running valuations, and stress-testing assumptions. By embedding Claude into this environment, Anthropic is meeting financial professionals exactly where they work rather than asking them to toggle between applications.Claude for Excel allows users to work with the AI in a sidebar where it can read, analyze, modify, and create new Excel workbooks while providing full transparency about the actions it takes by tracking and explaining changes and letting users navigate directly to referenced cells.This transparency feature addresses one of the most persistent anxieties around AI in finance: the \"black box\" problem. When billions of dollars ride on a financial model&#x27;s output, analysts need to understand not just the answer but how the AI arrived at it. By showing its work at the cell level, Anthropic is attempting to build the trust necessary for widespread adoption in an industry where careers and fortunes can turn on a misplaced decimal point.The technical implementation is sophisticated. Claude can discuss how spreadsheets work, modify them while preserving formula dependencies — a notoriously complex task — debug cell formulas, populate templates with new data, or build entirely new spreadsheets from scratch. This isn&#x27;t merely a chatbot that answers questions about your data; it&#x27;s a collaborative tool that can actively manipulate the models that drive investment decisions worth trillions of dollars.How Anthropic is building data moats around its financial AI platformPerhaps more significant than the Excel integration is Anthropic&#x27;s expansion of its connector ecosystem, which now links Claude to live market data and proprietary research from financial information giants. The company added six major new data partnerships spanning the entire spectrum of financial information that professional investors rely upon.Aiera now provides Claude with real-time earnings call transcripts and summaries of investor events like shareholder meetings, presentations, and conferences. The Aiera connector also enables a data feed from Third Bridge, which gives Claude access to a library of insights interviews, company intelligence, and industry analysis from experts and former executives. Chronograph gives private equity investors operational and financial information for portfolio monitoring and conducting due diligence, including performance metrics, valuations, and fund-level data.Egnyte enables Claude to securely search permitted data for internal data rooms, investment documents, and approved financial models while maintaining governed access controls. LSEG, the London Stock Exchange Group, connects Claude to live market data including fixed income pricing, equities, foreign exchange rates, macroeconomic indicators, and analysts&#x27; estimates of other important financial metrics. Moody&#x27;s provides access to proprietary credit ratings, research, and company data covering ownership, financials, and news on more than 600 million public and private companies, supporting work and research in compliance, credit analysis, and business development. MT Newswires provides Claude with access to the latest global multi-asset class news on financial markets and economies.These partnerships amount to a land grab for the informational infrastructure that powers modern finance. Previously announced in July, Anthropic had already secured integrations with S&P Capital IQ, Daloopa, Morningstar, FactSet, PitchBook, Snowflake, and Databricks. Together, these connectors give Claude access to virtually every category of financial data an analyst might need: fundamental company data, market prices, credit assessments, private company intelligence, alternative data, and breaking news.This matters because the quality of AI outputs depends entirely on the quality of inputs. Generic large language models trained on public internet data simply cannot compete with systems that have direct pipelines to Bloomberg-quality financial information. By securing these partnerships, Anthropic is building moats around its financial services offering that competitors will find difficult to replicate.The strategic calculus here is clear: Anthropic is betting that domain-specific AI systems with privileged access to proprietary data will outcompete general-purpose AI assistants. It&#x27;s a direct challenge to the \"one AI to rule them all\" approach favored by some competitors.Pre-configured workflows target the daily grind of Wall Street analystsThe third pillar of Anthropic&#x27;s announcement involves six new \"Agent Skills\" — pre-configured workflows for common financial tasks. These skills are Anthropic&#x27;s attempt to productize the workflows of entry-level and mid-level financial analysts, professionals who spend their days building models, processing due diligence documents, and writing research reports. Anthropic has designed skills specifically to automate these time-consuming tasks.The new skills include building discounted cash flow models complete with full free cash flow projections, weighted average cost of capital calculations, scenario toggles, and sensitivity tables. There&#x27;s comparable company analysis featuring valuation multiples and operating metrics that can be easily refreshed with updated data. Claude can now process data room documents into Excel spreadsheets populated with financial information, customer lists, and contract terms. It can create company teasers and profiles for pitch books and buyer lists, perform earnings analyses that use quarterly transcripts and financials to extract important metrics, guidance changes, and management commentary, and produce initiating coverage reports with industry analysis, company deep dives, and valuation frameworks.It&#x27;s worth noting that Anthropic&#x27;s Sonnet 4.5 model now tops the Finance Agent benchmark from Vals AI at 55.3% accuracy, a metric designed to test AI systems on tasks expected of entry-level financial analysts. A 55% accuracy rate might sound underwhelming, but it is state-of-the-art performance and highlights both the promise and limitations of AI in finance. The technology can clearly handle sophisticated analytical tasks, but it&#x27;s not yet reliable enough to operate autonomously without human oversight — a reality that may actually reassure both regulators and the analysts whose jobs might otherwise be at risk.The Agent Skills approach is particularly clever because it packages AI capabilities in terms that financial institutions already understand. Rather than selling generic \"AI assistance,\" Anthropic is offering solutions to specific, well-defined problems: \"You need a DCF model? We have a skill for that. You need to analyze earnings calls? We have a skill for that too.\"Trillion-dollar clients are already seeing massive productivity gainsAnthropic&#x27;s financial services strategy appears to be gaining traction with exactly the kind of marquee clients that matter in enterprise sales. The company counts among its clients AIA Labs at Bridgewater, Commonwealth Bank of Australia, American International Group, and Norges Bank Investment Management — Norway&#x27;s $1.6 trillion sovereign wealth fund, one of the world&#x27;s largest institutional investors.NBIM CEO Nicolai Tangen reported achieving approximately 20% productivity gains, equivalent to 213,000 hours, with portfolio managers and risk departments now able to \"seamlessly query our Snowflake data warehouse and analyze earnings calls with unprecedented efficiency.\"At AIG, CEO Peter Zaffino said the partnership has \"compressed the timeline to review business by more than 5x in our early rollouts while simultaneously improving our data accuracy from 75% to over 90%.\" If these numbers hold across broader deployments, the productivity implications for the financial services industry are staggering.These aren&#x27;t pilot programs or proof-of-concept deployments; they&#x27;re production implementations at institutions managing trillions of dollars in assets and making underwriting decisions that affect millions of customers. Their public endorsements provide the social proof that typically drives enterprise adoption in conservative industries.Regulatory uncertainty creates both opportunity and risk for AI deploymentYet Anthropic&#x27;s financial services ambitions unfold against a backdrop of heightened regulatory scrutiny and shifting enforcement priorities. In 2023, the Consumer Financial Protection Bureau released guidance requiring lenders to \"use specific and accurate reasons when taking adverse actions against consumers\" involving AI, and issued additional guidance requiring regulated entities to \"evaluate their underwriting models for bias\" and \"evaluate automated collateral-valuation and appraisal processes in ways that minimize bias.\"However, according to a Brookings Institution analysis, these measures have since been revoked with work stopped or eliminated at the current downsized CFPB under the current administration, creating regulatory uncertainty. The pendulum has swung from the Biden administration&#x27;s cautious approach, exemplified by an executive order on safe AI development, toward the Trump administration&#x27;s \"America&#x27;s AI Action Plan,\" which seeks to \"cement U.S. dominance in artificial intelligence\" through deregulation.This regulatory flux creates both opportunities and risks. Financial institutions eager to deploy AI now face less prescriptive federal oversight, potentially accelerating adoption. But the absence of clear guardrails also exposes them to potential liability if AI systems produce discriminatory outcomes, particularly in lending and underwriting.The Massachusetts Attorney General recently reached a $2.5 million settlement with student loan company Earnest Operations, alleging that its use of AI models resulted in \"disparate impact in approval rates and loan terms, specifically disadvantaging Black and Hispanic applicants.\" Such cases will likely multiply as AI deployment grows, creating a patchwork of state-level enforcement even as federal oversight recedes.Anthropic appears acutely aware of these risks. In an interview with Banking Dive, Jonathan Pelosi, Anthropic&#x27;s global head of industry for financial services, emphasized that Claude requires a \"human in the loop.\" The platform, he said, is not intended for autonomous financial decision-making or to provide stock recommendations that users follow blindly. During client onboarding, Pelosi told the publication, Anthropic focuses on training and understanding model limitations, putting guardrails in place so people treat Claude as a helpful technology rather than a replacement for human judgment.Competition heats up as every major tech company targets finance AIAnthropic&#x27;s financial services push comes as AI competition intensifies across the enterprise. OpenAI, Microsoft, Google, and numerous startups are all vying for position in what may become one of AI&#x27;s most lucrative verticals. Goldman Sachs introduced a generative AI assistant to its bankers, traders, and asset managers in January, signaling that major banks may build their own capabilities rather than rely exclusively on third-party providers.The emergence of domain-specific AI models like BloombergGPT — trained specifically on financial data — suggests the market may fragment between generalized AI assistants and specialized tools. Anthropic&#x27;s strategy appears to stake out a middle ground: general-purpose models, since Claude was not trained exclusively on financial data, enhanced with financial-specific tooling, data access, and workflows.The company&#x27;s partnership strategy with implementation consultancies including Deloitte, KPMG, PwC, Slalom, TribeAI, and Turing is equally critical. These firms serve as force multipliers, embedding Anthropic&#x27;s technology into their own service offerings and providing the change management expertise that financial institutions need to successfully adopt AI at scale.CFOs worry about AI hallucinations and cascading errorsThe broader question is whether AI tools like Claude will genuinely transform financial services productivity or merely shift work around. The PYMNTS Intelligence report \"The Agentic Trust Gap\" found that chief financial officers remain hesitant about AI agents, with \"nagging concern\" about hallucinations where \"an AI agent can go off script and expose firms to cascading payment errors and other inaccuracies.\"\"For finance leaders, the message is stark: Harness AI&#x27;s momentum now, but build the guardrails before the next quarterly call—or risk owning the fallout,\" the report warned.A 2025 KPMG report found that 70% of board members have developed responsible use policies for employees, with other popular initiatives including implementing a recognized AI risk and governance framework, developing ethical guidelines and training programs for AI developers, and conducting regular AI use audits.The financial services industry faces a delicate balancing act: move too slowly and risk competitive disadvantage as rivals achieve productivity gains; move too quickly and risk operational failures, regulatory penalties, or reputational damage. Speaking at the Evident AI Symposium in New York last week, Ian Glasner, HSBC&#x27;s group head of emerging technology, innovation and ventures, struck an optimistic tone about the sector&#x27;s readiness for AI adoption. \"As an industry, we are very well prepared to manage risk,\" he said, according to CIO Dive. \"Let&#x27;s not overcomplicate this. We just need to be focused on the business use case and the value associated.\"Anthropic&#x27;s latest moves suggest the company sees financial services as a beachhead market where AI&#x27;s value proposition is clear, customers have deep pockets, and the technical requirements play to Claude&#x27;s strengths in reasoning and accuracy. By building Excel integration, securing data partnerships, and pre-packaging common workflows, Anthropic is reducing the friction that typically slows enterprise AI adoption.The $61.5 billion valuation the company commanded in its March fundraising round — up from roughly $16 billion a year earlier — suggests investors believe this strategy will work. But the real test will come as these tools move from pilot programs to production deployments across thousands of analysts and billions of dollars in transactions.Financial services may prove to be AI&#x27;s most demanding proving ground: an industry where mistakes are costly, regulation is stringent, and trust is everything. If Claude can successfully navigate the spreadsheet cells and data feeds of Wall Street without hallucinating a decimal point in the wrong direction, Anthropic will have accomplished something far more valuable than winning another benchmark test. It will have proven that AI can be trusted with the money.",
          "feed_position": 1,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/7FxShaZWxncA14CgV1wwvN/8ddd8d938cc83eb730d4630fa88e9c48/nuneybits_Vector_art_of_money_sign_on_retro_computer_screen_in__5728d90d-4417-472b-b380-857cf4cd4682.webp?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/audio/headphones/best-wireless-workout-headphones-191517835.html",
          "published_at": "Mon, 27 Oct 2025 09:00:37 +0000",
          "title": "The best wireless workout headphones for 2025",
          "standfirst": "Regardless of what kind of exercise you’re into, if you’re working out, you’ll want a pair of wireless workout headphones. They allow you to be free and untethered during a serious weight-lifting session, a 5K run, an hour at the skate park and everywhere in between where you’re moving and sweating a ton. There are dozens of great wireless headphones and wireless earbud options out there, but for exercise in particular, there are additional factors to consider before picking one up like water resistance, battery life and overall comfort.At Engadget, we’ve tested a bunch of fitness-ready headphones and earbuds to come up with our top picks, plus some advice to consider before you pick up a pair. All of our top picks below will work in and out of the gym, so you can invest in just one pair and make those your daily driver. If you’re primarily a runner, check out our list of best headphones for running. Best workout headphones for 2025 Others wireless workout headphones we tested Apple AirPods Pro 3 When it comes to running and working out, the edge that the AirPods Pro 3 have over the Pro 2, or even the top picks on our list, is built-in heart rate monitoring. That means you could go out with just your Pro 3 earbuds and your iPhone and still get heart rate information for your entire training session. But otherwise, the Pro 3 buds are just as capable as the Pro 2 when it comes to exercise. Some may prefer the soft-touch finish on our top picks to the AirPods' slick texture. Beats Powerbeats Pro 2 The Powerbeats Pro 2 are a good alternative to the Beats Fit Pro if you’re a stickler for a hook design. However, they cost $50 more than the Powerbeats Fit, and the main added advantage here is built-in heart rate sensors. Anker Soundcore AeroFit Pro The Soundcore AeroFit Pro is Anker’s version of the Shokz OpenFit, but I found the fit to be less secure and not as comfortable. The actual earbuds on the AeroFit Pro are noticeably bulkier than those on the OpenFit and that caused them to shift and move much more during exercise. They never fell off of my ears completely, but I spent more time adjusting them than I did enjoying them. JBL Endurance Peak 3 The most noteworthy thing about the Endurance Peak 3 is that they have the same IP68 rating as the Jabra Elite 8 Active, except they only cost $100. But, while you get the same protection here, you’ll have to sacrifice in other areas. The Endurance Peak 3 didn’t blow me away when it came to sound quality or comfort (its hook is more rigid than those on my favorite similarly designed buds) and their charging case is massive compared to most competitors. What to look for in workout headphones Design Before diving in, it’s worth mentioning that this guide focuses on wireless earbuds. While you could wear over-ear or on-ear headphones during a workout, most of the best headphones available now do not have the same level of durability. Water and dust resistance, particularly the former, is important for any audio gear you plan on sweating with or taking outdoors, and that’s more prevalent in the wireless earbuds world. Most earbuds have one of three designs: in-ear, in-ear with hook or open-ear. The first two are the most popular. In-ears are arguably the most common, while those with hooks promise better security and fit since they have an appendage that curls around the top of your ear. Open-ear designs don’t stick into your ear canal, but rather sit just outside of it. This makes it easier to hear the world around you while also listening to audio, and could be more comfortable for those who don’t like the intrusiveness of in-ear buds. Water resistance and dust protection Even if a pair of headphones for working out aren’t marketed specifically as exercise headphones, a sturdy, water-resistant design will, by default, make them suitable for exercise. To avoid repetition, here’s a quick primer on durability, or ingression protection (IP) ratings. The first digit you’ll see after the “IP” refers to protection from dust and other potential intrusions, measured on a scale from 1 to 6. The second refers to water resistance or even waterproofing, in the best cases. The ratings for water resistance are ranked on a scale of 1 to 9; higher numbers mean more protection, while the letter “X” means the device is not rated for protection in that regard. All of the earbuds we tested for this guide have at least an IPX4 rating, which means there’s no dust protection, but the buds can withstand splashes from any direction and are sweat resistant, but probably shouldn't be submerged. For a detailed breakdown of all the possible permutations, check out this guide published by a supplier called The Enclosure Company. Active noise cancellation and transparency mode Active noise cancellation (ANC) is becoming standard on wireless earbuds, at least those above a certain price point. If you’re looking for a pair of buds that can be your workout companion and serve you outside of the gym, too, noise cancelation is a good feature to have. It makes the buds more versatile, allowing you to block out the dull roar of your home or office so you can focus, or give you some solitude during a busy commute. But an earbud’s ability to block out the world goes hand-in-hand with its ability to open things back up should you need it. Many ANC earbuds also support some sort of “transparency mode,” or various levels of noise reduction. This is important for running headphones because exercising outdoors, alongside busy streets, can be dangerous. You probably don’t want to be totally oblivious to what’s going on around you when you’re running outside; adjusting noise cancelation levels to increase your awareness will help with that. Stronger noise cancelation might be more appealing to those doing more indoor training if they want to block out the dull roar of a gym or the guy exaggeratingly lifting weights next to you. Battery life All of the Bluetooth earbuds we tested have a battery life of six to eight hours. In general, that’s what you can expect from this space, with a few outliers that can get up to 15 hours of life on a charge. Even the low end of the spectrum should be good enough for most athletes and gym junkies, but it’ll be handy to keep the buds’ charging case on you if you think you’ll get close to using up all their juice during a single session. You’ll get an average of 20 to 28 extra hours of battery out of most charging cases and all of the earbuds we tested had holders that provided at least an extra 15 hours. This will dictate how often you actually have to charge the device — as in physically connect the case with earbuds inside to a charging cable, or set it on a wireless charger to power up. How we test workout headphones In testing wireless workout headphones, I wear them during every bit of exercise I do — be it a casual walk around the block, a brisk morning run or a challenging weight-lifting session. I’m looking for comfort arguably most of all, because you should never be fussing with your earbuds when you should be focusing on working out. In the same vein, I’m cognizant of if they get loose during fast movements or slippery when I’m sweating. I also use the earbuds when not exercising to take calls and listen to music throughout the day. Many people will want just one pair of earbuds that they can use while exercising and just doing everyday things, so I evaluate each pair on their ability to be comfortable and provide a good listening experience in multiple different activities. While I am also evaluating sound quality, I’m admittedly not an audio expert. My colleague Billy Steele holds that title at Engadget, and you’ll find much more detailed information about audio quality for some of our top picks in his reviews and buying guides. With these headphones for working out, however, I will make note of related issues if they stood out (i.e. if a pair of earbuds had noticeably strong bass out of the box, weak highs, etc). Most of the wireless workout headphones we tested work with companion apps that have adjustable EQ settings, so you’ll be able to tweak sound profiles to your liking in most cases.This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/best-wireless-workout-headphones-191517835.html?src=rss",
          "content": "Regardless of what kind of exercise you’re into, if you’re working out, you’ll want a pair of wireless workout headphones. They allow you to be free and untethered during a serious weight-lifting session, a 5K run, an hour at the skate park and everywhere in between where you’re moving and sweating a ton. There are dozens of great wireless headphones and wireless earbud options out there, but for exercise in particular, there are additional factors to consider before picking one up like water resistance, battery life and overall comfort.At Engadget, we’ve tested a bunch of fitness-ready headphones and earbuds to come up with our top picks, plus some advice to consider before you pick up a pair. All of our top picks below will work in and out of the gym, so you can invest in just one pair and make those your daily driver. If you’re primarily a runner, check out our list of best headphones for running. Best workout headphones for 2025 Others wireless workout headphones we tested Apple AirPods Pro 3 When it comes to running and working out, the edge that the AirPods Pro 3 have over the Pro 2, or even the top picks on our list, is built-in heart rate monitoring. That means you could go out with just your Pro 3 earbuds and your iPhone and still get heart rate information for your entire training session. But otherwise, the Pro 3 buds are just as capable as the Pro 2 when it comes to exercise. Some may prefer the soft-touch finish on our top picks to the AirPods' slick texture. Beats Powerbeats Pro 2 The Powerbeats Pro 2 are a good alternative to the Beats Fit Pro if you’re a stickler for a hook design. However, they cost $50 more than the Powerbeats Fit, and the main added advantage here is built-in heart rate sensors. Anker Soundcore AeroFit Pro The Soundcore AeroFit Pro is Anker’s version of the Shokz OpenFit, but I found the fit to be less secure and not as comfortable. The actual earbuds on the AeroFit Pro are noticeably bulkier than those on the OpenFit and that caused them to shift and move much more during exercise. They never fell off of my ears completely, but I spent more time adjusting them than I did enjoying them. JBL Endurance Peak 3 The most noteworthy thing about the Endurance Peak 3 is that they have the same IP68 rating as the Jabra Elite 8 Active, except they only cost $100. But, while you get the same protection here, you’ll have to sacrifice in other areas. The Endurance Peak 3 didn’t blow me away when it came to sound quality or comfort (its hook is more rigid than those on my favorite similarly designed buds) and their charging case is massive compared to most competitors. What to look for in workout headphones Design Before diving in, it’s worth mentioning that this guide focuses on wireless earbuds. While you could wear over-ear or on-ear headphones during a workout, most of the best headphones available now do not have the same level of durability. Water and dust resistance, particularly the former, is important for any audio gear you plan on sweating with or taking outdoors, and that’s more prevalent in the wireless earbuds world. Most earbuds have one of three designs: in-ear, in-ear with hook or open-ear. The first two are the most popular. In-ears are arguably the most common, while those with hooks promise better security and fit since they have an appendage that curls around the top of your ear. Open-ear designs don’t stick into your ear canal, but rather sit just outside of it. This makes it easier to hear the world around you while also listening to audio, and could be more comfortable for those who don’t like the intrusiveness of in-ear buds. Water resistance and dust protection Even if a pair of headphones for working out aren’t marketed specifically as exercise headphones, a sturdy, water-resistant design will, by default, make them suitable for exercise. To avoid repetition, here’s a quick primer on durability, or ingression protection (IP) ratings. The first digit you’ll see after the “IP” refers to protection from dust and other potential intrusions, measured on a scale from 1 to 6. The second refers to water resistance or even waterproofing, in the best cases. The ratings for water resistance are ranked on a scale of 1 to 9; higher numbers mean more protection, while the letter “X” means the device is not rated for protection in that regard. All of the earbuds we tested for this guide have at least an IPX4 rating, which means there’s no dust protection, but the buds can withstand splashes from any direction and are sweat resistant, but probably shouldn't be submerged. For a detailed breakdown of all the possible permutations, check out this guide published by a supplier called The Enclosure Company. Active noise cancellation and transparency mode Active noise cancellation (ANC) is becoming standard on wireless earbuds, at least those above a certain price point. If you’re looking for a pair of buds that can be your workout companion and serve you outside of the gym, too, noise cancelation is a good feature to have. It makes the buds more versatile, allowing you to block out the dull roar of your home or office so you can focus, or give you some solitude during a busy commute. But an earbud’s ability to block out the world goes hand-in-hand with its ability to open things back up should you need it. Many ANC earbuds also support some sort of “transparency mode,” or various levels of noise reduction. This is important for running headphones because exercising outdoors, alongside busy streets, can be dangerous. You probably don’t want to be totally oblivious to what’s going on around you when you’re running outside; adjusting noise cancelation levels to increase your awareness will help with that. Stronger noise cancelation might be more appealing to those doing more indoor training if they want to block out the dull roar of a gym or the guy exaggeratingly lifting weights next to you. Battery life All of the Bluetooth earbuds we tested have a battery life of six to eight hours. In general, that’s what you can expect from this space, with a few outliers that can get up to 15 hours of life on a charge. Even the low end of the spectrum should be good enough for most athletes and gym junkies, but it’ll be handy to keep the buds’ charging case on you if you think you’ll get close to using up all their juice during a single session. You’ll get an average of 20 to 28 extra hours of battery out of most charging cases and all of the earbuds we tested had holders that provided at least an extra 15 hours. This will dictate how often you actually have to charge the device — as in physically connect the case with earbuds inside to a charging cable, or set it on a wireless charger to power up. How we test workout headphones In testing wireless workout headphones, I wear them during every bit of exercise I do — be it a casual walk around the block, a brisk morning run or a challenging weight-lifting session. I’m looking for comfort arguably most of all, because you should never be fussing with your earbuds when you should be focusing on working out. In the same vein, I’m cognizant of if they get loose during fast movements or slippery when I’m sweating. I also use the earbuds when not exercising to take calls and listen to music throughout the day. Many people will want just one pair of earbuds that they can use while exercising and just doing everyday things, so I evaluate each pair on their ability to be comfortable and provide a good listening experience in multiple different activities. While I am also evaluating sound quality, I’m admittedly not an audio expert. My colleague Billy Steele holds that title at Engadget, and you’ll find much more detailed information about audio quality for some of our top picks in his reviews and buying guides. With these headphones for working out, however, I will make note of related issues if they stood out (i.e. if a pair of earbuds had noticeably strong bass out of the box, weak highs, etc). Most of the wireless workout headphones we tested work with companion apps that have adjustable EQ settings, so you’ll be able to tweak sound profiles to your liking in most cases.This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/best-wireless-workout-headphones-191517835.html?src=rss",
          "feed_position": 19
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/google-cloud-takes-aim-at-coreweave-and-aws-with-managed-slurm-for",
          "published_at": "Mon, 27 Oct 2025 04:00:00 GMT",
          "title": "Google Cloud takes aim at CoreWeave and AWS with managed Slurm for enterprise-scale AI training",
          "standfirst": "Some enterprises are best served by fine-tuning large models to their needs, but a number of companies plan to build their own models, a project that would require access to GPUs. Google Cloud wants to play a bigger role in enterprises’ model-making journey with its new service, Vertex AI Training. The service gives enterprises looking to train their own models access to a managed Slurm environment, data science tooling and any chips capable of large-scale model training. With this new service, Google Cloud hopes to turn more enterprises away from other providers and encourage the building of more company-specific AI models. While Google Cloud has always offered the ability to customize its Gemini models, the new service allows customers to bring in their own models or customize any open-source model Google Cloud hosts. Vertex AI Training positions Google Cloud directly against companies like CoreWeave and Lambda Labs, as well as its cloud competitors AWS and Microsoft Azure. Jaime de Guerre, senior director of product management at Gloogle Cloud, told VentureBeat that the company has been hearing from a lot of organizations of varying sizes that they need a way to better optimize compute but in a more reliable environment.“What we&#x27;re seeing is that there&#x27;s an increasing number of companies that are building or customizing large gen AI models to introduce a product offering built around those models, or to help power their business in some way,” de Guerre said. “This includes AI startups, technology companies, sovereign organizations building a model for a particular region or culture or language and some large enterprises that might be building it into internal processes.”De Guerre noted that while anyone can technically use the service, Google is targeting companies planning large-scale model training rather than simple fine-tuning or LoRA adopters. Vertex AI Services will focus on longer-running training jobs spanning hundreds or even thousands of chips. Pricing will depend on the amount of compute the enterprise will need. “Vertex AI Training is not for adding more information to the context or using RAG; this is to train a model where you might start from completely random weights,” he said.Model customization on the rise Enterprises are recognizing the value of building customized models beyond just fine-tuning an LLM via retrieval-augmented generation (RAG). Custom models would know more in-depth company information and respond with answers specific to the organization. Companies like Arcee.ai have begun offering their models for customization to clients. Adobe recently announced a new service that allows enterprises to retrain Firefly for their specific needs. Organizations like FICO, which create small language models specific to the finance industry, often buy GPUs to train them at significant cost. Google Cloud said Vertex AI Training differentiates itself by giving access to a larger set of chips, services to monitor and manage training and the expertise it learned from training the Gemini models. Some early customers of Vertex AI Training include AI Singapore, a consortium of Singaporean research institutes and startups that built the 27-billion-parameter SEA-LION v4, and Salesforce’s AI research team. Enterprises often have to choose between taking an already-built LLM and fine-tuning it or building their own model. But creating an LLM from scratch is usually unattainable for smaller companies, or it simply doesn’t make sense for some use cases. However, for organizations where a fully custom or from-scratch model makes sense, the issue is gaining access to the GPUs needed to run training.Model training can be expensiveTraining a model, de Guerre said, can be difficult and expensive, especially when organizations compete with several others for GPU space.Hyperscalers like AWS and Microsoft — and, yes, Google — have pitched that their massive data centers and racks and racks of high-end chips deliver the most value to enterprises. Not only will they have access to expensive GPUs, but cloud providers often offer full-stack services to help enterprises move to production.Services like CoreWeave gained prominence for offering on-demand access to Nvidia H100s, giving customers flexibility in compute power when building models or applications. This has also given rise to a business model in which companies with GPUs rent out server space.De Guerre said Vertex AI Training isn’t just about offering access to train models on bare compute, where the enterprise rents a GPU server; they also have to bring their own training software and manage the timing and failures. “This is a managed Slurm environment that will help with all the job scheduling and automatic recovery of jobs failing,” de Guerre said. “So if a training job slows down or stops due to a hardware failure, the training will automatically restart very quickly, based on automatic checkpointing that we do in management of the checkpoints to continue with very little downtime.”He added that this provides higher throughput and more efficient training for a larger scale of compute clusters. Services like Vertex AI Training could make it easier for enterprises to build niche models or completely customize existing models. Still, just because the option exists doesn’t mean it&#x27;s the right fit for every enterprise.",
          "content": "Some enterprises are best served by fine-tuning large models to their needs, but a number of companies plan to build their own models, a project that would require access to GPUs. Google Cloud wants to play a bigger role in enterprises’ model-making journey with its new service, Vertex AI Training. The service gives enterprises looking to train their own models access to a managed Slurm environment, data science tooling and any chips capable of large-scale model training. With this new service, Google Cloud hopes to turn more enterprises away from other providers and encourage the building of more company-specific AI models. While Google Cloud has always offered the ability to customize its Gemini models, the new service allows customers to bring in their own models or customize any open-source model Google Cloud hosts. Vertex AI Training positions Google Cloud directly against companies like CoreWeave and Lambda Labs, as well as its cloud competitors AWS and Microsoft Azure. Jaime de Guerre, senior director of product management at Gloogle Cloud, told VentureBeat that the company has been hearing from a lot of organizations of varying sizes that they need a way to better optimize compute but in a more reliable environment.“What we&#x27;re seeing is that there&#x27;s an increasing number of companies that are building or customizing large gen AI models to introduce a product offering built around those models, or to help power their business in some way,” de Guerre said. “This includes AI startups, technology companies, sovereign organizations building a model for a particular region or culture or language and some large enterprises that might be building it into internal processes.”De Guerre noted that while anyone can technically use the service, Google is targeting companies planning large-scale model training rather than simple fine-tuning or LoRA adopters. Vertex AI Services will focus on longer-running training jobs spanning hundreds or even thousands of chips. Pricing will depend on the amount of compute the enterprise will need. “Vertex AI Training is not for adding more information to the context or using RAG; this is to train a model where you might start from completely random weights,” he said.Model customization on the rise Enterprises are recognizing the value of building customized models beyond just fine-tuning an LLM via retrieval-augmented generation (RAG). Custom models would know more in-depth company information and respond with answers specific to the organization. Companies like Arcee.ai have begun offering their models for customization to clients. Adobe recently announced a new service that allows enterprises to retrain Firefly for their specific needs. Organizations like FICO, which create small language models specific to the finance industry, often buy GPUs to train them at significant cost. Google Cloud said Vertex AI Training differentiates itself by giving access to a larger set of chips, services to monitor and manage training and the expertise it learned from training the Gemini models. Some early customers of Vertex AI Training include AI Singapore, a consortium of Singaporean research institutes and startups that built the 27-billion-parameter SEA-LION v4, and Salesforce’s AI research team. Enterprises often have to choose between taking an already-built LLM and fine-tuning it or building their own model. But creating an LLM from scratch is usually unattainable for smaller companies, or it simply doesn’t make sense for some use cases. However, for organizations where a fully custom or from-scratch model makes sense, the issue is gaining access to the GPUs needed to run training.Model training can be expensiveTraining a model, de Guerre said, can be difficult and expensive, especially when organizations compete with several others for GPU space.Hyperscalers like AWS and Microsoft — and, yes, Google — have pitched that their massive data centers and racks and racks of high-end chips deliver the most value to enterprises. Not only will they have access to expensive GPUs, but cloud providers often offer full-stack services to help enterprises move to production.Services like CoreWeave gained prominence for offering on-demand access to Nvidia H100s, giving customers flexibility in compute power when building models or applications. This has also given rise to a business model in which companies with GPUs rent out server space.De Guerre said Vertex AI Training isn’t just about offering access to train models on bare compute, where the enterprise rents a GPU server; they also have to bring their own training software and manage the timing and failures. “This is a managed Slurm environment that will help with all the job scheduling and automatic recovery of jobs failing,” de Guerre said. “So if a training job slows down or stops due to a hardware failure, the training will automatically restart very quickly, based on automatic checkpointing that we do in management of the checkpoints to continue with very little downtime.”He added that this provides higher throughput and more efficient training for a larger scale of compute clusters. Services like Vertex AI Training could make it easier for enterprises to build niche models or completely customize existing models. Still, just because the option exists doesn’t mean it&#x27;s the right fit for every enterprise.",
          "feed_position": 2,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/2YeFC7KfZXgvsmj0mIz3qZ/d7e6ef2efddb78aba1c472a8ead8d850/crimedy7_illustration_of_a_server_farm_--ar_169_--v_7_e717ea2e-977b-4ba6-825e-30497516b55d_0.png?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/data-infrastructure/how-ai-powered-cameras-are-redefining-business-intelligence",
          "published_at": "Mon, 27 Oct 2025 04:00:00 GMT",
          "title": "How AI-powered cameras are redefining business intelligence",
          "standfirst": "Presented by Axis Communications Many businesses are equipped with a network of intelligent eyes that span operations. These IP cameras and intelligent edge devices were once solely focused on ensuring the safety of employees, customers, and inventory. These technologies have long proved to be essential tools for businesses, and while this sentiment still rings true, they’re now emerging as powerful resources.These cameras and edge devices have rapidly evolved into real-time data producers. IP cameras can now see and understand, and the accompanying artificial intelligence helps companies and decision-makers generate business intelligence, improve operational efficiency, and gain a competitive advantage.By treating cameras as vision sensors and sources of operational insight, businesses can transform everyday visibility into measurable business value.Intelligence on the edgeNetwork cameras have come a long way since Axis Communications first introduced this technology in 1996. Over time, innovations like the ARTPEC chip, the first chip purpose-built for IP video, helped enhance image quality, analytics, and encoding performance.Today, these intelligent devices are powering a new generation of business intelligence and operational efficiency solutions via embedded AI. Actionable insights are now fed directly into intelligence platforms, ERP systems, and real-time dashboards, and the results are significant and far-reaching.In manufacturing, intelligent cameras are detecting defects on the production line early, before an entire production run is compromised. In retail, these cameras can run software that maps customer journeys and optimizes product placement. In healthcare, these solutions help facilities enhance patient care while improving operational efficiency and reducing costs.The combination of video and artificial intelligence has significantly expanded what cameras can do — transforming them into vital tools for improving business performance.Proof in practiceCompanies are creatively taking advantage of edge devices like AI-enabled cameras to improve business intelligence and operational efficiencies. BMW has relied on intelligent IP cameras to optimize efficiency and product quality, with AI-driven video systems catching defects that are often invisible to the human eye. Or take Google Cloud’s shelf-checking AI technology, an innovative software that allows retailers to make instant restocking decisions using real-time data. These technologies appeal to far more than retailers and vendors. The A.C. Camargo Cancer Center in Brazil uses network cameras to reduce theft, assure visitor and employee safety, and optimize patient flow. By relying on newfound business intelligence, the facility has saved more than $2 million in operational costs through two years, with those savings being reinvested directly into patient care. Urban projects can also benefit from edge devices and artificial intelligence. For example, Vanderbilt University turned to video analytics to study traffic flow, relying on AI to uncover the causes of phantom congestion and enabling smarter traffic management. These studies will have additional impact on the local environment and public, as the learnings can be used to optimize safety, air quality, and fuel efficiency. Each case illustrates the same point: AI-powered cameras can fuel a tangible return on investment and crucial business intelligence, regardless of the industry.Preparing for the next phaseThe role of AI in video intelligence is still expanding, with several emerging trends driving greater advancements and impact in the years ahead:Predictive operations: cameras that are capable of forecasting needs or risks through predictive analyticsVersatile analytics: systems that incorporate audio, thermal, and environmental sensors for more comprehensive and accurate insightsTechnological collaboration: cameras that integrate with other intelligent edge devices to autonomously manage tasksSustainability initiatives: intelligent technologies that reduce energy use and support resource efficiencyAxis Communications helps advance these possibilities with open-source, scalable systems engineered to address both today’s challenges and tomorrow’s opportunities. By staying ahead of this ever-changing environment, Axis helps ensure that organizations continue to benefit from actionable business intelligence while maintaining the highest standards of security and safety.Cameras have evolved beyond simple surveillance tools. They are strategic assets that inform operations, foster innovation, and enable future readiness. Business leaders who cling to traditional views of IP cameras and edge devices risk missing opportunities for efficiency and innovation. Those who embrace an AI-driven approach can expect not only stronger security but also better business outcomes.Ultimately, the value of IP cameras and edge devices lies not in categories but in capabilities. In an era of rapidly evolving artificial intelligence, these unique technologies will become indispensable to overall business success.About Axis CommunicationsAxis enables a smarter and safer world by improving security, safety, operational efficiency, and business intelligence. As a network technology company and industry leader, Axis offers video surveillance, access control, intercoms, and audio solutions. These are enhanced by intelligent analytics applications and supported by high-quality training.Axis has around 5,000 dedicated employees in over 50 countries and collaborates with technology and system integration partners worldwide to deliver customer solutions. Axis was founded in 1984, and the headquarters are in Lund, Sweden.Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "content": "Presented by Axis Communications Many businesses are equipped with a network of intelligent eyes that span operations. These IP cameras and intelligent edge devices were once solely focused on ensuring the safety of employees, customers, and inventory. These technologies have long proved to be essential tools for businesses, and while this sentiment still rings true, they’re now emerging as powerful resources.These cameras and edge devices have rapidly evolved into real-time data producers. IP cameras can now see and understand, and the accompanying artificial intelligence helps companies and decision-makers generate business intelligence, improve operational efficiency, and gain a competitive advantage.By treating cameras as vision sensors and sources of operational insight, businesses can transform everyday visibility into measurable business value.Intelligence on the edgeNetwork cameras have come a long way since Axis Communications first introduced this technology in 1996. Over time, innovations like the ARTPEC chip, the first chip purpose-built for IP video, helped enhance image quality, analytics, and encoding performance.Today, these intelligent devices are powering a new generation of business intelligence and operational efficiency solutions via embedded AI. Actionable insights are now fed directly into intelligence platforms, ERP systems, and real-time dashboards, and the results are significant and far-reaching.In manufacturing, intelligent cameras are detecting defects on the production line early, before an entire production run is compromised. In retail, these cameras can run software that maps customer journeys and optimizes product placement. In healthcare, these solutions help facilities enhance patient care while improving operational efficiency and reducing costs.The combination of video and artificial intelligence has significantly expanded what cameras can do — transforming them into vital tools for improving business performance.Proof in practiceCompanies are creatively taking advantage of edge devices like AI-enabled cameras to improve business intelligence and operational efficiencies. BMW has relied on intelligent IP cameras to optimize efficiency and product quality, with AI-driven video systems catching defects that are often invisible to the human eye. Or take Google Cloud’s shelf-checking AI technology, an innovative software that allows retailers to make instant restocking decisions using real-time data. These technologies appeal to far more than retailers and vendors. The A.C. Camargo Cancer Center in Brazil uses network cameras to reduce theft, assure visitor and employee safety, and optimize patient flow. By relying on newfound business intelligence, the facility has saved more than $2 million in operational costs through two years, with those savings being reinvested directly into patient care. Urban projects can also benefit from edge devices and artificial intelligence. For example, Vanderbilt University turned to video analytics to study traffic flow, relying on AI to uncover the causes of phantom congestion and enabling smarter traffic management. These studies will have additional impact on the local environment and public, as the learnings can be used to optimize safety, air quality, and fuel efficiency. Each case illustrates the same point: AI-powered cameras can fuel a tangible return on investment and crucial business intelligence, regardless of the industry.Preparing for the next phaseThe role of AI in video intelligence is still expanding, with several emerging trends driving greater advancements and impact in the years ahead:Predictive operations: cameras that are capable of forecasting needs or risks through predictive analyticsVersatile analytics: systems that incorporate audio, thermal, and environmental sensors for more comprehensive and accurate insightsTechnological collaboration: cameras that integrate with other intelligent edge devices to autonomously manage tasksSustainability initiatives: intelligent technologies that reduce energy use and support resource efficiencyAxis Communications helps advance these possibilities with open-source, scalable systems engineered to address both today’s challenges and tomorrow’s opportunities. By staying ahead of this ever-changing environment, Axis helps ensure that organizations continue to benefit from actionable business intelligence while maintaining the highest standards of security and safety.Cameras have evolved beyond simple surveillance tools. They are strategic assets that inform operations, foster innovation, and enable future readiness. Business leaders who cling to traditional views of IP cameras and edge devices risk missing opportunities for efficiency and innovation. Those who embrace an AI-driven approach can expect not only stronger security but also better business outcomes.Ultimately, the value of IP cameras and edge devices lies not in categories but in capabilities. In an era of rapidly evolving artificial intelligence, these unique technologies will become indispensable to overall business success.About Axis CommunicationsAxis enables a smarter and safer world by improving security, safety, operational efficiency, and business intelligence. As a network technology company and industry leader, Axis offers video surveillance, access control, intercoms, and audio solutions. These are enhanced by intelligent analytics applications and supported by high-quality training.Axis has around 5,000 dedicated employees in over 50 countries and collaborates with technology and system integration partners worldwide to deliver customer solutions. Axis was founded in 1984, and the headquarters are in Lund, Sweden.Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "feed_position": 3,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/IE0cHvEooxE88DdrCEo2E/4f17dbfbd317da9fd1944ff1f68743de/VB_HeroImage_NoLogo.jpg?w=300&q=30"
        }
      ],
      "featured_image": "https://images.ctfassets.net/jdtwqhzvc2n1/5ooQmDHIK8joIBWGcWySzH/e0d4c547081630465c4b8862570d0fd1/cfr0z3n_extremely_small_tiny_figurine_of_a_humanoid_robot_weari_47d6d5f6-f57a-4685-b6aa-d28c2657eef8.png?w=300&q=30",
      "popularity_score": 2019.7786888888888,
      "ai_summary": [
        "The guide focuses on over-ear wireless headphones.",
        "The guide highlights top choices tested.",
        "The guide considers noise cancellation.",
        "The guide considers features and wear style.",
        "The guide offers options for different budgets."
      ]
    },
    {
      "id": "cluster_27",
      "coverage": 1,
      "updated_at": "Mon, 27 Oct 2025 20:18:05 +0000",
      "title": "AI-powered search engines rely on “less popular” sources, researchers find",
      "neutral_headline": "AI Search Engines Rely on Less Popular Sources",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2025/10/ai-powered-search-engines-rely-on-less-popular-sources-researchers-find/",
          "published_at": "Mon, 27 Oct 2025 20:18:05 +0000",
          "title": "AI-powered search engines rely on “less popular” sources, researchers find",
          "standfirst": "Generative search engines often cite sites that wouldn't appear in Google's top 100 links.",
          "content": "Since last year’s disastrous rollout of Google’s AI Overviews, the world at large has been aware of how AI-powered search results can differ wildly from the traditional list of links search engines have generated for decades. Now, new research helps quantify that difference, showing that AI search engines tend to cite less popular websites and ones that wouldn’t even appear in the Top 100 links listed in an “organic” Google search. In the pre-print paper “Characterizing Web Search in The Age of Generative AI,” researchers from Ruhr University in Bochum, Germany, and the Max Planck Institute for Software Systems compared traditional link results from Google’s search engine to its AI Overviews and Gemini-2.5-Flash. The researchers also looked at GPT-4o’s web search mode and the separate “GPT-4o with Search Tool,” which resorts to searching the web only when the LLM decides it needs information found outside its own pre-trained data. The researchers drew test queries from a number of sources, including specific questions submitted to ChatGPT in the WildChat dataset, general political topics listed on AllSides, and products included in the 100 most-searched Amazon products list.Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-184366155-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-184366155-1152x648.jpg",
      "popularity_score": 347.0698,
      "ai_summary": [
        "AI-powered search engines use different sources.",
        "They often cite sites not in Google's top 100.",
        "Researchers found this difference.",
        "The sources are considered less popular.",
        "The search engines are generative."
      ]
    },
    {
      "id": "cluster_13",
      "coverage": 1,
      "updated_at": "Mon, 27 Oct 2025 23:01:06 +0000",
      "title": "Porsche’s 2026 911 Turbo S is a ballistic, twin-turbo, 701-horsepower monster",
      "neutral_headline": "Porsche 911 Turbo S: 701-Horsepower Monster",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2025/10/porsches-2026-911-turbo-s-is-a-ballistic-twin-turbo-701-horsepower-monster/",
          "published_at": "Mon, 27 Oct 2025 23:01:06 +0000",
          "title": "Porsche’s 2026 911 Turbo S is a ballistic, twin-turbo, 701-horsepower monster",
          "standfirst": "Big power, no lag, surprising agility make for a stellar drive—at an astronomical cost.",
          "content": "Porsche provided flights from Albany, New York, to Malaga, Spain, and accommodation so Ars could drive the 911 Turbo S. Ars does not accept paid editorial content. Turbochargers have been injecting more power into engines for over 100 years, but never before have they been so prevalent in our cars. A little boost can add a lot of power and efficiency, too, making a turbocharger a great solution to eke maximum performance out of today’s engines. Usually, though, that comes with the penalty of throttle lag: You put your foot to the floor, and nothing much happens for a beat or two. As we’ve recently seen in our review of the new 911 GTS, Porsche’s engineers have worked some magic to create a turbocharger that provides all the power and fun of forced induction but with none of the throttle response penalty. If adding one high-tech, high-voltage turbocharger is good, surely two would be better, right? Indeed, it is, if you can afford the cost of entry. Meet the 701 hp (523 kW) 2026 911 Turbo S, Porsche’s new most powerful 911 ever. Twinning the T-Hybrid For Porsche’s first hybrid 911, the GTS, the company didn’t simply add an electric motor and bigger battery into the mix and call it a day. It also inserted another high-speed motor into the turbocharger, enabling it to spin up to maximum speed in less than a second, nearly eliminating turbo lag.Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/2026-Porsche-911-Turbo-S-first-drive-005-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/2026-Porsche-911-Turbo-S-first-drive-005-1152x648.jpg",
      "popularity_score": 344.7867444444444,
      "ai_summary": [
        "The 2026 Porsche 911 Turbo S is announced.",
        "It has a twin-turbo engine.",
        "The car produces 701 horsepower.",
        "It offers surprising agility.",
        "The car comes at a high cost."
      ]
    },
    {
      "id": "cluster_31",
      "coverage": 1,
      "updated_at": "Mon, 27 Oct 2025 19:58:43 +0000",
      "title": "AT&T ad congratulating itself for its ethics violated an ad-industry rule",
      "neutral_headline": "AT&T Ad Violated Advertising Industry Rule, Watchdog Demands Removal",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/10/att-ad-congratulating-itself-for-its-ethics-violated-an-ad-industry-rule/",
          "published_at": "Mon, 27 Oct 2025 19:58:43 +0000",
          "title": "AT&T ad congratulating itself for its ethics violated an ad-industry rule",
          "standfirst": "Ad industry watchdog says AT&#038;T violated program rule, demands removal of ads.",
          "content": "AT&T committed a big no-no in its latest advertising campaign against T-Mobile, according to the organization that runs the ad industry’s self-regulatory system. BBB National Programs’ National Advertising Division said Friday that AT&T “violated Section 2.1(I) of the National Advertising Division (NAD)/National Advertising Review Board (NARB) Procedures for the US advertising industry’s process of self-regulation by issuing a video advertisement and press release that use the NAD process and its findings for promotional purposes. NAD has demanded that AT&T immediately remove such violative promotional materials and cease all future dissemination.” The NAD said that AT&T’s action threatens the “integrity and success of the self-regulatory forum,” and “undermines NAD’s mission to promote truth and accuracy of advertising claims and foster consumer trust in the marketplace.”Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/luke-wilson-att-1152x648-1761591326.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/luke-wilson-att-1152x648-1761591326.jpg",
      "popularity_score": 321.7470222222222,
      "ai_summary": [
        "An advertising industry watchdog found AT&T's ad violated a program rule.",
        "The watchdog specifically cited the ad's self-congratulatory tone regarding ethics.",
        "The watchdog has demanded that AT&T remove the offending advertisements.",
        "The ad industry's program aims to ensure truthful and ethical advertising practices.",
        "AT&T has not yet publicly responded to the watchdog's demand for removal."
      ]
    },
    {
      "id": "cluster_37",
      "coverage": 1,
      "updated_at": "Mon, 27 Oct 2025 19:19:37 +0000",
      "title": "25 years, one website: ISS in Real Time captures quarter-century on space station",
      "neutral_headline": "Website Captures Twenty-Five Years of International Space Station Data",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2025/10/25-years-one-website-iss-in-real-time-captures-quarter-century-on-space-station/",
          "published_at": "Mon, 27 Oct 2025 19:19:37 +0000",
          "title": "25 years, one website: ISS in Real Time captures quarter-century on space station",
          "standfirst": "From the makers of Apollo in Real Time comes a site with 500 times more data.",
          "content": "With the milestone just days away, you are likely to hear this week that there has now been a continuous human presence on the International Space Station (ISS) for the past 25 years. But what does that quarter of a century actually encompass? If only there was a way to see, hear, and experience each of those 9,131 days. Fortunately, the astronauts and cosmonauts on the space station have devoted some of their work time and a lot of their free time to taking photos, filming videos, and calling down to Earth. Much of that data has been made available to the public, but in separate repositories, with no real way to correlate or connect it with the timeline on which it was all created.Read full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/news-102725a-lg-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/news-102725a-lg-1152x648.jpg",
      "popularity_score": 319.09535555555556,
      "ai_summary": [
        "A website, \"ISS in Real Time,\" documents the ISS's quarter-century of operation.",
        "The site offers 500 times more data than the \"Apollo in Real Time\" project.",
        "The website provides real-time data and historical information about the ISS.",
        "Users can explore the ISS's activities and its evolution over time.",
        "The project aims to educate and engage the public about space exploration."
      ]
    },
    {
      "id": "cluster_56",
      "coverage": 1,
      "updated_at": "Mon, 27 Oct 2025 16:35:52 +0000",
      "title": "F1 in Mexico City: We have a new championship leader",
      "neutral_headline": "Formula One Race in Mexico City Sees New Championship Leader",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2025/10/f1-in-mexico-city-we-have-a-new-championship-leader/",
          "published_at": "Mon, 27 Oct 2025 16:35:52 +0000",
          "title": "F1 in Mexico City: We have a new championship leader",
          "standfirst": "It was a quiet race for the win, but there was plenty of action for second and third.",
          "content": "Mexico City is one of the more unusual places that Formula 1 races, and it’s all thanks to altitude. The city sits at than 7,350 feet (2,240 m) above sea level, which makes the air noticeably thin compared to the average Grand Prix held at sea level. Like humans, F1 cars need air. Oxygen is necessary if you want any internal combustion to happen inside the turbocharged 1.6 L V6 engine. A good flow of air across the various radiators and heat exchangers in the car is vital if you want to make it to the end of the race. And the downforce-generating wings and underbody only generate downforce by creating differences in air pressure above and below the car. At over a mile above sea level, there’s about 20 percent less air, and therefore less power created by combustion, less efficient cooling of the cars, and less downforce able to be generated.Read full article Comments",
          "feed_position": 4,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2243465873-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-2243465873-1152x648.jpg",
      "popularity_score": 298.36618888888887,
      "ai_summary": [
        "The Formula One race in Mexico City concluded with a new championship leader.",
        "The race itself was relatively calm for the winning position.",
        "There was significant action and competition for second and third places.",
        "The results have shifted the standings in the overall championship.",
        "Details of the race and the new leader are now available."
      ]
    },
    {
      "id": "cluster_65",
      "coverage": 1,
      "updated_at": "Mon, 27 Oct 2025 15:05:07 +0000",
      "title": "Melissa set to be the strongest hurricane to ever strike Jamaica",
      "neutral_headline": "Hurricane Melissa Forecasted to Be Strongest to Hit Jamaica",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/10/melissa-set-to-be-the-strongest-hurricane-to-ever-strike-jamaica/",
          "published_at": "Mon, 27 Oct 2025 15:05:07 +0000",
          "title": "Melissa set to be the strongest hurricane to ever strike Jamaica",
          "standfirst": "Storm reached sustained winds of 160 mph on Monday morning.",
          "content": "Hurricane Melissa will make landfall in southern Jamaica less than 24 hours from now, and it is likely to be the most catastrophic storm in the Caribbean island’s history. As it crawled across the northern Caribbean Sea on Monday morning, Melissa officially became a Category 5 hurricane with 160 mph winds, according to the National Hurricane Center. The hurricane will likely fluctuate in intensity over the next day or so, perhaps undergoing an eyewall replacement cycle. But the background conditions, including very warm Caribbean waters and low wind shear, will support a very powerful hurricane and the potential for further strengthening.Read full article Comments",
          "feed_position": 6,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/1000x1000-1000x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/1000x1000-1000x648.jpg",
      "popularity_score": 297.8536888888889,
      "ai_summary": [
        "Hurricane Melissa is predicted to be the strongest hurricane to strike Jamaica.",
        "The storm reached sustained winds of 160 miles per hour on Monday morning.",
        "The hurricane's intensity poses a significant threat to the island nation.",
        "Authorities are preparing for potential damage and necessary evacuations.",
        "Residents are urged to take precautions and heed official warnings."
      ]
    },
    {
      "id": "cluster_60",
      "coverage": 1,
      "updated_at": "Mon, 27 Oct 2025 16:04:35 +0000",
      "title": "Why imperfection could be key to Turing patterns in nature",
      "neutral_headline": "Imperfection May Be Key to Turing Patterns in Natural Systems",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/10/why-imperfection-could-be-key-to-turing-patterns-in-nature/",
          "published_at": "Mon, 27 Oct 2025 16:04:35 +0000",
          "title": "Why imperfection could be key to Turing patterns in nature",
          "standfirst": "Many Turing mechanism models yield too-perfect patterns; varying cell sizes vastly improves the results.",
          "content": "A mixture of two types of pigment-producing cells undergoes diffusiophoretic transport to self-assemble into a hexagonal pattern. Credit: Siamak Mirfendereski and Ankur Gupta/CU Boulder A mixture of two types of pigment-producing cells undergoes diffusiophoretic transport to self-assemble into a hexagonal pattern. Credit: Siamak Mirfendereski and Ankur Gupta/CU Boulder A zebra’s distinctive black-and-white stripes, or a leopard’s spots, are both examples of “Turing patterns,” after mathematician and computer scientist Alan Turing, who proposed an intriguing hypothetical mechanism for how such complex, irregular patterns might emerge in nature. But Turing’s original proposal proved too simplified to fully re-create those natural patterns. Scientists at the University of Colorado at Boulder (UCB) have devised a new modeling approach that achieves much more accurate final patterns by introducing deliberate imperfections, according to a new paper published in the journal Matter. Turing focused on chemicals known as morphogens in his seminal 1952 paper. He devised a mechanism involving the interaction between an activator chemical that expresses a unique characteristic (like a tiger’s stripe) and an inhibitor chemical that periodically kicks in to shut down the activator’s expression. Both activator and inhibitor diffuse throughout a system, much like gas atoms will do in an enclosed box. It’s a bit like injecting a drop of black ink into a beaker of water. Normally, this would stabilize a system, and the water would gradually turn a uniform gray. But if the inhibitor diffuses at a faster rate than the activator, the process is destabilized. That mechanism will produce spots or stripes. Scientists have tried to apply this basic concept to many different kinds of systems. For instance, neurons in the brain could serve as activators and inhibitors, depending on whether they amplify or dampen the firing of other nearby neurons—possibly the reason why we see certain patterns when we hallucinate. There is evidence for Turing mechanisms at work in zebra-fish stripes, the spacing between hair follicles in mice, feather buds on a bird’s skin, the ridges on a mouse’s palate, and the digits on a mouse’s paw.Read full article Comments",
          "feed_position": 5,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/turing1CROP-A-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/turing1CROP-A-1152x648.jpg",
      "popularity_score": 287.8448,
      "ai_summary": [
        "Research suggests imperfection is crucial for Turing patterns in nature.",
        "Many models produce overly perfect patterns, not reflecting reality.",
        "Varying cell sizes in models significantly improves pattern accuracy.",
        "This research enhances understanding of biological pattern formation.",
        "The findings could improve models of animal markings and other patterns."
      ]
    },
    {
      "id": "cluster_72",
      "coverage": 1,
      "updated_at": "Mon, 27 Oct 2025 13:44:02 +0000",
      "title": "New image-generating AIs are being used for fake expense reports",
      "neutral_headline": "Image-Generating AIs Used for Creating Fake Expense Reports",
      "bullet_summary": [
        "Software provider AppZen said fake AI receipts accounted for about 14% of fraud attempts",
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2025/10/ai-generated-receipts-make-submitting-fake-expenses-easier/",
          "published_at": "Mon, 27 Oct 2025 13:44:02 +0000",
          "title": "New image-generating AIs are being used for fake expense reports",
          "standfirst": "Software provider AppZen said fake AI receipts accounted for about 14% of fraud attempts.",
          "content": "Businesses are increasingly being deceived by employees using artificial intelligence for an age-old scam: faking expense receipts. The launch of new image-generation models by top AI groups such as OpenAI and Google in recent months has sparked an influx of AI-generated receipts submitted internally within companies, according to leading expense software platforms. Software provider AppZen said fake AI receipts accounted for about 14 percent of fraudulent documents submitted in September, compared with none last year. Fintech group Ramp said its new software flagged more than $1 million in fraudulent invoices within 90 days.Read full article Comments",
          "feed_position": 7,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/fakereceiptsbro-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/fakereceiptsbro-1152x648.jpg",
      "popularity_score": 280.5023,
      "ai_summary": [
        "New image-generating AIs are being utilized to create fraudulent expense reports.",
        "Software provider AppZen reported a rise in AI-generated fake receipts.",
        "Approximately 14% of fraud attempts involved AI-generated receipts.",
        "This highlights a new challenge in expense report verification.",
        "Companies must adapt to detect and prevent AI-driven fraud."
      ]
    },
    {
      "id": "cluster_77",
      "coverage": 1,
      "updated_at": "Mon, 27 Oct 2025 11:00:28 +0000",
      "title": "10M people watched a YouTuber shim a lock; the lock company sued him. Bad idea.",
      "neutral_headline": "Lock Company Sues YouTuber Who Showed Lock Picking Techniques",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/10/suing-a-popular-youtuber-who-shimmed-a-130-lock-what-could-possibly-go-wrong/",
          "published_at": "Mon, 27 Oct 2025 11:00:28 +0000",
          "title": "10M people watched a YouTuber shim a lock; the lock company sued him. Bad idea.",
          "standfirst": "It's still legal to pick locks, even when you swing your legs.",
          "content": "“Opening locks” might not sound like scintillating social media content, but Trevor McNally has turned lock-busting into online gold. A former US Marine Staff Sergeant, McNally today has more than 7 million followers and has amassed more than 2 billion views just by showing how easy it is to open many common locks by slapping, picking, or shimming them. This does not always endear him to the companies that make the locks. On March 3, 2025, a Florida lock company called Proven Industries released a social media promo video just begging for the McNally treatment. The video was called, somewhat improbably, “YOU GUYS KEEP SAYING YOU CAN EASILY BREAK OFF OUR LATCH PIN LOCK.” In it, an enthusiastic man in a ball cap says he will “prove a lot of you haters wrong.” He then goes hard at Proven’s $130 model 651 trailer hitch lock with a sledgehammer, bolt cutters, and a crowbar.Read full article Comments",
          "feed_position": 8,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/lockpick-death-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/lockpick-death-1152x648.jpg",
      "popularity_score": 253,
      "ai_summary": [
        "A lock company sued a YouTuber who demonstrated lock picking methods.",
        "The YouTuber's video attracted approximately ten million viewers.",
        "Lock picking remains legal, even when demonstrated publicly.",
        "The lawsuit's basis is not explicitly stated in the article.",
        "The case raises questions about the legality of educational content."
      ]
    }
  ]
}