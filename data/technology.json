{
  "updated_at": "2026-02-03T23:22:17.455Z",
  "clusters": [
    {
      "id": "cluster_25",
      "coverage": 4,
      "updated_at": "Tue, 03 Feb 2026 20:18:00 GMT",
      "title": "Xcode 26.3 finally brings agentic coding to Apple's developer tools",
      "neutral_headline": "Xcode 26.3 finally brings agentic coding to Apple's developer tools",
      "bullet_summary": [
        "On Tuesday, the company announced the release of Xcode 26",
        "Reported by ZDNet, The Verge, TechMeme and others"
      ],
      "items": [
        {
          "source": "ZDNet",
          "url": "https://www.zdnet.com/article/xcode-agentic-coding-apple-developer-tools/",
          "published_at": "Tue, 03 Feb 2026 20:18:00 GMT",
          "title": "Xcode 26.3 finally brings agentic coding to Apple's developer tools",
          "standfirst": "Xcode 26.3 could be Apple's biggest leap in AI coding tools, shifting from assistant prompts to autonomous agents that build, test, and update configurations directly inside Xcode.",
          "content": "Xcode 26.3 could be Apple's biggest leap in AI coding tools, shifting from assistant prompts to autonomous agents that build, test, and update configurations directly inside Xcode.",
          "feed_position": 2
        },
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/news/873300/apple-xcode-openai-anthropic-ai-agentic-coding",
          "published_at": "2026-02-03T14:04:09-05:00",
          "title": "Apple’s Xcode adds OpenAI and Anthropic’s coding agents",
          "standfirst": "Apple is building OpenAI and Anthropic's AI-powered coding agents directly into Xcode. New integrations in Xcode 26.3 will give developers the ability to call upon Anthropic's Claude Agent and OpenAI's Codex to write and edit code, update project settings, search documentation, and more. Xcode is the software developers can use to create and test apps [&#8230;]",
          "content": "Apple is building OpenAI and Anthropic's AI-powered coding agents directly into Xcode. New integrations in Xcode 26.3 will give developers the ability to call upon Anthropic's Claude Agent and OpenAI's Codex to write and edit code, update project settings, search documentation, and more. Xcode is the software developers can use to create and test apps for the iPhone, Mac, iPad, Apple Watch, and Apple TV. Both Claude and ChatGPT were previously available inside Xcode, but this latest update will allow AI agents to take action inside the app, rather than just provide coding assistance. Apple is also making Xcode available through the Model … Read the full story at The Verge.",
          "feed_position": 6
        },
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/260203/p30#a260203p30",
          "published_at": "Tue, 03 Feb 2026 13:35:02 -0500",
          "title": "Apple brings agentic coding to Xcode 26.3, allowing developers to use Anthropic's Claude Agent and OpenAI's Codex, and integrates support for MCP (Sarah Perez/TechCrunch)",
          "standfirst": "Sarah Perez / TechCrunch: Apple brings agentic coding to Xcode 26.3, allowing developers to use Anthropic's Claude Agent and OpenAI's Codex, and integrates support for MCP &mdash; Apple is bringing agentic coding to Xcode. On Tuesday, the company announced the release of Xcode 26.3, which will allow developers to use agentic tools &hellip;",
          "content": "Sarah Perez / TechCrunch: Apple brings agentic coding to Xcode 26.3, allowing developers to use Anthropic's Claude Agent and OpenAI's Codex, and integrates support for MCP &mdash; Apple is bringing agentic coding to Xcode. On Tuesday, the company announced the release of Xcode 26.3, which will allow developers to use agentic tools &hellip;",
          "feed_position": 12,
          "image_url": "http://www.techmeme.com/260203/i30.jpg"
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2026/02/03/xcode-moves-into-agentic-coding-with-deeper-openai-and-anthropic-integrations/",
          "published_at": "Tue, 03 Feb 2026 18:00:00 +0000",
          "title": "Xcode moves into agentic coding with deeper OpenAI and Anthropic integrations",
          "standfirst": "Xcode 26.3 offers agentic coding capabilities with Anthropic's Claude Agent and OpenAI's Codex.",
          "content": "Xcode 26.3 offers agentic coding capabilities with Anthropic's Claude Agent and OpenAI's Codex.",
          "feed_position": 6
        }
      ],
      "featured_image": "http://www.techmeme.com/260203/i30.jpg",
      "popularity_score": 4016.928484722222
    },
    {
      "id": "cluster_26",
      "coverage": 4,
      "updated_at": "Tue, 03 Feb 2026 20:13:08 +0000",
      "title": "X office raided in France's Grok probe; Elon Musk summoned for questioning",
      "neutral_headline": "X office raided in France's Grok probe; Elon Musk summoned for questioning",
      "bullet_summary": [
        "As previously reported by Reuters, Elon Musk and former X CEO Linda Yaccarino were also summoned for hearings in April",
        "The Paris prosecutor’s office announced that it is expanding a criminal investigation into X for alleged crimes, including the possession and distribution of child sexual exploitation material"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/02/x-office-raided-in-frances-grok-probe-elon-musk-summoned-for-questioning/",
          "published_at": "Tue, 03 Feb 2026 20:13:08 +0000",
          "title": "X office raided in France's Grok probe; Elon Musk summoned for questioning",
          "standfirst": "Paris prosecutor: Illegal content probe includes pornographic images of minors.",
          "content": "French law enforcement authorities today raided X's Paris office and summoned Elon Musk for questioning as part of an investigation into illegal content. The Paris public prosecutor’s office said the yearlong probe was recently expanded because the Grok chatbot was disseminating Holocaust-denial claims and sexually explicit deepfakes. Europol, which is assisting French authorities, said today the \"investigation concerns a range of suspected criminal offenses linked to the functioning and use of the platform, including the dissemination of illegal content and other forms of online criminal activity.\" Europol's cybercrime center provided \"an analyst on the ground in Paris to assist national authorities.\" The French Gendarmerie’s cybercrime unit is also aiding the investigation. French authorities want to question Musk and former X CEO Linda Yaccarino, who quit last year amid a controversy over Grok's praise of Hitler. Prosecutors summoned Musk and Yaccarino for interviews in April 2026, though the interviews are being described as voluntary.Read full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2024/02/Elon-Musk-X-1152x648.jpg"
        },
        {
          "source": "Guardian Tech",
          "url": "https://www.theguardian.com/technology/2026/feb/03/french-headquarters-elon-musk-x-raided-paris-cybercrime-unit",
          "published_at": "Tue, 03 Feb 2026 19:01:37 GMT",
          "title": "French headquarters of Elon Musk’s X raided by Paris cybercrime unit",
          "standfirst": "Prosecutors’ announcement comes amid a hardening of European attitudes to social media firmsProsecutors have raided the French headquarters of Elon Musk’s social media platform X and summoned the tech billionaire and the company’s former chief executive for questioning as part of an investigation into alleged cybercrime.“A search is under way by the cybercrime unit of the Paris prosecutor’s office, the national police cyber unit and Europol,” the Paris prosecutors’ office said in a post on X on Tuesday, adding that it would no longer be publishing on the network. Continue reading...",
          "content": "Prosecutors’ announcement comes amid a hardening of European attitudes to social media firmsProsecutors have raided the French headquarters of Elon Musk’s social media platform X and summoned the tech billionaire and the company’s former chief executive for questioning as part of an investigation into alleged cybercrime.“A search is under way by the cybercrime unit of the Paris prosecutor’s office, the national police cyber unit and Europol,” the Paris prosecutors’ office said in a post on X on Tuesday, adding that it would no longer be publishing on the network. Continue reading...",
          "feed_position": 1
        },
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/tech/873142/french-police-raid-x-investigation",
          "published_at": "2026-02-03T12:10:33-05:00",
          "title": "French police raid X&#8217;s Paris office as UK investigation continues",
          "standfirst": "A raid on X's Paris office was carried out by the Paris prosecutor's cybercrime unit on Tuesday with Europol and French police as part of an ongoing investigation that expanded in July to include Grok. As previously reported by Reuters, Elon Musk and former X CEO Linda Yaccarino were also summoned for hearings in April. [&#8230;]",
          "content": "A raid on X's Paris office was carried out by the Paris prosecutor's cybercrime unit on Tuesday with Europol and French police as part of an ongoing investigation that expanded in July to include Grok. As previously reported by Reuters, Elon Musk and former X CEO Linda Yaccarino were also summoned for hearings in April. The investigation, which was initially launched last year, is looking into several allegations against X and Grok, including complicity in possession and distribution of child pornography and denial of crimes against humanity (related to Holocaust denial content), along with claims that X was manipulating its algorithm and … Read the full story at The Verge.",
          "feed_position": 8
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2026/02/03/french-police-search-x-office-in-paris-summon-elon-musk-for-questioning/",
          "published_at": "Tue, 03 Feb 2026 16:55:11 +0000",
          "title": "French police search X office in Paris, summon Elon Musk for questioning",
          "standfirst": "The Paris prosecutor’s office announced that it is expanding a criminal investigation into X for alleged crimes, including the possession and distribution of child sexual exploitation material.",
          "content": "The Paris prosecutor’s office announced that it is expanding a criminal investigation into X for alleged crimes, including the possession and distribution of child sexual exploitation material.",
          "feed_position": 10
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2024/02/Elon-Musk-X-1152x648.jpg",
      "popularity_score": 4016.847373611111
    },
    {
      "id": "cluster_2",
      "coverage": 3,
      "updated_at": "Tue, 03 Feb 2026 22:47:00 GMT",
      "title": "Qwen3-Coder-Next offers vibe coders a powerful open source, ultra-sparse model with 10x higher throughput for repo tasks",
      "neutral_headline": "Apple just made Xcode better for vibe coding",
      "bullet_summary": [
        "The team found that training on diverse tool chat templates significantly improved the model&#x27;s robustness to unseen schemas at deployment time",
        "\"The big shift here is that Claude and Codex have so much more visibility into the breadth of the project,\" he said",
        "LinkedIn announced last week that it will begin offering official certifications in AI coding skills, drawing on usage data from platforms like Lovable and Replit",
        "\"I think we&#x27;re due a Challenger disaster with respect to coding agent security,\" he said, referring to the 1986 space shuttle explosion that killed all seven crew members"
      ],
      "items": [
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/technology/qwen3-coder-next-offers-vibe-coders-a-powerful-open-source-ultra-sparse",
          "published_at": "Tue, 03 Feb 2026 22:47:00 GMT",
          "title": "Qwen3-Coder-Next offers vibe coders a powerful open source, ultra-sparse model with 10x higher throughput for repo tasks",
          "standfirst": "Chinese e-commerce giant Alibaba&#x27;s Qwen team of AI researchers has emerged in the last year as one of the global leaders of open source AI development, releasing a host of powerful large language models and specialized multimodal models that approach, and in some cases, surpass the performance of the proprietary U.S. leaders such as OpenAI, Anthropic, Google and xAI.Now the Qwen team is back again this week with a compelling release that matches the \"vibe coding\" frenzy that has arisen in recent months: Qwen3-Coder-Next, a specialized 80-billion-parameter model designed to deliver elite agentic performance within a lightweight active footprint. It&#x27;s been released on a permissive Apache 2.0 license, enabling commercial usage by large enterprises and indie developers alike, with the model weights available on Hugging Face in four variants and a technical report describing some of its training approach and innovations. The release marks a major escalation in the global arms race for the ultimate coding assistant, following a week that has seen the space explode with new entrants. From the massive efficiency gains of Anthropic’s Claude Code harness to the high-profile launch of the OpenAI Codex app and the rapid community adoption of open-source frameworks like OpenClaw, the competitive landscape has never been more crowded. In this high-stakes environment, Alibaba isn&#x27;t just keeping pace — it is attempting to set a new standard for open-weight intelligence.For LLM decision-makers, Qwen3-Coder-Next represents a fundamental shift in the economics of AI engineering. While the model houses 80 billion total parameters, it utilizes an ultra-sparse Mixture-of-Experts (MoE) architecture that activates only 3 billion parameters per forward pass. This design allows it to deliver reasoning capabilities that rival massive proprietary systems while maintaining the low deployment costs and high throughput of a lightweight local model.Solving the long-context bottleneckThe core technical breakthrough behind Qwen3-Coder-Next is a hybrid architecture designed specifically to circumvent the quadratic scaling issues that plague traditional Transformers. As context windows expand — and this model supports a massive 262,144 tokens — traditional attention mechanisms become computationally prohibitive. Standard Transformers suffer from a \"memory wall\" where the cost of processing context grows quadratically with sequence length. Qwen addresses this by combining Gated DeltaNet with Gated Attention.Gated DeltaNet acts as a linear-complexity alternative to standard softmax attention. It allows the model to maintain state across its quarter-million-token window without the exponential latency penalties typical of long-horizon reasoning. When paired with the ultra-sparse MoE, the result is a theoretical 10x higher throughput for repository-level tasks compared to dense models of similar total capacity. This architecture ensures an agent can \"read\" an entire Python library or complex JavaScript framework and respond with the speed of a 3B model, yet with the structural understanding of an 80B system. To prevent context hallucination during training, the team utilized Best-Fit Packing (BFP), a strategy that maintains efficiency without the truncation errors found in traditional document concatenation.Trained to be agent-firstThe \"Next\" in the model&#x27;s nomenclature refers to a fundamental pivot in training methodology. Historically, coding models were trained on static code-text pairs—essentially a \"read-only\" education. Qwen3-Coder-Next was instead developed through a massive \"agentic training\" pipeline. The technical report details a synthesis pipeline that produced 800,000 verifiable coding tasks. These were not mere snippets; they were real-world bug-fixing scenarios mined from GitHub pull requests and paired with fully executable environments.The training infrastructure, known as MegaFlow, is a cloud-native orchestration system based on Alibaba Cloud Kubernetes. In MegaFlow, each agentic task is expressed as a three-stage workflow: agent rollout, evaluation, and post-processing. During rollout, the model interacts with a live containerized environment. If it generates code that fails a unit test or crashes a container, it receives immediate feedback through mid-training and reinforcement learning. This \"closed-loop\" education allows the model to learn from environment feedback, teaching it to recover from faults and refine solutions in real-time.Product specifications include:Support for 370 Programming Languages: An expansion from 92 in previous versions.XML-Style Tool Calling: A new qwen3_coder format designed for string-heavy arguments, allowing the model to emit long code snippets without the nested quoting and escaping overhead typical of JSON.Repository-Level Focus: Mid-training was expanded to approximately 600B tokens of repository-level data, proving more impactful for cross-file dependency logic than file-level datasets alone.Specialization via expert modelsA key differentiator in the Qwen3-Coder-Next pipeline is its use of specialized Expert Models. Rather than training one generalist model for all tasks, the team developed domain-specific experts for Web Development and User Experience (UX).The Web Development Expert targets full-stack tasks like UI construction and component composition. All code samples were rendered in a Playwright-controlled Chromium environment. For React samples, a Vite server was deployed to ensure all dependencies were correctly initialized. A Vision-Language Model (VLM) then judged the rendered pages for layout integrity and UI quality.The User Experience Expert was optimized for tool-call format adherence across diverse CLI/IDE scaffolds such as Cline and OpenCode. The team found that training on diverse tool chat templates significantly improved the model&#x27;s robustness to unseen schemas at deployment time. Once these experts achieved peak performance, their capabilities were distilled back into the single 80B/3B MoE model. This ensures the lightweight deployment version retains the nuanced knowledge of much larger teacher models.Punching up on benchmarks while offering high securityThe results of this specialized training are evident in the model&#x27;s competitive standing against industry giants. In benchmark evaluations conducted using the SWE-Agent scaffold, Qwen3-Coder-Next demonstrated exceptional efficiency relative to its active parameter count. On SWE-Bench Verified, the model achieved a score of 70.6%. This performance is notably competitive when placed alongside significantly larger models; it outpaces DeepSeek-V3.2, which scores 70.2%, and trails only slightly behind the 74.2% score of GLM-4.7.Crucially, the model demonstrates robust inherent security awareness. On SecCodeBench, which evaluates a model&#x27;s ability to repair vulnerabilities, Qwen3-Coder-Next outperformed Claude-Opus-4.5 in code generation scenarios (61.2% vs. 52.5%). Notably, it maintained high scores even when provided with no security hints, indicating it has learned to anticipate common security pitfalls during its 800k-task agentic training phase. In multilingual multilingual security evaluations, the model also demonstrated a competitive balance between functional and secure code generation, outperforming both DeepSeek-V3.2 and GLM-4.7 on the CWEval benchmark with a func-sec@1 score of 56.32%.Challenging the proprietary giantsThe release represents the most significant challenge to the dominance of closed-source coding models in 2026. By proving that a model with only 3B active parameters can navigate the complexities of real-world software engineering as effectively as a \"giant,\" Alibaba has effectively democratized agentic coding.The \"aha!\" moment for the industry is the realization that context length and throughput are the two most important levers for agentic success. A model that can process 262k tokens of a repository in seconds and verify its own work in a Docker container is fundamentally more useful than a larger model that is too slow or expensive to iterate. As the Qwen team concludes in their report: \"Scaling agentic training, rather than model size alone, is a key driver for advancing real-world coding agent capability\". With Qwen3-Coder-Next, the era of the \"mammoth\" coding model may be coming to an end, replaced by ultra-fast, sparse experts that can think as deeply as they can run.",
          "content": "Chinese e-commerce giant Alibaba&#x27;s Qwen team of AI researchers has emerged in the last year as one of the global leaders of open source AI development, releasing a host of powerful large language models and specialized multimodal models that approach, and in some cases, surpass the performance of the proprietary U.S. leaders such as OpenAI, Anthropic, Google and xAI.Now the Qwen team is back again this week with a compelling release that matches the \"vibe coding\" frenzy that has arisen in recent months: Qwen3-Coder-Next, a specialized 80-billion-parameter model designed to deliver elite agentic performance within a lightweight active footprint. It&#x27;s been released on a permissive Apache 2.0 license, enabling commercial usage by large enterprises and indie developers alike, with the model weights available on Hugging Face in four variants and a technical report describing some of its training approach and innovations. The release marks a major escalation in the global arms race for the ultimate coding assistant, following a week that has seen the space explode with new entrants. From the massive efficiency gains of Anthropic’s Claude Code harness to the high-profile launch of the OpenAI Codex app and the rapid community adoption of open-source frameworks like OpenClaw, the competitive landscape has never been more crowded. In this high-stakes environment, Alibaba isn&#x27;t just keeping pace — it is attempting to set a new standard for open-weight intelligence.For LLM decision-makers, Qwen3-Coder-Next represents a fundamental shift in the economics of AI engineering. While the model houses 80 billion total parameters, it utilizes an ultra-sparse Mixture-of-Experts (MoE) architecture that activates only 3 billion parameters per forward pass. This design allows it to deliver reasoning capabilities that rival massive proprietary systems while maintaining the low deployment costs and high throughput of a lightweight local model.Solving the long-context bottleneckThe core technical breakthrough behind Qwen3-Coder-Next is a hybrid architecture designed specifically to circumvent the quadratic scaling issues that plague traditional Transformers. As context windows expand — and this model supports a massive 262,144 tokens — traditional attention mechanisms become computationally prohibitive. Standard Transformers suffer from a \"memory wall\" where the cost of processing context grows quadratically with sequence length. Qwen addresses this by combining Gated DeltaNet with Gated Attention.Gated DeltaNet acts as a linear-complexity alternative to standard softmax attention. It allows the model to maintain state across its quarter-million-token window without the exponential latency penalties typical of long-horizon reasoning. When paired with the ultra-sparse MoE, the result is a theoretical 10x higher throughput for repository-level tasks compared to dense models of similar total capacity. This architecture ensures an agent can \"read\" an entire Python library or complex JavaScript framework and respond with the speed of a 3B model, yet with the structural understanding of an 80B system. To prevent context hallucination during training, the team utilized Best-Fit Packing (BFP), a strategy that maintains efficiency without the truncation errors found in traditional document concatenation.Trained to be agent-firstThe \"Next\" in the model&#x27;s nomenclature refers to a fundamental pivot in training methodology. Historically, coding models were trained on static code-text pairs—essentially a \"read-only\" education. Qwen3-Coder-Next was instead developed through a massive \"agentic training\" pipeline. The technical report details a synthesis pipeline that produced 800,000 verifiable coding tasks. These were not mere snippets; they were real-world bug-fixing scenarios mined from GitHub pull requests and paired with fully executable environments.The training infrastructure, known as MegaFlow, is a cloud-native orchestration system based on Alibaba Cloud Kubernetes. In MegaFlow, each agentic task is expressed as a three-stage workflow: agent rollout, evaluation, and post-processing. During rollout, the model interacts with a live containerized environment. If it generates code that fails a unit test or crashes a container, it receives immediate feedback through mid-training and reinforcement learning. This \"closed-loop\" education allows the model to learn from environment feedback, teaching it to recover from faults and refine solutions in real-time.Product specifications include:Support for 370 Programming Languages: An expansion from 92 in previous versions.XML-Style Tool Calling: A new qwen3_coder format designed for string-heavy arguments, allowing the model to emit long code snippets without the nested quoting and escaping overhead typical of JSON.Repository-Level Focus: Mid-training was expanded to approximately 600B tokens of repository-level data, proving more impactful for cross-file dependency logic than file-level datasets alone.Specialization via expert modelsA key differentiator in the Qwen3-Coder-Next pipeline is its use of specialized Expert Models. Rather than training one generalist model for all tasks, the team developed domain-specific experts for Web Development and User Experience (UX).The Web Development Expert targets full-stack tasks like UI construction and component composition. All code samples were rendered in a Playwright-controlled Chromium environment. For React samples, a Vite server was deployed to ensure all dependencies were correctly initialized. A Vision-Language Model (VLM) then judged the rendered pages for layout integrity and UI quality.The User Experience Expert was optimized for tool-call format adherence across diverse CLI/IDE scaffolds such as Cline and OpenCode. The team found that training on diverse tool chat templates significantly improved the model&#x27;s robustness to unseen schemas at deployment time. Once these experts achieved peak performance, their capabilities were distilled back into the single 80B/3B MoE model. This ensures the lightweight deployment version retains the nuanced knowledge of much larger teacher models.Punching up on benchmarks while offering high securityThe results of this specialized training are evident in the model&#x27;s competitive standing against industry giants. In benchmark evaluations conducted using the SWE-Agent scaffold, Qwen3-Coder-Next demonstrated exceptional efficiency relative to its active parameter count. On SWE-Bench Verified, the model achieved a score of 70.6%. This performance is notably competitive when placed alongside significantly larger models; it outpaces DeepSeek-V3.2, which scores 70.2%, and trails only slightly behind the 74.2% score of GLM-4.7.Crucially, the model demonstrates robust inherent security awareness. On SecCodeBench, which evaluates a model&#x27;s ability to repair vulnerabilities, Qwen3-Coder-Next outperformed Claude-Opus-4.5 in code generation scenarios (61.2% vs. 52.5%). Notably, it maintained high scores even when provided with no security hints, indicating it has learned to anticipate common security pitfalls during its 800k-task agentic training phase. In multilingual multilingual security evaluations, the model also demonstrated a competitive balance between functional and secure code generation, outperforming both DeepSeek-V3.2 and GLM-4.7 on the CWEval benchmark with a func-sec@1 score of 56.32%.Challenging the proprietary giantsThe release represents the most significant challenge to the dominance of closed-source coding models in 2026. By proving that a model with only 3B active parameters can navigate the complexities of real-world software engineering as effectively as a \"giant,\" Alibaba has effectively democratized agentic coding.The \"aha!\" moment for the industry is the realization that context length and throughput are the two most important levers for agentic success. A model that can process 262k tokens of a repository in seconds and verify its own work in a Docker container is fundamentally more useful than a larger model that is too slow or expensive to iterate. As the Qwen team concludes in their report: \"Scaling agentic training, rather than model size alone, is a key driver for advancing real-world coding agent capability\". With Qwen3-Coder-Next, the era of the \"mammoth\" coding model may be coming to an end, replaced by ultra-fast, sparse experts that can think as deeply as they can run.",
          "feed_position": 0,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/7ErEzHma6LbYLaznwE3rtA/39944c4739dbecaa3f8a336826de352d/sVJFWPtv0RFGdOIc_fKWG_C0uLbr6A__1_.png?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/technology/apple-integrates-anthropics-claude-and-openais-codex-into-xcode-26-3-in-push",
          "published_at": "Tue, 03 Feb 2026 20:45:00 GMT",
          "title": "Apple integrates Anthropic’s Claude and OpenAI’s Codex into Xcode 26.3 in push for ‘agentic coding’",
          "standfirst": "Apple on Tuesday announced a major update to its flagship developer tool that gives artificial intelligence agents unprecedented control over the app-building process, a move that signals the iPhone maker&#x27;s aggressive push into an emerging and controversial practice known as \"agentic coding.\"Xcode 26.3, available immediately as a release candidate, integrates Anthropic&#x27;s Claude Agent and OpenAI&#x27;s Codex directly into Apple&#x27;s development environment, allowing the AI systems to autonomously write code, build projects, run tests, and visually verify their own work — all with minimal human oversight.The update is Apple&#x27;s most significant embrace of AI-assisted software development since introducing intelligence features in Xcode 26 last year, and arrives as \"vibe coding\" — the practice of delegating software creation to large language models — has become one of the most debated topics in technology.\"Integrating intelligence into the Xcode developer workflow is powerful, but the model itself still has a somewhat limited aperture,\" Tim Sneath, an Apple executive, said during a press conference Tuesday morning. \"It answers questions based on what the developer provides, but it doesn&#x27;t have access to the full context of the project, and it&#x27;s not able today to take action on its own. And so that changes today.\"How Apple&#x27;s new AI coding features let developers build apps faster than everThe key innovation in Xcode 26.3 is the depth of integration between AI agents and Apple&#x27;s development tools. Unlike previous iterations that offered code suggestions and autocomplete features, the new system grants AI agents access to nearly every aspect of the development process.During a live demonstration, Jerome Bouvard, an Apple engineer, showed how the Claude agent could receive a simple prompt — \"add a new feature to show the weather at a landmark\" — and then independently analyze the project&#x27;s file structure, consult Apple&#x27;s documentation, write the necessary code, build the project, and take screenshots of the running application to verify its work matched the requested design.\"The agent is able to use the tools like build or, you know, grabbing a preview of the screenshots to verify its work, visually analyze the image and confirm that everything has been built accordingly,\" Bouvard explained. \"Before that, when you&#x27;re interacting with a model, the model will provide you an answer and it will just stop there.\"The system creates automatic checkpoints as developers interact with the AI, allowing them to roll back changes if results prove unsatisfactory — a safeguard that acknowledges the unpredictable nature of AI-generated code.Apple worked directly with Anthropic and OpenAI to optimize the experience, Sneath said, with particular attention paid to reducing token usage — the computational units that determine costs when using cloud-based AI models — and improving the efficiency of tool calling.\"Developers can download new agents with a single click, and they update automatically,\" Sneath noted.Why Apple&#x27;s adoption of the Model Context Protocol could reshape the AI development landscapeUnderlying the integration is the Model Context Protocol, or MCP, an open standard that Anthropic developed for connecting AI agents with external tools. Apple&#x27;s adoption of MCP means that any compatible agent — not just Claude or Codex — can now interact with Xcode&#x27;s capabilities.\"This also works for agents that are running outside of Xcode,\" Sneath explained. \"Any agent that is compatible with MCP can now work with Xcode to do all the same things—Project Discovery and change management, building and testing apps, working with previews and code snippets, and accessing the latest documentation.\"The decision to embrace an open protocol, rather than building a proprietary system, represents a notable departure for Apple, which has historically favored closed ecosystems. It also positions Xcode as a potential hub for a growing universe of AI development tools.Xcode&#x27;s troubled history with AI tools — and why Apple says this time is differentThe announcement comes against a backdrop of mixed experiences with AI-assisted coding in Apple&#x27;s tools. During the press conference, one developer described previous attempts to use AI agents with Xcode as \"horrible,\" citing constant crashes and an inability to complete basic tasks.Sneath acknowledged the concerns while arguing that the new integration addresses fundamental limitations of earlier approaches.\"The big shift here is that Claude and Codex have so much more visibility into the breadth of the project,\" he said. \"If they hallucinate and write code that doesn&#x27;t work, they can now build. They can see the compile errors, and they can iterate in real time to fix those issues, and we&#x27;ll do so in this case before you even, you know, presented it as a finished work.\"The power of IDE integration, Sneath argued, extends beyond error correction. Agents can now automatically add entitlements to projects when needed to access protected APIs — a task that would be \"otherwise very difficult to do\" for an AI operating outside the development environment and \"dealing with binary file that it may not have the file format for.\"From Andrej Karpathy&#x27;s tweet to LinkedIn certifications: The unstoppable rise of vibe codingApple&#x27;s announcement arrives at a crucial moment in the evolution of AI-assisted development. The term \"vibe coding,\" coined by AI researcher Andrej Karpathy in early 2025, has transformed from a curiosity into a genuine cultural phenomenon that is reshaping how software gets built.LinkedIn announced last week that it will begin offering official certifications in AI coding skills, drawing on usage data from platforms like Lovable and Replit. Job postings requiring AI proficiency doubled in the past year, according to edX research, with Indeed&#x27;s Hiring Lab reporting that 4.2% of U.S. job listings now mention AI-related keywords.The enthusiasm is driven by genuine productivity gains. Casey Newton, the technology journalist, recently described building a complete personal website using Claude Code in about an hour — a task that previously required expensive Squarespace subscriptions and years of frustrated attempts with various website builders.More dramatically, Jaana Dogan, a principal engineer at Google, posted that she gave Claude Code \"a description of the problem\" and \"it generated what we built last year in an hour.\" Her post, which accumulated more than 8 million views, began with the disclaimer: \"I&#x27;m not joking and this isn&#x27;t funny.\"Security experts warn that AI-generated code could lead to &#x27;catastrophic explosions&#x27;But the rapid adoption of agentic coding has also sparked significant concerns among security researchers and software engineers.David Mytton, founder and CEO of developer security provider Arcjet, warned last month that the proliferation of vibe-coded applications \"into production will lead to catastrophic problems for organizations that don&#x27;t properly review AI-developed software.\"\"In 2026, I expect more and more vibe-coded applications hitting production in a big way,\" Mytton wrote. \"That&#x27;s going to be great for velocity… but you&#x27;ve still got to pay attention. There&#x27;s going to be some big explosions coming!\"Simon Willison, co-creator of the Django web framework, drew an even starker comparison. \"I think we&#x27;re due a Challenger disaster with respect to coding agent security,\" he said, referring to the 1986 space shuttle explosion that killed all seven crew members. \"So many people, myself included, are running these coding agents practically as root. We&#x27;re letting them do all of this stuff.\"A pre-print paper from researchers this week warned that vibe coding could pose existential risks to the open-source software ecosystem. The study found that AI-assisted development pulls user interaction away from community projects, reduces visits to documentation websites and forums, and makes launching new open-source initiatives significantly harder.Stack Overflow usage has plummeted as developers increasingly turn to AI chatbots for answers—a shift that could ultimately starve the very knowledge bases that trained the AI models in the first place.Previous research painted an even more troubling picture: a 2024 report found that vibe coding using tools like GitHub Copilot \"offered no real benefits unless adding 41% more bugs is a measure of success.\"The hidden mental health cost of letting AI write your codeEven enthusiastic adopters have begun acknowledging the darker aspects of AI-assisted development.Peter Steinberger, creator of the viral AI agent originally known as Clawdbot (now OpenClaw), recently revealed that he had to step back from vibe coding after it consumed his life.\"I was out with my friends and instead of joining the conversation in the restaurant, I was just like, vibe coding on my phone,\" Steinberger said in a recent podcast interview. \"I decided, OK, I have to stop this more for my mental health than for anything else.\"Steinberger warned that the constant building of increasingly powerful AI tools creates the \"illusion of making you more productive\" without necessarily advancing real goals. \"If you don&#x27;t have a vision of what you&#x27;re going to build, it&#x27;s still going to be slop,\" he added.Google CEO Sundar Pichai has expressed similar reservations, saying he won&#x27;t vibe code on \"large codebases where you really have to get it right.\"\"The security has to be there,\" Pichai said in a November podcast interview.Boris Cherny, the Anthropic engineer who created Claude Code, acknowledged that vibe coding works best for \"prototypes or throwaway code, not software that sits at the core of a business.\"\"You want maintainable code sometimes. You want to be very thoughtful about every line sometimes,\" Cherny said.Apple is gambling that deep IDE integration can make AI coding safe for productionApple appears to be betting that the benefits of deep IDE integration can mitigate many of these concerns. By giving AI agents access to build systems, test suites, and visual verification tools, the company is essentially arguing that Xcode can serve as a quality control mechanism for AI-generated code.Susan Prescott, Apple&#x27;s vice president of Worldwide Developer Relations, framed the update as part of Apple&#x27;s broader mission.\"At Apple, our goal is to make tools that put industry-leading technologies directly in developers&#x27; hands so they can build the very best apps,\" Prescott said in a statement. \"Agentic coding supercharges productivity and creativity, streamlining the development workflow so developers can focus on innovation.\"But the question remains whether the safeguards will prove sufficient as AI agents grow more autonomous. Asked about debugging capabilities, Bouvard noted that while Xcode has \"a very powerful debugger built in,\" there is \"no direct MCP tool for debugging.\"Developers can run the debugger and manually relay information to the agent, but the AI cannot yet independently investigate runtime issues — a limitation that could prove significant as the complexity of AI-generated code increases.The update also does not currently support running multiple agents simultaneously on the same project, though Sneath noted that developers can open projects in multiple Xcode windows using Git worktrees as a workaround.The future of software development hangs in the balance — and Apple just raised the stakesXcode 26.3 is available immediately as a release candidate for members of the Apple Developer Program, with a general release expected soon on the App Store. The release candidate designation — Apple&#x27;s final beta before production — means developers who download today will automatically receive the finished version when it ships.The integration supports both API keys and direct account credentials from OpenAI and Anthropic, offering developers flexibility in managing their AI subscriptions. But those conveniences belie the magnitude of what Apple is attempting: nothing less than a fundamental reimagining of how software comes into existence.For the world&#x27;s most valuable company, the calculus is straightforward. Apple&#x27;s ability to attract and retain developers has always underpinned its platform dominance. If agentic coding delivers on its promise of radical productivity gains, early and deep integration could cement Apple&#x27;s position for another generation. If it doesn&#x27;t — if the security disasters and \"catastrophic explosions\" that critics predict come to pass — Cupertino could find itself at the epicenter of a very different kind of transformation.The technology industry has spent decades building systems to catch human errors before they reach users. Now it must answer a more unsettling question: What happens when the errors aren&#x27;t human at all?As Sneath conceded during Tuesday&#x27;s press conference, with what may prove to be unintentional understatement: \"Large language models, as agents sometimes do, sometimes hallucinate.\"Millions of lines of code are about to find out how often.",
          "content": "Apple on Tuesday announced a major update to its flagship developer tool that gives artificial intelligence agents unprecedented control over the app-building process, a move that signals the iPhone maker&#x27;s aggressive push into an emerging and controversial practice known as \"agentic coding.\"Xcode 26.3, available immediately as a release candidate, integrates Anthropic&#x27;s Claude Agent and OpenAI&#x27;s Codex directly into Apple&#x27;s development environment, allowing the AI systems to autonomously write code, build projects, run tests, and visually verify their own work — all with minimal human oversight.The update is Apple&#x27;s most significant embrace of AI-assisted software development since introducing intelligence features in Xcode 26 last year, and arrives as \"vibe coding\" — the practice of delegating software creation to large language models — has become one of the most debated topics in technology.\"Integrating intelligence into the Xcode developer workflow is powerful, but the model itself still has a somewhat limited aperture,\" Tim Sneath, an Apple executive, said during a press conference Tuesday morning. \"It answers questions based on what the developer provides, but it doesn&#x27;t have access to the full context of the project, and it&#x27;s not able today to take action on its own. And so that changes today.\"How Apple&#x27;s new AI coding features let developers build apps faster than everThe key innovation in Xcode 26.3 is the depth of integration between AI agents and Apple&#x27;s development tools. Unlike previous iterations that offered code suggestions and autocomplete features, the new system grants AI agents access to nearly every aspect of the development process.During a live demonstration, Jerome Bouvard, an Apple engineer, showed how the Claude agent could receive a simple prompt — \"add a new feature to show the weather at a landmark\" — and then independently analyze the project&#x27;s file structure, consult Apple&#x27;s documentation, write the necessary code, build the project, and take screenshots of the running application to verify its work matched the requested design.\"The agent is able to use the tools like build or, you know, grabbing a preview of the screenshots to verify its work, visually analyze the image and confirm that everything has been built accordingly,\" Bouvard explained. \"Before that, when you&#x27;re interacting with a model, the model will provide you an answer and it will just stop there.\"The system creates automatic checkpoints as developers interact with the AI, allowing them to roll back changes if results prove unsatisfactory — a safeguard that acknowledges the unpredictable nature of AI-generated code.Apple worked directly with Anthropic and OpenAI to optimize the experience, Sneath said, with particular attention paid to reducing token usage — the computational units that determine costs when using cloud-based AI models — and improving the efficiency of tool calling.\"Developers can download new agents with a single click, and they update automatically,\" Sneath noted.Why Apple&#x27;s adoption of the Model Context Protocol could reshape the AI development landscapeUnderlying the integration is the Model Context Protocol, or MCP, an open standard that Anthropic developed for connecting AI agents with external tools. Apple&#x27;s adoption of MCP means that any compatible agent — not just Claude or Codex — can now interact with Xcode&#x27;s capabilities.\"This also works for agents that are running outside of Xcode,\" Sneath explained. \"Any agent that is compatible with MCP can now work with Xcode to do all the same things—Project Discovery and change management, building and testing apps, working with previews and code snippets, and accessing the latest documentation.\"The decision to embrace an open protocol, rather than building a proprietary system, represents a notable departure for Apple, which has historically favored closed ecosystems. It also positions Xcode as a potential hub for a growing universe of AI development tools.Xcode&#x27;s troubled history with AI tools — and why Apple says this time is differentThe announcement comes against a backdrop of mixed experiences with AI-assisted coding in Apple&#x27;s tools. During the press conference, one developer described previous attempts to use AI agents with Xcode as \"horrible,\" citing constant crashes and an inability to complete basic tasks.Sneath acknowledged the concerns while arguing that the new integration addresses fundamental limitations of earlier approaches.\"The big shift here is that Claude and Codex have so much more visibility into the breadth of the project,\" he said. \"If they hallucinate and write code that doesn&#x27;t work, they can now build. They can see the compile errors, and they can iterate in real time to fix those issues, and we&#x27;ll do so in this case before you even, you know, presented it as a finished work.\"The power of IDE integration, Sneath argued, extends beyond error correction. Agents can now automatically add entitlements to projects when needed to access protected APIs — a task that would be \"otherwise very difficult to do\" for an AI operating outside the development environment and \"dealing with binary file that it may not have the file format for.\"From Andrej Karpathy&#x27;s tweet to LinkedIn certifications: The unstoppable rise of vibe codingApple&#x27;s announcement arrives at a crucial moment in the evolution of AI-assisted development. The term \"vibe coding,\" coined by AI researcher Andrej Karpathy in early 2025, has transformed from a curiosity into a genuine cultural phenomenon that is reshaping how software gets built.LinkedIn announced last week that it will begin offering official certifications in AI coding skills, drawing on usage data from platforms like Lovable and Replit. Job postings requiring AI proficiency doubled in the past year, according to edX research, with Indeed&#x27;s Hiring Lab reporting that 4.2% of U.S. job listings now mention AI-related keywords.The enthusiasm is driven by genuine productivity gains. Casey Newton, the technology journalist, recently described building a complete personal website using Claude Code in about an hour — a task that previously required expensive Squarespace subscriptions and years of frustrated attempts with various website builders.More dramatically, Jaana Dogan, a principal engineer at Google, posted that she gave Claude Code \"a description of the problem\" and \"it generated what we built last year in an hour.\" Her post, which accumulated more than 8 million views, began with the disclaimer: \"I&#x27;m not joking and this isn&#x27;t funny.\"Security experts warn that AI-generated code could lead to &#x27;catastrophic explosions&#x27;But the rapid adoption of agentic coding has also sparked significant concerns among security researchers and software engineers.David Mytton, founder and CEO of developer security provider Arcjet, warned last month that the proliferation of vibe-coded applications \"into production will lead to catastrophic problems for organizations that don&#x27;t properly review AI-developed software.\"\"In 2026, I expect more and more vibe-coded applications hitting production in a big way,\" Mytton wrote. \"That&#x27;s going to be great for velocity… but you&#x27;ve still got to pay attention. There&#x27;s going to be some big explosions coming!\"Simon Willison, co-creator of the Django web framework, drew an even starker comparison. \"I think we&#x27;re due a Challenger disaster with respect to coding agent security,\" he said, referring to the 1986 space shuttle explosion that killed all seven crew members. \"So many people, myself included, are running these coding agents practically as root. We&#x27;re letting them do all of this stuff.\"A pre-print paper from researchers this week warned that vibe coding could pose existential risks to the open-source software ecosystem. The study found that AI-assisted development pulls user interaction away from community projects, reduces visits to documentation websites and forums, and makes launching new open-source initiatives significantly harder.Stack Overflow usage has plummeted as developers increasingly turn to AI chatbots for answers—a shift that could ultimately starve the very knowledge bases that trained the AI models in the first place.Previous research painted an even more troubling picture: a 2024 report found that vibe coding using tools like GitHub Copilot \"offered no real benefits unless adding 41% more bugs is a measure of success.\"The hidden mental health cost of letting AI write your codeEven enthusiastic adopters have begun acknowledging the darker aspects of AI-assisted development.Peter Steinberger, creator of the viral AI agent originally known as Clawdbot (now OpenClaw), recently revealed that he had to step back from vibe coding after it consumed his life.\"I was out with my friends and instead of joining the conversation in the restaurant, I was just like, vibe coding on my phone,\" Steinberger said in a recent podcast interview. \"I decided, OK, I have to stop this more for my mental health than for anything else.\"Steinberger warned that the constant building of increasingly powerful AI tools creates the \"illusion of making you more productive\" without necessarily advancing real goals. \"If you don&#x27;t have a vision of what you&#x27;re going to build, it&#x27;s still going to be slop,\" he added.Google CEO Sundar Pichai has expressed similar reservations, saying he won&#x27;t vibe code on \"large codebases where you really have to get it right.\"\"The security has to be there,\" Pichai said in a November podcast interview.Boris Cherny, the Anthropic engineer who created Claude Code, acknowledged that vibe coding works best for \"prototypes or throwaway code, not software that sits at the core of a business.\"\"You want maintainable code sometimes. You want to be very thoughtful about every line sometimes,\" Cherny said.Apple is gambling that deep IDE integration can make AI coding safe for productionApple appears to be betting that the benefits of deep IDE integration can mitigate many of these concerns. By giving AI agents access to build systems, test suites, and visual verification tools, the company is essentially arguing that Xcode can serve as a quality control mechanism for AI-generated code.Susan Prescott, Apple&#x27;s vice president of Worldwide Developer Relations, framed the update as part of Apple&#x27;s broader mission.\"At Apple, our goal is to make tools that put industry-leading technologies directly in developers&#x27; hands so they can build the very best apps,\" Prescott said in a statement. \"Agentic coding supercharges productivity and creativity, streamlining the development workflow so developers can focus on innovation.\"But the question remains whether the safeguards will prove sufficient as AI agents grow more autonomous. Asked about debugging capabilities, Bouvard noted that while Xcode has \"a very powerful debugger built in,\" there is \"no direct MCP tool for debugging.\"Developers can run the debugger and manually relay information to the agent, but the AI cannot yet independently investigate runtime issues — a limitation that could prove significant as the complexity of AI-generated code increases.The update also does not currently support running multiple agents simultaneously on the same project, though Sneath noted that developers can open projects in multiple Xcode windows using Git worktrees as a workaround.The future of software development hangs in the balance — and Apple just raised the stakesXcode 26.3 is available immediately as a release candidate for members of the Apple Developer Program, with a general release expected soon on the App Store. The release candidate designation — Apple&#x27;s final beta before production — means developers who download today will automatically receive the finished version when it ships.The integration supports both API keys and direct account credentials from OpenAI and Anthropic, offering developers flexibility in managing their AI subscriptions. But those conveniences belie the magnitude of what Apple is attempting: nothing less than a fundamental reimagining of how software comes into existence.For the world&#x27;s most valuable company, the calculus is straightforward. Apple&#x27;s ability to attract and retain developers has always underpinned its platform dominance. If agentic coding delivers on its promise of radical productivity gains, early and deep integration could cement Apple&#x27;s position for another generation. If it doesn&#x27;t — if the security disasters and \"catastrophic explosions\" that critics predict come to pass — Cupertino could find itself at the epicenter of a very different kind of transformation.The technology industry has spent decades building systems to catch human errors before they reach users. Now it must answer a more unsettling question: What happens when the errors aren&#x27;t human at all?As Sneath conceded during Tuesday&#x27;s press conference, with what may prove to be unintentional understatement: \"Large language models, as agents sometimes do, sometimes hallucinate.\"Millions of lines of code are about to find out how often.",
          "feed_position": 1,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/2Q8OGhbv336AGtWlkPE9wO/51480cf6096208fab81a5f6c184a9a20/nuneybits_Vector_art_of_Apple_logo_inside_code_brackets_63cd7c00-dd68-44a7-b323-831a5a2226c0.webp?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/apple-just-made-xcode-better-for-vibe-coding-195653049.html",
          "published_at": "Tue, 03 Feb 2026 19:56:53 +0000",
          "title": "Apple just made Xcode better for vibe coding",
          "standfirst": "Apple has just released Xcode 26.3, and it's a big step forward in terms of the company's support of coding agents. The new release expands on the AI features the company introduced with Xcode 26 at WWDC 2025 to give systems like Claude and ChatGPT more robust access to its in-house IDE. With the update, Apple says Claude and OpenAI's Codex \"can search documentation, explore file structures, update project settings, and verify their work visually by capturing Xcode Previews and iterating through builds and fixes.\" This is in contrast to earlier releases of Xcode 26 where those same agents were limited in what they could see of a developer's Xcode environment, restricting their utility. According to Apple, the change will give users tools they can use to streamline their processes and work more efficiently than before. Developers can add Claude and Codex to their Xcode terminal from the Intelligence section of the app's setting menu. Once a provider is selected, the interface allows users to also pick their preferred model. So if you like the outputs of say GPT 5.1 over GPT 5.2, you can use the older system. The tighter integration with Claude and Codex was made possible by Model Context Protocol (MCP) servers Apple has deployed. MCP is a technology Anthropic debuted in fall 2024 to make it easier for large language models like Claude to share data with third-party tools and systems. Since its introduction, MCP has become an industry standard — with OpenAI, for instance, adopting the protocol last year to facilitate its own set of connections. Apple says it worked directly with Anthropic and OpenAI to optimize token usage through Xcode, but the company’s adoption of MCP means developers will be able to add any coding agent that supports the protocol to their terminal in the future. Xcode 26.3 is available to download for all members of the Apple Developer Program starting today, with the Mac Store availability “coming soon.” This article originally appeared on Engadget at https://www.engadget.com/ai/apple-just-made-xcode-better-for-vibe-coding-195653049.html?src=rss",
          "content": "Apple has just released Xcode 26.3, and it's a big step forward in terms of the company's support of coding agents. The new release expands on the AI features the company introduced with Xcode 26 at WWDC 2025 to give systems like Claude and ChatGPT more robust access to its in-house IDE. With the update, Apple says Claude and OpenAI's Codex \"can search documentation, explore file structures, update project settings, and verify their work visually by capturing Xcode Previews and iterating through builds and fixes.\" This is in contrast to earlier releases of Xcode 26 where those same agents were limited in what they could see of a developer's Xcode environment, restricting their utility. According to Apple, the change will give users tools they can use to streamline their processes and work more efficiently than before. Developers can add Claude and Codex to their Xcode terminal from the Intelligence section of the app's setting menu. Once a provider is selected, the interface allows users to also pick their preferred model. So if you like the outputs of say GPT 5.1 over GPT 5.2, you can use the older system. The tighter integration with Claude and Codex was made possible by Model Context Protocol (MCP) servers Apple has deployed. MCP is a technology Anthropic debuted in fall 2024 to make it easier for large language models like Claude to share data with third-party tools and systems. Since its introduction, MCP has become an industry standard — with OpenAI, for instance, adopting the protocol last year to facilitate its own set of connections. Apple says it worked directly with Anthropic and OpenAI to optimize token usage through Xcode, but the company’s adoption of MCP means developers will be able to add any coding agent that supports the protocol to their terminal in the future. Xcode 26.3 is available to download for all members of the Apple Developer Program starting today, with the Mac Store availability “coming soon.” This article originally appeared on Engadget at https://www.engadget.com/ai/apple-just-made-xcode-better-for-vibe-coding-195653049.html?src=rss",
          "feed_position": 3
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/fitbit-founders-launch-luffu-a-way-to-integrate-your-familys-health-data-173251994.html",
          "published_at": "Tue, 03 Feb 2026 18:14:45 +0000",
          "title": "Fitbit founders launch Luffu, a way to integrate your family's health data",
          "standfirst": "Fitbit's founders have a new startup. Two years after leaving Google, James Park and Eric Friedman announced a new platform that shifts the focus from the individual to the family. They say the Luffu mobile app \"uses AI quietly in the background\" to collect and organize family health information.\"At Fitbit, we focused on personal health — but after Fitbit, health for me became bigger than just thinking about myself,\" Park said in a press release. The app is particularly focused on the \"CEO of the family\" — the person who manages appointments, prescriptions and other health-related tasks.But the definition of family isn't limited to parents raising children. The company sees its tool as especially valuable for caregivers in their 40s and 50s who may be managing the needs of both aging parents and kids. It even tracks pets' health habits.\"We're managing care across three generations — kids at home, busy parents in the middle, and my dad in his 80s who's living with diabetes and still wants to stay fiercely independent,\" Friedman wrote. \"And the moments that matter most are often the most chaotic: a late-night fever, a sudden urgent care visit, a doctor asking questions you can't answer quickly because the details are scattered.\"The app's AI includes a Morning Brief that recaps everyone's health.LuffuThe company claims the app's AI \"isn't a chatbot layer.\" Rather, it serves as a \"guardian\" — proactively monitoring for changes silently in the background. The AI then provides insights and triggers alerts when something is out of whack. You can also ask the app health data questions using plain language (so, there is some kind of chatbot) and share data with family members.The company clearly wants to make entering data as easy as possible. Luffu allows family members to log info using voice, text or photos. It integrates with health platforms such as Apple Health and Fitbit. And the company eventually wants to expand into a hardware ecosystem — presumably, devices that make health data collection even easier.Speaking of data collection, Luffu says, \"Users are always in control of exactly what is shared, with whom, and privacy and security are paramount for all family data.\" In addition, the company told Axios that users can choose whether their data is used to train its AI. On the other hand, Big Tech has repeatedly shown that its most egregious data-collection practices are always wrapped in comforting language. So, at the very least, I'd take their pitch with grains of salt and, most importantly, make sure each family member knows exactly what they're consenting to. After all, this is a for-profit company, and we don’t yet know its monetization strategy.Luffu is currently taking waitlist sign-ups for a forthcoming limited public beta. You can learn more and sign up for the waitlist on the company website.Update, February 3, 2026, 1:14PM ET: This story has been updated to note that the Luffu public beta hasn’t started yet, but you can sign up for a waitlist to eventually get access when it starts.This article originally appeared on Engadget at https://www.engadget.com/mobile/fitbit-founders-launch-luffu-a-way-to-integrate-your-familys-health-data-173251994.html?src=rss",
          "content": "Fitbit's founders have a new startup. Two years after leaving Google, James Park and Eric Friedman announced a new platform that shifts the focus from the individual to the family. They say the Luffu mobile app \"uses AI quietly in the background\" to collect and organize family health information.\"At Fitbit, we focused on personal health — but after Fitbit, health for me became bigger than just thinking about myself,\" Park said in a press release. The app is particularly focused on the \"CEO of the family\" — the person who manages appointments, prescriptions and other health-related tasks.But the definition of family isn't limited to parents raising children. The company sees its tool as especially valuable for caregivers in their 40s and 50s who may be managing the needs of both aging parents and kids. It even tracks pets' health habits.\"We're managing care across three generations — kids at home, busy parents in the middle, and my dad in his 80s who's living with diabetes and still wants to stay fiercely independent,\" Friedman wrote. \"And the moments that matter most are often the most chaotic: a late-night fever, a sudden urgent care visit, a doctor asking questions you can't answer quickly because the details are scattered.\"The app's AI includes a Morning Brief that recaps everyone's health.LuffuThe company claims the app's AI \"isn't a chatbot layer.\" Rather, it serves as a \"guardian\" — proactively monitoring for changes silently in the background. The AI then provides insights and triggers alerts when something is out of whack. You can also ask the app health data questions using plain language (so, there is some kind of chatbot) and share data with family members.The company clearly wants to make entering data as easy as possible. Luffu allows family members to log info using voice, text or photos. It integrates with health platforms such as Apple Health and Fitbit. And the company eventually wants to expand into a hardware ecosystem — presumably, devices that make health data collection even easier.Speaking of data collection, Luffu says, \"Users are always in control of exactly what is shared, with whom, and privacy and security are paramount for all family data.\" In addition, the company told Axios that users can choose whether their data is used to train its AI. On the other hand, Big Tech has repeatedly shown that its most egregious data-collection practices are always wrapped in comforting language. So, at the very least, I'd take their pitch with grains of salt and, most importantly, make sure each family member knows exactly what they're consenting to. After all, this is a for-profit company, and we don’t yet know its monetization strategy.Luffu is currently taking waitlist sign-ups for a forthcoming limited public beta. You can learn more and sign up for the waitlist on the company website.Update, February 3, 2026, 1:14PM ET: This story has been updated to note that the Luffu public beta hasn’t started yet, but you can sign up for a waitlist to eventually get access when it starts.This article originally appeared on Engadget at https://www.engadget.com/mobile/fitbit-founders-launch-luffu-a-way-to-integrate-your-familys-health-data-173251994.html?src=rss",
          "feed_position": 5,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/luffu.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/sonys-wh-1000xm6-headphones-are-down-to-a-record-low-price-175038776.html",
          "published_at": "Tue, 03 Feb 2026 17:50:38 +0000",
          "title": "Sony's WH-1000XM6 headphones are down to a record-low price",
          "standfirst": "Sony's wireless WH-1000XM6 headphones are on sale for $398 via Amazon. This is a record-low price, as it drops $62 from the price tag. The sale applies to all three colorways. These easily topped our list of the best wireless headphones. They are, in a word, fantastic. The headphones are packed with premium features, like advanced ANC. There are a whopping 12 ANC microphones throughout and a brand-new chip to power the feature. The end result? It successfully blocks background noise at medium and high frequencies, including the human voice. The sound quality is extremely pleasing to the ears, thanks to new audio drivers and a team of mastering engineers that assisted with tuning. There are perforations in the driver's voice coil, which extends high frequency reproduction. The design has been upgraded from the previous iteration and we found them extremely comfortable to wear for long periods of time, which is important with headphones. The battery gets around 30 hours, which is a fairly standard metric for this type of thing. The only real major nitpick here is the original asking price. It's tough to recommend any pair of headphones for $460, but a bit easier at under $400. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/sonys-wh-1000xm6-headphones-are-down-to-a-record-low-price-175038776.html?src=rss",
          "content": "Sony's wireless WH-1000XM6 headphones are on sale for $398 via Amazon. This is a record-low price, as it drops $62 from the price tag. The sale applies to all three colorways. These easily topped our list of the best wireless headphones. They are, in a word, fantastic. The headphones are packed with premium features, like advanced ANC. There are a whopping 12 ANC microphones throughout and a brand-new chip to power the feature. The end result? It successfully blocks background noise at medium and high frequencies, including the human voice. The sound quality is extremely pleasing to the ears, thanks to new audio drivers and a team of mastering engineers that assisted with tuning. There are perforations in the driver's voice coil, which extends high frequency reproduction. The design has been upgraded from the previous iteration and we found them extremely comfortable to wear for long periods of time, which is important with headphones. The battery gets around 30 hours, which is a fairly standard metric for this type of thing. The only real major nitpick here is the original asking price. It's tough to recommend any pair of headphones for $460, but a bit easier at under $400. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/sonys-wh-1000xm6-headphones-are-down-to-a-record-low-price-175038776.html?src=rss",
          "feed_position": 6
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/data/databricks-serverless-database-slashes-app-development-from-months-to-days",
          "published_at": "Tue, 03 Feb 2026 17:00:00 GMT",
          "title": "Databricks' serverless database slashes app development from months to days as companies prep for agentic AI",
          "standfirst": "Five years ago, Databricks coined the term &#x27;data lakehouse&#x27; to describe a new type of data architecture that combines a data lake with a data warehouse. That term and data architecture are now commonplace across the data industry for analytics workloads.Now, Databricks is once again looking to create a new category with its Lakebase service, now generally available today. While the data lakehouse construct deals with OLAP (online analytical processing) databases, Lakebase is all about OLTP (online transaction processing) and operational databases. The Lakebase service has been in development since June 2025 and is based on technology Databricks gained via its acquisition of PostgreSQL database provider Neon. It was further enhanced in October of 2025 with the acquisition of Mooncake, which brought capabilities to help bridge PostgreSQL with lakehouse data formats.Lakebase is a serverless operational database that represents a fundamental rethinking of how databases work in the age of autonomous AI agents. Early adopters, including easyJet, Hafnia and Warner Music Group, are cutting application delivery times by 75 to 95%, but the deeper architectural innovation positions databases as ephemeral, self-service infrastructure that AI agents can provision and manage without human intervention.This isn&#x27;t just another managed Postgres service. Lakebase treats operational databases as lightweight, disposable compute running on data lake storage rather than monolithic systems requiring careful capacity planning and database administrator (DBA) oversight. \"Really, for the vibe coding trend to take off, you need developers to believe they can actually create new apps very quickly, but you also need the central IT team, or DBAs, to be comfortable with the tsunami of apps and databases,\" Databricks co-founder Reynold Xin told VentureBeat. \"Classic databases simply won&#x27;t scale to that because they can&#x27;t afford to put a DBA per database and per app.\"92% faster delivery: From two months to five daysThe production numbers demonstrate immediate impact beyond the agent provisioning vision. Hafnia reduced delivery time for production-ready applications from two months to five days — or 92% — using Lakebase as the transactional engine for their internal operations portal. The shipping company moved beyond static BI reports to real-time business applications for fleet, commercial and finance workflows.EasyJet consolidated more than 100 Git repositories into just two and cut development cycles from nine months to four months — a 56% reduction — while building a web-based revenue management hub on Lakebase to replace a decade-old desktop app and one of Europe&#x27;s largest legacy SQL Server environments.Warner Music Group is moving insights directly into production systems using the unified foundation, while Quantum Capital Group uses it to maintain consistent, governed data for identifying and evaluating oil and gas investments — eliminating the data duplication that previously forced teams to maintain multiple copies in different formats.The acceleration stems from the elimination of two major bottlenecks: database cloning for test environments and ETL pipeline maintenance for syncing operational and analytical data.Technical architecture: Why this isn&#x27;t just managed PostgresTraditional databases couple storage and compute — organizations provision a database instance with attached storage and scale by adding more instances or storage. AWS Aurora innovated by separating these layers using proprietary storage, but the storage remained locked inside AWS&#x27;s ecosystem and wasn&#x27;t independently accessible for analytics.Lakebase takes the separation of storage and compute to its logical conclusion by putting storage directly in the data lakehouse. The compute layer runs essentially vanilla PostgreSQL— maintaining full compatibility with the Postgres ecosystem — but every write goes to lakehouse storage in formats that Spark, Databricks SQL and other analytics engines can immediately query without ETL.\"The unique technical insight was that data lakes decouple storage from compute, which was great, but we need to introduce data management capabilities like governance and transaction management into the data lake,\" Xin explained. \"We&#x27;re actually not that different from the lakehouse concept, but we&#x27;re building lightweight, ephemeral compute for OLTP databases on top.\"Databricks built Lakebase with the technology it gained from the acquisition of Neon. But Xin emphasized that Databricks significantly expanded Neon&#x27;s original capabilities to create something fundamentally different.\"They didn’t have the enterprise experience, and they didn’t have the cloud scale,\" Xin said. \"We brought the Neon team&#x27;s novel architectural idea together with the robustness of the Databricks infrastructure and combined them. So now we&#x27;ve created a super scalable platform.\"From hundreds of databases to millions built for agentic AIXin outlined a vision directly tied to the economics of AI coding tools that explains why the Lakebase construct matters beyond current use cases. As development costs plummet, enterprises will shift from buying hundreds of SaaS applications to building millions of bespoke internal applications.\"As the cost of software development goes down, which we&#x27;re seeing today because of AI coding tools, it will shift from the proliferation of SaaS in the last 10 to 15 years to the proliferation of in-house application development,\" Xin said. \"Instead of building maybe hundreds of applications, they&#x27;ll be building millions of bespoke apps over time.\"This creates an impossible fleet management problem with traditional approaches. You cannot hire enough DBAs to manually provision, monitor and troubleshoot thousands of databases. Xin&#x27;s solution: Treat database management itself as a data problem rather than an operations problem.Lakebase stores all telemetry and metadata — query performance, resource utilization, connection patterns, error rates — directly in the lakehouse, where it can be analyzed using standard data engineering and data science tools. Instead of configuring dashboards in database-specific monitoring tools, data teams query telemetry data with SQL or analyze it with machine learning models to identify outliers and predict issues.\"Instead of creating a dashboard for every 50 or 100 databases, you can actually look at the chart to understand if something has misbehaved,\" Xin explained. \"Database management will look very similar to an analytics problem. You look at outliers, you look at trends, you try to understand why things happen. This is how you manage at scale when agents are creating and destroying databases programmatically.\"The implications extend to autonomous agents themselves. An AI agent experiencing performance issues could query the telemetry data to diagnose problems — treating database operations as just another analytics task rather than requiring specialized DBA knowledge. Database management becomes something agents can do for themselves using the same data analysis capabilities they already have.What this means for enterprise data teamsThe Lakebase construct signals a fundamental shift in how enterprises should think about operational databases — not as precious, carefully managed infrastructure requiring specialized DBAs, but as ephemeral, self-service resources that scale programmatically like cloud compute. This matters whether or not autonomous agents materialize as quickly as Databricks envisions, because the underlying architectural principle — treating database management as an analytics problem rather than an operations problem — changes the skill sets and team structures enterprises need.Data leaders should pay attention to the convergence of operational and analytical data happening across the industry. When writes to an operational database are immediately queryable by analytics engines without ETL, the traditional boundaries between transactional systems and data warehouses blur. This unified architecture reduces the operational overhead of maintaining separate systems, but it also requires rethinking data team structures built around those boundaries.When lakehouse launched, competitors rejected the concept before eventually adopting it themselves. Xin expects the same trajectory for Lakebase. \"It just makes sense to separate storage and compute and put all the storage in the lake — it enables so many capabilities and possibilities,\" he said.",
          "content": "Five years ago, Databricks coined the term &#x27;data lakehouse&#x27; to describe a new type of data architecture that combines a data lake with a data warehouse. That term and data architecture are now commonplace across the data industry for analytics workloads.Now, Databricks is once again looking to create a new category with its Lakebase service, now generally available today. While the data lakehouse construct deals with OLAP (online analytical processing) databases, Lakebase is all about OLTP (online transaction processing) and operational databases. The Lakebase service has been in development since June 2025 and is based on technology Databricks gained via its acquisition of PostgreSQL database provider Neon. It was further enhanced in October of 2025 with the acquisition of Mooncake, which brought capabilities to help bridge PostgreSQL with lakehouse data formats.Lakebase is a serverless operational database that represents a fundamental rethinking of how databases work in the age of autonomous AI agents. Early adopters, including easyJet, Hafnia and Warner Music Group, are cutting application delivery times by 75 to 95%, but the deeper architectural innovation positions databases as ephemeral, self-service infrastructure that AI agents can provision and manage without human intervention.This isn&#x27;t just another managed Postgres service. Lakebase treats operational databases as lightweight, disposable compute running on data lake storage rather than monolithic systems requiring careful capacity planning and database administrator (DBA) oversight. \"Really, for the vibe coding trend to take off, you need developers to believe they can actually create new apps very quickly, but you also need the central IT team, or DBAs, to be comfortable with the tsunami of apps and databases,\" Databricks co-founder Reynold Xin told VentureBeat. \"Classic databases simply won&#x27;t scale to that because they can&#x27;t afford to put a DBA per database and per app.\"92% faster delivery: From two months to five daysThe production numbers demonstrate immediate impact beyond the agent provisioning vision. Hafnia reduced delivery time for production-ready applications from two months to five days — or 92% — using Lakebase as the transactional engine for their internal operations portal. The shipping company moved beyond static BI reports to real-time business applications for fleet, commercial and finance workflows.EasyJet consolidated more than 100 Git repositories into just two and cut development cycles from nine months to four months — a 56% reduction — while building a web-based revenue management hub on Lakebase to replace a decade-old desktop app and one of Europe&#x27;s largest legacy SQL Server environments.Warner Music Group is moving insights directly into production systems using the unified foundation, while Quantum Capital Group uses it to maintain consistent, governed data for identifying and evaluating oil and gas investments — eliminating the data duplication that previously forced teams to maintain multiple copies in different formats.The acceleration stems from the elimination of two major bottlenecks: database cloning for test environments and ETL pipeline maintenance for syncing operational and analytical data.Technical architecture: Why this isn&#x27;t just managed PostgresTraditional databases couple storage and compute — organizations provision a database instance with attached storage and scale by adding more instances or storage. AWS Aurora innovated by separating these layers using proprietary storage, but the storage remained locked inside AWS&#x27;s ecosystem and wasn&#x27;t independently accessible for analytics.Lakebase takes the separation of storage and compute to its logical conclusion by putting storage directly in the data lakehouse. The compute layer runs essentially vanilla PostgreSQL— maintaining full compatibility with the Postgres ecosystem — but every write goes to lakehouse storage in formats that Spark, Databricks SQL and other analytics engines can immediately query without ETL.\"The unique technical insight was that data lakes decouple storage from compute, which was great, but we need to introduce data management capabilities like governance and transaction management into the data lake,\" Xin explained. \"We&#x27;re actually not that different from the lakehouse concept, but we&#x27;re building lightweight, ephemeral compute for OLTP databases on top.\"Databricks built Lakebase with the technology it gained from the acquisition of Neon. But Xin emphasized that Databricks significantly expanded Neon&#x27;s original capabilities to create something fundamentally different.\"They didn’t have the enterprise experience, and they didn’t have the cloud scale,\" Xin said. \"We brought the Neon team&#x27;s novel architectural idea together with the robustness of the Databricks infrastructure and combined them. So now we&#x27;ve created a super scalable platform.\"From hundreds of databases to millions built for agentic AIXin outlined a vision directly tied to the economics of AI coding tools that explains why the Lakebase construct matters beyond current use cases. As development costs plummet, enterprises will shift from buying hundreds of SaaS applications to building millions of bespoke internal applications.\"As the cost of software development goes down, which we&#x27;re seeing today because of AI coding tools, it will shift from the proliferation of SaaS in the last 10 to 15 years to the proliferation of in-house application development,\" Xin said. \"Instead of building maybe hundreds of applications, they&#x27;ll be building millions of bespoke apps over time.\"This creates an impossible fleet management problem with traditional approaches. You cannot hire enough DBAs to manually provision, monitor and troubleshoot thousands of databases. Xin&#x27;s solution: Treat database management itself as a data problem rather than an operations problem.Lakebase stores all telemetry and metadata — query performance, resource utilization, connection patterns, error rates — directly in the lakehouse, where it can be analyzed using standard data engineering and data science tools. Instead of configuring dashboards in database-specific monitoring tools, data teams query telemetry data with SQL or analyze it with machine learning models to identify outliers and predict issues.\"Instead of creating a dashboard for every 50 or 100 databases, you can actually look at the chart to understand if something has misbehaved,\" Xin explained. \"Database management will look very similar to an analytics problem. You look at outliers, you look at trends, you try to understand why things happen. This is how you manage at scale when agents are creating and destroying databases programmatically.\"The implications extend to autonomous agents themselves. An AI agent experiencing performance issues could query the telemetry data to diagnose problems — treating database operations as just another analytics task rather than requiring specialized DBA knowledge. Database management becomes something agents can do for themselves using the same data analysis capabilities they already have.What this means for enterprise data teamsThe Lakebase construct signals a fundamental shift in how enterprises should think about operational databases — not as precious, carefully managed infrastructure requiring specialized DBAs, but as ephemeral, self-service resources that scale programmatically like cloud compute. This matters whether or not autonomous agents materialize as quickly as Databricks envisions, because the underlying architectural principle — treating database management as an analytics problem rather than an operations problem — changes the skill sets and team structures enterprises need.Data leaders should pay attention to the convergence of operational and analytical data happening across the industry. When writes to an operational database are immediately queryable by analytics engines without ETL, the traditional boundaries between transactional systems and data warehouses blur. This unified architecture reduces the operational overhead of maintaining separate systems, but it also requires rethinking data team structures built around those boundaries.When lakehouse launched, competitors rejected the concept before eventually adopting it themselves. Xin expects the same trajectory for Lakebase. \"It just makes sense to separate storage and compute and put all the storage in the lake — it enables so many capabilities and possibilities,\" he said.",
          "feed_position": 2,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/469ZkXofQMti2royetGH8u/756e2b7f0b026e2b48d72bf886cd7868/database-in-a-lake-smk1.jpg?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/cybersecurity/vpn/how-much-do-vpns-cost-170000567.html",
          "published_at": "Tue, 03 Feb 2026 17:00:00 +0000",
          "title": "How much do VPNs cost?",
          "standfirst": "So you've decided you need a virtual private network to hide your browsing activity from your ISP, change your virtual location, stay safe on public Wi-Fi and enjoy all the other benefits. The inevitable next question is: \"Should I pay for one? If so, how much?\"All the best VPNs cost money, but it can be hard to tell an overpriced service apart from one that's priced according to its value. On this page, I'll share the costs for top VPN services, calculate the industry average and explain what makes VPNs cost as much as they do. At the end, I'll share a few tips for making a VPN fit your budget.How much is a VPN?I'd like to start by introducing the complexity of the problem. If you just want the numbers, you’ll find those in the sections below.The main thing that makes VPNs so hard to budget for is that providers aren't always honest about how much they're charging. They rarely lie outright, but they often overcomplicate their pricing structures and hide increases in the fine print.Let's take CyberGhost as an example, since I just reviewed it. A one-month subscription to CyberGhost costs $12.99 — simple enough. However, you can also get a six-month subscription by paying $41.94 upfront, though the website more prominently calls this \"$6.99 per month.\" Finally, you can pay $56.94 for a 28-month subscription, but only once; after that, it'll be $56.94 for a year.These prices are subject to change.Sam Chapman for EngadgetAs you can see in the image, the website heavily emphasizes the average monthly price, in text that dwarfs the actual price you'll pay at checkout. This gets even worse with services like NordVPN that have multiple tiers of subscription as well as multiple durations. It's not uncommon to see 10 or more prices quoted for the exact same VPN.The best way to cut through the confusion and shop on your own terms is to compare different VPNs at the same duration and subscription tier. For example, you could find the cost of one year of the most basic available plan, since most basic subscriptions still include full VPN service. In the next two sections, I'll compare and average the basic tiers of my top seven VPNs at the monthly and yearly levels.Average monthly cost of a VPNHere's what the best VPNs cost per month. The numbers below are for subscribing to one month at a time, excluding any discounts and special deals.Proton VPN: $9.99ExpressVPN: $12.99Surfshark: $15.45NordVPN: $12.99CyberGhost: $12.99Mullvad: $5.98 (depends on dollar/euro exchange rate)hide.me: $11.99Average: $11.77As you can see, $12.99 is a normal price for one month of a VPN — but the average price is somewhat lower, as several providers sell monthly plans for less. In general, expect to pay in the range between $10 and $13. Companies like Surfshark sometimes inflate their monthly prices in a bid to drive more traffic toward the longer plans.Mullvad is also an outlier, since you can only ever subscribe to it month-by-month. There are other outliers, such as Astrill, which costs a whopping $30 per month. But the above holds true for all the best-regarded providers.Average yearly cost of a VPNIf you choose to sign up for a year at a time, you'll probably save money but you'll have to pay more upfront. VPNs offer long-term deals to pump their cash flow and active user numbers. One-year costs for the top seven VPNs are written below as a lump sum, since several of them add extra months to the first subscription period so they can quote a lower monthly price. Since CyberGhost doesn't have a one-year plan, I've replaced it with Windscribe.Proton VPN: $47.88ExpressVPN: $52.39 for the first subscription, $99.95 afterwardsSurfshark: $47.85NordVPN: $59.88 for the first subscription, $139.08 afterwardsWindscribe: $69.00Mullvad: $71.82 (depends on dollar/euro exchange rate)hide.me: $54.99Average: $57.69For one year of a VPN service, you can expect to pay somewhere between $45 and $70. Note that at least two services, ExpressVPN and NordVPN, raise prices after the first year, so account for that in your budget if you really like them.Why do VPNs cost so much?The length of the subscription is the biggest factor in determining how much you'll pay. Beyond that, it's all a bit fuzzy. Commercial VPNs are still a relatively new industry, so there's not a lot of standardization in the pricing.Most of the variation in cost comes from competition: VPNs value themselves lower to offer a better deal than their rivals, or higher if they think they've got a unique differentiator. Astrill gets away with charging $30 a month because of a widespread belief that it's the best VPN for China (in truth, no VPN can be sure of working in China 100 percent of the time).Another factor that might influence a VPN's price is the cost of maintaining its infrastructure. For each new server location, the provider has to either rent space in an existing data center, build its own physical server farm or set up a virtual server with an IP address from a particular location.On Proton VPN, for example, you can switch locations by clicking the name of any country in the list on the left.Sam Chapman for EngadgetOnce the locations exist, they have to be maintained, including regular changes to their IP address so firewalls don't identify and block them. Loads at locations need to be balanced between servers and technology has to be upgraded as faster solutions become available. Since VPNs can have hundreds of server locations, all that upkeep doesn't come cheap, and customers often eat the cost. Factor in the price of extra features outside core VPN functionality and you'll understand why these companies are so desperate for liquidity that they'll offer discounts over 80 percent — as long as you hand over a lump sum right now.What about free VPNs?VPNs can get pricey, especially if you want high quality. But some VPNs charge nothing at all. Is there any reason not to go with free VPNs every time?The answer is a pretty clear yes; paying for a VPN is almost always a better idea. When we rounded up the best free VPNs, only three got our unqualified recommendation. All three were paid services with free plans, and all come with strict limitations on server locations, data usage and other privileges.The unfortunate reality is that free VPNs come with downsides no matter which one you use. Plenty of them are hacked-together apps with little value, thrown together to make a quick buck. Others turn you into the product by selling your data to advertisers or renting out your home IP address. Some drop any pretense and plant malware directly on your device.These risks, which are often invisible to the end user, are the reason I almost always advise going with a free VPN funded by a paid plan, like Proton VPN, hide.me or Windscribe. Those plans may be restricted, but at least the provider's motives are out in the open: they make money off the paid plan and they want you to switch to it.How to save money on a VPNIf you've decided to pay for a VPN but want to stretch your budget as much as possible, the tips below can push your cybersecurity dollar a bit farther. To begin with, the general advice on choosing a VPN always applies: read expert opinions, check the reviews and use the free trial to test its speed and security.Get a long-term plan. If you're confident that you'll actually use the VPN for the whole duration, there's no reason not to go with a 12-month or 24-month subscription. These are win-win deals that genuinely do save you a lot of money overall.Cancel auto-renewal. VPN accounts are set to automatically renew by default. In some cases, this can inadvertently lock you into a higher-priced long-term plan. I recommend cancelling auto-renew right after subscribing even if you're sure you want to continue. From there, you can create a new account to get the introductory rate again — or go with a different VPN to get a better deal.Look for resubscription deals. Another perk of cancelling immediately is that the VPN will often try to woo you back with exclusive discounts. Stay strong until your subscription is a month or two from expiring, then look for emails offering better rates.Wait for seasonal discounts. If you can hold off until November, most VPNs offer steep discounts from Black Friday season all the way through New Year's. Check around other holidays too, as VPNs will take any excuse for marketing; CyberGhost is offering a Valentine's Day deal as I type this. We also keep track of the best VPN deals you can get at any time of the year.Use the VPN to save money on streaming. Most streaming services are more expensive than VPNs. If you use a VPN to access more content without adding a new streaming subscription, you'll come out ahead. For example, if you only have Netflix but want to watch Schitt’s Creek, you can pay $16.99 per month for Peacock without ads — or $9.99 per month for Proton VPN to unblock Netflix Canada, which features that show.Shop for regional discounts. Like the previous point, this won't save you money on the VPN itself, but might save you enough money on other expenses that you turn a profit. Changing your virtual location can get you discounts on purchases where prices vary by region, especially travel costs.This article originally appeared on Engadget at https://www.engadget.com/cybersecurity/vpn/how-much-do-vpns-cost-170000567.html?src=rss",
          "content": "So you've decided you need a virtual private network to hide your browsing activity from your ISP, change your virtual location, stay safe on public Wi-Fi and enjoy all the other benefits. The inevitable next question is: \"Should I pay for one? If so, how much?\"All the best VPNs cost money, but it can be hard to tell an overpriced service apart from one that's priced according to its value. On this page, I'll share the costs for top VPN services, calculate the industry average and explain what makes VPNs cost as much as they do. At the end, I'll share a few tips for making a VPN fit your budget.How much is a VPN?I'd like to start by introducing the complexity of the problem. If you just want the numbers, you’ll find those in the sections below.The main thing that makes VPNs so hard to budget for is that providers aren't always honest about how much they're charging. They rarely lie outright, but they often overcomplicate their pricing structures and hide increases in the fine print.Let's take CyberGhost as an example, since I just reviewed it. A one-month subscription to CyberGhost costs $12.99 — simple enough. However, you can also get a six-month subscription by paying $41.94 upfront, though the website more prominently calls this \"$6.99 per month.\" Finally, you can pay $56.94 for a 28-month subscription, but only once; after that, it'll be $56.94 for a year.These prices are subject to change.Sam Chapman for EngadgetAs you can see in the image, the website heavily emphasizes the average monthly price, in text that dwarfs the actual price you'll pay at checkout. This gets even worse with services like NordVPN that have multiple tiers of subscription as well as multiple durations. It's not uncommon to see 10 or more prices quoted for the exact same VPN.The best way to cut through the confusion and shop on your own terms is to compare different VPNs at the same duration and subscription tier. For example, you could find the cost of one year of the most basic available plan, since most basic subscriptions still include full VPN service. In the next two sections, I'll compare and average the basic tiers of my top seven VPNs at the monthly and yearly levels.Average monthly cost of a VPNHere's what the best VPNs cost per month. The numbers below are for subscribing to one month at a time, excluding any discounts and special deals.Proton VPN: $9.99ExpressVPN: $12.99Surfshark: $15.45NordVPN: $12.99CyberGhost: $12.99Mullvad: $5.98 (depends on dollar/euro exchange rate)hide.me: $11.99Average: $11.77As you can see, $12.99 is a normal price for one month of a VPN — but the average price is somewhat lower, as several providers sell monthly plans for less. In general, expect to pay in the range between $10 and $13. Companies like Surfshark sometimes inflate their monthly prices in a bid to drive more traffic toward the longer plans.Mullvad is also an outlier, since you can only ever subscribe to it month-by-month. There are other outliers, such as Astrill, which costs a whopping $30 per month. But the above holds true for all the best-regarded providers.Average yearly cost of a VPNIf you choose to sign up for a year at a time, you'll probably save money but you'll have to pay more upfront. VPNs offer long-term deals to pump their cash flow and active user numbers. One-year costs for the top seven VPNs are written below as a lump sum, since several of them add extra months to the first subscription period so they can quote a lower monthly price. Since CyberGhost doesn't have a one-year plan, I've replaced it with Windscribe.Proton VPN: $47.88ExpressVPN: $52.39 for the first subscription, $99.95 afterwardsSurfshark: $47.85NordVPN: $59.88 for the first subscription, $139.08 afterwardsWindscribe: $69.00Mullvad: $71.82 (depends on dollar/euro exchange rate)hide.me: $54.99Average: $57.69For one year of a VPN service, you can expect to pay somewhere between $45 and $70. Note that at least two services, ExpressVPN and NordVPN, raise prices after the first year, so account for that in your budget if you really like them.Why do VPNs cost so much?The length of the subscription is the biggest factor in determining how much you'll pay. Beyond that, it's all a bit fuzzy. Commercial VPNs are still a relatively new industry, so there's not a lot of standardization in the pricing.Most of the variation in cost comes from competition: VPNs value themselves lower to offer a better deal than their rivals, or higher if they think they've got a unique differentiator. Astrill gets away with charging $30 a month because of a widespread belief that it's the best VPN for China (in truth, no VPN can be sure of working in China 100 percent of the time).Another factor that might influence a VPN's price is the cost of maintaining its infrastructure. For each new server location, the provider has to either rent space in an existing data center, build its own physical server farm or set up a virtual server with an IP address from a particular location.On Proton VPN, for example, you can switch locations by clicking the name of any country in the list on the left.Sam Chapman for EngadgetOnce the locations exist, they have to be maintained, including regular changes to their IP address so firewalls don't identify and block them. Loads at locations need to be balanced between servers and technology has to be upgraded as faster solutions become available. Since VPNs can have hundreds of server locations, all that upkeep doesn't come cheap, and customers often eat the cost. Factor in the price of extra features outside core VPN functionality and you'll understand why these companies are so desperate for liquidity that they'll offer discounts over 80 percent — as long as you hand over a lump sum right now.What about free VPNs?VPNs can get pricey, especially if you want high quality. But some VPNs charge nothing at all. Is there any reason not to go with free VPNs every time?The answer is a pretty clear yes; paying for a VPN is almost always a better idea. When we rounded up the best free VPNs, only three got our unqualified recommendation. All three were paid services with free plans, and all come with strict limitations on server locations, data usage and other privileges.The unfortunate reality is that free VPNs come with downsides no matter which one you use. Plenty of them are hacked-together apps with little value, thrown together to make a quick buck. Others turn you into the product by selling your data to advertisers or renting out your home IP address. Some drop any pretense and plant malware directly on your device.These risks, which are often invisible to the end user, are the reason I almost always advise going with a free VPN funded by a paid plan, like Proton VPN, hide.me or Windscribe. Those plans may be restricted, but at least the provider's motives are out in the open: they make money off the paid plan and they want you to switch to it.How to save money on a VPNIf you've decided to pay for a VPN but want to stretch your budget as much as possible, the tips below can push your cybersecurity dollar a bit farther. To begin with, the general advice on choosing a VPN always applies: read expert opinions, check the reviews and use the free trial to test its speed and security.Get a long-term plan. If you're confident that you'll actually use the VPN for the whole duration, there's no reason not to go with a 12-month or 24-month subscription. These are win-win deals that genuinely do save you a lot of money overall.Cancel auto-renewal. VPN accounts are set to automatically renew by default. In some cases, this can inadvertently lock you into a higher-priced long-term plan. I recommend cancelling auto-renew right after subscribing even if you're sure you want to continue. From there, you can create a new account to get the introductory rate again — or go with a different VPN to get a better deal.Look for resubscription deals. Another perk of cancelling immediately is that the VPN will often try to woo you back with exclusive discounts. Stay strong until your subscription is a month or two from expiring, then look for emails offering better rates.Wait for seasonal discounts. If you can hold off until November, most VPNs offer steep discounts from Black Friday season all the way through New Year's. Check around other holidays too, as VPNs will take any excuse for marketing; CyberGhost is offering a Valentine's Day deal as I type this. We also keep track of the best VPN deals you can get at any time of the year.Use the VPN to save money on streaming. Most streaming services are more expensive than VPNs. If you use a VPN to access more content without adding a new streaming subscription, you'll come out ahead. For example, if you only have Netflix but want to watch Schitt’s Creek, you can pay $16.99 per month for Peacock without ads — or $9.99 per month for Proton VPN to unblock Netflix Canada, which features that show.Shop for regional discounts. Like the previous point, this won't save you money on the VPN itself, but might save you enough money on other expenses that you turn a profit. Changing your virtual location can get you discounts on purchases where prices vary by region, especially travel costs.This article originally appeared on Engadget at https://www.engadget.com/cybersecurity/vpn/how-much-do-vpns-cost-170000567.html?src=rss",
          "feed_position": 8,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/CyberGhost_pricing_4053.png"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/smartphones/samsung-galaxy-unpacked-2026-everything-were-expecting-from-the-s26-launch-130000556.html",
          "published_at": "Tue, 03 Feb 2026 16:02:48 +0000",
          "title": "Samsung Galaxy Unpacked 2026: Everything we're expecting from the S26 launch",
          "standfirst": "Samsung’s 2025 was filled with new foldables, an ultra-thin new form factor and the launch of Google's XR platform. After making some announcements at CES 2026, the company is expected to host its first Galaxy Unpacked of the year in February to introduce the Galaxy S26 lineup. Official invites have yet to be shared, but the date is widely expected to be near the end of the month.Whenever it does happen, Engadget will be covering Galaxy Unpacked live, and we'll most likely have hands-on coverage of Samsung's new smartphones soon after they're announced. While we wait for an official invite, here's everything we expect Samsung will introduce at the first Galaxy Unpacked event of 2026.What is Unpacked 2026 taking place?But first, when is Unpacked going to happen? A recent image shared by leakster Evan Blass indicated Unpacked should be taking place on “February 25 2026.” Blass has a long history of credible leaks, which means this date is all but confirmed, and the main questions remaining would be — what time and in what timezone? We’re still waiting on Samsung for the official details, which should include answers to those questions.Galaxy S26, S26+ and S26 UltraSamsung Galaxy S25 Ultra hands-on photoPhoto by Sam Rutherford/EngadgetSamsung's restrained approach to updating its phones will likely continue with the Galaxy S26. Based on leaked images of the new lineup, the company is not expected to radically reinvent the look of the Galaxy S26, Galaxy S26+ or Galaxy S26 Ultra, and instead will stick with a similar design to what it used on the Galaxy S25. The phones will have a flat front screen and frame, with rounded corners and cameras housed in a vertical pill-shaped plateau on the back. Unlike Apple's move from the iPhone 16 Pro to the iPhone 17 Pro, the biggest difference here will likely be internal components like the screens, chips and camera sensors Samsung uses.Qualcomm's new Snapdragon 8 Elite Gen 5 chip is expected to be in all Samsung Galaxy S26 phones, though Korean news site Yonhap News reports Samsung's relatively new Exynos 2600 chip could be used in some phones in the lineup depending on the region, a strategy Samsung has deployed in the past. Either way the new phones should be more performant than the previous generation, and in the case of the models with the Snapdragon 8 Elite Gen 5, particularly good at on-device AI processing.I have compiled the most accurate comprehensive parameter comparison of Galaxy S25, S25+ and Galaxy S26、 S26+. Which one do you want to buy? pic.twitter.com/aQpoSvYjOz— Ice Universe (@UniverseIce) November 29, 2025One notable difference between the Galaxy S26 and the Galaxy S25 could be the phone's screen. The new phone will reportedly feature a 6.3-inch FHD+ display according to specs shared by leaker Ice Universe, which makes it ever so slightly larger than the 6.2-inch display used on the Galaxy S25. The S26 will also allegedly come with 12GB of RAM, either 256GB or 512GB of storage and a slightly larger 4,300mAh battery. Samsung isn't changing the cameras on the entry-level phone, though: leaks suggest it'll feature the same 50-megapixel main camera, 12-megapixel ultrawide, 10-megapixel 3x telephoto and 12-megapixel selfie camera as the previous generation. Changes appear to be even more minor on the Galaxy S26+. Other than the new Snapdragon chip, the phone will reportedly feature the same 6.7-inch FHD+ screen, 4,900mAh battery, 12GB of RAM and the same camera array used on the base Galaxy S26.The difference between the Galaxy S26 Ultra and Galaxy S25 Ultra is reportedly a bit clearer. According to Android Headlines, the new phone's cameras will be slightly more raised, and stand out thanks to a new metallic finish. Samsung may also switch back to using an aluminum frame on the Galaxy S26 Ultra, after using titanium frames on both the Galaxy S24 and S25 Ultras. Most importantly, to make the phone actually support Qi2 rather than only technically work with the standard when a case is attached, rumors suggest Samsung will remove the S Pen digitizer layer in the phone and adopt a new method for accepting stylus input. It's not clear what that new method will actually be, but it could let the Galaxy S26 Ultra more easily work with Qi2 accessories without losing its stylus.Android Headlines also recently shared what appear to be full image renders of the S26 series, and they generally line up with what has already been rumored, leaked and reported so far. If these pictures are accurate, they give us a clearer look at the camera bump and two color variants of the S26 Ultra.Fans of magnets may continue to be disappointed by Samsung if the latest rumors are accurate. Despite the launch of the Qi 2 wireless charging standard adding support for convenient magnetic alignment years ago, Samsung has yet to bring that feature to its phones. Though the S-series have the higher speed charging rates that the spec enables, Nieuwemobiel.nl is reporting that, due to images it received of cases with magnetic rings, the S26 series likely won’t have built-in magnets. Samsung has made these cases to add the magnetic capability to its S-series in the past, and the existence of the images of these accessories lends weight to the idea that the company will continue this approach.Galaxy Buds 4Galaxy Buds 3 Pro in case.EngadgetSamsung released the Galaxy Buds 3 and 3 Pro in 2024, with a major redesign that brought them much more in line with Apple's AirPods. The Galaxy Buds 4 and Buds 4 Pro Samsung is rumored to be announcing soon won't necessarily change that, though they will feature a more compact case and less angular stems, according to leaked images from the Samsung Tips app.Support for head gestures to accept and decline calls, a feature Apple includes on the AirPods Pro 3 and AirPods 4, is also rumored to work on both versions of the new Galaxy Buds. SamMobile reports the Galaxy Buds 4 and 4 Pro may also ship with a new Ultra Wideband chip that will make them easier to find with Google's Find Hub network.Galaxy Z TrifoldYes, the TriFold has a crease, two in fact. But they still don't ruin the experience. Sam Rutherford for EngadgetSamsung announced the Galaxy Z TriFold in late 2025 without firm details of when the new smartphone-that-folds-into-a-tablet would be available in North America. That info came on January 27, when the company announced the TriFold would be available in the US on January 30, for a whopping $2,900. Considering we’ve already seen the device in person at CES 2026 and people are most likely to have had a chance to look at, if not buy the foldable for themselves by the time Unpacked rolls around, we don’t expect Samsung to spend too much time dwelling on it, if at all.Galaxy S26 EdgeAt just 5.8mm thick, the Samsung Galaxy S25 Edge is one of the thinnest smartphones ever made. Sam Rutherford for EngadgetWhen the Galaxy S25 Edge was announced in 2025, it seemed possible that Samsung could replace its \"Plus\" smartphone with a unique form factor, just like Apple has opted to do with the iPhone Air. There have been conflicting reports on the matter, but it seems like Samsung will not be doing that with the Galaxy S26 Edge.Instead, the smartphone will reportedly remain another option, much like foldables are for customers not swayed by Samsung's traditional smartphones. The Galaxy S26 Edge is rumored to feature a slightly different design than last year's model, according to Android Headlines, with a large rectangular camera plateau that's reminiscent of Google's Pixel phones, and the raised oval Apple used on the iPhone Air. Beyond that, the phone is also expected to be ever so slightly thinner at 5.5mm than the 5.8mm Galaxy S25 Edge.Bixby and other AI featuresSamsung already acts as a first place Google can show off new AI features for Android, but the company is reportedly exploring other AI partnerships, too. In June 2025, Bloomberg reported that Samsung was nearing a deal with Perplexity to integrate its AI-powered search engine across OneUI and its homegrown mobile browser. Perplexity already has a deal with Motorola on its Razr phones, so the only thing that would make a deal with Samsung unusual is the close relationship the company already has with Google.The company also accidentally announced a new version of its Bixby AI assistant, which will likely also be integrated with Perplexity and could serve as an alternative to Google Gemini. Both a new Bixby and a deeper integration with Perplexity seem like natural new software features to show off at Galaxy Unpacked.Update, January 27 2026, 11:55AM ET: This story has been updated to reflect the latest news around the Galaxy Z TriFold’s price and availability in the US.Update, January 30 2026, 12:45PM ET: This story has been updated to include the latest leaks on the possible dates for Unpacked 2026.Update, February 02 2026, 11:30AM ET: This story has been updated to include the latest leaks with full image renders of the S26 trio of devices.Update, February 03 2026, 11:00AM ET: This story has been updated to include the latest leaks about the possible lack of magnetic support on the S26 series.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/samsung-galaxy-unpacked-2026-everything-were-expecting-from-the-s26-launch-130000556.html?src=rss",
          "content": "Samsung’s 2025 was filled with new foldables, an ultra-thin new form factor and the launch of Google's XR platform. After making some announcements at CES 2026, the company is expected to host its first Galaxy Unpacked of the year in February to introduce the Galaxy S26 lineup. Official invites have yet to be shared, but the date is widely expected to be near the end of the month.Whenever it does happen, Engadget will be covering Galaxy Unpacked live, and we'll most likely have hands-on coverage of Samsung's new smartphones soon after they're announced. While we wait for an official invite, here's everything we expect Samsung will introduce at the first Galaxy Unpacked event of 2026.What is Unpacked 2026 taking place?But first, when is Unpacked going to happen? A recent image shared by leakster Evan Blass indicated Unpacked should be taking place on “February 25 2026.” Blass has a long history of credible leaks, which means this date is all but confirmed, and the main questions remaining would be — what time and in what timezone? We’re still waiting on Samsung for the official details, which should include answers to those questions.Galaxy S26, S26+ and S26 UltraSamsung Galaxy S25 Ultra hands-on photoPhoto by Sam Rutherford/EngadgetSamsung's restrained approach to updating its phones will likely continue with the Galaxy S26. Based on leaked images of the new lineup, the company is not expected to radically reinvent the look of the Galaxy S26, Galaxy S26+ or Galaxy S26 Ultra, and instead will stick with a similar design to what it used on the Galaxy S25. The phones will have a flat front screen and frame, with rounded corners and cameras housed in a vertical pill-shaped plateau on the back. Unlike Apple's move from the iPhone 16 Pro to the iPhone 17 Pro, the biggest difference here will likely be internal components like the screens, chips and camera sensors Samsung uses.Qualcomm's new Snapdragon 8 Elite Gen 5 chip is expected to be in all Samsung Galaxy S26 phones, though Korean news site Yonhap News reports Samsung's relatively new Exynos 2600 chip could be used in some phones in the lineup depending on the region, a strategy Samsung has deployed in the past. Either way the new phones should be more performant than the previous generation, and in the case of the models with the Snapdragon 8 Elite Gen 5, particularly good at on-device AI processing.I have compiled the most accurate comprehensive parameter comparison of Galaxy S25, S25+ and Galaxy S26、 S26+. Which one do you want to buy? pic.twitter.com/aQpoSvYjOz— Ice Universe (@UniverseIce) November 29, 2025One notable difference between the Galaxy S26 and the Galaxy S25 could be the phone's screen. The new phone will reportedly feature a 6.3-inch FHD+ display according to specs shared by leaker Ice Universe, which makes it ever so slightly larger than the 6.2-inch display used on the Galaxy S25. The S26 will also allegedly come with 12GB of RAM, either 256GB or 512GB of storage and a slightly larger 4,300mAh battery. Samsung isn't changing the cameras on the entry-level phone, though: leaks suggest it'll feature the same 50-megapixel main camera, 12-megapixel ultrawide, 10-megapixel 3x telephoto and 12-megapixel selfie camera as the previous generation. Changes appear to be even more minor on the Galaxy S26+. Other than the new Snapdragon chip, the phone will reportedly feature the same 6.7-inch FHD+ screen, 4,900mAh battery, 12GB of RAM and the same camera array used on the base Galaxy S26.The difference between the Galaxy S26 Ultra and Galaxy S25 Ultra is reportedly a bit clearer. According to Android Headlines, the new phone's cameras will be slightly more raised, and stand out thanks to a new metallic finish. Samsung may also switch back to using an aluminum frame on the Galaxy S26 Ultra, after using titanium frames on both the Galaxy S24 and S25 Ultras. Most importantly, to make the phone actually support Qi2 rather than only technically work with the standard when a case is attached, rumors suggest Samsung will remove the S Pen digitizer layer in the phone and adopt a new method for accepting stylus input. It's not clear what that new method will actually be, but it could let the Galaxy S26 Ultra more easily work with Qi2 accessories without losing its stylus.Android Headlines also recently shared what appear to be full image renders of the S26 series, and they generally line up with what has already been rumored, leaked and reported so far. If these pictures are accurate, they give us a clearer look at the camera bump and two color variants of the S26 Ultra.Fans of magnets may continue to be disappointed by Samsung if the latest rumors are accurate. Despite the launch of the Qi 2 wireless charging standard adding support for convenient magnetic alignment years ago, Samsung has yet to bring that feature to its phones. Though the S-series have the higher speed charging rates that the spec enables, Nieuwemobiel.nl is reporting that, due to images it received of cases with magnetic rings, the S26 series likely won’t have built-in magnets. Samsung has made these cases to add the magnetic capability to its S-series in the past, and the existence of the images of these accessories lends weight to the idea that the company will continue this approach.Galaxy Buds 4Galaxy Buds 3 Pro in case.EngadgetSamsung released the Galaxy Buds 3 and 3 Pro in 2024, with a major redesign that brought them much more in line with Apple's AirPods. The Galaxy Buds 4 and Buds 4 Pro Samsung is rumored to be announcing soon won't necessarily change that, though they will feature a more compact case and less angular stems, according to leaked images from the Samsung Tips app.Support for head gestures to accept and decline calls, a feature Apple includes on the AirPods Pro 3 and AirPods 4, is also rumored to work on both versions of the new Galaxy Buds. SamMobile reports the Galaxy Buds 4 and 4 Pro may also ship with a new Ultra Wideband chip that will make them easier to find with Google's Find Hub network.Galaxy Z TrifoldYes, the TriFold has a crease, two in fact. But they still don't ruin the experience. Sam Rutherford for EngadgetSamsung announced the Galaxy Z TriFold in late 2025 without firm details of when the new smartphone-that-folds-into-a-tablet would be available in North America. That info came on January 27, when the company announced the TriFold would be available in the US on January 30, for a whopping $2,900. Considering we’ve already seen the device in person at CES 2026 and people are most likely to have had a chance to look at, if not buy the foldable for themselves by the time Unpacked rolls around, we don’t expect Samsung to spend too much time dwelling on it, if at all.Galaxy S26 EdgeAt just 5.8mm thick, the Samsung Galaxy S25 Edge is one of the thinnest smartphones ever made. Sam Rutherford for EngadgetWhen the Galaxy S25 Edge was announced in 2025, it seemed possible that Samsung could replace its \"Plus\" smartphone with a unique form factor, just like Apple has opted to do with the iPhone Air. There have been conflicting reports on the matter, but it seems like Samsung will not be doing that with the Galaxy S26 Edge.Instead, the smartphone will reportedly remain another option, much like foldables are for customers not swayed by Samsung's traditional smartphones. The Galaxy S26 Edge is rumored to feature a slightly different design than last year's model, according to Android Headlines, with a large rectangular camera plateau that's reminiscent of Google's Pixel phones, and the raised oval Apple used on the iPhone Air. Beyond that, the phone is also expected to be ever so slightly thinner at 5.5mm than the 5.8mm Galaxy S25 Edge.Bixby and other AI featuresSamsung already acts as a first place Google can show off new AI features for Android, but the company is reportedly exploring other AI partnerships, too. In June 2025, Bloomberg reported that Samsung was nearing a deal with Perplexity to integrate its AI-powered search engine across OneUI and its homegrown mobile browser. Perplexity already has a deal with Motorola on its Razr phones, so the only thing that would make a deal with Samsung unusual is the close relationship the company already has with Google.The company also accidentally announced a new version of its Bixby AI assistant, which will likely also be integrated with Perplexity and could serve as an alternative to Google Gemini. Both a new Bixby and a deeper integration with Perplexity seem like natural new software features to show off at Galaxy Unpacked.Update, January 27 2026, 11:55AM ET: This story has been updated to reflect the latest news around the Galaxy Z TriFold’s price and availability in the US.Update, January 30 2026, 12:45PM ET: This story has been updated to include the latest leaks on the possible dates for Unpacked 2026.Update, February 02 2026, 11:30AM ET: This story has been updated to include the latest leaks with full image renders of the S26 trio of devices.Update, February 03 2026, 11:00AM ET: This story has been updated to include the latest leaks about the possible lack of magnetic support on the S26 series.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/samsung-galaxy-unpacked-2026-everything-were-expecting-from-the-s26-launch-130000556.html?src=rss",
          "feed_position": 11,
          "image_url": "https://media-mbst-pub-ue1.s3.amazonaws.com/creatr-uploaded-images/2025-01/59db82d0-d8d0-11ef-babd-deb856accfc5"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/laptops/msi-prestige-14-flip-ai-review-an-ultraportable-for-arc-raiders-thanks-to-intels-panther-lake-160000606.html",
          "published_at": "Tue, 03 Feb 2026 16:00:00 +0000",
          "title": "MSI Prestige 14 Flip AI+ review: An ultraportable for Arc Raiders, thanks to Intel's Panther Lake",
          "standfirst": "MSI Prestige 14 Flip AI+ is a surprisingly powerful ultraportable held back by a clunky trackpad. It's a shame, really, because it's very well-designed and thanks to Intel’s Panther Lake CPU, it can even run games like Arc Raiders without breaking a sweat. It also has more ports than most thin and light machines, its OLED screen is great for productivity work and at three pounds it's easy to carry around all day. But curse its mechanical trackpad — why does it even exist when Apple, Microsoft and others have been able to implement excellent haptic touchpads for years? Come on now. Hardware With its grey case, subdued design and somewhat chunky bezels, the MSI Prestige 14 Flip AI+ doesn't exactly make a striking impression. From afar, you can tell it's certainly thin, and it's also clear that MSI made the most of its slim case by shoving in two USB-A ports, two USB-C connections, a single HDMI port and a headphone jack. It would have been nice to have some sort of SD card slot too, but at least the Prestige 14 can connect to older accessories, monitors and TVs without a USB-C hub. Once you pick it up, though, the Prestige 14's three-pound frame feels downright remarkable. It's just a tad heavier than the 2.7-pound MacBook Air, but its screen size directly competes with the 3.4- to 3.6-pound 14-inchMacBook Pro. The \"Flip\" in its name also means it’s versatile, with the ability to rotate its screen into a tablet mode, or a variety of tent configurations. What makes the MSI Prestige 14 Flip AI+ truly interesting is its Intel Core Ultra X7 358H processor, which features 16 cores and a maximum speed of 4.8GHz. Specifically, it features four P-cores for speedy performance, eight efficient E-cores and four low-power E-cores. The Ultra X7 is also one of the new Panther Lake chips with gobs of graphics power in Intel's Arc B390 GPU, giving them far more gaming chops than previous ultraportable chips. The laptop also sports 32GB of RAM, which is the ideal amount for serious productivity work, and a roomy 1TB SSD. MSI Prestige 14 Flip AI+ Devindra Hardawar for Engadget The Prestige 14's stylus-friendly 14-inch OLED screen helps to distract from its mundane case design, with the typical deep black levels and excellent contrast I appreciate from OLED, together with bold 100 percent DCI-P3 color coverage. It makes just about everything look great, though I wish MSI offered more than a 60Hz refresh rate — a 90Hz or 120Hz screen would make scrolling through web pages look far smoother. And speaking of the stylus, that’s tucked away at the bottom of the Prestige 14. I didn’t find it particularly useful for notetaking, but for those who do it’s easy to stow away. It’s just too thin for extended handwriting, and anyone doing serious notetaking or digital art would be better off with a larger stylus or dedicated drawing pad. MSI Prestige 14 Flip AI+ in tent mode Devindra Hardawar for Engadget In-use: A stealth performer After seeing a relatively slim Lenovo Panther Lake laptop reaching 190 fps in Battlefield 6, using only Intel's built-in Arc B390 GPU, I was eager to see how that new hardware would perform in the real world. Simply put, the MSI Prestige 14 Flip AI+ didn't disappoint. It scored 10,169 points in PCMark 10, the highest score we've seen yet on a Windows PC. And yes, that includes plenty of powerful gaming systems like the Alienware 16 Area 51 (8,245 points) and the Razer Blade 18 (7,703), both of which were running Intel's last-gen Core Ultra 9 275HX chip. Of course, those systems have faster GPUs, like NVIDIA's RTX 5080, but PCMark 10 doesn't lean too heavily on graphics performance. The Prestige 14 edged close to the M5 MacBook Pro in Geekbench 6's multi-threaded CPU test, scoring 16,633 points compared to Apple's 18,003. But the MacBook Pro reigned supreme in the single-threaded test, scoring 4,310 points compared to the MSI's 2,864. Computer PCMark 10 Geekbench 6 Geekbench 6 GPU Cinebench 2024 MSI Prestige 14 Flip AI+ (Intel Core Ultra X7 358H) 10,169 2,864/16,633 56,425 117/719 Apple MacBook Pro 14-inch (M5, 2025) N/A 4,310/18,003 48,840 197/1,034 | GPU: 6,143 Dell 16 Premium (Core Ultra 7 255H, NVIDIA RTX 5070) 7,780 2,711/15,919 109,443 127/1,104 When it came to games, the Prestige 14 reached a surprisingly high 80-95 fps in Arc Raiders while playing in 1080p with medium graphics settings, as well as AMD's FSR3 upscaling and 2x frame generation. Without those AMD features, Arc Raiders ran at 45-50 fps, which is still respectable for an ultraportable. To my surprise, Intel's XeSS upscaling technology wasn't available in Arc Raiders during my testing, but there's a good chance that tool would eke out even more performance. (I've asked Intel about XeSS's omission, and will update when I hear back.) In Cyberpunk 2077, The Prestige 14 hit 35 fps while playing in 1080p with default settings. Flipping on Intel's XeSS frame generation bumped that to 45 fps. If you're used to the 30 fps performance of consoles, those numbers are still vaguely playable, but they certainly fall short of the 60 fps PC players typically look for. It's best to think of the MSI Prestige 14 Flip AI+ as a laptop where you can play games sometimes, perhaps while you're away from your gaming desktop. It's certainly not a replacement for a dedicated gaming laptop. For more prosaic productivity tasks, like juggling dozens of browser tabs and editing large images, the Prestige 14 didn't break a sweat. Its healthy 32GB of RAM gave it plenty of breathing room for multi-tasking, and unlike other ultraportables, I didn't notice any serious performance dips while running on battery. On that note, the Prestige 14 also lasted a whopping 22 hours and 15 minutes in PCMark 10's battery benchmark. That's the highest figure we've ever seen from a laptop, and it's a promising sign of what we can expect from other Panther Lake systems. MSI Prestige 14 Flip AI+ keyboard and trackpad Devindra Hardawar for Engadget While there's clearly plenty to love about the MSI Prestige 14 Flip AI+, I was less impressed with its mechanical trackpad and keyboard. Perhaps I've been spoiled by the more responsive haptic trackpads from the competition, but the Prestige 14's old-school trackpad kept slowing me down with missed clicks and other annoyances. The laptop's keyboard felt similarly cheap, with a lack of depth and comfort that I've come to expect from other ultraportables in the $1,299 price range. Even after hours of testing, I had a hard time typing on the Prestige 14 at full speed without errors. It's a shame that MSI gets so much right, but is hindered by these weak components. MSI Prestige 14 Flip AI+ in tablet mode Devindra Hardawar for Engadget Should you buy the MSI Prestige 14 Flip AI+? As one of the earliest Panther Lake laptops on the market, the $1,299 Prestige 14 Flip AI+ is a solid machine, if you're willing to overlook its touchpad flaws. More than anything though, the Prestige 14 makes me excited to see what other PC makers offer with Intel's new chips. It's taken a while, but now Intel finally has some decent competition against Apple's M-series hardware. The era of gaming with ultralight machines is finally here.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/msi-prestige-14-flip-ai-review-an-ultraportable-for-arc-raiders-thanks-to-intels-panther-lake-160000606.html?src=rss",
          "content": "MSI Prestige 14 Flip AI+ is a surprisingly powerful ultraportable held back by a clunky trackpad. It's a shame, really, because it's very well-designed and thanks to Intel’s Panther Lake CPU, it can even run games like Arc Raiders without breaking a sweat. It also has more ports than most thin and light machines, its OLED screen is great for productivity work and at three pounds it's easy to carry around all day. But curse its mechanical trackpad — why does it even exist when Apple, Microsoft and others have been able to implement excellent haptic touchpads for years? Come on now. Hardware With its grey case, subdued design and somewhat chunky bezels, the MSI Prestige 14 Flip AI+ doesn't exactly make a striking impression. From afar, you can tell it's certainly thin, and it's also clear that MSI made the most of its slim case by shoving in two USB-A ports, two USB-C connections, a single HDMI port and a headphone jack. It would have been nice to have some sort of SD card slot too, but at least the Prestige 14 can connect to older accessories, monitors and TVs without a USB-C hub. Once you pick it up, though, the Prestige 14's three-pound frame feels downright remarkable. It's just a tad heavier than the 2.7-pound MacBook Air, but its screen size directly competes with the 3.4- to 3.6-pound 14-inchMacBook Pro. The \"Flip\" in its name also means it’s versatile, with the ability to rotate its screen into a tablet mode, or a variety of tent configurations. What makes the MSI Prestige 14 Flip AI+ truly interesting is its Intel Core Ultra X7 358H processor, which features 16 cores and a maximum speed of 4.8GHz. Specifically, it features four P-cores for speedy performance, eight efficient E-cores and four low-power E-cores. The Ultra X7 is also one of the new Panther Lake chips with gobs of graphics power in Intel's Arc B390 GPU, giving them far more gaming chops than previous ultraportable chips. The laptop also sports 32GB of RAM, which is the ideal amount for serious productivity work, and a roomy 1TB SSD. MSI Prestige 14 Flip AI+ Devindra Hardawar for Engadget The Prestige 14's stylus-friendly 14-inch OLED screen helps to distract from its mundane case design, with the typical deep black levels and excellent contrast I appreciate from OLED, together with bold 100 percent DCI-P3 color coverage. It makes just about everything look great, though I wish MSI offered more than a 60Hz refresh rate — a 90Hz or 120Hz screen would make scrolling through web pages look far smoother. And speaking of the stylus, that’s tucked away at the bottom of the Prestige 14. I didn’t find it particularly useful for notetaking, but for those who do it’s easy to stow away. It’s just too thin for extended handwriting, and anyone doing serious notetaking or digital art would be better off with a larger stylus or dedicated drawing pad. MSI Prestige 14 Flip AI+ in tent mode Devindra Hardawar for Engadget In-use: A stealth performer After seeing a relatively slim Lenovo Panther Lake laptop reaching 190 fps in Battlefield 6, using only Intel's built-in Arc B390 GPU, I was eager to see how that new hardware would perform in the real world. Simply put, the MSI Prestige 14 Flip AI+ didn't disappoint. It scored 10,169 points in PCMark 10, the highest score we've seen yet on a Windows PC. And yes, that includes plenty of powerful gaming systems like the Alienware 16 Area 51 (8,245 points) and the Razer Blade 18 (7,703), both of which were running Intel's last-gen Core Ultra 9 275HX chip. Of course, those systems have faster GPUs, like NVIDIA's RTX 5080, but PCMark 10 doesn't lean too heavily on graphics performance. The Prestige 14 edged close to the M5 MacBook Pro in Geekbench 6's multi-threaded CPU test, scoring 16,633 points compared to Apple's 18,003. But the MacBook Pro reigned supreme in the single-threaded test, scoring 4,310 points compared to the MSI's 2,864. Computer PCMark 10 Geekbench 6 Geekbench 6 GPU Cinebench 2024 MSI Prestige 14 Flip AI+ (Intel Core Ultra X7 358H) 10,169 2,864/16,633 56,425 117/719 Apple MacBook Pro 14-inch (M5, 2025) N/A 4,310/18,003 48,840 197/1,034 | GPU: 6,143 Dell 16 Premium (Core Ultra 7 255H, NVIDIA RTX 5070) 7,780 2,711/15,919 109,443 127/1,104 When it came to games, the Prestige 14 reached a surprisingly high 80-95 fps in Arc Raiders while playing in 1080p with medium graphics settings, as well as AMD's FSR3 upscaling and 2x frame generation. Without those AMD features, Arc Raiders ran at 45-50 fps, which is still respectable for an ultraportable. To my surprise, Intel's XeSS upscaling technology wasn't available in Arc Raiders during my testing, but there's a good chance that tool would eke out even more performance. (I've asked Intel about XeSS's omission, and will update when I hear back.) In Cyberpunk 2077, The Prestige 14 hit 35 fps while playing in 1080p with default settings. Flipping on Intel's XeSS frame generation bumped that to 45 fps. If you're used to the 30 fps performance of consoles, those numbers are still vaguely playable, but they certainly fall short of the 60 fps PC players typically look for. It's best to think of the MSI Prestige 14 Flip AI+ as a laptop where you can play games sometimes, perhaps while you're away from your gaming desktop. It's certainly not a replacement for a dedicated gaming laptop. For more prosaic productivity tasks, like juggling dozens of browser tabs and editing large images, the Prestige 14 didn't break a sweat. Its healthy 32GB of RAM gave it plenty of breathing room for multi-tasking, and unlike other ultraportables, I didn't notice any serious performance dips while running on battery. On that note, the Prestige 14 also lasted a whopping 22 hours and 15 minutes in PCMark 10's battery benchmark. That's the highest figure we've ever seen from a laptop, and it's a promising sign of what we can expect from other Panther Lake systems. MSI Prestige 14 Flip AI+ keyboard and trackpad Devindra Hardawar for Engadget While there's clearly plenty to love about the MSI Prestige 14 Flip AI+, I was less impressed with its mechanical trackpad and keyboard. Perhaps I've been spoiled by the more responsive haptic trackpads from the competition, but the Prestige 14's old-school trackpad kept slowing me down with missed clicks and other annoyances. The laptop's keyboard felt similarly cheap, with a lack of depth and comfort that I've come to expect from other ultraportables in the $1,299 price range. Even after hours of testing, I had a hard time typing on the Prestige 14 at full speed without errors. It's a shame that MSI gets so much right, but is hindered by these weak components. MSI Prestige 14 Flip AI+ in tablet mode Devindra Hardawar for Engadget Should you buy the MSI Prestige 14 Flip AI+? As one of the earliest Panther Lake laptops on the market, the $1,299 Prestige 14 Flip AI+ is a solid machine, if you're willing to overlook its touchpad flaws. More than anything though, the Prestige 14 makes me excited to see what other PC makers offer with Intel's new chips. It's taken a while, but now Intel finally has some decent competition against Apple's M-series hardware. The era of gaming with ultralight machines is finally here.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/msi-prestige-14-flip-ai-review-an-ultraportable-for-arc-raiders-thanks-to-intels-panther-lake-160000606.html?src=rss",
          "feed_position": 13,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/MSI_Flip_14-1.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/amazons-echo-show-8-and-11-are-down-to-new-all-time-lows-150021328.html",
          "published_at": "Tue, 03 Feb 2026 15:00:21 +0000",
          "title": "Amazon's Echo Show 8 and 11 are down to new all-time lows",
          "standfirst": "Amazon is running a sale on two of its newest devices. First, there's the Echo Show 8, which is down to $150 from $180 — a 17 percent discount. Next up is the Echo Show 11, which is more or less the same device, just bigger. This model has dropped 18 percent to $180 from $220. Both deals bring the Echo Shows down to new all-time low prices. The Echo Show 8 and 11 came out in mid-November with the main difference being screen size. The Echo Show 8 has an 8.7-inch HD screen that Amazon claims is 15 percent larger than its predecessor. Meanwhile, the Echo Show 11 is, you guessed it, an 11-inch Full-HD display that has 60 percent more viewing area than the Echo Show 8. Both of the devices come with an AZ23 Pro chip and Omnisense technology, which Amazon describes as \"our custom sensor platform designed for ambient AI.\" They also have Prime Video and Netflix apps, while other streamers can be reached through the browser. Each comes with spatial audio, dual full-range drivers and a 2.8-inch woofer. Plus, they have a 13MP camera with auto-framing. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/amazons-echo-show-8-and-11-are-down-to-new-all-time-lows-150021328.html?src=rss",
          "content": "Amazon is running a sale on two of its newest devices. First, there's the Echo Show 8, which is down to $150 from $180 — a 17 percent discount. Next up is the Echo Show 11, which is more or less the same device, just bigger. This model has dropped 18 percent to $180 from $220. Both deals bring the Echo Shows down to new all-time low prices. The Echo Show 8 and 11 came out in mid-November with the main difference being screen size. The Echo Show 8 has an 8.7-inch HD screen that Amazon claims is 15 percent larger than its predecessor. Meanwhile, the Echo Show 11 is, you guessed it, an 11-inch Full-HD display that has 60 percent more viewing area than the Echo Show 8. Both of the devices come with an AZ23 Pro chip and Omnisense technology, which Amazon describes as \"our custom sensor platform designed for ambient AI.\" They also have Prime Video and Netflix apps, while other streamers can be reached through the browser. Each comes with spatial audio, dual full-range drivers and a 2.8-inch woofer. Plus, they have a 13MP camera with auto-framing. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/amazons-echo-show-8-and-11-are-down-to-new-all-time-lows-150021328.html?src=rss",
          "feed_position": 17
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/infrastructure/vercel-rebuilt-v0-to-tackle-the-90-problem-connecting-ai-generated-code-to",
          "published_at": "Tue, 03 Feb 2026 14:00:00 GMT",
          "title": "Vercel rebuilt v0 to tackle the 90% problem: Connecting AI-generated code to existing production infrastructure, not prototypes",
          "standfirst": "Before Claude Code wrote its first line of code, Vercel was already in the vibe coding space with its v0 service.The basic idea behind the original v0, which launched in 2024, was essentially to be version 0. That is, the earliest version of an application, helping developers solve the blank canvas problem. Developers could prompt their way to a user interface (UI) scaffolding that looked good, but the code was disposable. Getting those prototypes into production required rewrites.More than 4 million people have used v0 to build millions of prototypes, but the platform was missing elements required to get into production. The challenge is a familiar one with vibe coding tools, as there is a gap in what tools provide and what enterprise builders require. Claude Code, for instance, generates backend logic and scripts effectively, but does not deploy production UIs within existing company design systems while enforcing security policiesThis creates what Vercel CPO Tom Occhino calls \"the world&#x27;s largest shadow IT problem.\" AI-enabled software creation is already happening inside every enterprise. Credentials are copied into prompts. Company data flows to unmanaged tools. Apps deploy outside approved infrastructure. There&#x27;s no audit trail.Vercel rebuilt v0 to address this production deployment gap. The new version, generally available today, imports existing GitHub repositories and automatically pulls environment variables and configurations. It generates code in a sandbox-based runtime that maps directly to real Vercel deployments and enforces security controls and proper git workflows while allowing non-engineers to ship production code.\"What&#x27;s really nice about v0 is that you still have the code visible and reviewable and governed,\" Occhino told VentureBeat in an exclusive interview. \"Teams end up collaborating on the product, not on PRDs and stuff.\"This shift matters because most enterprise software work happens on existing applications, not new prototypes. Teams need tools that integrate with their current codebases and infrastructure.How v0&#x27;s sandbox runtime connects AI-generated code to existing repositoriesThe original v0 generated UI scaffolding from prompts and let users iterate through conversations. But the code lived in v0&#x27;s isolated environment, which meant moving it to production required copying files, rewriting imports and manually wiring everything together.The rebuilt v0 fundamentally changes this by directly importing existing GitHub repositories. A sandbox-based runtime automatically pulls environment variables, deployments and configurations from Vercel, so every prompt generates production-ready code that already understands the company&#x27;s infrastructure. The code lives in the repository, not a separate prototyping tool.Previously, v0 was a separate prototyping environment. Now, it&#x27;s connected to the actual codebase with full VS Code built into the interface, which means developers can edit code directly without switching tools.A new git panel handles proper workflows. Anyone on a team can create branches from within v0, open pull requests against main and deploy on merge. Pull requests are first-class citizens and previews map directly to real Vercel deployments, not isolated demos.This matters because product managers and marketers can now ship production code through proper git workflows without needing local development environments or handing code snippets to engineers for integration. The new version also adds direct integrations with Snowflake and AWS databases, so teams can wire apps to production data sources with proper access controls built in, rather than requiring manual work.Vercel&#x27;s React and Next.js experience explains v0&#x27;s deployment infrastructurePrior to joining Vercel in 2023, Occhino spent a dozen years as an engineer at Meta (formerly Facebook) and helped lead that company&#x27;s development of the widely-used React JavaScript framework.Vercel&#x27;s claim to fame is that its company founder, Guillermo Rauch, is the creator of Next.js, a full-stack framework built on top of React. In the vibe coding era, Next.js has become an increasingly popular framework. The company recently published a list of React best practices specifically designed to help AI agents and LLMs work.The Vercel platform encapsulates best practices and learnings from Next.js and React. That decade of building frameworks and infrastructure together means v0 outputs production-ready code that deploys on the same infrastructure Vercel uses for millions of deployments annually. The platform includes agentic workflow support, MCP integration, web application firewall, SSO and deployment protections. Teams can open any project in a cloud dev environment and push changes in a single click to a Vercel preview or production deployment.With no shortage of competitive offerings in the vibe coding space, including Replit, Lovable and Cursor among others, it&#x27;s the core foundational infrastructure that Occhino sees as standing out.\"The biggest differentiator for us is the Vercel infrastructure,\" Occhino said. \"It&#x27;s been building managed infrastructure, framework-defined infrastructure, now self-driving infrastructure for the past 10 years.\"Why vibe coding security requires infrastructure control, not just policyThe shadow IT problem isn&#x27;t that employees are using AI tools. It&#x27;s that most vibe coding tools operate entirely outside enterprise infrastructure. Credentials are copied into prompts because there&#x27;s no secure way to connect generated code to enterprise databases. Apps deploy to public URLs because the tools don&#x27;t integrate with company deployment pipelines. Data leaks happen because visibility controls don&#x27;t exist.The technical challenge is that securing AI-generated code requires controlling where it runs and what it can access. Policy documents don&#x27;t help if the tooling itself can&#x27;t enforce those policies.This is where infrastructure matters. When vibe coding tools operate on separate platforms, enterprises face a choice: Block the tools entirely or accept the security risks. When the vibe coding tool runs on the same infrastructure as production deployments, security controls can be enforced automatically.v0 runs on Vercel&#x27;s infrastructure, which means enterprises can set deployment protections, visibility controls and access policies that apply to AI-generated code the same way they apply to hand-written code. Direct integrations with Snowflake and AWS databases let teams connect to production data with proper access controls rather than copying credentials into prompts.\"IT teams are comfortable with what their teams are building because they have control over who has access,\" Occhino said. \"They have control over what those applications have access to from Snowflake or data systems.\"Generative UI vs. generative softwareIn addition to the new version of v0, Vercel has recently introduced a generative UI technology called json-render.v0 is what Vercel calls generative software. This differs from the company&#x27;s json-render framework for a true generative UI. Vercel software engineer Chris Tate explained that v0 builds full-stack apps and agents, not just UIs or frontends. In contrast, json-render is a framework that enables AI to generate UI components directly at runtime by outputting JSON instead of code. \"The AI doesn&#x27;t write software,\" Tate told VentureBeat. \"It plugs directly into the rendering layer to create spontaneous, personalized interfaces on demand.\"The distinction matters for enterprise use cases. Teams use v0 when they need to build complete applications, custom components or production software.They use JSON-render for dynamic, personalized UI elements within applications, dashboards that adapt to individual users, contextual widgets and interfaces that respond to changing data without code changes.Both leverage the AI SDK infrastructure that Vercel has built for streaming and structured outputs.Three lessons enterprises learned from vibe coding adoptionAs enterprises adopted vibe coding tools over the past two years, several patterns emerged about AI-generated code in production environments.Lesson 1: Prototyping without production deployment creates false progress. Enterprises saw teams generate impressive demos in v0&#x27;s early versions, then hit a wall moving those demos to production. The problem wasn&#x27;t the quality of generated code. It was that prototypes lived in isolated environments disconnected from production infrastructure.\"While demos are easy to generate, I think most of the iteration that&#x27;s happening on these code bases is happening on real production apps,\" Occhino said. \"90% of what we need to do is make changes to an existing code base.\"Lesson 2: The software development lifecycle has already changed, whether enterprises planned for it or not. Domain experts are building software directly instead of writing product requirement documents (PRDs) for engineers to interpret. Product managers and marketers ship features without waiting for engineering sprints.This shift means enterprises need tools that maintain code visibility and governance while enabling non-engineers to ship. The alternative is creating bottlenecks by forcing all AI-generated code through traditional development workflows.Lesson 3: Blocking vibe coding tools doesn&#x27;t stop vibe coding. It just pushes the activity outside IT&#x27;s visibility. Enterprises that try to restrict AI-powered development find employees using tools anyway, creating the shadow IT problem at scale.The practical implication is that enterprises should focus less on whether to allow vibe coding and more on ensuring it happens within infrastructure that can enforce existing security and deployment policies.",
          "content": "Before Claude Code wrote its first line of code, Vercel was already in the vibe coding space with its v0 service.The basic idea behind the original v0, which launched in 2024, was essentially to be version 0. That is, the earliest version of an application, helping developers solve the blank canvas problem. Developers could prompt their way to a user interface (UI) scaffolding that looked good, but the code was disposable. Getting those prototypes into production required rewrites.More than 4 million people have used v0 to build millions of prototypes, but the platform was missing elements required to get into production. The challenge is a familiar one with vibe coding tools, as there is a gap in what tools provide and what enterprise builders require. Claude Code, for instance, generates backend logic and scripts effectively, but does not deploy production UIs within existing company design systems while enforcing security policiesThis creates what Vercel CPO Tom Occhino calls \"the world&#x27;s largest shadow IT problem.\" AI-enabled software creation is already happening inside every enterprise. Credentials are copied into prompts. Company data flows to unmanaged tools. Apps deploy outside approved infrastructure. There&#x27;s no audit trail.Vercel rebuilt v0 to address this production deployment gap. The new version, generally available today, imports existing GitHub repositories and automatically pulls environment variables and configurations. It generates code in a sandbox-based runtime that maps directly to real Vercel deployments and enforces security controls and proper git workflows while allowing non-engineers to ship production code.\"What&#x27;s really nice about v0 is that you still have the code visible and reviewable and governed,\" Occhino told VentureBeat in an exclusive interview. \"Teams end up collaborating on the product, not on PRDs and stuff.\"This shift matters because most enterprise software work happens on existing applications, not new prototypes. Teams need tools that integrate with their current codebases and infrastructure.How v0&#x27;s sandbox runtime connects AI-generated code to existing repositoriesThe original v0 generated UI scaffolding from prompts and let users iterate through conversations. But the code lived in v0&#x27;s isolated environment, which meant moving it to production required copying files, rewriting imports and manually wiring everything together.The rebuilt v0 fundamentally changes this by directly importing existing GitHub repositories. A sandbox-based runtime automatically pulls environment variables, deployments and configurations from Vercel, so every prompt generates production-ready code that already understands the company&#x27;s infrastructure. The code lives in the repository, not a separate prototyping tool.Previously, v0 was a separate prototyping environment. Now, it&#x27;s connected to the actual codebase with full VS Code built into the interface, which means developers can edit code directly without switching tools.A new git panel handles proper workflows. Anyone on a team can create branches from within v0, open pull requests against main and deploy on merge. Pull requests are first-class citizens and previews map directly to real Vercel deployments, not isolated demos.This matters because product managers and marketers can now ship production code through proper git workflows without needing local development environments or handing code snippets to engineers for integration. The new version also adds direct integrations with Snowflake and AWS databases, so teams can wire apps to production data sources with proper access controls built in, rather than requiring manual work.Vercel&#x27;s React and Next.js experience explains v0&#x27;s deployment infrastructurePrior to joining Vercel in 2023, Occhino spent a dozen years as an engineer at Meta (formerly Facebook) and helped lead that company&#x27;s development of the widely-used React JavaScript framework.Vercel&#x27;s claim to fame is that its company founder, Guillermo Rauch, is the creator of Next.js, a full-stack framework built on top of React. In the vibe coding era, Next.js has become an increasingly popular framework. The company recently published a list of React best practices specifically designed to help AI agents and LLMs work.The Vercel platform encapsulates best practices and learnings from Next.js and React. That decade of building frameworks and infrastructure together means v0 outputs production-ready code that deploys on the same infrastructure Vercel uses for millions of deployments annually. The platform includes agentic workflow support, MCP integration, web application firewall, SSO and deployment protections. Teams can open any project in a cloud dev environment and push changes in a single click to a Vercel preview or production deployment.With no shortage of competitive offerings in the vibe coding space, including Replit, Lovable and Cursor among others, it&#x27;s the core foundational infrastructure that Occhino sees as standing out.\"The biggest differentiator for us is the Vercel infrastructure,\" Occhino said. \"It&#x27;s been building managed infrastructure, framework-defined infrastructure, now self-driving infrastructure for the past 10 years.\"Why vibe coding security requires infrastructure control, not just policyThe shadow IT problem isn&#x27;t that employees are using AI tools. It&#x27;s that most vibe coding tools operate entirely outside enterprise infrastructure. Credentials are copied into prompts because there&#x27;s no secure way to connect generated code to enterprise databases. Apps deploy to public URLs because the tools don&#x27;t integrate with company deployment pipelines. Data leaks happen because visibility controls don&#x27;t exist.The technical challenge is that securing AI-generated code requires controlling where it runs and what it can access. Policy documents don&#x27;t help if the tooling itself can&#x27;t enforce those policies.This is where infrastructure matters. When vibe coding tools operate on separate platforms, enterprises face a choice: Block the tools entirely or accept the security risks. When the vibe coding tool runs on the same infrastructure as production deployments, security controls can be enforced automatically.v0 runs on Vercel&#x27;s infrastructure, which means enterprises can set deployment protections, visibility controls and access policies that apply to AI-generated code the same way they apply to hand-written code. Direct integrations with Snowflake and AWS databases let teams connect to production data with proper access controls rather than copying credentials into prompts.\"IT teams are comfortable with what their teams are building because they have control over who has access,\" Occhino said. \"They have control over what those applications have access to from Snowflake or data systems.\"Generative UI vs. generative softwareIn addition to the new version of v0, Vercel has recently introduced a generative UI technology called json-render.v0 is what Vercel calls generative software. This differs from the company&#x27;s json-render framework for a true generative UI. Vercel software engineer Chris Tate explained that v0 builds full-stack apps and agents, not just UIs or frontends. In contrast, json-render is a framework that enables AI to generate UI components directly at runtime by outputting JSON instead of code. \"The AI doesn&#x27;t write software,\" Tate told VentureBeat. \"It plugs directly into the rendering layer to create spontaneous, personalized interfaces on demand.\"The distinction matters for enterprise use cases. Teams use v0 when they need to build complete applications, custom components or production software.They use JSON-render for dynamic, personalized UI elements within applications, dashboards that adapt to individual users, contextual widgets and interfaces that respond to changing data without code changes.Both leverage the AI SDK infrastructure that Vercel has built for streaming and structured outputs.Three lessons enterprises learned from vibe coding adoptionAs enterprises adopted vibe coding tools over the past two years, several patterns emerged about AI-generated code in production environments.Lesson 1: Prototyping without production deployment creates false progress. Enterprises saw teams generate impressive demos in v0&#x27;s early versions, then hit a wall moving those demos to production. The problem wasn&#x27;t the quality of generated code. It was that prototypes lived in isolated environments disconnected from production infrastructure.\"While demos are easy to generate, I think most of the iteration that&#x27;s happening on these code bases is happening on real production apps,\" Occhino said. \"90% of what we need to do is make changes to an existing code base.\"Lesson 2: The software development lifecycle has already changed, whether enterprises planned for it or not. Domain experts are building software directly instead of writing product requirement documents (PRDs) for engineers to interpret. Product managers and marketers ship features without waiting for engineering sprints.This shift means enterprises need tools that maintain code visibility and governance while enabling non-engineers to ship. The alternative is creating bottlenecks by forcing all AI-generated code through traditional development workflows.Lesson 3: Blocking vibe coding tools doesn&#x27;t stop vibe coding. It just pushes the activity outside IT&#x27;s visibility. Enterprises that try to restrict AI-powered development find employees using tools anyway, creating the shadow IT problem at scale.The practical implication is that enterprises should focus less on whether to allow vibe coding and more on ensuring it happens within infrastructure that can enforce existing security and deployment policies.",
          "feed_position": 3,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/2U5I1bHA9QfvqoZdPB6qk0/7e4945d1392da8bd955144193be626f7/enterprise-vibe-coder-smk1.jpg?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/gaming/nintendo/mario-tennis-fever-preview-a-racket-smashing-blast-140000408.html",
          "published_at": "Tue, 03 Feb 2026 14:00:00 +0000",
          "title": "Mario Tennis Fever preview: A racket-smashing blast",
          "standfirst": "New Mario sports games typically only come around once in a generation. So to get a fresh installment of tennis featuring a deep roster of characters this early in the Switch 2's lifecycle is rather exciting. And after getting a chance to play Mario Tennis Fever prior to its official release on February 12, the best entry to the franchise yet might only be a couple of weeks away. Once again, Mario Tennis Fever relies on the series' familiar mix of topspin, slice and flat (power) shots used in previous games. The big new mechanic for this title is that instead of Zone Shots from Mario Tennis Aces, you can equip each character with a different racket, similar to how you can choose between a range of vehicles in Mario Kart. Every racket features a different special ability that you can charge up by rallying back and forth. When the gauge is full, you can unleash a Fever Shot to potentially devastating results. The Fever Shot is just one of the special abilities from the 30 different rackets available in Mario Tennis Fever. Nintendo For example, the Fire Racket turns the ball into a fireball that leaves multiple embers on the court. If your opponent gets burned, they will slowly lose health, which will make them move slower or knock them out (but only temporarily) if you're playing doubles. Alternatively, the Pokey Racket can summon the giant cactus monster it's named after onto the court, which not only blocks your view but gets in the way as you chase down shots. And just like the game's large stable of characters (38 in total), there are almost just as many different Fever Rackets (30) to choose from. The thing I like most is that compared to special shots in previous titles, Fever Shots have built-in counterplay. Zone Shots from Mario Tennis Aces sometimes made it feel like you were playing a fighting game as people battled to conserve meter, while signature moves in Mario Tennis: Ultra Smash often turned into automatic points. If someone sends a Fever Shot at you, you can send it back simply by returning the ball before it bounces. This naturally sets up some frenetic sequences as characters try to volley back and forth without letting the ball hit the ground in order to prevent the Fever Shot from taking effect on their side of the court. This is exactly the kind of chaos that makes Mario Tennis so fun — it just feels a bit more balanced now. Pokey is here to be a thorn on your court. Nintendo That said, if you prefer a different kind of mayhem, there are also new Wonder Court Matches, which borrow the titular blue flower seeds from Mario's most recent 2D platformer. This game mode nixes Fever Rackets in favor of changing up the rules of the sport on the fly in weird and unexpected ways. Don't be surprised when you have a hard time hitting seeds with your shots to activate wondrous effects while spike balls get tossed at you or a parade of piranha decides to have a party on top of the net. Unfortunately, I wasn't able to play Mario Tennis Fever's Adventure mode, which is a bit of a shame as I've heard that it's deeper and more fleshed out. This is a welcome upgrade from the somewhat thin single-player campaign from Aces. Thankfully, the game still supports motion controls for younger players or anyone who'd rather swing a virtual racket instead of mashing buttons. I also appreciate that Nintendo is making it easy to get into multiplayer matches, as the game supports both online matches (ranked and unranked) and local wireless connectivity (LAN). For the latter, you can also use the Switch 2's Game Share feature to send the title to other nearby systems so people can try out Mario Tennis Fever for themselves, even if they don't own a copy. Wonder Court Matches are another new way to upend the rules of Mario Tennis. Nintendo So if you're like me and you've always preferred sports games that are more bombastic instead of realistic, Mario Tennis Fever ($70) is shaping up to be a real grand slam. Pre-orders are live now ahead of the title's official release on February 12. This article originally appeared on Engadget at https://www.engadget.com/gaming/nintendo/mario-tennis-fever-preview-a-racket-smashing-blast-140000408.html?src=rss",
          "content": "New Mario sports games typically only come around once in a generation. So to get a fresh installment of tennis featuring a deep roster of characters this early in the Switch 2's lifecycle is rather exciting. And after getting a chance to play Mario Tennis Fever prior to its official release on February 12, the best entry to the franchise yet might only be a couple of weeks away. Once again, Mario Tennis Fever relies on the series' familiar mix of topspin, slice and flat (power) shots used in previous games. The big new mechanic for this title is that instead of Zone Shots from Mario Tennis Aces, you can equip each character with a different racket, similar to how you can choose between a range of vehicles in Mario Kart. Every racket features a different special ability that you can charge up by rallying back and forth. When the gauge is full, you can unleash a Fever Shot to potentially devastating results. The Fever Shot is just one of the special abilities from the 30 different rackets available in Mario Tennis Fever. Nintendo For example, the Fire Racket turns the ball into a fireball that leaves multiple embers on the court. If your opponent gets burned, they will slowly lose health, which will make them move slower or knock them out (but only temporarily) if you're playing doubles. Alternatively, the Pokey Racket can summon the giant cactus monster it's named after onto the court, which not only blocks your view but gets in the way as you chase down shots. And just like the game's large stable of characters (38 in total), there are almost just as many different Fever Rackets (30) to choose from. The thing I like most is that compared to special shots in previous titles, Fever Shots have built-in counterplay. Zone Shots from Mario Tennis Aces sometimes made it feel like you were playing a fighting game as people battled to conserve meter, while signature moves in Mario Tennis: Ultra Smash often turned into automatic points. If someone sends a Fever Shot at you, you can send it back simply by returning the ball before it bounces. This naturally sets up some frenetic sequences as characters try to volley back and forth without letting the ball hit the ground in order to prevent the Fever Shot from taking effect on their side of the court. This is exactly the kind of chaos that makes Mario Tennis so fun — it just feels a bit more balanced now. Pokey is here to be a thorn on your court. Nintendo That said, if you prefer a different kind of mayhem, there are also new Wonder Court Matches, which borrow the titular blue flower seeds from Mario's most recent 2D platformer. This game mode nixes Fever Rackets in favor of changing up the rules of the sport on the fly in weird and unexpected ways. Don't be surprised when you have a hard time hitting seeds with your shots to activate wondrous effects while spike balls get tossed at you or a parade of piranha decides to have a party on top of the net. Unfortunately, I wasn't able to play Mario Tennis Fever's Adventure mode, which is a bit of a shame as I've heard that it's deeper and more fleshed out. This is a welcome upgrade from the somewhat thin single-player campaign from Aces. Thankfully, the game still supports motion controls for younger players or anyone who'd rather swing a virtual racket instead of mashing buttons. I also appreciate that Nintendo is making it easy to get into multiplayer matches, as the game supports both online matches (ranked and unranked) and local wireless connectivity (LAN). For the latter, you can also use the Switch 2's Game Share feature to send the title to other nearby systems so people can try out Mario Tennis Fever for themselves, even if they don't own a copy. Wonder Court Matches are another new way to upend the rules of Mario Tennis. Nintendo So if you're like me and you've always preferred sports games that are more bombastic instead of realistic, Mario Tennis Fever ($70) is shaping up to be a real grand slam. Pre-orders are live now ahead of the title's official release on February 12. This article originally appeared on Engadget at https://www.engadget.com/gaming/nintendo/mario-tennis-fever-preview-a-racket-smashing-blast-140000408.html?src=rss",
          "feed_position": 18,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/imgi_1_8e948f08e7c26b733f3935c848fb4aad533dcbce9103d76899d8b049adc08f3e.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/gaming/nintendo/the-switch-2s-virtual-boy-is-a-tribute-to-nintendos-wackiest-console-140000003.html",
          "published_at": "Tue, 03 Feb 2026 14:00:00 +0000",
          "title": "The Switch 2's Virtual Boy is a tribute to Nintendo's wackiest console",
          "standfirst": "Even in 2026, VR still feels like tech that isn't quite ready for prime time. When Nintendo released the original Virtual Boy way back in 1995, it was hard for my 10-year-old brain to comprehend a 3D console with a bipod, a facemask and a monochrome red display. Then, when you factor in weak sales that led to the system being discontinued after only a year, you end up with a gadget that felt more like a mythical creature than something you could actually buy. But that's changing later this month when the Virtual Boy returns as an add-on for the Switch 2. After getting an early demo of Nintendo's new accessory, I can confirm that this thing feels just as weird and quirky as it did when it first came out more than 30 years ago. The biggest difference on the new model is that it uses the Switch 2's screen as its main display and processor. Sam Rutherford for EngadgetThe most impressive thing about the revamped Virtual Boy is how much it looks and feels like the original. It still features that classic red and black color scheme along with a stand for propping it up. The biggest difference is that instead of having a built-in display, there's a slot where you can slide in a Switch 2 (with its Joy-Con detached). This brings several advantages: Since the Switch 2 has its own battery, there's no need for cords anymore. It also means you don't have to worry about swapping in individual game carts, as software can be downloaded directly from Nintendo's online store. Graphics also look much sharper than I remember, though I admit that could just be me getting old. Finally, instead of reviving the Virtual Boy's archaic gamepad, Nintendo smartly opted to let us use the Switch 2's current lineup of controllers. The end result is a design that's faithful to the original but doesn't suffer from many of the pitfalls that plagued so many 90s gadgets — like tangled wires, awkward controls and fuzzy displays. One thing Nintendo didn't change is Virtual Boy's monochrome red visuals. Sam Rutherford for EngadgetHowever, even with a fair bit of modernization, it's hard to prepare your mind for the journey back in time that happens when you actually use it. Unlike every other contemporary VR headset, you still don't strap the new Virtual Boy onto your face. Instead, you have to adjust its bipod so that its facemask is level with your face and then you kind of just lean in to immerse yourself in a world where red is the only color. It's definitely a bit awkward, but it works. Nintendo even included a way to adjust IPD, so visuals look just as crisp (if not moreso) as they did on the original.That said, the clunkiest thing about the Virtual Boy is its games. While Nintendo updated its exterior and internals, the company didn't really mess with its software — for better and worse. This means you get a relatively unadulterated look at where people thought VR was headed 30 years ago, which becomes immediately evident as soon as you boot into one of the console's first seven games. Galactic Pinball is slow and trying to time when to hit the flippers to prevent the ball from getting past you is an exercise in frustration. Meanwhile, Red Alarm feels like a cheap port of Battlezone, just with a vaguely Arwing-shaped plane instead of a tank. And once again, the pacing on this aerial shooter is glacial. Then there's 3D Tetris, which just kind of hurts your head as you try to drop pieces from a top-down perspective while the entire stage pivots around and never stops moving. The only title that really stands out is Virtual Boy Wario Land, which was and still is the best game on the entire platform. There's no getting around it, the Virtual Boy's bipod is just kind of awkward.Sam Rutherford for EngadgetAfter playing with the revamped Virtual Boy for just under half an hour, it's just as eccentric and ungainly as the original was three decades ago. But you know what, I wouldn't have it any other way because this thing is just as much of a time capsule as it is a nostalgic revival of a forgotten system. And if you want to experience a hazy concept of what people thought the future was going to be, there still isn't anything like the Virtual Boy. The Virtual Boy add-on for the Switch 2 officially goes on sale on February 17 for $100, with the caveat that buyers will need an active Nintendo Switch Online + Expansion pack membership. Also, in addition to the seven games available at launch, Nintendo is planning to add nine more throughout the year including Mario's Tennis and previously unreleased titles such as Zero Racers and D-Hopper. This article originally appeared on Engadget at https://www.engadget.com/gaming/nintendo/the-switch-2s-virtual-boy-is-a-tribute-to-nintendos-wackiest-console-140000003.html?src=rss",
          "content": "Even in 2026, VR still feels like tech that isn't quite ready for prime time. When Nintendo released the original Virtual Boy way back in 1995, it was hard for my 10-year-old brain to comprehend a 3D console with a bipod, a facemask and a monochrome red display. Then, when you factor in weak sales that led to the system being discontinued after only a year, you end up with a gadget that felt more like a mythical creature than something you could actually buy. But that's changing later this month when the Virtual Boy returns as an add-on for the Switch 2. After getting an early demo of Nintendo's new accessory, I can confirm that this thing feels just as weird and quirky as it did when it first came out more than 30 years ago. The biggest difference on the new model is that it uses the Switch 2's screen as its main display and processor. Sam Rutherford for EngadgetThe most impressive thing about the revamped Virtual Boy is how much it looks and feels like the original. It still features that classic red and black color scheme along with a stand for propping it up. The biggest difference is that instead of having a built-in display, there's a slot where you can slide in a Switch 2 (with its Joy-Con detached). This brings several advantages: Since the Switch 2 has its own battery, there's no need for cords anymore. It also means you don't have to worry about swapping in individual game carts, as software can be downloaded directly from Nintendo's online store. Graphics also look much sharper than I remember, though I admit that could just be me getting old. Finally, instead of reviving the Virtual Boy's archaic gamepad, Nintendo smartly opted to let us use the Switch 2's current lineup of controllers. The end result is a design that's faithful to the original but doesn't suffer from many of the pitfalls that plagued so many 90s gadgets — like tangled wires, awkward controls and fuzzy displays. One thing Nintendo didn't change is Virtual Boy's monochrome red visuals. Sam Rutherford for EngadgetHowever, even with a fair bit of modernization, it's hard to prepare your mind for the journey back in time that happens when you actually use it. Unlike every other contemporary VR headset, you still don't strap the new Virtual Boy onto your face. Instead, you have to adjust its bipod so that its facemask is level with your face and then you kind of just lean in to immerse yourself in a world where red is the only color. It's definitely a bit awkward, but it works. Nintendo even included a way to adjust IPD, so visuals look just as crisp (if not moreso) as they did on the original.That said, the clunkiest thing about the Virtual Boy is its games. While Nintendo updated its exterior and internals, the company didn't really mess with its software — for better and worse. This means you get a relatively unadulterated look at where people thought VR was headed 30 years ago, which becomes immediately evident as soon as you boot into one of the console's first seven games. Galactic Pinball is slow and trying to time when to hit the flippers to prevent the ball from getting past you is an exercise in frustration. Meanwhile, Red Alarm feels like a cheap port of Battlezone, just with a vaguely Arwing-shaped plane instead of a tank. And once again, the pacing on this aerial shooter is glacial. Then there's 3D Tetris, which just kind of hurts your head as you try to drop pieces from a top-down perspective while the entire stage pivots around and never stops moving. The only title that really stands out is Virtual Boy Wario Land, which was and still is the best game on the entire platform. There's no getting around it, the Virtual Boy's bipod is just kind of awkward.Sam Rutherford for EngadgetAfter playing with the revamped Virtual Boy for just under half an hour, it's just as eccentric and ungainly as the original was three decades ago. But you know what, I wouldn't have it any other way because this thing is just as much of a time capsule as it is a nostalgic revival of a forgotten system. And if you want to experience a hazy concept of what people thought the future was going to be, there still isn't anything like the Virtual Boy. The Virtual Boy add-on for the Switch 2 officially goes on sale on February 17 for $100, with the caveat that buyers will need an active Nintendo Switch Online + Expansion pack membership. Also, in addition to the seven games available at launch, Nintendo is planning to add nine more throughout the year including Mario's Tennis and previously unreleased titles such as Zero Racers and D-Hopper. This article originally appeared on Engadget at https://www.engadget.com/gaming/nintendo/the-switch-2s-virtual-boy-is-a-tribute-to-nintendos-wackiest-console-140000003.html?src=rss",
          "feed_position": 19,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/virtual-boy-side.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/turbotax-deluxe-is-on-sale-for-45-before-tax-season-204848947.html",
          "published_at": "Tue, 03 Feb 2026 13:36:26 +0000",
          "title": "TurboTax Deluxe is on sale for $45 before tax season",
          "standfirst": "Tax season is fast approaching, and unfortunately for 2026, Direct File isn't an option anymore. The free, government-provided service was shut down, so you'll need to look to other federal programs, including IRS Free File, to file your paperwork. If you don't qualify for Free File, TurboTax might be your best bet for a relatively cheap, efficient way to file your taxes. While it pains us to suggest you give money to a company that has spent decades lobbying to ensure America's tax system remains a nightmare, we can at least help you save a bit of cash if you've determined TurboTax is a necessary expense for you this year. Right now, Amazon has discounted the deluxe desktop edition of TurboTax by 44 percent. That gets you $35 off software that normally costs $80, which you can use to file both your individual state and federal taxes. For most Americans, that should cover their needs. However, if you're self-employed, you'll need to pony up for the more expensive Business version of TurboTax, which is currently 42 percent off, or $54 off. One last thing to note: you'll need a PC with either Windows 11 or macOS Sonoma to run the software, so an older machine won't do, unfortunately. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/turbotax-deluxe-is-on-sale-for-45-before-tax-season-204848947.html?src=rss",
          "content": "Tax season is fast approaching, and unfortunately for 2026, Direct File isn't an option anymore. The free, government-provided service was shut down, so you'll need to look to other federal programs, including IRS Free File, to file your paperwork. If you don't qualify for Free File, TurboTax might be your best bet for a relatively cheap, efficient way to file your taxes. While it pains us to suggest you give money to a company that has spent decades lobbying to ensure America's tax system remains a nightmare, we can at least help you save a bit of cash if you've determined TurboTax is a necessary expense for you this year. Right now, Amazon has discounted the deluxe desktop edition of TurboTax by 44 percent. That gets you $35 off software that normally costs $80, which you can use to file both your individual state and federal taxes. For most Americans, that should cover their needs. However, if you're self-employed, you'll need to pony up for the more expensive Business version of TurboTax, which is currently 42 percent off, or $54 off. One last thing to note: you'll need a PC with either Windows 11 or macOS Sonoma to run the software, so an older machine won't do, unfortunately. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/turbotax-deluxe-is-on-sale-for-45-before-tax-season-204848947.html?src=rss",
          "feed_position": 21
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/the-8bitdo-pro-3-bluetooth-controller-is-down-to-a-new-all-time-low-143036684.html",
          "published_at": "Tue, 03 Feb 2026 13:30:36 +0000",
          "title": "The 8BitDo Pro 3 Bluetooth Controller is down to a new all-time low",
          "standfirst": "If you've been inside all winter gaming then it might be time to upgrade your gear. Right now, the 8Bitdo Pro 3 Bluetooth Controller is available for just over $48, down from $70. The 31 percent discount is the lowest price we've seen yet for the controller. Notably, the sale is only available on the Gray model. The new 8Bitdo Pro 3 came out in August and offers TMR Joysticks with a 12-bit ADC sampling chip. It also has a Trigger Mode Switch, 2 Pro paddle buttons and swappable magnetic ABXY buttons for moving between the Switch and Xbox layouts. Plus, it has an integrated charging dock. This 8Bitdo controller is compatible with Apple, SteamOS, Android devices, PC, Switch, and Switch 2 devices. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/the-8bitdo-pro-3-bluetooth-controller-is-down-to-a-new-all-time-low-143036684.html?src=rss",
          "content": "If you've been inside all winter gaming then it might be time to upgrade your gear. Right now, the 8Bitdo Pro 3 Bluetooth Controller is available for just over $48, down from $70. The 31 percent discount is the lowest price we've seen yet for the controller. Notably, the sale is only available on the Gray model. The new 8Bitdo Pro 3 came out in August and offers TMR Joysticks with a 12-bit ADC sampling chip. It also has a Trigger Mode Switch, 2 Pro paddle buttons and swappable magnetic ABXY buttons for moving between the Switch and Xbox layouts. Plus, it has an integrated charging dock. This 8Bitdo controller is compatible with Apple, SteamOS, Android devices, PC, Switch, and Switch 2 devices. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/the-8bitdo-pro-3-bluetooth-controller-is-down-to-a-new-all-time-low-143036684.html?src=rss",
          "feed_position": 22
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/save-on-the-disney-and-hulu-bundle-get-one-month-for-only-10-192814917.html",
          "published_at": "Tue, 03 Feb 2026 13:04:39 +0000",
          "title": "Save on the Disney+ and Hulu bundle: Get one month for only $10",
          "standfirst": "The peak time for deals on streaming services — the holiday shopping season — has come and gone, but Disney is back with a fresh offer for the new year. New and eligible returning subscribers can get one month of the ad-supported Disney+ Hulu bundle for just $10. That's $3 off the usual monthly rate for the bundle, and more than 58 percent off if you consider the prices for each service individually (Disney+ at $12 per month and, separately, Hulu also at $12 per month). We'd be remiss if we didn't mention that this isn't quite as good as the Black Friday deal we saw last year, which offered the same bundle for $5 per month for one year. However, if you missed that offer or just want to try out Disney+ and Hulu for a brief period of time, this is a good way to do so. Disney+ and Hulu make one of the most balanced streaming pairs available, blending family-friendly favorites with acclaimed originals and network TV staples. Disney+ brings a vast library of animated classics, blockbuster franchises and exclusive content from Marvel, Pixar, Star Wars and National Geographic. It’s the place to stream nearly every Star Wars film and series, plus the full Marvel Cinematic Universe lineup and Disney’s most recent theatrical releases. Hulu balances things out with a more adult-oriented lineup of current TV shows, next-day network episodes and a growing roster of award-winning originals. The platform hosts series like The Bear, The Handmaid’s Tale and Only Murders in the Building, alongside comedies, thrillers and documentaries that regularly feature in awards conversations. It’s also the home for next-day streaming of ABC and FX shows, making it especially useful if you’ve already cut the cable cord but still want to keep up with primetime TV. The Duo Basic bundle ties these two services together under a single subscription, offering a simple way to expand your library without juggling multiple accounts. This tier includes ads on both platforms, but the trade-off is significant savings compared with paying for each service separately. For many households, that’s an acceptable compromise when it means access to such a wide range of content. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/save-on-the-disney-and-hulu-bundle-get-one-month-for-only-10-192814917.html?src=rss",
          "content": "The peak time for deals on streaming services — the holiday shopping season — has come and gone, but Disney is back with a fresh offer for the new year. New and eligible returning subscribers can get one month of the ad-supported Disney+ Hulu bundle for just $10. That's $3 off the usual monthly rate for the bundle, and more than 58 percent off if you consider the prices for each service individually (Disney+ at $12 per month and, separately, Hulu also at $12 per month). We'd be remiss if we didn't mention that this isn't quite as good as the Black Friday deal we saw last year, which offered the same bundle for $5 per month for one year. However, if you missed that offer or just want to try out Disney+ and Hulu for a brief period of time, this is a good way to do so. Disney+ and Hulu make one of the most balanced streaming pairs available, blending family-friendly favorites with acclaimed originals and network TV staples. Disney+ brings a vast library of animated classics, blockbuster franchises and exclusive content from Marvel, Pixar, Star Wars and National Geographic. It’s the place to stream nearly every Star Wars film and series, plus the full Marvel Cinematic Universe lineup and Disney’s most recent theatrical releases. Hulu balances things out with a more adult-oriented lineup of current TV shows, next-day network episodes and a growing roster of award-winning originals. The platform hosts series like The Bear, The Handmaid’s Tale and Only Murders in the Building, alongside comedies, thrillers and documentaries that regularly feature in awards conversations. It’s also the home for next-day streaming of ABC and FX shows, making it especially useful if you’ve already cut the cable cord but still want to keep up with primetime TV. The Duo Basic bundle ties these two services together under a single subscription, offering a simple way to expand your library without juggling multiple accounts. This tier includes ads on both platforms, but the trade-off is significant savings compared with paying for each service separately. For many households, that’s an acceptable compromise when it means access to such a wide range of content. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/save-on-the-disney-and-hulu-bundle-get-one-month-for-only-10-192814917.html?src=rss",
          "feed_position": 23
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/proton-vpn-two-year-subscriptions-are-70-percent-off-right-now-123000972.html",
          "published_at": "Tue, 03 Feb 2026 12:30:00 +0000",
          "title": "Proton VPN two-year subscriptions are 70 percent off right now",
          "standfirst": "Proton VPN is running a solid deal right now, dropping its two-year Proton VPN Plus plan to $2.99 per month. That works out to $72 billed upfront for the first 24 months, which represents a 70 percent discount compared to its regular pricing. We’ve rated Proton VPN highly thanks to its strong privacy credentials, transparent nonprofit backing and consistently fast performance. It’s one of the services we recommend in our guide to the best VPNs, and this deal also shows up alongside other standout offers in our ongoing roundup of the best VPN deals. It’s a good option if you’re looking to lock in long-term protection at a lower monthly cost.In our Proton VPN review, the service impressed us with consistently fast performance and strong privacy protections. We measured average download speeds at 88 percent of our unprotected connection and upload speeds at 98 percent, which is more than enough for 4K streaming, gaming and torrenting. It also unblocked Netflix in every region we tested, and while its Mac and iOS apps aren’t quite as polished as the Windows and Android versions, the service is still easy to install and largely set-it-and-forget-it across platforms. We gave Proton VPN a score of 90 out of 100.Proton VPN Plus is the company’s premium tier and includes access to its full server network, which now spans more than 15,000 servers across 120-plus countries. A single subscription covers up to 10 devices at once and unlocks features like NetShield ad and malware blocking, Secure Core “double hop” connections, split tunneling, custom DNS controls and priority customer support. Proton VPN Plus also supports fast P2P traffic on nearly all paid servers and includes VPN Accelerator, which helps maintain high speeds over long-distance connections.Right now, Proton VPN Plus is discounted to $2.99 per month when you commit to two years, billed as $72 upfront for the first 24 months. After that, the plan renews annually at $83.88. That’s a 70 percent discount compared to the standard monthly rate. As with Proton’s other paid plans, the subscription comes with a 30-day money-back guarantee, so you can try it risk-free if you’re not ready to lock in long term.This article originally appeared on Engadget at https://www.engadget.com/deals/proton-vpn-two-year-subscriptions-are-70-percent-off-right-now-123000972.html?src=rss",
          "content": "Proton VPN is running a solid deal right now, dropping its two-year Proton VPN Plus plan to $2.99 per month. That works out to $72 billed upfront for the first 24 months, which represents a 70 percent discount compared to its regular pricing. We’ve rated Proton VPN highly thanks to its strong privacy credentials, transparent nonprofit backing and consistently fast performance. It’s one of the services we recommend in our guide to the best VPNs, and this deal also shows up alongside other standout offers in our ongoing roundup of the best VPN deals. It’s a good option if you’re looking to lock in long-term protection at a lower monthly cost.In our Proton VPN review, the service impressed us with consistently fast performance and strong privacy protections. We measured average download speeds at 88 percent of our unprotected connection and upload speeds at 98 percent, which is more than enough for 4K streaming, gaming and torrenting. It also unblocked Netflix in every region we tested, and while its Mac and iOS apps aren’t quite as polished as the Windows and Android versions, the service is still easy to install and largely set-it-and-forget-it across platforms. We gave Proton VPN a score of 90 out of 100.Proton VPN Plus is the company’s premium tier and includes access to its full server network, which now spans more than 15,000 servers across 120-plus countries. A single subscription covers up to 10 devices at once and unlocks features like NetShield ad and malware blocking, Secure Core “double hop” connections, split tunneling, custom DNS controls and priority customer support. Proton VPN Plus also supports fast P2P traffic on nearly all paid servers and includes VPN Accelerator, which helps maintain high speeds over long-distance connections.Right now, Proton VPN Plus is discounted to $2.99 per month when you commit to two years, billed as $72 upfront for the first 24 months. After that, the plan renews annually at $83.88. That’s a 70 percent discount compared to the standard monthly rate. As with Proton’s other paid plans, the subscription comes with a 30-day money-back guarantee, so you can try it risk-free if you’re not ready to lock in long term.This article originally appeared on Engadget at https://www.engadget.com/deals/proton-vpn-two-year-subscriptions-are-70-percent-off-right-now-123000972.html?src=rss",
          "feed_position": 24
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/general/the-morning-after-elon-musks-spacex-is-buying-his-ai-company-xai-121500751.html",
          "published_at": "Tue, 03 Feb 2026 12:15:00 +0000",
          "title": "The Morning After: Elon Musk’s SpaceX is buying his AI company, xAI",
          "standfirst": "Like some sort of corporate Russian doll, SpaceX has announced its acquisition of xAI. The merger will “form the most ambitious, vertically integrated innovation engine on (and off) Earth,” according to, well, owner Elon Musk. The AI company, arguably best known for its ongoing CSAM-generating chatbot controversy, might seem like a strange fit for a rocket company. But SpaceX is apparently key to Musk’s latest scheme to build AI data centers in space. There might be an argument for moving the resource-intensive operations to space — but Musk continued.He also claimed space-based data centers will eventually enable further advances in space travel. “The capabilities we unlock by making space-based data centers a reality will fund and enable self-growing bases on the Moon, an entire civilization on Mars and ultimately expansion to the Universe.”Back on Earth, xAI and X (formerly Twitter) merged last year, which means SpaceX now owns the social network Musk bought in 2022. — Mat SmithThe biggest stories you might have missediPhone Fold rumors: Everything we know so far, including the leaked designRivian made an electric ambulance for Grey’s AnatomyTikTok says it’s ‘back to normal’ after winter storm-related outages Sony A7 V camera reviewAwesome speed and photo quality.TMAEngadgetThe Sony A7 V is an imaging powerhouse that brings the speed and precision of its high-end siblings to the enthusiast tier. Thanks to a new 33MP partially stacked sensor, image quality is where it truly pulls ahead, offering best-in-class dynamic range and low-light performance that outclasses 24MP rivals despite the higher resolution. If your primary goal is capturing the perfect still, the combination of accurate AI autofocus and improved color science makes this arguably the best all-around Sony shooter yet.However, if you’re a video-first creator, the A7 V might feel like it’s a little behind. While the 10-bit 4K footage is sharp and benefits from impressive AI auto-framing and stabilization, it lacks internal RAW recording, which competitors like the Canon R6 III and Panasonic S1 II now offer. Make sure you check out the full review.Continue reading.Apple acquires Q.ai for a reported $2 billionAfter Beats, it’s the company’s second-biggest ever purchase.It’s the time of AI acquisitions, it seems. Even Apple’s doing it. Apple has acquired Israel-based startup Q.ai. Although Apple has not disclosed the terms of the deal, The Financial Times reports the arrangement is valued at nearly $2 billion. Apple hasn’t shared specifics on how it plans to leverage the startup, but patents filed by Q.ai focus on integrating its technology into headphones or even glasses, using “facial skin micro movements” to communicate without talking.Continue reading.This article originally appeared on Engadget at https://www.engadget.com/general/the-morning-after-elon-musks-spacex-is-buying-his-ai-company-xai-121500751.html?src=rss",
          "content": "Like some sort of corporate Russian doll, SpaceX has announced its acquisition of xAI. The merger will “form the most ambitious, vertically integrated innovation engine on (and off) Earth,” according to, well, owner Elon Musk. The AI company, arguably best known for its ongoing CSAM-generating chatbot controversy, might seem like a strange fit for a rocket company. But SpaceX is apparently key to Musk’s latest scheme to build AI data centers in space. There might be an argument for moving the resource-intensive operations to space — but Musk continued.He also claimed space-based data centers will eventually enable further advances in space travel. “The capabilities we unlock by making space-based data centers a reality will fund and enable self-growing bases on the Moon, an entire civilization on Mars and ultimately expansion to the Universe.”Back on Earth, xAI and X (formerly Twitter) merged last year, which means SpaceX now owns the social network Musk bought in 2022. — Mat SmithThe biggest stories you might have missediPhone Fold rumors: Everything we know so far, including the leaked designRivian made an electric ambulance for Grey’s AnatomyTikTok says it’s ‘back to normal’ after winter storm-related outages Sony A7 V camera reviewAwesome speed and photo quality.TMAEngadgetThe Sony A7 V is an imaging powerhouse that brings the speed and precision of its high-end siblings to the enthusiast tier. Thanks to a new 33MP partially stacked sensor, image quality is where it truly pulls ahead, offering best-in-class dynamic range and low-light performance that outclasses 24MP rivals despite the higher resolution. If your primary goal is capturing the perfect still, the combination of accurate AI autofocus and improved color science makes this arguably the best all-around Sony shooter yet.However, if you’re a video-first creator, the A7 V might feel like it’s a little behind. While the 10-bit 4K footage is sharp and benefits from impressive AI auto-framing and stabilization, it lacks internal RAW recording, which competitors like the Canon R6 III and Panasonic S1 II now offer. Make sure you check out the full review.Continue reading.Apple acquires Q.ai for a reported $2 billionAfter Beats, it’s the company’s second-biggest ever purchase.It’s the time of AI acquisitions, it seems. Even Apple’s doing it. Apple has acquired Israel-based startup Q.ai. Although Apple has not disclosed the terms of the deal, The Financial Times reports the arrangement is valued at nearly $2 billion. Apple hasn’t shared specifics on how it plans to leverage the startup, but patents filed by Q.ai focus on integrating its technology into headphones or even glasses, using “facial skin micro movements” to communicate without talking.Continue reading.This article originally appeared on Engadget at https://www.engadget.com/general/the-morning-after-elon-musks-spacex-is-buying-his-ai-company-xai-121500751.html?src=rss",
          "feed_position": 25,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/sony-a7-v-review_7482.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/accessories/best-bluetooth-tracker-140028377.html",
          "published_at": "Tue, 03 Feb 2026 08:00:35 +0000",
          "title": "The best Bluetooth trackers for 2026",
          "standfirst": "Most people think of AirTags when they picture a Bluetooth tracker. And indeed, Apple’s little white discs were once the only capable option, relying on a vast finding network of nearby iPhones to pinpoint lost tags. But now Google has a finding network of its own, and third party brands like Chipolo, Hyper and Pebblebee have trackers that pair with your choice of Google or Apple’s network. That means you’ve got a lot of options for tagging and tracking your keys, backpacks, luggage and more. We tested the major brands out there to see how well they work, how loud they are and how they look to put together a guide to help you get the most out of your chosen tracker. Here are the best Bluetooth trackers you can buy.Editor's note: Apple just released a new version of its AirTag trackers. We are in the process of testing the new model and will update this guide once we're done. Best Bluetooth trackers for 2026 What to look for in a Bluetooth tracking device Bluetooth trackers are small discs or cards that rely on short-range, low-energy wireless signals to communicate with your smartphone. Attach one of these gadgets your stuff and, if it’s in range, your phone can “ring” the chip so you can find it. These tracking devices offer other features like separation alerts to tell you when you’ve left a tagged item behind, or where a lost item was last detected. Some can even tap into a larger network of smartphones to track down your device when you’re out of range. Depending on what you want the tracker to do, there are a few specs to look for when deciding which to get. Device compatibility Like most things from the folks in Cupertino, AirTags only work with products in the Apple ecosystem. Both Apple and Google have opened up access to the Find My and Find Hub networks to third-party manufacturers, including Chipolo and Pebblebee. Those two companies make device-agnostic models that will work with the larger tracking network from either brand, so iPhone and Android users can buy the same tag. Tile trackers work with either Android or Apple devices, but use Tile’s own Life 360 finding network. Samsung’s latest fob, the Galaxy SmartTag2, only works with Samsung phones and taps into a finding system that relies on other Samsung devices to locate lost tags. Finding network Crowd-sourced finding capabilities are what make headlines, with stories about recovering stolen equipment or tracking lost luggage across the globe. Using anonymous signals that ping other people’s devices, these Bluetooth tracking devices can potentially tell you where a tagged item is, even if your smartphone is out of Bluetooth range. Apple’s Find My network is the largest, with over a billion iPhones and iPads in service all running Apple’s Find My app by default. So unless an iPhone user opts out, their phone silently acts as a location detector for any nearby AirTags. Apple recently increased the AirTag’s finding power by enabling you to share the tracker's location with a third party, party, like an airline. Chipolo fobs that work on Apple’s network have the same ability. Google launched its Find My Device network in 2024 and has since renamed it Find Hub, which, like Apple's fining app, combines devices and people finding in one place. That network is now a close second for the largest in the US Now that Google’s Find Hub network is up and running, it’s a close second for the largest in the US. Like Apple, Android users are automatically part of the network, but can opt-out by selecting the Google services option in their phone’s Settings app and toggling the option in the Find Hub menu. Samsung’s SmartTag 2 and related network also defaults to an opt-in status for finding tags and other devices. Tile offers a large finding grid that includes Tile users, Amazon Sidewalk customers and people running the Life360 network. Life360 acquired Tile in 2021, and, according to the company, the Life360 network has more than 70 million monthly active users. In our tests, AirTags and third-party tags using its network, like the Chipolo Loop and Pop and the Pebblebee Clip 5, were the fastest to track down lost items. They offered nearly real-time location data in moderately to heavily trafficked spots around Albuquerque, including a bar, bookstore and coffee shops in Nob Hill, along with various outdoor hangouts on UNM’s campus. Samsung's SmartTags were able to locate our lost items most of the time, though not with the same precision finding accuracy as AirTags. When we tested Google’s Find Hub (then called Find My Device) network right after launch, it was noticeably slower than Apple’s network when using the community finding feature. Testing it again in mid 2025, the time it took to locate a lost item was considerably improved, taking less than 20 minutes on average for the community to track a fob. In our tests, Tile’s finding network wasn’t able to consistently locate its lost fobs. Amy Skorheim / Engadget Separation alerts A tracker’s day-to-day utility becomes really apparent when it prevents you from losing something in the first place. Separation alerts tell you when you’ve traveled too far from your tagged items. Useful if you want to make sure your laptop bag, jacket or umbrella always comes with you when you leave the house. Apple’s Find My app delivers these notifications, but Google’s Find Hub does not. However, if you have a Chipolo device and allow its companion app to run in the background on your Android phone, left-behind alerts are enabled. Tile trackers require a yearly subscription to enable the alerts (currently $7 to $25 monthly). Both AirTags and Tiles allow you to turn off separation alerts at certain locations, meaning you can set your home as a “safe” place where items can be left behind, but alerts will still trigger elsewhere. In our tests, AirTags and others using the Find My network alerted us between the 600- and 1,400-foot mark. Tiles sent a notification after about an average of 1,500 feet and were more consistent when using an Android phone than an iPhone. Chipolo Pop tags paired with an Android phone and using its own app sent an alert when we got around 450 feet away from our tagged item. Connectivity and volume The feature you may use most often is the key finder function, which makes the tracker ring when you hit a button in the app. With Apple's AirTags, you can say \"Hey Siri, where are my keys?\" and the assistant will ring the tag (assuming it doesn't mistakenly think you're asking for directions to the Floridian archipelago). You can also use the Find Item app in your Apple Watch to ring your fob. Asking smart home/personal assistants like Alexa or the Google Assistant to find your keys will work with Chipolo, Tile and Pebblebee trackers linked to your Android device. If you have your tag but can’t find your phone, some trackers will let you ring them to find your handset. SmartTag2 fobs reliably rang our Galaxy phone when we double-pressed it. Tile trackers have the same feature. Chipolo Pop and Loop trackers can ring your phone, but uses the Chipolo app to do so, which can run concurrently with the Find My or Find Hub connection. AirTags and third-party tags using Google’s network don’t offer this feature. The volume of the Bluetooth tracking device may determine whether you can find an item buried in your couch cushions or in a noisy room. AirTags have a reputation for being on the quiet side, and that aligned with what we saw (measuring roughly 65 decibels). Chipolo’s Pop tags and Tile’s Pro model measure between 83 and 86 decibels on average. Pebblebee’s new Clip 5 was the loudest of any tag we’ve tested, clocking in at 97 ear-splitting decibels. Design and alternative formats Design will determine what you can attach the tracker to. AirTags are small, smooth discs that can’t be secured to anything without accessories, which are numerous, but that is an additional cost to consider. Chipolo, Pebblebee and Tile offer trackers with holes that easily attach to your key ring, and all three companies also offer card-shaped versions designed to fit in your wallet. Pebblebee Clip 5 tags come with a handy carabiner-style key ring. You can even get trackers embedded into useful items like luggage locks. The SmartLock from KeySmart is a TSA-approved luggage lock, but in addition to the three digit code, it’s also a Bluetooth tracker that’s compatible with Apple Find My. It wasn’t quite as loud as other trackers in my tests, and the range wasn’t as long, but it paired easily and worked with Apple’s finding network just like an AirTag. Battery life AirTag, Tile Pro, SmartTag2, HyperShield and Chipolo Pop fobs use replaceable batteries and each should go for at least a year before needing to be swapped. Pebblebee Clip 5 and Chipolo Loop trackers are rechargeable via a standard USB-C port. The Clip 5 has a long battery life claim at 12 months. The Loop should go for six months on a charge. Trackers shaped like credit cards, aka wallet trackers, don't have replaceable batteries, but some, like the Chipolo Card and the Pebblebee Card 5 are USB-C rechargeable. Stalking, theft and data privacy AirTags have gotten a lot of attention and even prompted some lawsuits for Apple due to bad actors planting them on people in order to stalk them. While this fact may not influence your buying decision, any discussion of Bluetooth trackers should note what steps Apple, Google and Tile have taken to address the issue. Last year, all the major players in the Bluetooth tracker business teamed up to combat misuse and standardize how unauthorized tracking detection and alerts work for iOS and Android. Last year, Tile launched a feature called Anti-Theft Mode, which enables you to render one of its trackers undetectable by others. That means if someone steals your tagged item, they won’t be able to use the anti-stalking features to find and disable the tracker. That sort of negates one of the major ways potential stalking victims can stay safe, so Tile hopes ID verification and a $1 million penalty will deter misuse. As a theft deterrent, a Bluetooth tracker may or may not be the best option. Anecdotal stories abound in which people have recovered stolen goods using a tracker — but other tales are more cautionary. Neither Apple nor Google promotes its trackers or finding networks as a way to deal with theft. GPS trackers, on the other hand, are typically marketed for just that purpose. How we tested Bluetooth trackers Before deciding on which trackers to test, we researched the field, looking at user reviews on Amazon, Best Buy and other retailers, along with discussions on sites like Reddit. We also checked out what other publications had to say on the matter before narrowing down our options. Here’s the full list of every tracker we tested: Apple AirTag Chipolo Card Spot Chipolo One Spot Chipolo One Chipolo Card Chipolo Loop Chipolo Pop HyperShield KeySmart SmartLock Motorola Moto Tag Pebblebee Clip 5 Pebblebee Clip Universal Pebblebee Clip Samsung SmartTag 2 Chipolo One Point Pebblebee Clip for Android Tile Pro (2024) Tile Mate (2024) Tile Mate (2022) Tile Pro (2022) Tile Slim (2022) After acquiring the trackers, I tested each one over the course of a few weeks using both an iPhone 11 followed by an iPhone 16 and a Samsung Galaxy S22 then an S23 Ultra. I recreated likely user experiences, such as losing and leaving items behind at home and out in the city. I planted trackers at different spots near downtown Albuquerque, mostly concentrated in and around the University of New Mexico and the surrounding neighborhood of Nob Hill. Later, I conducted tests in the Queen Anne neighborhood of Seattle. Each test was performed multiple times, both while walking and driving and I used the measure distance feature on Google Maps to track footage for alerts. I paid attention to how easy the app was to use, how reliable the phone-to-tracker connection was and any other perks and drawbacks that came up during regular use. As new trackers come to market, or as we learn of worthy models to try, I'll test them and add the results to this guide. Other Bluetooth trackers we tested Motorola Moto Tag The Moto Tag haunts me. At this very moment, my Galaxy phone says the fob is “Near you right now.” But I don’t know where. I tap to play a sound and the Find Hub tries, but ultimately says it can’t. I tap the Find Nearby function that’s supposed to visually guide you to the tag. I parade my phone around the house like a divining rod, take it down into the basement, walk it all over the garage. Nothing. But the Hub app unendingly says the Moto Tag is “Near you right now” and I get flashes of every old-school horror movie where the telephone operator tells the soon-to-be victim that the call is coming from inside the house. It’s partly my fault. I tend to keep good tabs on the gadgets I test for work. But during my most recent move, the tiny green disc didn’t make it into the safety of my review unit cabinet after relocation. Perhaps in retribution for my neglect, the Moto Tag keeps itself just out of reach. Taunting me. I’ll let you know if I ever find it, but in the meantime, it’s clear this finding device doesn’t want to be found. The recommended tags in this guide will serve you better. Tile Pro and Tile Mate (2024) Tile recently came out with a new suite of trackers, replacing the Tile Mate, Tile Pro, Tile Sticker and Tile Slim with updated models. In addition to fun new colors for the Mate and Slim, Tile added an SOS feature that can send a notification to your Life360 Circle when you triple press the button on the tracker. It’s a clever addition that turns your keys into a panic button, something offered by personal safety companies as standalone devices. There are a few caveats: You and the people you want to notify in an emergency will need the Life360 app installed on your phones. If you want your Tile to also trigger a call to emergency services, you’ll need a $15-per-month Life360 subscription (that’s in addition to a Tile membership, which starts at $3/month or $30 annually). And enabling the SOS triple-press disables the ability to ring your phone with the fob. I tested the SOS feature and it did indeed send a text message to my Circle, with the message that I had triggered an SOS and a link to a website that showed my current location. I thought it odd that the link didn’t open the Life360 app (which shows the location of users' phones), but I wasn’t as much concerned with Tile’s personal safety features as I was with the tracking capabilities, which turned out to be less than ideal. For my tests, I planted Tile trackers in a densely populated area of Seattle (about 15,000 people per square mile). After setting the trackers to “lost” in the Tile app, I waited. After four hours, one of the trackers was not discovered by the finding community, so I went and retrieved it. Another fob I planted alerted me that the tracker had been found by the Tile community after three hours — but the location it gave me was off by a third of a mile. I then decided to plant a tracker in the busiest place I could think of — the dried fruit and nuts aisle of a Trader Joes on a Friday evening before a major holiday. It still took over a half an hour before another Tile user anonymously pinged my lost tracker. In my tests with Samsung’s trackers and the fobs on Google’s Find Hub network, it took around ten minutes for them to be discovered. AirTags took half that time and all were tested in a far less populated city. Tile's four hours with no ping and over a half hour before getting a hit in a crowded TJs were pretty long stretches. Tile devices work with both mobile operating systems and its latest models are indeed louder than they were before. But they aren’t as quick to connect and you need to pay for a membership to activate left-behind alerts. And when you do, those notifications don’t kick in as quickly as they do with competing trackers. Bluetooth tracker FAQs Which Bluetooth tracker has the longest range? Both the Tile Pro and the Samsung Galaxy SmartTag2 claim a maximum range of around 400 feet, which is longer than the 300-foot claim for Chipolo’s Pop tags. The Pebblebee Clip 5 claims a 500-foot range, though other trackers with a shorter claimed range often performed better in our tests. Apple doesn’t make range claims for AirTags, but 30 meters (100 feet) seems to be the general consensus for those fobs. Any Bluetooth signal, of course, is dependent on a few factors. Obstacles like walls and people can block the signal, so a clear line of sight is the only way to achieve the maximum range. Other signals, like Wi-Fi, can also interfere with Bluetooth connections. Even high humidity can have an effect and lessen the distance at which your phone will connect to your tracker. Remember, when considering the range of Bluetooth trackers, the size of the “finding network” also comes into play. This is the number of nearby phones that can be used to anonymously ping your tracker when your own phone is out of Bluetooth range. As of now, Apple AirTags have the largest network, followed by Google’s Find Hub, Samsung’s finding community and finally, Tile’s Life360 members. What is the best Bluetooth tracker for a car? Bluetooth trackers are designed to track small, personal items like keys, jackets, backpacks and the like. All trackers have safeguards to prohibit the tag from being used to stalk people, so most will alert someone if a tracker that does not belong to them is detected following them. That means a car thief may get tipped off that there’s a tracker in the car they’re trying to steal. That said, you’ll see plenty of stories about people finding their car thanks to a Bluetooth tracker. Some police departments have even handed out trackers to combat high rates of carjacking. In most instances, the tracker of choice has been AirTags thanks to their wide finding network. If you’re looking for a tracker for your car, you may want to look into GPS trackers, some of which are designed for just that purpose. How accurate are Bluetooth trackers? Accuracy for Bluetooth trackers can be looked at in two ways: Finding items nearby and finding items misplaced outside your home. For nearby items, you’ll most often use the ring function on the device to hunt it down. Apple’s AirTags also use ultra-wideband technology, which creates directional navigation on your phone to get you within a foot of the tracker. Accurately finding lost items outside your home depends on the size of the finding network. Since this relies on the serendipity of a random phone passing within Bluetooth range of your tracker, the more phones on a given network, the better. And since Bluetooth ranges and distance estimates are only precise within about a meter or so, getting pings from more than one phone will help locating items. Here again, it’s worth noting that Apple’s Find My network is the largest, followed by Google, Samsung and Tile (both Chipolo and Pebblebee have fobs that work with the Apple and Google networks). Recent Updates February 2026: Added Pebblebee Clip 5 as the best rechargeable device. Added HyperShield tag as a budget pick. Updated FAQs for accuracy. October 2025: Added Chipolo Loop as a new pick for best rechargeable Bluetooth tracker. Detailed our experience with the Moto Tag and KeySmart SmartLock. Updated details about separation alerts and Ultra Wideband tech. August 2025: Updated the name of Google's finding network to Find Hub, instead of Find My Device. Added details about Pebblebee's new Alert feature. Added a table of contents. This article originally appeared on Engadget at https://www.engadget.com/computing/accessories/best-bluetooth-tracker-140028377.html?src=rss",
          "content": "Most people think of AirTags when they picture a Bluetooth tracker. And indeed, Apple’s little white discs were once the only capable option, relying on a vast finding network of nearby iPhones to pinpoint lost tags. But now Google has a finding network of its own, and third party brands like Chipolo, Hyper and Pebblebee have trackers that pair with your choice of Google or Apple’s network. That means you’ve got a lot of options for tagging and tracking your keys, backpacks, luggage and more. We tested the major brands out there to see how well they work, how loud they are and how they look to put together a guide to help you get the most out of your chosen tracker. Here are the best Bluetooth trackers you can buy.Editor's note: Apple just released a new version of its AirTag trackers. We are in the process of testing the new model and will update this guide once we're done. Best Bluetooth trackers for 2026 What to look for in a Bluetooth tracking device Bluetooth trackers are small discs or cards that rely on short-range, low-energy wireless signals to communicate with your smartphone. Attach one of these gadgets your stuff and, if it’s in range, your phone can “ring” the chip so you can find it. These tracking devices offer other features like separation alerts to tell you when you’ve left a tagged item behind, or where a lost item was last detected. Some can even tap into a larger network of smartphones to track down your device when you’re out of range. Depending on what you want the tracker to do, there are a few specs to look for when deciding which to get. Device compatibility Like most things from the folks in Cupertino, AirTags only work with products in the Apple ecosystem. Both Apple and Google have opened up access to the Find My and Find Hub networks to third-party manufacturers, including Chipolo and Pebblebee. Those two companies make device-agnostic models that will work with the larger tracking network from either brand, so iPhone and Android users can buy the same tag. Tile trackers work with either Android or Apple devices, but use Tile’s own Life 360 finding network. Samsung’s latest fob, the Galaxy SmartTag2, only works with Samsung phones and taps into a finding system that relies on other Samsung devices to locate lost tags. Finding network Crowd-sourced finding capabilities are what make headlines, with stories about recovering stolen equipment or tracking lost luggage across the globe. Using anonymous signals that ping other people’s devices, these Bluetooth tracking devices can potentially tell you where a tagged item is, even if your smartphone is out of Bluetooth range. Apple’s Find My network is the largest, with over a billion iPhones and iPads in service all running Apple’s Find My app by default. So unless an iPhone user opts out, their phone silently acts as a location detector for any nearby AirTags. Apple recently increased the AirTag’s finding power by enabling you to share the tracker's location with a third party, party, like an airline. Chipolo fobs that work on Apple’s network have the same ability. Google launched its Find My Device network in 2024 and has since renamed it Find Hub, which, like Apple's fining app, combines devices and people finding in one place. That network is now a close second for the largest in the US Now that Google’s Find Hub network is up and running, it’s a close second for the largest in the US. Like Apple, Android users are automatically part of the network, but can opt-out by selecting the Google services option in their phone’s Settings app and toggling the option in the Find Hub menu. Samsung’s SmartTag 2 and related network also defaults to an opt-in status for finding tags and other devices. Tile offers a large finding grid that includes Tile users, Amazon Sidewalk customers and people running the Life360 network. Life360 acquired Tile in 2021, and, according to the company, the Life360 network has more than 70 million monthly active users. In our tests, AirTags and third-party tags using its network, like the Chipolo Loop and Pop and the Pebblebee Clip 5, were the fastest to track down lost items. They offered nearly real-time location data in moderately to heavily trafficked spots around Albuquerque, including a bar, bookstore and coffee shops in Nob Hill, along with various outdoor hangouts on UNM’s campus. Samsung's SmartTags were able to locate our lost items most of the time, though not with the same precision finding accuracy as AirTags. When we tested Google’s Find Hub (then called Find My Device) network right after launch, it was noticeably slower than Apple’s network when using the community finding feature. Testing it again in mid 2025, the time it took to locate a lost item was considerably improved, taking less than 20 minutes on average for the community to track a fob. In our tests, Tile’s finding network wasn’t able to consistently locate its lost fobs. Amy Skorheim / Engadget Separation alerts A tracker’s day-to-day utility becomes really apparent when it prevents you from losing something in the first place. Separation alerts tell you when you’ve traveled too far from your tagged items. Useful if you want to make sure your laptop bag, jacket or umbrella always comes with you when you leave the house. Apple’s Find My app delivers these notifications, but Google’s Find Hub does not. However, if you have a Chipolo device and allow its companion app to run in the background on your Android phone, left-behind alerts are enabled. Tile trackers require a yearly subscription to enable the alerts (currently $7 to $25 monthly). Both AirTags and Tiles allow you to turn off separation alerts at certain locations, meaning you can set your home as a “safe” place where items can be left behind, but alerts will still trigger elsewhere. In our tests, AirTags and others using the Find My network alerted us between the 600- and 1,400-foot mark. Tiles sent a notification after about an average of 1,500 feet and were more consistent when using an Android phone than an iPhone. Chipolo Pop tags paired with an Android phone and using its own app sent an alert when we got around 450 feet away from our tagged item. Connectivity and volume The feature you may use most often is the key finder function, which makes the tracker ring when you hit a button in the app. With Apple's AirTags, you can say \"Hey Siri, where are my keys?\" and the assistant will ring the tag (assuming it doesn't mistakenly think you're asking for directions to the Floridian archipelago). You can also use the Find Item app in your Apple Watch to ring your fob. Asking smart home/personal assistants like Alexa or the Google Assistant to find your keys will work with Chipolo, Tile and Pebblebee trackers linked to your Android device. If you have your tag but can’t find your phone, some trackers will let you ring them to find your handset. SmartTag2 fobs reliably rang our Galaxy phone when we double-pressed it. Tile trackers have the same feature. Chipolo Pop and Loop trackers can ring your phone, but uses the Chipolo app to do so, which can run concurrently with the Find My or Find Hub connection. AirTags and third-party tags using Google’s network don’t offer this feature. The volume of the Bluetooth tracking device may determine whether you can find an item buried in your couch cushions or in a noisy room. AirTags have a reputation for being on the quiet side, and that aligned with what we saw (measuring roughly 65 decibels). Chipolo’s Pop tags and Tile’s Pro model measure between 83 and 86 decibels on average. Pebblebee’s new Clip 5 was the loudest of any tag we’ve tested, clocking in at 97 ear-splitting decibels. Design and alternative formats Design will determine what you can attach the tracker to. AirTags are small, smooth discs that can’t be secured to anything without accessories, which are numerous, but that is an additional cost to consider. Chipolo, Pebblebee and Tile offer trackers with holes that easily attach to your key ring, and all three companies also offer card-shaped versions designed to fit in your wallet. Pebblebee Clip 5 tags come with a handy carabiner-style key ring. You can even get trackers embedded into useful items like luggage locks. The SmartLock from KeySmart is a TSA-approved luggage lock, but in addition to the three digit code, it’s also a Bluetooth tracker that’s compatible with Apple Find My. It wasn’t quite as loud as other trackers in my tests, and the range wasn’t as long, but it paired easily and worked with Apple’s finding network just like an AirTag. Battery life AirTag, Tile Pro, SmartTag2, HyperShield and Chipolo Pop fobs use replaceable batteries and each should go for at least a year before needing to be swapped. Pebblebee Clip 5 and Chipolo Loop trackers are rechargeable via a standard USB-C port. The Clip 5 has a long battery life claim at 12 months. The Loop should go for six months on a charge. Trackers shaped like credit cards, aka wallet trackers, don't have replaceable batteries, but some, like the Chipolo Card and the Pebblebee Card 5 are USB-C rechargeable. Stalking, theft and data privacy AirTags have gotten a lot of attention and even prompted some lawsuits for Apple due to bad actors planting them on people in order to stalk them. While this fact may not influence your buying decision, any discussion of Bluetooth trackers should note what steps Apple, Google and Tile have taken to address the issue. Last year, all the major players in the Bluetooth tracker business teamed up to combat misuse and standardize how unauthorized tracking detection and alerts work for iOS and Android. Last year, Tile launched a feature called Anti-Theft Mode, which enables you to render one of its trackers undetectable by others. That means if someone steals your tagged item, they won’t be able to use the anti-stalking features to find and disable the tracker. That sort of negates one of the major ways potential stalking victims can stay safe, so Tile hopes ID verification and a $1 million penalty will deter misuse. As a theft deterrent, a Bluetooth tracker may or may not be the best option. Anecdotal stories abound in which people have recovered stolen goods using a tracker — but other tales are more cautionary. Neither Apple nor Google promotes its trackers or finding networks as a way to deal with theft. GPS trackers, on the other hand, are typically marketed for just that purpose. How we tested Bluetooth trackers Before deciding on which trackers to test, we researched the field, looking at user reviews on Amazon, Best Buy and other retailers, along with discussions on sites like Reddit. We also checked out what other publications had to say on the matter before narrowing down our options. Here’s the full list of every tracker we tested: Apple AirTag Chipolo Card Spot Chipolo One Spot Chipolo One Chipolo Card Chipolo Loop Chipolo Pop HyperShield KeySmart SmartLock Motorola Moto Tag Pebblebee Clip 5 Pebblebee Clip Universal Pebblebee Clip Samsung SmartTag 2 Chipolo One Point Pebblebee Clip for Android Tile Pro (2024) Tile Mate (2024) Tile Mate (2022) Tile Pro (2022) Tile Slim (2022) After acquiring the trackers, I tested each one over the course of a few weeks using both an iPhone 11 followed by an iPhone 16 and a Samsung Galaxy S22 then an S23 Ultra. I recreated likely user experiences, such as losing and leaving items behind at home and out in the city. I planted trackers at different spots near downtown Albuquerque, mostly concentrated in and around the University of New Mexico and the surrounding neighborhood of Nob Hill. Later, I conducted tests in the Queen Anne neighborhood of Seattle. Each test was performed multiple times, both while walking and driving and I used the measure distance feature on Google Maps to track footage for alerts. I paid attention to how easy the app was to use, how reliable the phone-to-tracker connection was and any other perks and drawbacks that came up during regular use. As new trackers come to market, or as we learn of worthy models to try, I'll test them and add the results to this guide. Other Bluetooth trackers we tested Motorola Moto Tag The Moto Tag haunts me. At this very moment, my Galaxy phone says the fob is “Near you right now.” But I don’t know where. I tap to play a sound and the Find Hub tries, but ultimately says it can’t. I tap the Find Nearby function that’s supposed to visually guide you to the tag. I parade my phone around the house like a divining rod, take it down into the basement, walk it all over the garage. Nothing. But the Hub app unendingly says the Moto Tag is “Near you right now” and I get flashes of every old-school horror movie where the telephone operator tells the soon-to-be victim that the call is coming from inside the house. It’s partly my fault. I tend to keep good tabs on the gadgets I test for work. But during my most recent move, the tiny green disc didn’t make it into the safety of my review unit cabinet after relocation. Perhaps in retribution for my neglect, the Moto Tag keeps itself just out of reach. Taunting me. I’ll let you know if I ever find it, but in the meantime, it’s clear this finding device doesn’t want to be found. The recommended tags in this guide will serve you better. Tile Pro and Tile Mate (2024) Tile recently came out with a new suite of trackers, replacing the Tile Mate, Tile Pro, Tile Sticker and Tile Slim with updated models. In addition to fun new colors for the Mate and Slim, Tile added an SOS feature that can send a notification to your Life360 Circle when you triple press the button on the tracker. It’s a clever addition that turns your keys into a panic button, something offered by personal safety companies as standalone devices. There are a few caveats: You and the people you want to notify in an emergency will need the Life360 app installed on your phones. If you want your Tile to also trigger a call to emergency services, you’ll need a $15-per-month Life360 subscription (that’s in addition to a Tile membership, which starts at $3/month or $30 annually). And enabling the SOS triple-press disables the ability to ring your phone with the fob. I tested the SOS feature and it did indeed send a text message to my Circle, with the message that I had triggered an SOS and a link to a website that showed my current location. I thought it odd that the link didn’t open the Life360 app (which shows the location of users' phones), but I wasn’t as much concerned with Tile’s personal safety features as I was with the tracking capabilities, which turned out to be less than ideal. For my tests, I planted Tile trackers in a densely populated area of Seattle (about 15,000 people per square mile). After setting the trackers to “lost” in the Tile app, I waited. After four hours, one of the trackers was not discovered by the finding community, so I went and retrieved it. Another fob I planted alerted me that the tracker had been found by the Tile community after three hours — but the location it gave me was off by a third of a mile. I then decided to plant a tracker in the busiest place I could think of — the dried fruit and nuts aisle of a Trader Joes on a Friday evening before a major holiday. It still took over a half an hour before another Tile user anonymously pinged my lost tracker. In my tests with Samsung’s trackers and the fobs on Google’s Find Hub network, it took around ten minutes for them to be discovered. AirTags took half that time and all were tested in a far less populated city. Tile's four hours with no ping and over a half hour before getting a hit in a crowded TJs were pretty long stretches. Tile devices work with both mobile operating systems and its latest models are indeed louder than they were before. But they aren’t as quick to connect and you need to pay for a membership to activate left-behind alerts. And when you do, those notifications don’t kick in as quickly as they do with competing trackers. Bluetooth tracker FAQs Which Bluetooth tracker has the longest range? Both the Tile Pro and the Samsung Galaxy SmartTag2 claim a maximum range of around 400 feet, which is longer than the 300-foot claim for Chipolo’s Pop tags. The Pebblebee Clip 5 claims a 500-foot range, though other trackers with a shorter claimed range often performed better in our tests. Apple doesn’t make range claims for AirTags, but 30 meters (100 feet) seems to be the general consensus for those fobs. Any Bluetooth signal, of course, is dependent on a few factors. Obstacles like walls and people can block the signal, so a clear line of sight is the only way to achieve the maximum range. Other signals, like Wi-Fi, can also interfere with Bluetooth connections. Even high humidity can have an effect and lessen the distance at which your phone will connect to your tracker. Remember, when considering the range of Bluetooth trackers, the size of the “finding network” also comes into play. This is the number of nearby phones that can be used to anonymously ping your tracker when your own phone is out of Bluetooth range. As of now, Apple AirTags have the largest network, followed by Google’s Find Hub, Samsung’s finding community and finally, Tile’s Life360 members. What is the best Bluetooth tracker for a car? Bluetooth trackers are designed to track small, personal items like keys, jackets, backpacks and the like. All trackers have safeguards to prohibit the tag from being used to stalk people, so most will alert someone if a tracker that does not belong to them is detected following them. That means a car thief may get tipped off that there’s a tracker in the car they’re trying to steal. That said, you’ll see plenty of stories about people finding their car thanks to a Bluetooth tracker. Some police departments have even handed out trackers to combat high rates of carjacking. In most instances, the tracker of choice has been AirTags thanks to their wide finding network. If you’re looking for a tracker for your car, you may want to look into GPS trackers, some of which are designed for just that purpose. How accurate are Bluetooth trackers? Accuracy for Bluetooth trackers can be looked at in two ways: Finding items nearby and finding items misplaced outside your home. For nearby items, you’ll most often use the ring function on the device to hunt it down. Apple’s AirTags also use ultra-wideband technology, which creates directional navigation on your phone to get you within a foot of the tracker. Accurately finding lost items outside your home depends on the size of the finding network. Since this relies on the serendipity of a random phone passing within Bluetooth range of your tracker, the more phones on a given network, the better. And since Bluetooth ranges and distance estimates are only precise within about a meter or so, getting pings from more than one phone will help locating items. Here again, it’s worth noting that Apple’s Find My network is the largest, followed by Google, Samsung and Tile (both Chipolo and Pebblebee have fobs that work with the Apple and Google networks). Recent Updates February 2026: Added Pebblebee Clip 5 as the best rechargeable device. Added HyperShield tag as a budget pick. Updated FAQs for accuracy. October 2025: Added Chipolo Loop as a new pick for best rechargeable Bluetooth tracker. Detailed our experience with the Moto Tag and KeySmart SmartLock. Updated details about separation alerts and Ultra Wideband tech. August 2025: Updated the name of Google's finding network to Find Hub, instead of Find My Device. Added details about Pebblebee's new Alert feature. Added a table of contents. This article originally appeared on Engadget at https://www.engadget.com/computing/accessories/best-bluetooth-tracker-140028377.html?src=rss",
          "feed_position": 28,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2023-02/94489620-abc7-11ed-b375-842957054bf1"
        },
        {
          "source": "Guardian Tech",
          "url": "https://www.theguardian.com/science/2026/feb/02/elon-musk-spacex-xai-merger",
          "published_at": "Tue, 03 Feb 2026 07:25:18 GMT",
          "title": "Elon Musk merges SpaceX with xAI at $1.25tn valuation",
          "standfirst": "Aerospace business and artificial intelligence firm to unite for IPO as world’s most valuable private companyMusk is taking SpaceX’s minority shareholders for a ride | Nils PratleyElon Musk’s aerospace company SpaceX has acquired his artificial intelligence business xAI, in a $1.25tn (£910bn) merger that consolidates part of Musk’s empire as SpaceX prepares to go public later this year.The two companies announced the deal on Monday in a statement on SpaceX’s website, saying the merger would form “the most ambitious, vertically-integrated innovation engine on (and off) Earth, with AI, rockets, space-based internet, direct-to-mobile device communications and the world’s foremost real-time information and free speech platform”. Continue reading...",
          "content": "Aerospace business and artificial intelligence firm to unite for IPO as world’s most valuable private companyMusk is taking SpaceX’s minority shareholders for a ride | Nils PratleyElon Musk’s aerospace company SpaceX has acquired his artificial intelligence business xAI, in a $1.25tn (£910bn) merger that consolidates part of Musk’s empire as SpaceX prepares to go public later this year.The two companies announced the deal on Monday in a statement on SpaceX’s website, saying the merger would form “the most ambitious, vertically-integrated innovation engine on (and off) Earth, with AI, rockets, space-based internet, direct-to-mobile device communications and the world’s foremost real-time information and free speech platform”. Continue reading...",
          "feed_position": 5
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/elon-musks-spacex-has-acquired-his-ai-company-xai-221617040.html",
          "published_at": "Mon, 02 Feb 2026 22:16:17 +0000",
          "title": "Elon Musk's SpaceX has acquired his AI company, xAI",
          "standfirst": "Elon Musk’s SpaceX has acquired Musk’s xAI, the companies announced. The merger will “form the most ambitious, vertically-integrated innovation engine on (and off) Earth, with AI, rockets, space-based internet, direct-to-mobile device communications and the world’s foremost real-time information and free speech platform,” Musk wrote in an update.The AI company that right now is best known for its CSAM-generating chatbot might seem like a strange fit for a rocket company. But SpaceX is key to Musk’s latest scheme to build AI data centers in space. In his update, Musk wrote that “global electricity demand for AI simply cannot be met with terrestrial solutions” and that moving the resource-intensive operations to space is “the only logical solution.” SpaceX just days ago filed an application with the FCC to create an “orbital data center” by launching a million new satellites.Musk also claimed that, eventually, space-based data centers will enable other advancements in space travel. “The capabilities we unlock by making space-based data centers a reality will fund and enable self-growing bases on the Moon, an entire civilization on Mars and ultimately expansion to the Universe.” Notably, it’s not the first time Musk has made lofty claims about Mars. He predicted in 2017 that SpaceX would send crewed missions to Mars by 2024. This also isn’t the first time Musk has acquired one of his own companies. He merged xAI and X last year, which means SpaceX now owns the social network Musk bought in 2022. And he recently announced that Tesla was investing $2 billion into xAI. SpaceX is planning to go public later this year in an initial public offering (IPO) that could value the company at more than $1 trillion, according to Bloomberg, which notes that SpaceX has also “discussed a possible merger with Tesla.”This article originally appeared on Engadget at https://www.engadget.com/ai/elon-musks-spacex-has-acquired-his-ai-company-xai-221617040.html?src=rss",
          "content": "Elon Musk’s SpaceX has acquired Musk’s xAI, the companies announced. The merger will “form the most ambitious, vertically-integrated innovation engine on (and off) Earth, with AI, rockets, space-based internet, direct-to-mobile device communications and the world’s foremost real-time information and free speech platform,” Musk wrote in an update.The AI company that right now is best known for its CSAM-generating chatbot might seem like a strange fit for a rocket company. But SpaceX is key to Musk’s latest scheme to build AI data centers in space. In his update, Musk wrote that “global electricity demand for AI simply cannot be met with terrestrial solutions” and that moving the resource-intensive operations to space is “the only logical solution.” SpaceX just days ago filed an application with the FCC to create an “orbital data center” by launching a million new satellites.Musk also claimed that, eventually, space-based data centers will enable other advancements in space travel. “The capabilities we unlock by making space-based data centers a reality will fund and enable self-growing bases on the Moon, an entire civilization on Mars and ultimately expansion to the Universe.” Notably, it’s not the first time Musk has made lofty claims about Mars. He predicted in 2017 that SpaceX would send crewed missions to Mars by 2024. This also isn’t the first time Musk has acquired one of his own companies. He merged xAI and X last year, which means SpaceX now owns the social network Musk bought in 2022. And he recently announced that Tesla was investing $2 billion into xAI. SpaceX is planning to go public later this year in an initial public offering (IPO) that could value the company at more than $1 trillion, according to Bloomberg, which notes that SpaceX has also “discussed a possible merger with Tesla.”This article originally appeared on Engadget at https://www.engadget.com/ai/elon-musks-spacex-has-acquired-his-ai-company-xai-221617040.html?src=rss",
          "feed_position": 31
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/shared-memory-is-the-missing-layer-in-ai-orchestration",
          "published_at": "Mon, 02 Feb 2026 20:34:00 GMT",
          "title": "Shared memory is the missing layer in AI orchestration",
          "standfirst": "The key to successful AI agents within an enterprise? Shared memory and context. This, according to Asana CPO Arnab Bose, provides detailed history and direct access from the get-go — with guardrail checkpoints and human oversight, of course. This way, “when you assign a task, you&#x27;re not having to go ahead and re-provide all of the context about how your business works,” Bose said at a recent VB event in San Francisco. AI as an active teammate, rather than a passive add-onAsana launched Asana AI Teammates last year with the philosophy that, just like humans, AI agents should be plugged directly into a team or project to create a collaborative system. To further this mission, the project management company has fully integrated with Anthropic’s Claude. Users can choose from 12 pre-built agents — for common use cases like IT ticket deflection — or build their own, then assign them to project teams and immediately provide a historical record of what tasks have already been completed and what is still yet to be resolved. Agents also have access to third-party resources like Microsoft 365 or Google Drive. “When that agent gets created, it&#x27;s not acting on behalf of someone, it manifests itself as a teammate and it gets all of the same sharing permissions, it inherits that,” Bose explained. Everything anyone does — humans and AI included — is documented to allow for “ease of explainability” and a “very transparent and trustworthy system.”But just like human workers, AI agents are kept in check: Critically, workflows incorporate checkpoints, where humans can give feedback and ask the agent to tweak certain elements of a project or adjust research plans. This is documented in what Bose called a “very human-readable way.” Also importantly, the UI provides instructions and knowledge about agent behavior, and approved admins can pause, edit and redirect models in the API when they take actions based on conflicting directions or start acting “in a weird way.”“The person with edit rights can delete those things that are conflicting and make it go back to its correct behavior,” said Bose. “We&#x27;re leaning into that common human-understandable interaction pattern.”Overcoming challenges of authorization, integration But because AI agents are so new, there are still many challenges around security, accessibility and compatibility. Asana users, for instance, must go through an OAuth flow and grant Claude access to Asana via their MCP and other public APIs. But getting all knowledge workers to know that that integration exists — and more importantly, which OAuth grants are OK and which are to be avoided — can be a tall order.Some of the challenges around direct OAuth grants between applications could be centralized by identity providers, Bose noted, or a centralized listing of approved enterprise AI agents with their skill sets, “almost like an active directory or universal directory of agents.”Right now, though, beyond what Asana is doing, there’s no standard protocol around shared knowledge and memory, said Bose. His team has been getting “a lot of interesting inbound asks” from partners who want their agents to operate on the Asana work graph and benefit from shared work.“But because the protocol or standard doesn&#x27;t exist, today it has to be a very custom bespoke conversation,” said Bose. Ultimately, there are three questions the CPO called “extremely interesting” in AI orchestration right now: How do you build, manage and secure an authoritative list of known approved AI agents? How can you enable app-to-app integrations as an IT team without potentially configuring dangerous or harmful agents?Today’s agent-to-agent interactions are very single player. Clouds can independently be connected to Asana or Figma or Slack. How can we finally get to a unified, multi-player outcome?The increased adoption of modern context protocol (MCP) — the open standard introduced by Anthropic that connects AI agents to external systems in a single action, rather than custom integrations for every single pairing — is promising, he noted, and its widespread adoption could open up new and exciting use cases.However, “I think there probably isn&#x27;t a silver bullet standard out there right now,” said Bose.",
          "content": "The key to successful AI agents within an enterprise? Shared memory and context. This, according to Asana CPO Arnab Bose, provides detailed history and direct access from the get-go — with guardrail checkpoints and human oversight, of course. This way, “when you assign a task, you&#x27;re not having to go ahead and re-provide all of the context about how your business works,” Bose said at a recent VB event in San Francisco. AI as an active teammate, rather than a passive add-onAsana launched Asana AI Teammates last year with the philosophy that, just like humans, AI agents should be plugged directly into a team or project to create a collaborative system. To further this mission, the project management company has fully integrated with Anthropic’s Claude. Users can choose from 12 pre-built agents — for common use cases like IT ticket deflection — or build their own, then assign them to project teams and immediately provide a historical record of what tasks have already been completed and what is still yet to be resolved. Agents also have access to third-party resources like Microsoft 365 or Google Drive. “When that agent gets created, it&#x27;s not acting on behalf of someone, it manifests itself as a teammate and it gets all of the same sharing permissions, it inherits that,” Bose explained. Everything anyone does — humans and AI included — is documented to allow for “ease of explainability” and a “very transparent and trustworthy system.”But just like human workers, AI agents are kept in check: Critically, workflows incorporate checkpoints, where humans can give feedback and ask the agent to tweak certain elements of a project or adjust research plans. This is documented in what Bose called a “very human-readable way.” Also importantly, the UI provides instructions and knowledge about agent behavior, and approved admins can pause, edit and redirect models in the API when they take actions based on conflicting directions or start acting “in a weird way.”“The person with edit rights can delete those things that are conflicting and make it go back to its correct behavior,” said Bose. “We&#x27;re leaning into that common human-understandable interaction pattern.”Overcoming challenges of authorization, integration But because AI agents are so new, there are still many challenges around security, accessibility and compatibility. Asana users, for instance, must go through an OAuth flow and grant Claude access to Asana via their MCP and other public APIs. But getting all knowledge workers to know that that integration exists — and more importantly, which OAuth grants are OK and which are to be avoided — can be a tall order.Some of the challenges around direct OAuth grants between applications could be centralized by identity providers, Bose noted, or a centralized listing of approved enterprise AI agents with their skill sets, “almost like an active directory or universal directory of agents.”Right now, though, beyond what Asana is doing, there’s no standard protocol around shared knowledge and memory, said Bose. His team has been getting “a lot of interesting inbound asks” from partners who want their agents to operate on the Asana work graph and benefit from shared work.“But because the protocol or standard doesn&#x27;t exist, today it has to be a very custom bespoke conversation,” said Bose. Ultimately, there are three questions the CPO called “extremely interesting” in AI orchestration right now: How do you build, manage and secure an authoritative list of known approved AI agents? How can you enable app-to-app integrations as an IT team without potentially configuring dangerous or harmful agents?Today’s agent-to-agent interactions are very single player. Clouds can independently be connected to Asana or Figma or Slack. How can we finally get to a unified, multi-player outcome?The increased adoption of modern context protocol (MCP) — the open standard introduced by Anthropic that connects AI agents to external systems in a single action, rather than custom integrations for every single pairing — is promising, he noted, and its widespread adoption could open up new and exciting use cases.However, “I think there probably isn&#x27;t a silver bullet standard out there right now,” said Bose.",
          "feed_position": 4,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/hgdgcVYh6eTScx5sg3xmL/51a2bb25a7e65cb132358db07dcc2315/Connecting_data.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/smartphones/samsung-galaxy-a17-5g-review-a-respectable-and-affordable-android-option-190000154.html",
          "published_at": "Mon, 02 Feb 2026 19:00:00 +0000",
          "title": "Samsung Galaxy A17 5G review: A respectable and affordable Android option",
          "standfirst": "Buying a good budget phone can be a challenge. High-end handsets continue to get more features, but on the other end of the spectrum, there are only so many things you can skimp on before a device becomes too compromised. With the Galaxy A17, Samsung is trying to balance both sides of that equation with something that sports a solid design, a bright screen, decent cameras and respectable battery life for just $200. And despite some flaws, the company has succeeded at making a capable phone that fits into almost every budget. Design and display The Galaxy A17 does a good job of demonstrating how all plastics aren't the same. Despite having a polycarbonate frame and back, the phone never feels cheap. Everything from its buttons to its camera module feels nice and tight. The optical image stabilization system used for its rear shooters rattles, though that’s something even $1,000 flagships suffer from, so it’s not a big deal. Some small concessions for cost savings include a teardrop cutout for its front selfie cam and a small chin beneath its display, but considering its price, they're very forgivable. There's also only a single mono speaker and instead of an in-screen fingerprint sensor, Samsung built one into the power button on its side. Though for some, the latter might actually be a bonus. The Galaxy A17's 6.7-inch OLED display is one of the phone's best components thanks to solid brightness and a 90Hz refresh rate. Sam Rutherford for Engadget Meanwhile, one thing the A17 has that you don't get on high-end handsets anymore is a microSD card slot (that's shared with its SIM tray) for expandable storage. This gives you a cheap way to increase the phone's base 128GB of space and considering how rare this is nowadays, it’s another win for people looking for a truly affordable device. The Galaxy A17's screen is also surprisingly nice for its price, as it sports a 6.7-inch OLED display with up to 800 nits of brightness. Granted, its refresh rate tops out at 90Hz instead of the 120Hz you get on more expensive fare. But once again, considering how much it costs, I'm not complaining. Especially when you remember that base iPhones were still saddled with 60Hz panels as recently as 2024. Performance One area where budget phones often struggle is performance because skimping on RAM or the processor can save manufacturers a lot of money. And while the Galaxy A17 is generally fine considering its price bracket, I really wish Samsung had opted for a slightly newer chip. The phone comes with just 4GB of RAM (though there are slightly pricier versions with more), 128GB of onboard storage and an Exynos 1330 SoC, the latter of which is nearly three years old. The Galaxy A17 comes with three rear cameras, but its really more like two because one of those is a 2MP macro cam. Sam Rutherford for Engadget At first, I was really worried because during the initial setup, the phone was a laggy, stuttery mess. Thankfully, after signing in, giving the phone some time to download updates in the background and making sure all of its apps were up to date, performance improved significantly. To be clear, this thing still isn't a speed demon and when you're multitasking or quickly switching between heavy apps, you may notice some slowdown. I also wish touch input felt a bit more responsive because sometimes when you tap an icon, there's a small delay before anything happens. But thankfully, it's relatively minor, and in most situations, the phone is snappy enough. Cameras The A17 comes with a 13-megapixel selfie camera and three rear shooters, though in practice it's really more like two because one of those is a 2MP macro cam, which doesn't get much use unless you take a lot of up-close photos. That said, the phone takes better pictures than you might expect given its price. In well-lit conditions, both its 50MP main and 5MP ultrawide cams don't give you much to complain about. Images look sharp and sport vivid colors. However, in low-light situations, there's an obvious difference in quality between the A17 and more expensive midrange phones like Pixel 9a. In a shot of some fruit in my dimly lit kitchen, the A17's pic looks soft and features washed-out colors compared to what Google's phone produced. Then, when I went outside and snapped a photo of a car still buried after the recent snowstorm, textures on the slush in the road, along with various highlights and shadows looked worse in the A17's images. So while the phone can hold its own, camera quality is still one of the biggest reasons you might want to consider upgrading to a more expensive handset. Battery life The bottom of the Galaxy A17 features the phone's USB-C port and its single, mono speaker. Sam Rutherford for Engadget For a phone with a 5,000mAh battery and a low-power chip, the Galaxy A17 didn't last quite as long as I expected. On our local video rundown test, it lasted just over 23 hours (23:08), which is decent, but also five hours less than the Pixel 9a (28:04). On the other hand, its wired charging speed of 25 watts is more than enough. Just don't be surprised when you plop it on a wireless charging pad and nothing happens because the phone doesn't support that. Wrap-up If you are hard-capped at $200, the Samsung Galaxy A17 is a surprisingly impressive device. It's got a solid build, decent cameras with a handful of different lenses, respectable battery life and even a built-in microSD card slot for extra storage. You even get six years of OS and security updates, which is significantly longer than almost all of its similarly-priced rivals. And while its performance could be smoother, it's not laggy enough to get truly bothered about on a phone this affordable. Even though the Galaxy A17 is made out of plastic, the phone still doesn't feel cheap. Sam Rutherford for Engadget For those with wiggle room in their gadget allowance, I would seriously consider looking at a version with 8GB of RAM, which is just $30 more. Alternatively, the Pixel 9a remains my favorite Android phone when it comes to value for money and it’s $399 (down from its launch price of $499). But if money is tight, the Galaxy A17 delivers everything you need without blowing up your budget. This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/samsung-galaxy-a17-5g-review-a-respectable-and-affordable-android-option-190000154.html?src=rss",
          "content": "Buying a good budget phone can be a challenge. High-end handsets continue to get more features, but on the other end of the spectrum, there are only so many things you can skimp on before a device becomes too compromised. With the Galaxy A17, Samsung is trying to balance both sides of that equation with something that sports a solid design, a bright screen, decent cameras and respectable battery life for just $200. And despite some flaws, the company has succeeded at making a capable phone that fits into almost every budget. Design and display The Galaxy A17 does a good job of demonstrating how all plastics aren't the same. Despite having a polycarbonate frame and back, the phone never feels cheap. Everything from its buttons to its camera module feels nice and tight. The optical image stabilization system used for its rear shooters rattles, though that’s something even $1,000 flagships suffer from, so it’s not a big deal. Some small concessions for cost savings include a teardrop cutout for its front selfie cam and a small chin beneath its display, but considering its price, they're very forgivable. There's also only a single mono speaker and instead of an in-screen fingerprint sensor, Samsung built one into the power button on its side. Though for some, the latter might actually be a bonus. The Galaxy A17's 6.7-inch OLED display is one of the phone's best components thanks to solid brightness and a 90Hz refresh rate. Sam Rutherford for Engadget Meanwhile, one thing the A17 has that you don't get on high-end handsets anymore is a microSD card slot (that's shared with its SIM tray) for expandable storage. This gives you a cheap way to increase the phone's base 128GB of space and considering how rare this is nowadays, it’s another win for people looking for a truly affordable device. The Galaxy A17's screen is also surprisingly nice for its price, as it sports a 6.7-inch OLED display with up to 800 nits of brightness. Granted, its refresh rate tops out at 90Hz instead of the 120Hz you get on more expensive fare. But once again, considering how much it costs, I'm not complaining. Especially when you remember that base iPhones were still saddled with 60Hz panels as recently as 2024. Performance One area where budget phones often struggle is performance because skimping on RAM or the processor can save manufacturers a lot of money. And while the Galaxy A17 is generally fine considering its price bracket, I really wish Samsung had opted for a slightly newer chip. The phone comes with just 4GB of RAM (though there are slightly pricier versions with more), 128GB of onboard storage and an Exynos 1330 SoC, the latter of which is nearly three years old. The Galaxy A17 comes with three rear cameras, but its really more like two because one of those is a 2MP macro cam. Sam Rutherford for Engadget At first, I was really worried because during the initial setup, the phone was a laggy, stuttery mess. Thankfully, after signing in, giving the phone some time to download updates in the background and making sure all of its apps were up to date, performance improved significantly. To be clear, this thing still isn't a speed demon and when you're multitasking or quickly switching between heavy apps, you may notice some slowdown. I also wish touch input felt a bit more responsive because sometimes when you tap an icon, there's a small delay before anything happens. But thankfully, it's relatively minor, and in most situations, the phone is snappy enough. Cameras The A17 comes with a 13-megapixel selfie camera and three rear shooters, though in practice it's really more like two because one of those is a 2MP macro cam, which doesn't get much use unless you take a lot of up-close photos. That said, the phone takes better pictures than you might expect given its price. In well-lit conditions, both its 50MP main and 5MP ultrawide cams don't give you much to complain about. Images look sharp and sport vivid colors. However, in low-light situations, there's an obvious difference in quality between the A17 and more expensive midrange phones like Pixel 9a. In a shot of some fruit in my dimly lit kitchen, the A17's pic looks soft and features washed-out colors compared to what Google's phone produced. Then, when I went outside and snapped a photo of a car still buried after the recent snowstorm, textures on the slush in the road, along with various highlights and shadows looked worse in the A17's images. So while the phone can hold its own, camera quality is still one of the biggest reasons you might want to consider upgrading to a more expensive handset. Battery life The bottom of the Galaxy A17 features the phone's USB-C port and its single, mono speaker. Sam Rutherford for Engadget For a phone with a 5,000mAh battery and a low-power chip, the Galaxy A17 didn't last quite as long as I expected. On our local video rundown test, it lasted just over 23 hours (23:08), which is decent, but also five hours less than the Pixel 9a (28:04). On the other hand, its wired charging speed of 25 watts is more than enough. Just don't be surprised when you plop it on a wireless charging pad and nothing happens because the phone doesn't support that. Wrap-up If you are hard-capped at $200, the Samsung Galaxy A17 is a surprisingly impressive device. It's got a solid build, decent cameras with a handful of different lenses, respectable battery life and even a built-in microSD card slot for extra storage. You even get six years of OS and security updates, which is significantly longer than almost all of its similarly-priced rivals. And while its performance could be smoother, it's not laggy enough to get truly bothered about on a phone this affordable. Even though the Galaxy A17 is made out of plastic, the phone still doesn't feel cheap. Sam Rutherford for Engadget For those with wiggle room in their gadget allowance, I would seriously consider looking at a version with 8GB of RAM, which is just $30 more. Alternatively, the Pixel 9a remains my favorite Android phone when it comes to value for money and it’s $399 (down from its launch price of $499). But if money is tight, the Galaxy A17 delivers everything you need without blowing up your budget. This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/samsung-galaxy-a17-5g-review-a-respectable-and-affordable-android-option-190000154.html?src=rss",
          "feed_position": 36,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/a17-display.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/openai-brings-its-codex-coding-app-to-mac-with-new-multi-agent-abilities-included-183103262.html",
          "published_at": "Mon, 02 Feb 2026 18:31:03 +0000",
          "title": "OpenAI brings its Codex coding app to Mac, with new multi-agent abilities included",
          "standfirst": "Since last spring, OpenAI has offered Codex. What started life as the company's response to Claude Code is becoming something more sophisticated with the release of a new dedicated macOS app. At its most basic form, Codex is a programming agent capable of writing code for users, but now it can also manage multiple AI assistants that can work together to complete more complex tasks.OpenAI gives an example of how this could work in practice. The company used Codex to create a Mario Kart-like racing game, complete with a selection of different playable cars, eight tracks and a collection of powerups players can use against the competition. For a single AI agent, generating a game from scratch, with all the needed visual assets, would be a tough ask, but Codex was able to complete the task because it could delegate the work of making the game to different models with complementary capabilities. For example, it turned to GPT Image for the visual assets, while a separate model simultaneously coded the web game. \"It took on the roles of designer, game developer and QA tester to validate its work by actually playing the game,\" OpenAI says of the process. If that sounds complicated, OpenAI has tried to make it more approachable with a section of the app titled Skills. The feature bundles “instructions, resources, and scripts so Codex can reliably connect to tools, run workflows, and complete tasks according to your team’s preferences,\" the company explains. \"The Codex app includes a dedicated interface to create and manage skills. You can explicitly ask Codex to use specific skills, or let it automatically use them based on the task at hand.\"As you might imagine, Codex can also automate repetitive tasks. A dedicated Automations section of the app allows you to schedule tasks, which the software will complete in the background. \"At OpenAI, we’ve been using Automations to handle the repetitive but important tasks, like daily issue triage, finding and summarizing CI failures, generating daily release briefs, checking for bugs, and more,\" the company said. The release of the Codex macOS app comes as AI startups explore what a group of AI agents working in parallel can accomplish. At the start of the year, Anysphere, the company behind Cursor, found it was possible to build a working web browser from scratch using such an approach, though it did encounter problems along the way. For a limited time, OpenAI is making Codex available to ChatGPT Free and Go users so they can see what's possible with this new software. At the same time, the company is doubling rates for Plus and Pro subscribers. This article originally appeared on Engadget at https://www.engadget.com/ai/openai-brings-its-codex-coding-app-to-mac-with-new-multi-agent-abilities-included-183103262.html?src=rss",
          "content": "Since last spring, OpenAI has offered Codex. What started life as the company's response to Claude Code is becoming something more sophisticated with the release of a new dedicated macOS app. At its most basic form, Codex is a programming agent capable of writing code for users, but now it can also manage multiple AI assistants that can work together to complete more complex tasks.OpenAI gives an example of how this could work in practice. The company used Codex to create a Mario Kart-like racing game, complete with a selection of different playable cars, eight tracks and a collection of powerups players can use against the competition. For a single AI agent, generating a game from scratch, with all the needed visual assets, would be a tough ask, but Codex was able to complete the task because it could delegate the work of making the game to different models with complementary capabilities. For example, it turned to GPT Image for the visual assets, while a separate model simultaneously coded the web game. \"It took on the roles of designer, game developer and QA tester to validate its work by actually playing the game,\" OpenAI says of the process. If that sounds complicated, OpenAI has tried to make it more approachable with a section of the app titled Skills. The feature bundles “instructions, resources, and scripts so Codex can reliably connect to tools, run workflows, and complete tasks according to your team’s preferences,\" the company explains. \"The Codex app includes a dedicated interface to create and manage skills. You can explicitly ask Codex to use specific skills, or let it automatically use them based on the task at hand.\"As you might imagine, Codex can also automate repetitive tasks. A dedicated Automations section of the app allows you to schedule tasks, which the software will complete in the background. \"At OpenAI, we’ve been using Automations to handle the repetitive but important tasks, like daily issue triage, finding and summarizing CI failures, generating daily release briefs, checking for bugs, and more,\" the company said. The release of the Codex macOS app comes as AI startups explore what a group of AI agents working in parallel can accomplish. At the start of the year, Anysphere, the company behind Cursor, found it was possible to build a working web browser from scratch using such an approach, though it did encounter problems along the way. For a limited time, OpenAI is making Codex available to ChatGPT Free and Go users so they can see what's possible with this new software. At the same time, the company is doubling rates for Plus and Pro subscribers. This article originally appeared on Engadget at https://www.engadget.com/ai/openai-brings-its-codex-coding-app-to-mac-with-new-multi-agent-abilities-included-183103262.html?src=rss",
          "feed_position": 38
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/openai-launches-a-codex-desktop-app-for-macos-to-run-multiple-ai-coding",
          "published_at": "Mon, 02 Feb 2026 18:00:00 GMT",
          "title": "OpenAI launches a Codex desktop app for macOS to run multiple AI coding agents in parallel",
          "standfirst": "OpenAI on Monday released a new desktop application for its Codex artificial intelligence coding system, a tool the company says transforms software development from a collaborative exercise with a single AI assistant into something more akin to managing a team of autonomous workers.The Codex app for macOS functions as what OpenAI executives describe as a \"command center for agents,\" allowing developers to delegate multiple coding tasks simultaneously, automate repetitive work, and supervise AI systems that can run for up to 30 minutes independently before returning completed code.\"This is the most loved internal product we&#x27;ve ever had,\" Sam Altman, OpenAI&#x27;s chief executive, told VentureBeat in a press briefing ahead of Monday&#x27;s launch. \"It&#x27;s been totally an amazing thing for us to be using recently at OpenAI.\"The release arrives at a pivotal moment for the enterprise AI market. According to a survey of 100 Global 2000 companies published last week by venture capital firm Andreessen Horowitz, 78% of enterprise CIOs now use OpenAI models in production, though competitors Anthropic and Google are gaining ground rapidly. Anthropic posted the largest share increase of any frontier lab since May 2025, growing 25% in enterprise penetration, with 44% of enterprises now using Anthropic in production.The timing of OpenAI&#x27;s Codex app launch — with its focus on professional software engineering workflows — appears designed to defend the company&#x27;s position in what has become the most contested segment of the AI market: coding tools.Why developers are abandoning their IDEs for AI agent managementThe Codex app introduces a fundamentally different approach to AI-assisted coding. While previous tools like GitHub Copilot focused on autocompleting lines of code in real-time, the new application enables developers to \"effortlessly manage multiple agents at once, run work in parallel, and collaborate with agents over long-running tasks.\"Alexander Embiricos, the product lead for Codex, explained the evolution during the press briefing by tracing the product&#x27;s lineage back to 2021, when OpenAI first introduced a model called Codex that powered GitHub Copilot.\"Back then, people were using AI to write small chunks of code in their IDEs,\" Embiricos said. \"GPT-5 in August last year was a big jump, and then 5.2 in December was another massive jump, where people started doing longer and longer tasks, asking models to do work end to end. So what we saw is that developers, instead of working closely with the model, pair coding, they started delegating entire features.\"The shift has been so profound that Altman said he recently completed a substantial coding project without ever opening a traditional integrated development environment.\"I was astonished by this…I did this fairly big project in a few days earlier this week and over the weekend. I did not open an IDE during the process. Not a single time,\" Altman said. \"I did look at some code, but I was not doing it the old-fashioned way, and I did not think that was going to be happening by now.\"How skills and automations extend AI coding beyond simple code generationThe Codex app introduces several new capabilities designed to extend AI coding beyond writing lines of code. Chief among these are \"Skills,\" which bundle instructions, resources, and scripts so that Codex can \"reliably connect to tools, run workflows, and complete tasks according to your team&#x27;s preferences.\"The app includes a dedicated interface for creating and managing skills, and users can explicitly invoke specific skills or allow the system to automatically select them based on the task at hand. OpenAI has published a library of skills for common workflows, including tools to fetch design context from Figma, manage projects in Linear, deploy web applications to cloud hosts like Cloudflare and Vercel, generate images using GPT Image, and create professional documents in PDF, spreadsheet, and Word formats.To demonstrate the system&#x27;s capabilities, OpenAI asked Codex to build a racing game from a single prompt. Using an image generation skill and a web game development skill, Codex built the game by working independently using more than 7 million tokens with just one initial user prompt, taking on \"the roles of designer, game developer, and QA tester to validate its work by actually playing the game.\"The company has also introduced \"Automations,\" which allow developers to schedule Codex to work in the background on an automatic schedule. \"When an Automation finishes, the results land in a review queue so you can jump back in and continue working if needed.\"Thibault Sottiaux, who leads the Codex team at OpenAI, described how the company uses these automations internally: \"We&#x27;ve been using Automations to handle the repetitive but important tasks, like daily issue triage, finding and summarizing CI failures, generating daily release briefs, checking for bugs, and more.\"The app also includes built-in support for \"worktrees,\" allowing multiple agents to work on the same repository without conflicts. \"Each agent works on an isolated copy of your code, allowing you to explore different paths without needing to track how they impact your codebase.\"OpenAI battles Anthropic and Google for control of enterprise AI spendingThe launch comes as enterprise spending on AI coding tools accelerates dramatically. According to the Andreessen Horowitz survey, average enterprise AI spend on large language models has risen from approximately $4.5 million to $7 million over the last two years, with enterprises expecting growth of another 65% this year to approximately $11.6 million.Leadership in the enterprise AI market varies significantly by use case. OpenAI dominates \"early, horizontal use cases like general purpose chatbots, enterprise knowledge management and customer support,\" while Anthropic leads in \"software development and data analysis, where CIOs consistently cite rapid capability gains since the second half of 2024.\"When asked during the press briefing how Codex differentiates from Anthropic&#x27;s Claude Code, which has been described as having its \"ChatGPT moment,\" Sottiaux emphasized OpenAI&#x27;s focus on model capability for long-running tasks.\"One of the things that our models are extremely good at—they really sit at the frontier of intelligence and doing reliable work for long periods of time,\" Sottiaux said. \"This is also what we&#x27;re optimizing this new surface to be very good at, so that you can start many parallel agents and coordinate them over long periods of time and not get lost.\"Altman added that while many tools can handle \"vibe coding front ends,\" OpenAI&#x27;s 5.2 model remains \"the strongest model by far\" for sophisticated work on complex systems.\"Taking that level of model capability and putting it in an interface where you can do what Thibault was saying, we think is going to matter quite a bit,\" Altman said. \"That&#x27;s probably the, at least listening to users and sort of looking at the chatter on social that&#x27;s that&#x27;s the single biggest differentiator.\"The surprising satisfies on AI progress: how fast humans can typeThe philosophical underpinning of the Codex app reflects a view that OpenAI executives have been articulating for months: that human limitations — not AI capabilities — now constitute the primary constraint on productivity.In a December appearance on Lenny’s Podcast, Embiricos described human typing speed as \"the current underappreciated limiting factor\" to achieving artificial general intelligence. The logic: if AI can perform complex coding tasks but humans can&#x27;t write prompts or review outputs fast enough, progress stalls.The Codex app attempts to address this by enabling what the team calls an \"abundance mindset\" — running multiple tasks in parallel rather than perfecting single requests. During the briefing, Embiricos described how power users at OpenAI work with the tool.\"Last night, I was working on the app, and I was making a few changes, and all of these changes are able to run in parallel together. And I was just sort of going between them, managing them,\" Embiricos said. \"Behind the scenes, all these tasks are running on something called gate work trees, which means that the agents are running independently, and you don&#x27;t have to manage them.\"In the Sequoia Capital podcast \"Training Data,\" Embiricos elaborated on this mindset shift: \"The mindset that works really well for Codex is, like, kind of like this abundance mindset and, like, hey, let&#x27;s try anything. Let&#x27;s try anything even multiple times and see what works.\" He noted that when users run 20 or more tasks in a day or an hour, \"they&#x27;ve probably understood basically how to use the tool.\"Building trust through sandboxes: how OpenAI secures autonomous coding agentsOpenAI has built security measures into the Codex architecture from the ground up. The app uses \"native, open-source and configurable system-level sandboxing,\" and by default, \"Codex agents are limited to editing files in the folder or branch where they&#x27;re working and using cached web search, then asking for permission to run commands that require elevated permissions like network access.\"Embiricos elaborated on the security approach during the briefing, noting that OpenAI has open-sourced its sandbox technology.\"Codex has this sandbox that we&#x27;re actually incredibly proud of, and it&#x27;s open source, so you can go check it out,\" Embiricos said. The sandbox \"basically ensures that when the agent is working on your computer, it can only make writes in a specific folder that you want it to make rights into, and it doesn&#x27;t access network without information.\"The system also includes a granular permission model that allows users to configure persistent approvals for specific actions, avoiding the need to repeatedly authorize routine operations. \"If the agent wants to do something and you find yourself annoyed that you&#x27;re constantly having to approve it, instead of just saying, &#x27;All right, you can do everything,&#x27; you can just say, &#x27;Hey, remember this one thing — I&#x27;m actually okay with you doing this going forward,&#x27;\" Embiricos explained.Altman emphasized that the permission architecture signals a broader philosophy about AI safety in agentic systems.\"I think this is going to be really important. I mean, it&#x27;s been so clear to us using this, how much you want it to have control of your computer, and how much you need it,\" Altman said. \"And the way the team built Codex such that you can sensibly limit what&#x27;s happening and also pick the level of control you&#x27;re comfortable with is important.\"He also acknowledged the dual-use nature of the technology. \"We do expect to get to our internal cybersecurity high moment of our models very soon. We&#x27;ve been preparing for this. We&#x27;ve talked about our mitigation plan,\" Altman said. \"A real thing for the world to contend with is going to be defending against a lot of capable cybersecurity threats using these models very quickly.\"The same capabilities that make Codex valuable for fixing bugs and refactoring code could, in the wrong hands, be used to discover vulnerabilities or write malicious software—a tension that will only intensify as AI coding agents become more capable.From Android apps to research breakthroughs: how Codex transformed OpenAI&#x27;s own operationsPerhaps the most compelling evidence for Codex&#x27;s capabilities comes from OpenAI&#x27;s own use of the tool. Sottiaux described how the system has accelerated internal development.\"A Sora Android app is an example of that where four engineers shipped in only 18 days internally, and then within the month we give access to the world,\" Sottiaux said. \"I had never noticed such speed at this scale before.\"Beyond product development, Sottiaux described how Codex has become integral to OpenAI&#x27;s research operations.\"Codex is really involved in all parts of the research — making new data sets, investigating its own screening runs,\" he said. \"When I sit in meetings with researchers, they all send Codex off to do an investigation while we&#x27;re having a chat, and then it will come back with useful information, and we&#x27;re able to debug much faster.\"The tool has also begun contributing to its own development. \"Codex also is starting to build itself,\" Sottiaux noted. \"There&#x27;s no screen within the Codex engineering team that doesn&#x27;t have Codex running on multiple, six, eight, ten, tasks at a time.\"When asked whether this constitutes evidence of \"recursive self-improvement\" — a concept that has long concerned AI safety researchers — Sottiaux was measured in his response.\"There is a human in the loop at all times,\" he said. \"I wouldn&#x27;t necessarily call it recursive self-improvement, a glimpse into the future there.\"Altman offered a more expansive view of the research implications.\"There&#x27;s two parts of what people talk about when they talk about automating research to a degree where you can imagine that happening,\" Altman said. \"One is, can you write software, extremely complex infrastructure, software to run training jobs across hundreds of thousands of GPUs and babysit them. And the second is, can you come up with the new scientific ideas that make algorithms more efficient.\"He noted that OpenAI is \"seeing early but promising signs on both of those.\"The end of technical debt? AI agents take on the work engineers hate mostOne of the more unexpected applications of Codex has been addressing technical debt — the accumulated maintenance burden that plagues most software projects.Altman described how AI coding agents excel at the unglamorous work that human engineers typically avoid.\"The kind of work that human engineers hate to do — go refactor this, clean up this code base, rewrite this, write this test — this is where the model doesn&#x27;t care. The model will do anything, whether it&#x27;s fun or not,\" Altman said.He reported that some infrastructure teams at OpenAI that \"had sort of like, given up hope that you were ever really going to long term win the war against tech debt, are now like, we&#x27;re going to win this, because the model is going to constantly be working behind us, making sure we have great test coverage, making sure that we refactor when we&#x27;re supposed to.\"The observation speaks to a broader theme that emerged repeatedly during the briefing: AI coding agents don&#x27;t experience the motivational fluctuations that affect human programmers. As Altman noted, a team member recently observed that \"the hardest mental adjustment to make about working with these sort of like aI coding teammates, unlike a human, is the models just don&#x27;t run out of dopamine. They keep trying. They don&#x27;t run out of motivation. They don&#x27;t get, you know, they don&#x27;t lose energy when something&#x27;s not working. They just keep going and, you know, they figure out how to get it done.\"What the Codex app costs and who can use it starting todayThe Codex app launches today on macOS and is available to anyone with a ChatGPT Plus, Pro, Business, Enterprise, or Edu subscription. Usage is included in ChatGPT subscriptions, with the option to purchase additional credits if needed.In a promotional push, OpenAI is temporarily making Codex available to ChatGPT Free and Go users \"to help more people try agentic workflows.\" The company is also doubling rate limits for existing Codex users across all paid plans during this promotional period.The pricing strategy reflects OpenAI&#x27;s determination to establish Codex as the default tool for AI-assisted development before competitors can gain further traction. More than a million developers have used Codex in the past month, and usage has nearly doubled since the launch of GPT-5.2-Codex in mid-December, building on more than 20x usage growth since August 2025.Customers using Codex include large enterprises like Cisco, Ramp, Virgin Atlantic, Vanta, Duolingo, and Gap, as well as startups like Harvey, Sierra, and Wonderful. Individual developers have also embraced the tool: Peter Steinberger, creator of OpenClaw, built the project entirely with Codex and reports that since fully switching to the tool, his productivity has roughly doubled across more than 82,000 GitHub contributions.OpenAI&#x27;s ambitious roadmap: Windows support, cloud triggers, and continuous background agentsOpenAI outlined an aggressive development roadmap for Codex. The company plans to make the app available on Windows, continue pushing \"the frontier of model capabilities,\" and roll out faster inference.Within the app, OpenAI will \"keep refining multi-agent workflows based on real-world feedback\" and is \"building out Automations with support for cloud-based triggers, so Codex can run continuously in the background—not just when your computer is open.\"The company also announced a new \"plan mode\" feature that allows Codex to read through complex changes in read-only mode, then discuss with the user before executing. \"This means that it lets you build a lot of confidence before, again, sending it to do a lot of work by itself, independently, in parallel to you,\" Embiricos explained.Additionally, OpenAI is introducing customizable personalities for Codex. \"The default personality for Codex has been quite terse. A lot of people love it, but some people want something more engaging,\" Embiricos said. Users can access the new personalities using the /personality command.Altman also hinted at future integration with ChatGPT&#x27;s broader ecosystem.\"There will be all kinds of cool things we can do over time to connect people&#x27;s ChatGPT accounts and leverage sort of all the history they&#x27;ve built up there,\" Altman said.Microsoft still dominates enterprise AI, but the window for disruption is openThe Codex app launch occurs as most enterprises have moved beyond single-vendor strategies. According to the Andreessen Horowitz survey, \"81% now use three or more model families in testing or production, up from 68% less than a year ago.\"Despite the proliferation of AI coding tools, Microsoft continues to dominate enterprise adoption through its existing relationships. \"Microsoft 365 Copilot leads enterprise chat though ChatGPT has closed the gap meaningfully,\" and \"Github Copilot is still the coding leader for enterprises.\" The survey found that \"65% of enterprises noted they preferred to go with incumbent solutions when available,\" citing trust, integration, and procurement simplicity.However, the survey also suggests significant opportunity for challengers: \"Enterprises consistently say they value faster innovation, deeper AI focus, and greater flexibility paired with cutting edge capabilities that AI native startups bring.\"OpenAI appears to be positioning Codex as a bridge between these worlds. \"Codex is built on a simple premise: everything is controlled by code,\" the company stated. \"The better an agent is at reasoning about and producing code, the more capable it becomes across all forms of technical and knowledge work.\"The company&#x27;s ambition extends beyond coding. \"We&#x27;ve focused on making Codex the best coding agent, which has also laid the foundation for it to become a strong agent for a broad range of knowledge work tasks that extend beyond writing code.\"When asked whether AI coding tools could eventually move beyond early adopters to become mainstream, Altman suggested the transition may be closer than many expect.\"Can it go from vibe coding to serious software engineering? That&#x27;s what this is about,\" Altman said. \"I think we are over the bar on that. I think this will be the way that most serious coders do their job — and very rapidly from now.\"He then pivoted to an even bolder prediction: that code itself could become the universal interface for all computer-based work.\"Code is a universal language to get computers to do what you want. And it&#x27;s gotten so good that I think, very quickly, we can go not just from vibe coding silly apps but to doing all the non-coding knowledge work,\" Altman said.At the close of the briefing, Altman urged journalists to try the product themselves: \"Please try the app. There&#x27;s no way to get this across just by talking about it. It&#x27;s a crazy amount of power.\"For developers who have spent careers learning to write code, the message was clear: the future belongs to those who learn to manage the machines that write it for them.",
          "content": "OpenAI on Monday released a new desktop application for its Codex artificial intelligence coding system, a tool the company says transforms software development from a collaborative exercise with a single AI assistant into something more akin to managing a team of autonomous workers.The Codex app for macOS functions as what OpenAI executives describe as a \"command center for agents,\" allowing developers to delegate multiple coding tasks simultaneously, automate repetitive work, and supervise AI systems that can run for up to 30 minutes independently before returning completed code.\"This is the most loved internal product we&#x27;ve ever had,\" Sam Altman, OpenAI&#x27;s chief executive, told VentureBeat in a press briefing ahead of Monday&#x27;s launch. \"It&#x27;s been totally an amazing thing for us to be using recently at OpenAI.\"The release arrives at a pivotal moment for the enterprise AI market. According to a survey of 100 Global 2000 companies published last week by venture capital firm Andreessen Horowitz, 78% of enterprise CIOs now use OpenAI models in production, though competitors Anthropic and Google are gaining ground rapidly. Anthropic posted the largest share increase of any frontier lab since May 2025, growing 25% in enterprise penetration, with 44% of enterprises now using Anthropic in production.The timing of OpenAI&#x27;s Codex app launch — with its focus on professional software engineering workflows — appears designed to defend the company&#x27;s position in what has become the most contested segment of the AI market: coding tools.Why developers are abandoning their IDEs for AI agent managementThe Codex app introduces a fundamentally different approach to AI-assisted coding. While previous tools like GitHub Copilot focused on autocompleting lines of code in real-time, the new application enables developers to \"effortlessly manage multiple agents at once, run work in parallel, and collaborate with agents over long-running tasks.\"Alexander Embiricos, the product lead for Codex, explained the evolution during the press briefing by tracing the product&#x27;s lineage back to 2021, when OpenAI first introduced a model called Codex that powered GitHub Copilot.\"Back then, people were using AI to write small chunks of code in their IDEs,\" Embiricos said. \"GPT-5 in August last year was a big jump, and then 5.2 in December was another massive jump, where people started doing longer and longer tasks, asking models to do work end to end. So what we saw is that developers, instead of working closely with the model, pair coding, they started delegating entire features.\"The shift has been so profound that Altman said he recently completed a substantial coding project without ever opening a traditional integrated development environment.\"I was astonished by this…I did this fairly big project in a few days earlier this week and over the weekend. I did not open an IDE during the process. Not a single time,\" Altman said. \"I did look at some code, but I was not doing it the old-fashioned way, and I did not think that was going to be happening by now.\"How skills and automations extend AI coding beyond simple code generationThe Codex app introduces several new capabilities designed to extend AI coding beyond writing lines of code. Chief among these are \"Skills,\" which bundle instructions, resources, and scripts so that Codex can \"reliably connect to tools, run workflows, and complete tasks according to your team&#x27;s preferences.\"The app includes a dedicated interface for creating and managing skills, and users can explicitly invoke specific skills or allow the system to automatically select them based on the task at hand. OpenAI has published a library of skills for common workflows, including tools to fetch design context from Figma, manage projects in Linear, deploy web applications to cloud hosts like Cloudflare and Vercel, generate images using GPT Image, and create professional documents in PDF, spreadsheet, and Word formats.To demonstrate the system&#x27;s capabilities, OpenAI asked Codex to build a racing game from a single prompt. Using an image generation skill and a web game development skill, Codex built the game by working independently using more than 7 million tokens with just one initial user prompt, taking on \"the roles of designer, game developer, and QA tester to validate its work by actually playing the game.\"The company has also introduced \"Automations,\" which allow developers to schedule Codex to work in the background on an automatic schedule. \"When an Automation finishes, the results land in a review queue so you can jump back in and continue working if needed.\"Thibault Sottiaux, who leads the Codex team at OpenAI, described how the company uses these automations internally: \"We&#x27;ve been using Automations to handle the repetitive but important tasks, like daily issue triage, finding and summarizing CI failures, generating daily release briefs, checking for bugs, and more.\"The app also includes built-in support for \"worktrees,\" allowing multiple agents to work on the same repository without conflicts. \"Each agent works on an isolated copy of your code, allowing you to explore different paths without needing to track how they impact your codebase.\"OpenAI battles Anthropic and Google for control of enterprise AI spendingThe launch comes as enterprise spending on AI coding tools accelerates dramatically. According to the Andreessen Horowitz survey, average enterprise AI spend on large language models has risen from approximately $4.5 million to $7 million over the last two years, with enterprises expecting growth of another 65% this year to approximately $11.6 million.Leadership in the enterprise AI market varies significantly by use case. OpenAI dominates \"early, horizontal use cases like general purpose chatbots, enterprise knowledge management and customer support,\" while Anthropic leads in \"software development and data analysis, where CIOs consistently cite rapid capability gains since the second half of 2024.\"When asked during the press briefing how Codex differentiates from Anthropic&#x27;s Claude Code, which has been described as having its \"ChatGPT moment,\" Sottiaux emphasized OpenAI&#x27;s focus on model capability for long-running tasks.\"One of the things that our models are extremely good at—they really sit at the frontier of intelligence and doing reliable work for long periods of time,\" Sottiaux said. \"This is also what we&#x27;re optimizing this new surface to be very good at, so that you can start many parallel agents and coordinate them over long periods of time and not get lost.\"Altman added that while many tools can handle \"vibe coding front ends,\" OpenAI&#x27;s 5.2 model remains \"the strongest model by far\" for sophisticated work on complex systems.\"Taking that level of model capability and putting it in an interface where you can do what Thibault was saying, we think is going to matter quite a bit,\" Altman said. \"That&#x27;s probably the, at least listening to users and sort of looking at the chatter on social that&#x27;s that&#x27;s the single biggest differentiator.\"The surprising satisfies on AI progress: how fast humans can typeThe philosophical underpinning of the Codex app reflects a view that OpenAI executives have been articulating for months: that human limitations — not AI capabilities — now constitute the primary constraint on productivity.In a December appearance on Lenny’s Podcast, Embiricos described human typing speed as \"the current underappreciated limiting factor\" to achieving artificial general intelligence. The logic: if AI can perform complex coding tasks but humans can&#x27;t write prompts or review outputs fast enough, progress stalls.The Codex app attempts to address this by enabling what the team calls an \"abundance mindset\" — running multiple tasks in parallel rather than perfecting single requests. During the briefing, Embiricos described how power users at OpenAI work with the tool.\"Last night, I was working on the app, and I was making a few changes, and all of these changes are able to run in parallel together. And I was just sort of going between them, managing them,\" Embiricos said. \"Behind the scenes, all these tasks are running on something called gate work trees, which means that the agents are running independently, and you don&#x27;t have to manage them.\"In the Sequoia Capital podcast \"Training Data,\" Embiricos elaborated on this mindset shift: \"The mindset that works really well for Codex is, like, kind of like this abundance mindset and, like, hey, let&#x27;s try anything. Let&#x27;s try anything even multiple times and see what works.\" He noted that when users run 20 or more tasks in a day or an hour, \"they&#x27;ve probably understood basically how to use the tool.\"Building trust through sandboxes: how OpenAI secures autonomous coding agentsOpenAI has built security measures into the Codex architecture from the ground up. The app uses \"native, open-source and configurable system-level sandboxing,\" and by default, \"Codex agents are limited to editing files in the folder or branch where they&#x27;re working and using cached web search, then asking for permission to run commands that require elevated permissions like network access.\"Embiricos elaborated on the security approach during the briefing, noting that OpenAI has open-sourced its sandbox technology.\"Codex has this sandbox that we&#x27;re actually incredibly proud of, and it&#x27;s open source, so you can go check it out,\" Embiricos said. The sandbox \"basically ensures that when the agent is working on your computer, it can only make writes in a specific folder that you want it to make rights into, and it doesn&#x27;t access network without information.\"The system also includes a granular permission model that allows users to configure persistent approvals for specific actions, avoiding the need to repeatedly authorize routine operations. \"If the agent wants to do something and you find yourself annoyed that you&#x27;re constantly having to approve it, instead of just saying, &#x27;All right, you can do everything,&#x27; you can just say, &#x27;Hey, remember this one thing — I&#x27;m actually okay with you doing this going forward,&#x27;\" Embiricos explained.Altman emphasized that the permission architecture signals a broader philosophy about AI safety in agentic systems.\"I think this is going to be really important. I mean, it&#x27;s been so clear to us using this, how much you want it to have control of your computer, and how much you need it,\" Altman said. \"And the way the team built Codex such that you can sensibly limit what&#x27;s happening and also pick the level of control you&#x27;re comfortable with is important.\"He also acknowledged the dual-use nature of the technology. \"We do expect to get to our internal cybersecurity high moment of our models very soon. We&#x27;ve been preparing for this. We&#x27;ve talked about our mitigation plan,\" Altman said. \"A real thing for the world to contend with is going to be defending against a lot of capable cybersecurity threats using these models very quickly.\"The same capabilities that make Codex valuable for fixing bugs and refactoring code could, in the wrong hands, be used to discover vulnerabilities or write malicious software—a tension that will only intensify as AI coding agents become more capable.From Android apps to research breakthroughs: how Codex transformed OpenAI&#x27;s own operationsPerhaps the most compelling evidence for Codex&#x27;s capabilities comes from OpenAI&#x27;s own use of the tool. Sottiaux described how the system has accelerated internal development.\"A Sora Android app is an example of that where four engineers shipped in only 18 days internally, and then within the month we give access to the world,\" Sottiaux said. \"I had never noticed such speed at this scale before.\"Beyond product development, Sottiaux described how Codex has become integral to OpenAI&#x27;s research operations.\"Codex is really involved in all parts of the research — making new data sets, investigating its own screening runs,\" he said. \"When I sit in meetings with researchers, they all send Codex off to do an investigation while we&#x27;re having a chat, and then it will come back with useful information, and we&#x27;re able to debug much faster.\"The tool has also begun contributing to its own development. \"Codex also is starting to build itself,\" Sottiaux noted. \"There&#x27;s no screen within the Codex engineering team that doesn&#x27;t have Codex running on multiple, six, eight, ten, tasks at a time.\"When asked whether this constitutes evidence of \"recursive self-improvement\" — a concept that has long concerned AI safety researchers — Sottiaux was measured in his response.\"There is a human in the loop at all times,\" he said. \"I wouldn&#x27;t necessarily call it recursive self-improvement, a glimpse into the future there.\"Altman offered a more expansive view of the research implications.\"There&#x27;s two parts of what people talk about when they talk about automating research to a degree where you can imagine that happening,\" Altman said. \"One is, can you write software, extremely complex infrastructure, software to run training jobs across hundreds of thousands of GPUs and babysit them. And the second is, can you come up with the new scientific ideas that make algorithms more efficient.\"He noted that OpenAI is \"seeing early but promising signs on both of those.\"The end of technical debt? AI agents take on the work engineers hate mostOne of the more unexpected applications of Codex has been addressing technical debt — the accumulated maintenance burden that plagues most software projects.Altman described how AI coding agents excel at the unglamorous work that human engineers typically avoid.\"The kind of work that human engineers hate to do — go refactor this, clean up this code base, rewrite this, write this test — this is where the model doesn&#x27;t care. The model will do anything, whether it&#x27;s fun or not,\" Altman said.He reported that some infrastructure teams at OpenAI that \"had sort of like, given up hope that you were ever really going to long term win the war against tech debt, are now like, we&#x27;re going to win this, because the model is going to constantly be working behind us, making sure we have great test coverage, making sure that we refactor when we&#x27;re supposed to.\"The observation speaks to a broader theme that emerged repeatedly during the briefing: AI coding agents don&#x27;t experience the motivational fluctuations that affect human programmers. As Altman noted, a team member recently observed that \"the hardest mental adjustment to make about working with these sort of like aI coding teammates, unlike a human, is the models just don&#x27;t run out of dopamine. They keep trying. They don&#x27;t run out of motivation. They don&#x27;t get, you know, they don&#x27;t lose energy when something&#x27;s not working. They just keep going and, you know, they figure out how to get it done.\"What the Codex app costs and who can use it starting todayThe Codex app launches today on macOS and is available to anyone with a ChatGPT Plus, Pro, Business, Enterprise, or Edu subscription. Usage is included in ChatGPT subscriptions, with the option to purchase additional credits if needed.In a promotional push, OpenAI is temporarily making Codex available to ChatGPT Free and Go users \"to help more people try agentic workflows.\" The company is also doubling rate limits for existing Codex users across all paid plans during this promotional period.The pricing strategy reflects OpenAI&#x27;s determination to establish Codex as the default tool for AI-assisted development before competitors can gain further traction. More than a million developers have used Codex in the past month, and usage has nearly doubled since the launch of GPT-5.2-Codex in mid-December, building on more than 20x usage growth since August 2025.Customers using Codex include large enterprises like Cisco, Ramp, Virgin Atlantic, Vanta, Duolingo, and Gap, as well as startups like Harvey, Sierra, and Wonderful. Individual developers have also embraced the tool: Peter Steinberger, creator of OpenClaw, built the project entirely with Codex and reports that since fully switching to the tool, his productivity has roughly doubled across more than 82,000 GitHub contributions.OpenAI&#x27;s ambitious roadmap: Windows support, cloud triggers, and continuous background agentsOpenAI outlined an aggressive development roadmap for Codex. The company plans to make the app available on Windows, continue pushing \"the frontier of model capabilities,\" and roll out faster inference.Within the app, OpenAI will \"keep refining multi-agent workflows based on real-world feedback\" and is \"building out Automations with support for cloud-based triggers, so Codex can run continuously in the background—not just when your computer is open.\"The company also announced a new \"plan mode\" feature that allows Codex to read through complex changes in read-only mode, then discuss with the user before executing. \"This means that it lets you build a lot of confidence before, again, sending it to do a lot of work by itself, independently, in parallel to you,\" Embiricos explained.Additionally, OpenAI is introducing customizable personalities for Codex. \"The default personality for Codex has been quite terse. A lot of people love it, but some people want something more engaging,\" Embiricos said. Users can access the new personalities using the /personality command.Altman also hinted at future integration with ChatGPT&#x27;s broader ecosystem.\"There will be all kinds of cool things we can do over time to connect people&#x27;s ChatGPT accounts and leverage sort of all the history they&#x27;ve built up there,\" Altman said.Microsoft still dominates enterprise AI, but the window for disruption is openThe Codex app launch occurs as most enterprises have moved beyond single-vendor strategies. According to the Andreessen Horowitz survey, \"81% now use three or more model families in testing or production, up from 68% less than a year ago.\"Despite the proliferation of AI coding tools, Microsoft continues to dominate enterprise adoption through its existing relationships. \"Microsoft 365 Copilot leads enterprise chat though ChatGPT has closed the gap meaningfully,\" and \"Github Copilot is still the coding leader for enterprises.\" The survey found that \"65% of enterprises noted they preferred to go with incumbent solutions when available,\" citing trust, integration, and procurement simplicity.However, the survey also suggests significant opportunity for challengers: \"Enterprises consistently say they value faster innovation, deeper AI focus, and greater flexibility paired with cutting edge capabilities that AI native startups bring.\"OpenAI appears to be positioning Codex as a bridge between these worlds. \"Codex is built on a simple premise: everything is controlled by code,\" the company stated. \"The better an agent is at reasoning about and producing code, the more capable it becomes across all forms of technical and knowledge work.\"The company&#x27;s ambition extends beyond coding. \"We&#x27;ve focused on making Codex the best coding agent, which has also laid the foundation for it to become a strong agent for a broad range of knowledge work tasks that extend beyond writing code.\"When asked whether AI coding tools could eventually move beyond early adopters to become mainstream, Altman suggested the transition may be closer than many expect.\"Can it go from vibe coding to serious software engineering? That&#x27;s what this is about,\" Altman said. \"I think we are over the bar on that. I think this will be the way that most serious coders do their job — and very rapidly from now.\"He then pivoted to an even bolder prediction: that code itself could become the universal interface for all computer-based work.\"Code is a universal language to get computers to do what you want. And it&#x27;s gotten so good that I think, very quickly, we can go not just from vibe coding silly apps but to doing all the non-coding knowledge work,\" Altman said.At the close of the briefing, Altman urged journalists to try the product themselves: \"Please try the app. There&#x27;s no way to get this across just by talking about it. It&#x27;s a crazy amount of power.\"For developers who have spent careers learning to write code, the message was clear: the future belongs to those who learn to manage the machines that write it for them.",
          "feed_position": 5,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/5ixq6lS6l5yrO3RJxCtr5w/c11ddd394c8969826452a5a30312234b/nuneybits_Vector_art_of_an_Apple_iMac_monitor_displaying_cascad_ecce1621-251d-41d9-ac6e-72eb25b2fd35.webp?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/expressvpn-two-year-plans-are-up-to-81-percent-off-right-now-180602205.html",
          "published_at": "Mon, 02 Feb 2026 16:15:36 +0000",
          "title": "ExpressVPN two-year plans are up to 81 percent off right now",
          "standfirst": "ExpressVPN is back on sale again, and its two-year plans are up to 81 percent off right now. You can get the Advanced tier for $88 for 28 months. This is marked down from the $392 that this time frame normally costs. On a per-month basis, it works out to roughly $3.14 for the promo period. We’ve consistently liked ExpressVPN because it’s fast, easy to use and widely available across a large global server network. In fact, it's our current pick for best premium VPN. One of the biggest drawbacks has always been its high cost, and this deal temporarily solves that issue. In our review we were able to get fast download and upload speeds, losing only 7 percent in the former and 2 percent in the latter worldwide. We found that it could unblock Netflix anywhere, and its mobile and desktop apps were simple to operate. We gave ExpressVPN an overall score of 85 out of 100. The virtual private network service now has three tiers. Basic is cheaper with fewer features, while Pro costs more and adds extra perks like support for 14 simultaneous devices and a password manager. Advanced sits in the middle and includes the password manager but only supports 12 devices.This article originally appeared on Engadget at https://www.engadget.com/deals/expressvpn-two-year-plans-are-up-to-81-percent-off-right-now-180602205.html?src=rss",
          "content": "ExpressVPN is back on sale again, and its two-year plans are up to 81 percent off right now. You can get the Advanced tier for $88 for 28 months. This is marked down from the $392 that this time frame normally costs. On a per-month basis, it works out to roughly $3.14 for the promo period. We’ve consistently liked ExpressVPN because it’s fast, easy to use and widely available across a large global server network. In fact, it's our current pick for best premium VPN. One of the biggest drawbacks has always been its high cost, and this deal temporarily solves that issue. In our review we were able to get fast download and upload speeds, losing only 7 percent in the former and 2 percent in the latter worldwide. We found that it could unblock Netflix anywhere, and its mobile and desktop apps were simple to operate. We gave ExpressVPN an overall score of 85 out of 100. The virtual private network service now has three tiers. Basic is cheaper with fewer features, while Pro costs more and adds extra perks like support for 14 simultaneous devices and a password manager. Advanced sits in the middle and includes the password manager but only supports 12 devices.This article originally appeared on Engadget at https://www.engadget.com/deals/expressvpn-two-year-plans-are-up-to-81-percent-off-right-now-180602205.html?src=rss",
          "feed_position": 44
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/super-bowl-2026-tv-deals-the-best-sales-this-week-on-oleds-and-other-smart-tvs-ahead-of-kickoff-160000485.html",
          "published_at": "Mon, 02 Feb 2026 15:43:20 +0000",
          "title": "Super Bowl 2026 TV deals: The best sales this week on OLEDs and other smart TVs ahead of kickoff",
          "standfirst": "The big game is one of the few instances now in the US where most people gather around the TV to watch the live event together. While the teams playing in Super Bowl 2026 are the true stars of the show (and Bad Bunny, of course), your TV is a pretty important part of the puzzle of putting together an excellent Super Bowl party. Maybe you’ve been thinking about replacing an aging set, or you’re itching for a full refresh of your home theater setup — either way, you’ll want to try to get a good deal on a new TV. Thankfully, the weeks leading up to the Super Bowl can be a great time to shop for a new TV. Generally, TV prices steadily decrease after a new model comes out. Some 2026 TV models were announced at CES and are forthcoming things year, making now a good time to look for discounts on 2025 sets. Aside from the holiday shopping season, now is one of the best times of the year to save on a TV. Here, we’ve curated the best Super Bowl TV deals we could find this year, from already affordable sets discounted even further to high-end OLEDs that are hundreds of dollars off. Super Bowl 2026 TV deals for less than $500 You can easily find solid 1080p and 4K TV sets within this budget-friendly price range. What you’ll be more limited in is size — most TV deals under $500 we’re seeing right now are on sets up to 55 inches. There are a few 65- and 75-inch models in there, but the pickings are slim. Hisense 32-inch Class A4 1080p FHD smart TV for $98 (18 percent off) Roku 24-inch 720p smart TV for $100 (18 percent off) TCL 40-inch Class S3 1080p smart TV for $150 (21 percent off) Roku 55-inch 4K smart TV for $248 (29 percent off) Roku 55-inch Mini LED 4K smart TV for $348 (30 percent off) TCL 75-inch Class S5 4K smart TV for $480 (26 percent off) OLED TV deals This is where you want to look if you want your new TV to have the richest colors, deepest blacks and excellent contrast performance. Of course, that all comes at steeper prices — it can be difficult to find a good OLED set for less than $1,000, even on sale. Sony 55-inch Bravia XR8B 4K smart TV for $998 (9 percent off) Samsung 65-inch Class OLED S95F 4K smart TV for $2,298 (23 percent off) Sony 77-inch Bravia XR A95L OLED 4K smart TV for $3,498 (30 percent off) Super Bowl 2026 TV deals for $500 and up This will likely be the sweet spot for many people when it comes to TV features, performance and price. Good 4K sets are common in this price range, and you’ll also find some Mini LED sets available here as well. TCL 65-inch Class T7 4K smart TV for $500 (29 percent off) Hisense 75-inch QD7 Mini-LED 4K smart TV for $548 (16 percent off) Amazon 65-inch Fire TV Omni Mini LED 4K smart TV for $920 (16 percent off) TCL 65-inch Class QM8K Mini LED 4K smart TV for $998 (33 percent off) Streaming and home entertainment deals A good TV is key, but having the right peripherals and accessories to go along with it will complete your home theater setup. Deals we’re tracking right now include discounts on streaming devices, soundbars and projectors. Sonos big game sale — up to 20 percent off home theater gear: Get the Sonos Beam soundbar for $130 off, the Era 300 speaker for $100 off and more Roku Streaming Stick HD 2025 for $16 (47 percent off) Roku Ultra streamer for $78 (22 percent off) Samsung HW B400F soundbar with built-in subwoofer for $100 (29 percent off) Anker Nebula Capsule 3 projector for $540 (28 percent off) Valerion VisionMaster Max 4K projector for $3,999 (20 percent off)This article originally appeared on Engadget at https://www.engadget.com/deals/super-bowl-2026-tv-deals-the-best-sales-this-week-on-oleds-and-other-smart-tvs-ahead-of-kickoff-160000485.html?src=rss",
          "content": "The big game is one of the few instances now in the US where most people gather around the TV to watch the live event together. While the teams playing in Super Bowl 2026 are the true stars of the show (and Bad Bunny, of course), your TV is a pretty important part of the puzzle of putting together an excellent Super Bowl party. Maybe you’ve been thinking about replacing an aging set, or you’re itching for a full refresh of your home theater setup — either way, you’ll want to try to get a good deal on a new TV. Thankfully, the weeks leading up to the Super Bowl can be a great time to shop for a new TV. Generally, TV prices steadily decrease after a new model comes out. Some 2026 TV models were announced at CES and are forthcoming things year, making now a good time to look for discounts on 2025 sets. Aside from the holiday shopping season, now is one of the best times of the year to save on a TV. Here, we’ve curated the best Super Bowl TV deals we could find this year, from already affordable sets discounted even further to high-end OLEDs that are hundreds of dollars off. Super Bowl 2026 TV deals for less than $500 You can easily find solid 1080p and 4K TV sets within this budget-friendly price range. What you’ll be more limited in is size — most TV deals under $500 we’re seeing right now are on sets up to 55 inches. There are a few 65- and 75-inch models in there, but the pickings are slim. Hisense 32-inch Class A4 1080p FHD smart TV for $98 (18 percent off) Roku 24-inch 720p smart TV for $100 (18 percent off) TCL 40-inch Class S3 1080p smart TV for $150 (21 percent off) Roku 55-inch 4K smart TV for $248 (29 percent off) Roku 55-inch Mini LED 4K smart TV for $348 (30 percent off) TCL 75-inch Class S5 4K smart TV for $480 (26 percent off) OLED TV deals This is where you want to look if you want your new TV to have the richest colors, deepest blacks and excellent contrast performance. Of course, that all comes at steeper prices — it can be difficult to find a good OLED set for less than $1,000, even on sale. Sony 55-inch Bravia XR8B 4K smart TV for $998 (9 percent off) Samsung 65-inch Class OLED S95F 4K smart TV for $2,298 (23 percent off) Sony 77-inch Bravia XR A95L OLED 4K smart TV for $3,498 (30 percent off) Super Bowl 2026 TV deals for $500 and up This will likely be the sweet spot for many people when it comes to TV features, performance and price. Good 4K sets are common in this price range, and you’ll also find some Mini LED sets available here as well. TCL 65-inch Class T7 4K smart TV for $500 (29 percent off) Hisense 75-inch QD7 Mini-LED 4K smart TV for $548 (16 percent off) Amazon 65-inch Fire TV Omni Mini LED 4K smart TV for $920 (16 percent off) TCL 65-inch Class QM8K Mini LED 4K smart TV for $998 (33 percent off) Streaming and home entertainment deals A good TV is key, but having the right peripherals and accessories to go along with it will complete your home theater setup. Deals we’re tracking right now include discounts on streaming devices, soundbars and projectors. Sonos big game sale — up to 20 percent off home theater gear: Get the Sonos Beam soundbar for $130 off, the Era 300 speaker for $100 off and more Roku Streaming Stick HD 2025 for $16 (47 percent off) Roku Ultra streamer for $78 (22 percent off) Samsung HW B400F soundbar with built-in subwoofer for $100 (29 percent off) Anker Nebula Capsule 3 projector for $540 (28 percent off) Valerion VisionMaster Max 4K projector for $3,999 (20 percent off)This article originally appeared on Engadget at https://www.engadget.com/deals/super-bowl-2026-tv-deals-the-best-sales-this-week-on-oleds-and-other-smart-tvs-ahead-of-kickoff-160000485.html?src=rss",
          "feed_position": 45
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/the-apple-watch-series-11-is-back-on-sale-for-299-151616498.html",
          "published_at": "Mon, 02 Feb 2026 15:16:17 +0000",
          "title": "The Apple Watch Series 11 is back on sale for $299",
          "standfirst": "Whether you're one of the few people still keeping up with New Year's resolutions or just want an upgraded smartwatch, now is a good time to get an Apple Watch. Currently, the Apple Watch Series 11 is on sale for $299, down from $399. The 25 percent discount brings the 2025 model back down to its record-low price. We named the Apple Watch Series 11 as our choice for best smartwatch overall. It scored a 90 in our review thanks to its 24 hours-plus of battery life and a thin, light design that's easy to wear. It also offers new health metrics, including Apple's hypertension alerts system and Sleep Score. The Apple Watch Series 11 deal is available on the 42mm case with a small/medium band. It also only includes GPS and four colorways: the Jet Black and Space Gray aluminum cases with a Black sport band, the Rose Gold aluminum case with a Light Blush sport band and the Silver aluminum case with a Purple Fog sport band. Check out our coverage of the best Apple deals for more discounts, and follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/the-apple-watch-series-11-is-back-on-sale-for-299-151616498.html?src=rss",
          "content": "Whether you're one of the few people still keeping up with New Year's resolutions or just want an upgraded smartwatch, now is a good time to get an Apple Watch. Currently, the Apple Watch Series 11 is on sale for $299, down from $399. The 25 percent discount brings the 2025 model back down to its record-low price. We named the Apple Watch Series 11 as our choice for best smartwatch overall. It scored a 90 in our review thanks to its 24 hours-plus of battery life and a thin, light design that's easy to wear. It also offers new health metrics, including Apple's hypertension alerts system and Sleep Score. The Apple Watch Series 11 deal is available on the 42mm case with a small/medium band. It also only includes GPS and four colorways: the Jet Black and Space Gray aluminum cases with a Black sport band, the Rose Gold aluminum case with a Light Blush sport band and the Silver aluminum case with a Purple Fog sport band. Check out our coverage of the best Apple deals for more discounts, and follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/the-apple-watch-series-11-is-back-on-sale-for-299-151616498.html?src=rss",
          "feed_position": 46
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/the-latest-ipad-mini-is-100-off-right-now-140900983.html",
          "published_at": "Mon, 02 Feb 2026 14:09:00 +0000",
          "title": "The latest iPad mini is $100 off right now",
          "standfirst": "We've finally made it to February, but, with the ongoing long nights, you might want a pick-me-up to get you through the rest of winter. Take the Apple iPad mini with the A17 Pro chip, which is on sale for $400, down from $500. Its small size is perfect for cozying up on the couch or to use on your daily commute. Apple released this iPad mini in late 2024 and it was a solid update. We gave it an 83 in our review thanks to the power of its A17 Pro chip and that it comes with a minimum of 128GB of storage. The model currently on sale comes with 128GB, Wi-Fi and all four color options: Blue, Purple, Space Gray and Starlight. We named the Apple iPad mini our favorite compact iPad — though, to be fair, its only competitor is itself. Still, it's a good iPad with an 8.3-inch Liquid Retina display, Apple Intelligence and 12MP Wide back and 12MP Ultra Wide cameras. For 20 percent off, it's a great option for a light, useful way to entertain yourself through the rest of winter and beyond. Check out our coverage of the best Apple deals for more discounts, and follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/the-latest-ipad-mini-is-100-off-right-now-140900983.html?src=rss",
          "content": "We've finally made it to February, but, with the ongoing long nights, you might want a pick-me-up to get you through the rest of winter. Take the Apple iPad mini with the A17 Pro chip, which is on sale for $400, down from $500. Its small size is perfect for cozying up on the couch or to use on your daily commute. Apple released this iPad mini in late 2024 and it was a solid update. We gave it an 83 in our review thanks to the power of its A17 Pro chip and that it comes with a minimum of 128GB of storage. The model currently on sale comes with 128GB, Wi-Fi and all four color options: Blue, Purple, Space Gray and Starlight. We named the Apple iPad mini our favorite compact iPad — though, to be fair, its only competitor is itself. Still, it's a good iPad with an 8.3-inch Liquid Retina display, Apple Intelligence and 12MP Wide back and 12MP Ultra Wide cameras. For 20 percent off, it's a great option for a light, useful way to entertain yourself through the rest of winter and beyond. Check out our coverage of the best Apple deals for more discounts, and follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/the-latest-ipad-mini-is-100-off-right-now-140900983.html?src=rss",
          "feed_position": 48
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/get-up-to-20-percent-off-sonos-home-theater-gear-before-super-bowl-2026-174053382.html",
          "published_at": "Mon, 02 Feb 2026 13:56:27 +0000",
          "title": "Get up to 20 percent off Sonos home theater gear before Super Bowl 2026",
          "standfirst": "It's big-game season, which means it's a good time to look for home theater gear on sale ahead of Super Bowl 2026. There are plenty of Super Bowl TV deals to consider, but if you have arguably the most important piece of the puzzle down, you may want to upgrade your sound system instead. Sonos' latest sale may have just what you need; a bunch of the company's home theater gear is up to 20 percent off right now. You can save $130 on the Beam (Gen 2) soundbar, bringing its price down to $369, and you'll also find deals on the flagship Arc Ultra soundbar, subwoofers, and more. The Sonos Beam is the company's sub-$500 soundbar. Engadget's pick for the best midrange model, the compact speaker has impressive sound for its size. Part of that is its Dolby Atmos support. Although the soundbar lacks upward-firing speakers, it uses software tricks to compensate. Audio timing and frequency adjustments make sound seem to come from the side or slightly above. One of the biggest drawbacks is that the Beam only has one HDMI port. Regardless, that compromise may be easier to accept at Beam's current $369 than at its usual $499. Several more home theater speakers are included in Sonos's sale. If you have a loftier budget for a soundbar, there's the Arc Ultra. Typically $1,099, it's now $899. The company's pair of subwoofers is included as well. You can get the Sub Mini for $399 (down from $499) or the Sub 4 for $759 (from $899). Although they aren't explicitly sold as home theater products, the Era 100 ($179) and Era 300 ($379) are also included in the sale. The portable Move 2 isn't discounted individually, but you will find it in a couple of bundles. You can check out the sale page for the complete list. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/get-up-to-20-percent-off-sonos-home-theater-gear-before-super-bowl-2026-174053382.html?src=rss",
          "content": "It's big-game season, which means it's a good time to look for home theater gear on sale ahead of Super Bowl 2026. There are plenty of Super Bowl TV deals to consider, but if you have arguably the most important piece of the puzzle down, you may want to upgrade your sound system instead. Sonos' latest sale may have just what you need; a bunch of the company's home theater gear is up to 20 percent off right now. You can save $130 on the Beam (Gen 2) soundbar, bringing its price down to $369, and you'll also find deals on the flagship Arc Ultra soundbar, subwoofers, and more. The Sonos Beam is the company's sub-$500 soundbar. Engadget's pick for the best midrange model, the compact speaker has impressive sound for its size. Part of that is its Dolby Atmos support. Although the soundbar lacks upward-firing speakers, it uses software tricks to compensate. Audio timing and frequency adjustments make sound seem to come from the side or slightly above. One of the biggest drawbacks is that the Beam only has one HDMI port. Regardless, that compromise may be easier to accept at Beam's current $369 than at its usual $499. Several more home theater speakers are included in Sonos's sale. If you have a loftier budget for a soundbar, there's the Arc Ultra. Typically $1,099, it's now $899. The company's pair of subwoofers is included as well. You can get the Sub Mini for $399 (down from $499) or the Sub 4 for $759 (from $899). Although they aren't explicitly sold as home theater products, the Era 100 ($179) and Era 300 ($379) are also included in the sale. The portable Move 2 isn't discounted individually, but you will find it in a couple of bundles. You can check out the sale page for the complete list. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/get-up-to-20-percent-off-sonos-home-theater-gear-before-super-bowl-2026-174053382.html?src=rss",
          "feed_position": 49
        }
      ],
      "featured_image": "https://images.ctfassets.net/jdtwqhzvc2n1/7ErEzHma6LbYLaznwE3rtA/39944c4739dbecaa3f8a336826de352d/sVJFWPtv0RFGdOIc_fKWG_C0uLbr6A__1_.png?w=300&q=30",
      "popularity_score": 3019.4118180555556
    },
    {
      "id": "cluster_22",
      "coverage": 2,
      "updated_at": "Tue, 03 Feb 2026 15:30:01 -0500",
      "title": "Microsoft launches the Publisher Content Marketplace in partnership with Condé Nast, Hearst, AP, and others, to let publishers license content to AI companies (Anu Adegbola/Search Engine Land)",
      "neutral_headline": "Microsoft says it’s building an app store for AI content licensing",
      "bullet_summary": [
        "Reported by TechMeme, The Verge"
      ],
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/260203/p35#a260203p35",
          "published_at": "Tue, 03 Feb 2026 15:30:01 -0500",
          "title": "Microsoft launches the Publisher Content Marketplace in partnership with Condé Nast, Hearst, AP, and others, to let publishers license content to AI companies (Anu Adegbola/Search Engine Land)",
          "standfirst": "Anu Adegbola / Search Engine Land: Microsoft launches the Publisher Content Marketplace in partnership with Cond&eacute; Nast, Hearst, AP, and others, to let publishers license content to AI companies &mdash; Table of Contents &mdash; New marketplace lets publishers set terms, track usage, and get paid when AI systems ground answers in premium, licensed content.",
          "content": "Anu Adegbola / Search Engine Land: Microsoft launches the Publisher Content Marketplace in partnership with Cond&eacute; Nast, Hearst, AP, and others, to let publishers license content to AI companies &mdash; Table of Contents &mdash; New marketplace lets publishers set terms, track usage, and get paid when AI systems ground answers in premium, licensed content.",
          "feed_position": 7,
          "image_url": "http://www.techmeme.com/260203/i35.jpg"
        },
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/news/873296/microsoft-publisher-content-marketplace-ai-licensing",
          "published_at": "2026-02-03T15:00:00-05:00",
          "title": "Microsoft says it’s building an app store for AI content licensing",
          "standfirst": "Microsoft says it is working on the Publisher Content Marketplace (PCM), an AI licensing hub that shows usage terms set by publishers. That way, AI companies can easily shop the terms and set up deals to use online content for \"grounding\" their AI models, while the content owners get usage-based reporting to help set prices. [&#8230;]",
          "content": "Microsoft says it is working on the Publisher Content Marketplace (PCM), an AI licensing hub that shows usage terms set by publishers. That way, AI companies can easily shop the terms and set up deals to use online content for \"grounding\" their AI models, while the content owners get usage-based reporting to help set prices. Microsoft says it's been codesigning PCM with companies including Verge parent Vox Media, The Associated Press, Cond&eacute; Nast, People, and others. The AI boom has been largely fueled by content ingested without payment, and many of the previously mentioned publishers have filed lawsuits and/or arranged content licensing de … Read the full story at The Verge.",
          "feed_position": 5
        }
      ],
      "featured_image": "http://www.techmeme.com/260203/i35.jpg",
      "popularity_score": 2017.1287625
    },
    {
      "id": "cluster_1",
      "coverage": 1,
      "updated_at": "Tue, 03 Feb 2026 22:55:59 +0000",
      "title": "Godlike Titan threatens humanity in Monarch: Legacy of Monsters S2 trailer",
      "neutral_headline": "Godlike Titan threatens humanity in Monarch: Legacy of Monsters S2 trailer",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/culture/2026/02/meet-the-new-tentacled-titan-x-in-monarch-legacy-of-monsters-s2-trailer/",
          "published_at": "Tue, 03 Feb 2026 22:55:59 +0000",
          "title": "Godlike Titan threatens humanity in Monarch: Legacy of Monsters S2 trailer",
          "standfirst": "\"This Titan is like a god, and the sea creatures worship it.\"",
          "content": "Last month, Apple TV released a teaser for the second season of Monarch: Legacy of Monsters, part of Legendary Entertainment’s MonsterVerse, which brought Godzilla, King Kong, and various other monsters (kaiju) created by Toho Co., Ltd into a shared narrative. But we only got the most fleeting glimpse of the promised new mythical Titan threatening the human race. The full trailer just dropped and rectifies that: it's a gigantic tentacled undersea being dubbed Titan X—and only Kong and Godzilla can stop it. (Spoilers for Season 1 below.) As previously reported, the first season picked up where 2014’s Godzilla left off, specifically the introduction of Project Monarch, a secret organization established in the 1950s to study Godzilla and other kaiju—after attempts to kill Godzilla with nuclear weapons failed. In the S1 finale, Godzilla fights off an Ion Dragon, tossing it through a rift back to the Hollow Earth, and Lee Shaw (Kurt Russell) seemingly sacrifices himself to save his colleagues. Per the official Season 2 premise:Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/monarch1-1152x648-1770156538.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/monarch1-1152x648-1770156538.jpg",
      "popularity_score": 367.5615402777778
    },
    {
      "id": "cluster_3",
      "coverage": 1,
      "updated_at": "Tue, 03 Feb 2026 22:44:15 +0000",
      "title": "Nvidia's $100 billion OpenAI deal has seemingly vanished",
      "neutral_headline": "Nvidia's $100 billion OpenAI deal has seemingly vanished",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/information-technology/2026/02/five-months-later-nvidias-100-billion-openai-investment-plan-has-fizzled-out/",
          "published_at": "Tue, 03 Feb 2026 22:44:15 +0000",
          "title": "Nvidia's $100 billion OpenAI deal has seemingly vanished",
          "standfirst": "Two AI giants shake market confidence after investment fails to materialize.",
          "content": "In September 2025, Nvidia and OpenAI announced a letter of intent for Nvidia to invest up to $100 billion in OpenAI's AI infrastructure. At the time, the companies said they expected to finalize details \"in the coming weeks.\" Five months later, no deal has closed, Nvidia's CEO now says the $100 billion figure was \"never a commitment,\" and Reuters reports that OpenAI has been quietly seeking alternatives to Nvidia chips since last year. Reuters also wrote that OpenAI is unsatisfied with the speed of some Nvidia chips for inference tasks, citing eight sources familiar with the matter. Inference is the process by which a trained AI model generates responses to user queries. According to the report, the issue became apparent in OpenAI's Codex, an AI code-generation tool. OpenAI staff reportedly attributed some of Codex's performance limitations to Nvidia's GPU-based hardware. After the Reuters story published and Nvidia's stock price took a dive, Nvidia and OpenAI have tried to smooth things over publicly. OpenAI CEO Sam Altman posted on X: \"We love working with NVIDIA and they make the best AI chips in the world. We hope to be a gigantic customer for a very long time. I don't get where all this insanity is coming from.\"Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/09/nvidia-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/09/nvidia-1152x648.jpg",
      "popularity_score": 357.3659847222222
    },
    {
      "id": "cluster_17",
      "coverage": 1,
      "updated_at": "Tue, 03 Feb 2026 21:15:57 +0000",
      "title": "Newborn dies after mother drinks raw milk during pregnancy",
      "neutral_headline": "Newborn dies after mother drinks raw milk during pregnancy",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2026/02/newborns-death-spurs-raw-milk-warning-in-new-mexico/",
          "published_at": "Tue, 03 Feb 2026 21:15:57 +0000",
          "title": "Newborn dies after mother drinks raw milk during pregnancy",
          "standfirst": "Raw milk is promoted by anti-vaccine Health Secretary Kennedy.",
          "content": "A newborn baby has died in New Mexico from a Listeria infection that state health officials say was likely contracted from raw (unpasteurized) milk that the baby's mother drank during pregnancy. In a news release Tuesday, officials warned people not to consume any raw dairy, highlighting that it can be teeming with a variety of pathogens. Those germs are especially dangerous to pregnant women, as well as young children, the elderly, and people with weakened immune systems. \"Raw milk can contain numerous disease-causing germs, including Listeria, which is bacteria that can cause miscarriage, stillbirth, preterm birth, or fatal infection in newborns, even if the mother is only mildly ill,\" the New Mexico Department of Health said in the press release.Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-2211793949-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-2211793949-1152x648.jpg",
      "popularity_score": 330.8943180555556
    },
    {
      "id": "cluster_41",
      "coverage": 1,
      "updated_at": "Tue, 03 Feb 2026 18:56:20 +0000",
      "title": "Nintendo Switch is the second-bestselling game console ever, behind only the PS2",
      "neutral_headline": "Nintendo Switch is the second-bestselling game console ever, behind only the PS2",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/02/original-nintendo-switch-passes-the-ds-to-become-nintendos-bestselling-console/",
          "published_at": "Tue, 03 Feb 2026 18:56:20 +0000",
          "title": "Nintendo Switch is the second-bestselling game console ever, behind only the PS2",
          "standfirst": "Switch 2 has already beaten the Wii U and is on its way to overtaking GameCube.",
          "content": "Although it was finally replaced last year by the new Switch 2, the orginal switch isn't done just yet. Many recent Switch games (and a handful of major updates, like the one for Animal Crossing) have been released in both Switch and Switch 2 editions, and Nintendo continues to sell all editions of the original console as entry-level systems for those who can't pay $450 for a Switch 2. The 9-year-old Switch's continued availability has helped it clear a milestone, according to the company's third-quarter financial results (PDF). As of December 31, 2025, Nintendo says the Switch \"has reached the highest sales volume of any Nintendo hardware\" with a total of 155.37 million units sold, surpassing the original DS's lifetime total of 154.02 million units. The console has sold 3.25 million units in Nintendo's fiscal 2026 so far, including 1.36 million units over the holidays. Those consoles have sold despite price hikes that Nintendo introduced in August of 2025, citing \"market conditions.\" That makes the Switch the second-bestselling game console of all time, just three years after it became the third-bestselling game console of all time. The only frontier left for the Switch to conquer is Sony's PlayStation 2, which Sony says sold \"over 160 million units\" over its long life. At its current sales rate (Nintendo predicts it will sell roughly 750,000 Switches in the next quarter), it would take the Switch another couple of years to cross that line, but those numbers are likely to taper off as we get deeper into the Switch 2 era.Read full article Comments",
          "feed_position": 4,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2021/07/NintendoSwitchOLEDmodel_02-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2021/07/NintendoSwitchOLEDmodel_02-1152x648.jpg",
      "popularity_score": 314.5673736111111
    },
    {
      "id": "cluster_52",
      "coverage": 1,
      "updated_at": "Tue, 03 Feb 2026 18:25:18 +0000",
      "title": "Google court filings suggest ChromeOS has an expiration date",
      "neutral_headline": "Google court filings suggest ChromeOS has an expiration date",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/google/2026/02/google-court-filings-suggest-googles-chromeos-has-an-expiration-date/",
          "published_at": "Tue, 03 Feb 2026 18:25:18 +0000",
          "title": "Google court filings suggest ChromeOS has an expiration date",
          "standfirst": "ChromeOS may be canned once the current support guarantee has run its course.",
          "content": "Chromebooks debuted 16 years ago with the limited release of Google's Cr-48, an unassuming compact laptop that was provided free to select users. From there, Chromebooks became one of the most popular budget computing options and a common fixture in schools and businesses. According to some newly uncovered court documents, Google's shift to Android PCs means Chromebooks have an expiration date in 2034. The documents were filed as part of Google's long-running search antitrust case, which began in 2020 and reached a verdict in 2024. While Google is still seeking to have the guilty verdict overturned, it has escaped most of the remedies that government prosecutors requested. According to The Verge, the company's plans for Chromebooks and the upcoming Android-based Aluminium came up in filings from the remedy phase of the trial. As Google moves toward releasing Aluminium, it sought to keep the upcoming machines above the fray and retain the Chrome browser (which it did). In Judge Amit Mehta's final order, devices running ChromeOS or a ChromeOS successor are excluded. To get there, Google had to provide a little more detail on its plans.Read full article Comments",
          "feed_position": 5,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/06/9_Lenovo-Chromebook-Plus-14-copy-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/06/9_Lenovo-Chromebook-Plus-14-copy-1152x648.jpg",
      "popularity_score": 310.0501513888889
    },
    {
      "id": "cluster_56",
      "coverage": 1,
      "updated_at": "Tue, 03 Feb 2026 18:01:49 +0000",
      "title": "Xcode 26.3 adds support for Claude, Codex, and other agentic tools via MCP",
      "neutral_headline": "Xcode 26.3 adds support for Claude, Codex, and other agentic tools via MCP",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/apple/2026/02/xcode-26-3-adds-support-for-claude-codex-and-other-agentic-tools-via-mcp/",
          "published_at": "Tue, 03 Feb 2026 18:01:49 +0000",
          "title": "Xcode 26.3 adds support for Claude, Codex, and other agentic tools via MCP",
          "standfirst": "With Model Context Protocol (MCP), this works with more than Codex/Claude, too.",
          "content": "Apple has announced a new version of Xcode, the latest version of its integrated development environment (IDE) for building software for its own platforms, like the iPhone and Mac. The key feature of 26.3 is support for full-fledged agentic coding tools, like OpenAI's Codex or Claude Agent, with a side panel interface for assigning tasks to agents with prompts and tracking their progress and changes. This is achieved via Model Context Protocol (MCP), an open protocol that lets AI agents work with external tools and structured resources. Xcode acts as an MCP endpoint that exposes a bunch of machine-invocable interfaces and gives AI tools like Codex or Claude Agent access to a wide range of IDE primitives like file graph, docs search, project settings, and so on. While AI chat and workflows were supported in Xcode before, this release gives them much deeper access to the features and capabilities of Xcode. This approach is notable because it means that even though OpenAI and Anthropic's model integrations are privileged with a dedicated spot in Xcode's settings, it's possible to connect other tooling that supports MCP, which also allows doing some of this with models running locally.Read full article Comments",
          "feed_position": 6,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/Xcode-1152x648.png"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/Xcode-1152x648.png",
      "popularity_score": 287.6587625
    },
    {
      "id": "cluster_62",
      "coverage": 1,
      "updated_at": "Tue, 03 Feb 2026 17:29:16 +0000",
      "title": "Wing Commander III: \"Isn't that the guy from Star Wars?\"",
      "neutral_headline": "Wing Commander III: \"Isn't that the guy from Star Wars?\"",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2026/02/wing-commander-iii-the-game-kind-of-sucked-but-the-experience-blew-me-away/",
          "published_at": "Tue, 03 Feb 2026 17:29:16 +0000",
          "title": "Wing Commander III: \"Isn't that the guy from Star Wars?\"",
          "standfirst": "C:\\ArsGames looks at a vanguard of the multimedia FMV future that never quite came to pass.",
          "content": "It's Christmas of 1994, and I am 16 years old. Sitting on the table in our family room next to a pile of cow-spotted boxes is the most incredible thing in the world: a brand-new Gateway 66MHz Pentium tower, with a 540MB hard disk drive, 8MB of RAM, and, most importantly, a CD-ROM drive. I am agog, practically trembling with barely suppressed joy, my bored Gen-X teenager mask threatening to slip and let actual feelings out. My life was about to change—at least where games were concerned. I'd been working for several months at Babbage's store No. 9, near Baybrook Mall in southeast suburban Houston. Although the Gateway PC's arrival on Christmas morning was utterly unexpected, the choice of what game to buy required no planning at all. I'd already decided a few weeks earlier, when Chris Roberts' latest opus had been drop-shipped to our shelves, just in time for the holiday season. The choice made itself, really. Gimli and Luke, together at last! Credit: Origin Systems / Electronic Arts The moment Babbage's opened its doors on December 26—a day I had off, fortunately—I was there, checkbook in hand. One entire paycheck's worth of capitalism later, I was sprinting out to my creaky 280-Z, sweatily clutching two boxes—one an impulse buy, The Star Trek: The Next Generation Interactive Technical Manual, and the other a game I felt sure would be the best thing I'd ever played or ever would play: Origin's Wing Commander III: The Heart of the Tiger. On the backs of Wing Commander I and Wing Commander II, how could it not be?!Read full article Comments",
          "feed_position": 7,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/wc3_boxart_sm-1152x648-1770132197.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/wc3_boxart_sm-1152x648-1770132197.jpg",
      "popularity_score": 277.1162625
    },
    {
      "id": "cluster_66",
      "coverage": 1,
      "updated_at": "Tue, 03 Feb 2026 17:08:34 +0000",
      "title": "Upset at reports that he'd given up, Trump now wants $1B from Harvard",
      "neutral_headline": "Upset at reports that he'd given up, Trump now wants $1B from Harvard",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/02/upset-at-reports-that-hed-given-up-trump-now-wants-1b-from-harvard/",
          "published_at": "Tue, 03 Feb 2026 17:08:34 +0000",
          "title": "Upset at reports that he'd given up, Trump now wants $1B from Harvard",
          "standfirst": "Hefty \"fine\" comes in wake of NY Times reporting of money-free settlement.",
          "content": "Amid the Trump administration's attack on universities, Harvard has emerged as a particular target. Early on, the administration put $2.2 billion in research money on hold and shortly thereafter blocked all future funding while demanding intrusive control over Harvard's hiring and admissions. Unlike many of its peer institutions, Harvard fought back, filing and ultimately winning a lawsuit that restored the cut funds. Despite Harvard's victory, the Trump administration continued to push for some sort of formal agreement that would settle the administration's accusations that Harvard created an environment that allowed antisemitism to flourish. In fact, it had become a running joke among some journalists that The New York Times had devoted a monthly column to reporting that a settlement between the two parties was near. Given the government's loss of leverage, it was no surprise that the latest installment of said column included the detail that the latest negotiations had dropped demands that Harvard pay any money as part of a final agreement. The Trump administration had extracted hundreds of millions of dollars from some other universities and had demanded over a billion dollars from UCLA, so this appeared to be a major concession to Harvard.Read full article Comments",
          "feed_position": 8,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-578751544-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-578751544-1152x648.jpg",
      "popularity_score": 266.7712625
    },
    {
      "id": "cluster_79",
      "coverage": 1,
      "updated_at": "Tue, 03 Feb 2026 15:33:06 +0000",
      "title": "China bans all retractable car door handles, starting next year",
      "neutral_headline": "China bans all retractable car door handles, starting next year",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2026/02/china-bans-all-retractable-car-door-handles-starting-next-year/",
          "published_at": "Tue, 03 Feb 2026 15:33:06 +0000",
          "title": "China bans all retractable car door handles, starting next year",
          "standfirst": "The pop-out door handle ban starts in 2027 for new cars, 2029 for existing models.",
          "content": "Flush door handles have been quite the automotive design trend of late. Stylists like them because they don't add visual noise to the side of a car. And aerodynamicists like them because they make a vehicle more slippery through the air. When Tesla designed its Model S, it needed a car that was both desirable and as efficient as possible, so flush door handles were a no-brainer. Since then, as electric vehicles have proliferated, so too have flush door handles. But as of next year, China says no. Just like pop-up headlights, despite the aesthetic and aerodynamic advantages, there are safety downsides. Tesla's handles are an extreme example: In the event of a crash and a loss of 12 V power, there is no way for first responders to open the door from the outside, which has resulted in at least 15 deaths. Those deaths prompted the National Highway Traffic Safety Administration to open an investigation last year, but China is being a little more proactive. It has been looking at whether retractable car door handles are safe since mid-2024, according to Bloomberg, and has concluded that no, they are not.Read full article Comments",
          "feed_position": 9,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/09/GettyImages-1277594023-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/09/GettyImages-1277594023-1152x648.jpg",
      "popularity_score": 255.18015138888887
    },
    {
      "id": "cluster_93",
      "coverage": 1,
      "updated_at": "Tue, 03 Feb 2026 12:00:01 +0000",
      "title": "The rise of Moltbook suggests viral AI prompts may be the next big security threat",
      "neutral_headline": "The rise of Moltbook suggests viral AI prompts may be the next big security threat",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2026/02/the-rise-of-moltbook-suggests-viral-ai-prompts-may-be-the-next-big-security-threat/",
          "published_at": "Tue, 03 Feb 2026 12:00:01 +0000",
          "title": "The rise of Moltbook suggests viral AI prompts may be the next big security threat",
          "standfirst": "We don't need self-replicating AI models to have problems, just self-replicating prompts.",
          "content": "On November 2, 1988, graduate student Robert Morris released a self-replicating program into the early Internet. Within 24 hours, the Morris worm had infected roughly 10 percent of all connected computers, crashing systems at Harvard, Stanford, NASA, and Lawrence Livermore National Laboratory. The worm exploited security flaws in Unix systems that administrators knew existed but had not bothered to patch. Morris did not intend to cause damage. He wanted to measure the size of the Internet. But a coding error caused the worm to replicate far faster than expected, and by the time he tried to send instructions for removing it, the network was too clogged to deliver the message. History may soon repeat itself with a novel new platform: networks of AI agents carrying out instructions from prompts and sharing them with other AI agents, which could spread the instructions further.Read full article Comments",
          "feed_position": 11,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/moltbook-chest-burster-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/moltbook-chest-burster-1152x648.jpg",
      "popularity_score": 166.6287625
    },
    {
      "id": "cluster_85",
      "coverage": 1,
      "updated_at": "Tue, 03 Feb 2026 14:02:57 +0000",
      "title": "Senior staff departing OpenAI as firm prioritizes ChatGPT development",
      "neutral_headline": "Senior staff departing OpenAI as firm prioritizes ChatGPT development",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2026/02/senior-staff-departing-openai-as-firm-prioritizes-chatgpt-development/",
          "published_at": "Tue, 03 Feb 2026 14:02:57 +0000",
          "title": "Senior staff departing OpenAI as firm prioritizes ChatGPT development",
          "standfirst": "Resources are redirected from long-term research toward improving the flagship chatbot.",
          "content": "OpenAI is prioritizing the advancement of ChatGPT over more long-term research, prompting the departure of senior staff as the $500 billion company adapts to stiff competition from rivals such as Google and Anthropic. The San Francisco-based start-up has reallocated resources for experimental work in favor of advances to the large language models that power its flagship chatbot, according to 10 current and former employees. Among those to leave OpenAI in recent months over the strategic shift are vice-president of research Jerry Tworek, model policy researcher Andrea Vallone, and economist Tom Cunningham.Read full article Comments",
          "feed_position": 10,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/03/openai-logo-1152x648-1741196873.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/03/openai-logo-1152x648-1741196873.jpg",
      "popularity_score": 164.67765138888888
    },
    {
      "id": "cluster_113",
      "coverage": 1,
      "updated_at": "Mon, 02 Feb 2026 21:55:44 +0000",
      "title": "SpaceX acquires xAI, plans to launch a massive satellite constellation to power it",
      "neutral_headline": "SpaceX acquires xAI, plans to launch a massive satellite constellation to power it",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2026/02/spacex-acquires-xai-plans-1-million-satellite-constellation-to-power-it/",
          "published_at": "Mon, 02 Feb 2026 21:55:44 +0000",
          "title": "SpaceX acquires xAI, plans to launch a massive satellite constellation to power it",
          "standfirst": "\"This marks not just the next chapter, but the next book in SpaceX and xAI's mission.\"",
          "content": "SpaceX has formally acquired another one of Elon Musk's companies, xAi, the space company announced on Monday afternoon. \"SpaceX has acquired xAI to form the most ambitious, vertically-integrated innovation engine on (and off) Earth, with AI, rockets, space-based internet, direct-to-mobile device communications and the world’s foremost real-time information and free speech platform,\" the company said. \"This marks not just the next chapter, but the next book in SpaceX and xAI's mission: scaling to make a sentient sun to understand the Universe and extend the light of consciousness to the stars!\" The merging of what is arguably Musk's most successful company, SpaceX, with the more speculative xAI venture is a risk. Founded in 2023, xAI's main products are the generative AI chatbot Grok and the social media site X, formerly known as Twitter. The company aims to compete with OpenAI and other artificial intelligence firms. However, Grok has been controversial, including the sexualization of women and children through AI-generated images, as has Musk's management of Twitter.Read full article Comments",
          "feed_position": 15,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/starship_march2025-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/starship_march2025-1152x648.jpg",
      "popularity_score": 156
    },
    {
      "id": "cluster_111",
      "coverage": 1,
      "updated_at": "Mon, 02 Feb 2026 22:31:46 +0000",
      "title": "Streaming service Crunchyroll raises prices weeks after killing its free tier",
      "neutral_headline": "Streaming service Crunchyroll raises prices weeks after killing its free tier",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/02/streaming-service-crunchyroll-raises-prices-weeks-after-killing-its-free-tier/",
          "published_at": "Mon, 02 Feb 2026 22:31:46 +0000",
          "title": "Streaming service Crunchyroll raises prices weeks after killing its free tier",
          "standfirst": "Sony has made streaming anime pricier since buying Crunchyroll.",
          "content": "Crunchyroll is one of the most popular streaming platforms for anime viewers. Over the past six years, the service has raised prices for fans, and today, it announced that it's increasing monthly subscription prices by up to 25 percent. Sony bought Crunchyroll from AT&T in 2020. At the time, Crunchyroll had 3 million paid subscribers and an additional 197 million users with free accounts, which let people watch a limited number of titles with commercials. At the time, Crunchyroll monthly subscription tiers cost $8, $10, or $15. After its acquisition by Sony, like many large technology companies that buy a smaller, beloved product, the company made controversial changes. The Tokyo-based company folded rival Funimation into Crunchyroll; Sony shut down Funimation, which it bought in 2017, in April 2024.Read full article Comments",
          "feed_position": 14,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-2258531948-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-2258531948-1024x648.jpg",
      "popularity_score": 148
    },
    {
      "id": "cluster_114",
      "coverage": 1,
      "updated_at": "Mon, 02 Feb 2026 21:32:18 +0000",
      "title": "Russian drones use Starlink, but Ukraine has plan to block their Internet access",
      "neutral_headline": "Russian drones use Starlink, but Ukraine has plan to block their Internet access",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/02/russian-drones-use-starlink-but-ukraine-has-plan-to-block-their-internet-access/",
          "published_at": "Mon, 02 Feb 2026 21:32:18 +0000",
          "title": "Russian drones use Starlink, but Ukraine has plan to block their Internet access",
          "standfirst": "Defense chief: \"No Ukrainians have been killed by Russian drones using Starlink.\"",
          "content": "Ukraine and SpaceX say they recently collaborated to stop strikes by Russian drones using Starlink and will soon block all unregistered use of Starlink terminals in an attempt to stop Russia's military from using the satellite broadband network over Ukraine territory. Ukrainians will soon be required to register their Starlink terminals to get on a whitelist. After that, \"only verified and registered terminals will be allowed to operate in the country. All others will be disconnected,\" the Ukraine Ministry of Defense said in a press release today. Ukraine Minister of Defense Mykhailo Fedorov \"emphasized that the only technical solution to counter this threat is to introduce a 'whitelist' and authorize all terminals,\" according to the ministry. \"This is a necessary step by the Government to save Ukrainian lives and protect critical energy infrastructure,\" Fedorov said.Read full article Comments",
          "feed_position": 16,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2023/02/getty-ukraine-starlink-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2023/02/getty-ukraine-starlink-1152x648.jpg",
      "popularity_score": 148
    },
    {
      "id": "cluster_120",
      "coverage": 1,
      "updated_at": "Mon, 02 Feb 2026 20:00:35 +0000",
      "title": "A century of hair samples proves leaded gas ban worked",
      "neutral_headline": "A century of hair samples proves leaded gas ban worked",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/02/a-century-of-hair-samples-proves-leaded-gas-ban-worked/",
          "published_at": "Mon, 02 Feb 2026 20:00:35 +0000",
          "title": "A century of hair samples proves leaded gas ban worked",
          "standfirst": "“We should not forget the lessons of history. And the lesson is those regulations have been very important.”",
          "content": "The Environmental Protection Agency (EPA) cracked down on lead-based products—including lead paint and leaded gasoline—in the 1970s because of its toxic effects on human health. Scientists at the University of Utah have analyzed human hair samples spanning nearly 100 years and found a 100-fold decrease in lead concentrations, concluding that this regulatory action was highly effective in achieving its stated objectives. They described their findings in a new paper published in the Proceedings of the National Academy of Sciences. We've known about the dangers of lead exposure for a very long time—arguably since the second century BCE—so why conduct this research now? Per the authors, it's because there are growing concerns over the Trump administration's move last year to deregulate many key elements of the EPA's mission. Lead specifically has not yet been deregulated, but there are hints that there could be a loosening of enforcement of the 2024 Lead and Cooper rule requiring water systems to replace old lead pipes. “We should not forget the lessons of history. And the lesson is those regulations have been very important,” said co-author Thure Cerling. “Sometimes they seem onerous and mean that industry can't do exactly what they'd like to do when they want to do it or as quickly as they want to do it. But it's had really, really positive effects.”Read full article Comments",
          "feed_position": 19,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/lead2-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/lead2-1152x648.jpg",
      "popularity_score": 148
    },
    {
      "id": "cluster_118",
      "coverage": 1,
      "updated_at": "Mon, 02 Feb 2026 20:30:56 +0000",
      "title": "Notepad++ users take note: It's time to check if you're hacked",
      "neutral_headline": "Notepad++ users take note: It's time to check if you're hacked",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/security/2026/02/notepad-updater-was-compromised-for-6-months-in-supply-chain-attack/",
          "published_at": "Mon, 02 Feb 2026 20:30:56 +0000",
          "title": "Notepad++ users take note: It's time to check if you're hacked",
          "standfirst": "Suspected China-state hackers used update infrastructure to deliver backdoored version.",
          "content": "Infrastructure delivering updates for Notepad++—a widely used text editor for Windows—was compromised for six months by suspected China-state hackers who used their control to deliver backdoored versions of the app to select targets, developers said Monday. “I deeply apologize to all users affected by this hijacking,” the author of a post published to the official notepad-plus-plus.org site wrote Monday. The post said that the attack began last June with an “infrastructure-level compromise that allowed malicious actors to intercept and redirect update traffic destined for notepad-plus-plus.org.” The attackers, whom multiple investigators tied to the Chinese government, then selectively redirected certain targeted users to malicious update servers where they received backdoored updates. Notepad++ didn’t regain control of its infrastructure until December. The attackers used their access to install a never-before-seen payload that has been dubbed Chrysalis. Security firm Rapid 7 descrbed it as a \"custom, feature-rich backdoor.\"Read full article Comments",
          "feed_position": 18,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2023/07/exploit-vulnerability-security.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2023/07/exploit-vulnerability-security.jpg",
      "popularity_score": 143
    },
    {
      "id": "cluster_102",
      "coverage": 1,
      "updated_at": "Tue, 03 Feb 2026 08:06:50 +0000",
      "title": "Unable to tame hydrogen leaks, NASA delays launch of Artemis II until March",
      "neutral_headline": "Unable to tame hydrogen leaks, NASA delays launch of Artemis II until March",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2026/02/unable-to-tame-hydrogen-leaks-nasa-delays-launch-of-artemis-ii-until-march/",
          "published_at": "Tue, 03 Feb 2026 08:06:50 +0000",
          "title": "Unable to tame hydrogen leaks, NASA delays launch of Artemis II until March",
          "standfirst": "NASA spent most of Monday trying to overcome hydrogen leaks on the Artemis II rocket.",
          "content": "The launch of NASA's Artemis II mission, the first flight of astronauts to the Moon in more than 53 years, will have to wait another month after a fueling test Monday uncovered hydrogen leaks in the connection between the rocket and its launch platform at Kennedy Space Center in Florida. \"Engineers pushed through several challenges during the two-day test and met many of the planned objectives,\" NASA said in a statement following the conclusion of the mock countdown, or wet dress rehearsal (WDR), early Tuesday morning. \"To allow teams to review data and conduct a second Wet Dress Rehearsal, NASA now will target March as the earliest possible launch opportunity for the flight test.\" The practice countdown was designed to identify problems and provide NASA an opportunity to fix them before launch. Most importantly, the test revealed NASA still has not fully resolved recurring hydrogen leaks that delayed the launch of the unpiloted Artemis I test flight by several months in 2022. Artemis I finally launched successfully after engineers revised their hydrogen loading procedures to overcome the leak.Read full article Comments",
          "feed_position": 12,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/AFRC2026-0017-15orig-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/AFRC2026-0017-15orig-1152x648.jpg",
      "popularity_score": 137.7423736111111
    },
    {
      "id": "cluster_110",
      "coverage": 1,
      "updated_at": "Mon, 02 Feb 2026 22:57:56 +0000",
      "title": "Looking back at Catacomb 3D, the game that led to Wolfenstein 3D",
      "neutral_headline": "Looking back at Catacomb 3D, the game that led to Wolfenstein 3D",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2026/02/looking-back-at-catacomb-3d-the-game-that-led-to-wolfenstein-3d/",
          "published_at": "Mon, 02 Feb 2026 22:57:56 +0000",
          "title": "Looking back at Catacomb 3D, the game that led to Wolfenstein 3D",
          "standfirst": "Romero, Carmack, and colleagues discuss an oft-forgotten piece of PC gaming history.",
          "content": "If you know anything about the history of id Software, you know how 1992's Wolfenstein 3D helped establish the company's leadership in the burgeoning first-person shooter genre, leading directly to subsequent hits like Doom and Quake. But only the serious id Software nerds remember Catacomb 3D, id's first-person adventure game that directly preceded and inspired work on Wolfenstein 3D. Now, nearly 35 years after Catacomb 3D's initial release, id co-founder John Romero brought the company's founding members together for an informative retrospective video on the creation of the oft-forgotten game. But the pioneering game—which included mouse support, color-coded keys, and shooting walls to find secrets—almost ended up being a gimmicky dead end for the company. id Software's founders look back at an oft-forgotten piece of gaming history. Texture maps and \"undo\" animation Catacomb 3D was a follow-up to id's earlier Catacomb, which was a simplified clone of the popular arcade hit Gauntlet. As such, the 3D game still has some of that \"quarter eater\" mentality that was not very fashionable in PC gaming at the time, as John Carmack remembered.Read full article Comments",
          "feed_position": 13,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/c3d-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/c3d-1152x648.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_116",
      "coverage": 1,
      "updated_at": "Mon, 02 Feb 2026 20:43:31 +0000",
      "title": "Court orders restart of all US offshore wind construction",
      "neutral_headline": "Court orders restart of all US offshore wind construction",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/02/court-orders-restart-of-all-us-offshore-wind-construction/",
          "published_at": "Mon, 02 Feb 2026 20:43:31 +0000",
          "title": "Court orders restart of all US offshore wind construction",
          "standfirst": "Trump admin's \"it's classified\" ploy put on hold in five different cases.",
          "content": "The Trump administration is no fan of renewable energy, but it reserves special ire for wind power. Trump himself has repeatedly made false statements about the cost of wind power, its use around the world, and its environmental impacts. That animosity was paired with an executive order that blocked all permitting for offshore wind and some land-based projects, an order that has since been thrown out by a court that ruled it arbitrary and capricious. Not content to block all future developments, the administration has also gone after the five offshore wind projects currently under construction. After temporarily blocking two of them for reasons that were never fully elaborated, the Department of the Interior settled on a single justification for blocking turbine installation: a classified national security risk. The response to that late-December announcement has been uniform: The companies building each of the projects sued the administration. As of Monday, every single one of them has achieved the same result: a temporary injunction that allows them to continue construction. This, despite the fact that the suits were filed in three different courts and heard by four different judges.Read full article Comments",
          "feed_position": 17,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-1623091024.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-1623091024.jpg",
      "popularity_score": 133
    }
  ]
}