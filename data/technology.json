{
  "updated_at": "2026-02-14T11:17:29.353Z",
  "clusters": [
    {
      "id": "cluster_12",
      "coverage": 2,
      "updated_at": "Sat, 14 Feb 2026 01:30:02 -0500",
      "title": "India partners with Alibaba.com to help Indian startups and small businesses reach overseas buyers, highlighting its selective engagement with Chinese platforms (Jagmeet Singh/TechCrunch)",
      "neutral_headline": "India partners with Alibaba.com for export push despite past China tech bans",
      "bullet_summary": [
        "Reported by TechMeme, TechCrunch"
      ],
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/260214/p3#a260214p3",
          "published_at": "Sat, 14 Feb 2026 01:30:02 -0500",
          "title": "India partners with Alibaba.com to help Indian startups and small businesses reach overseas buyers, highlighting its selective engagement with Chinese platforms (Jagmeet Singh/TechCrunch)",
          "standfirst": "Jagmeet Singh / TechCrunch: India partners with Alibaba.com to help Indian startups and small businesses reach overseas buyers, highlighting its selective engagement with Chinese platforms &mdash; India's government has partnered with China's Alibaba.com on an export-focused program aimed at helping startups and small businesses reach overseas buyers.",
          "content": "Jagmeet Singh / TechCrunch: India partners with Alibaba.com to help Indian startups and small businesses reach overseas buyers, highlighting its selective engagement with Chinese platforms &mdash; India's government has partnered with China's Alibaba.com on an export-focused program aimed at helping startups and small businesses reach overseas buyers.",
          "feed_position": 2,
          "image_url": "http://www.techmeme.com/260214/i3.jpg"
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2026/02/13/india-partners-with-alibaba-com-for-export-push-despite-past-china-tech-bans/",
          "published_at": "Fri, 13 Feb 2026 17:32:59 +0000",
          "title": "India partners with Alibaba.com for export push despite past China tech bans",
          "standfirst": "India turns to Alibaba.com's B2B network of 50 million buyers in 200 countries to help businesses scale global exports.",
          "content": "India turns to Alibaba.com's B2B network of 50 million buyers in 200 countries to help businesses scale global exports.",
          "feed_position": 9
        }
      ],
      "featured_image": "http://www.techmeme.com/260214/i3.jpg",
      "popularity_score": 2015.2090686111112
    },
    {
      "id": "cluster_32",
      "coverage": 2,
      "updated_at": "Fri, 13 Feb 2026 16:25:01 -0500",
      "title": "Blockchain-based lending company Figure confirms a data breach; ShinyHunters hacking group published 2.5GB of data, saying Figure refused to pay a ransom (Lorenzo Franceschi-Bicchierai/TechCrunch)",
      "neutral_headline": "Fintech lending giant Figure confirms data breach",
      "bullet_summary": [
        "5GB of data, saying Figure refused to pay a ransom &mdash; Figure Technology, a blockchain-based lending company, confirmed it experienced a data breach",
        "The company said hackers downloaded “a limited number of files” after breaking into an employee’s account"
      ],
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/260213/p18#a260213p18",
          "published_at": "Fri, 13 Feb 2026 16:25:01 -0500",
          "title": "Blockchain-based lending company Figure confirms a data breach; ShinyHunters hacking group published 2.5GB of data, saying Figure refused to pay a ransom (Lorenzo Franceschi-Bicchierai/TechCrunch)",
          "standfirst": "Lorenzo Franceschi-Bicchierai / TechCrunch: Blockchain-based lending company Figure confirms a data breach; ShinyHunters hacking group published 2.5GB of data, saying Figure refused to pay a ransom &mdash; Figure Technology, a blockchain-based lending company, confirmed it experienced a data breach. &mdash; On Friday, Figure spokesperson &hellip;",
          "content": "Lorenzo Franceschi-Bicchierai / TechCrunch: Blockchain-based lending company Figure confirms a data breach; ShinyHunters hacking group published 2.5GB of data, saying Figure refused to pay a ransom &mdash; Figure Technology, a blockchain-based lending company, confirmed it experienced a data breach. &mdash; On Friday, Figure spokesperson &hellip;",
          "feed_position": 9,
          "image_url": "http://www.techmeme.com/260213/i18.jpg"
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2026/02/13/fintech-lending-giant-figure-confirms-data-breach/",
          "published_at": "Fri, 13 Feb 2026 21:02:46 +0000",
          "title": "Fintech lending giant Figure confirms data breach",
          "standfirst": "The company said hackers downloaded “a limited number of files” after breaking into an employee’s account. The hacking group ShinyHunters took responsibility for the breach.",
          "content": "The company said hackers downloaded “a limited number of files” after breaking into an employee’s account. The hacking group ShinyHunters took responsibility for the breach.",
          "feed_position": 4
        }
      ],
      "featured_image": "http://www.techmeme.com/260213/i18.jpg",
      "popularity_score": 2006.1254575
    },
    {
      "id": "cluster_43",
      "coverage": 2,
      "updated_at": "Fri, 13 Feb 2026 20:05:00 +0000",
      "title": "Two years of the NordVPN Complete plan is 70 percent off",
      "neutral_headline": "Two years of the NordVPN Complete plan is 70 percent off",
      "bullet_summary": [
        "This difference is profound",
        "Here are the top ten as identified by the deliberating participants:As you can see, the Pepsi ad that used Coke’s polar bear was found to be the most effective of the night by a wide margin",
        "In fact, the Thinkscape system reported that this was a statistically significant result for a population of randomly selected consumers (p<0",
        "We found it effective due to its humor, clever use of polar bears, jab at Coca-Cola, memorability, nostalgic elements, wide appeal, product focus and ability to spark conversations"
      ],
      "items": [
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/two-years-of-the-nordvpn-complete-plan-is-70-percent-off-123000349.html",
          "published_at": "Fri, 13 Feb 2026 20:05:00 +0000",
          "title": "Two years of the NordVPN Complete plan is 70 percent off",
          "standfirst": "NordVPN is having a big sale on its two-year plans right now. The Complete tier, for example is 70 percent off, bringing the price of 24 months down to just $130. NordVPN regularly appears on Engadget’s list of the best VPN services thanks to its wide server network, strong security tools and consistent performance across devices. NordVPN’s latest promotion puts one of its most comprehensive plans at a price that undercuts many competing premium VPN subscriptions. The Complete tier includes full access to NordVPN’s core VPN service, which encrypts internet traffic and masks a user’s IP address to help protect online activity on public Wi-Fi networks and at home. Subscribers can use the service on multiple devices, including phones, tablets, laptops and smart TVs, with apps available for major operating systems. It also includes access to NordPass (more on that below), an ad blocker and 1TB of cloud storage. You’ll find similar discounts on all of NordVPN’s other plans: Basic, Plus and Prime. Beyond the basics, NordVPN offers features like threat protection to help block malicious websites and trackers, as well as specialty servers designed for added privacy or faster performance in specific scenarios. In our NordVPN review, the service was praised for its evolving feature set and overall reliability, even as the VPN market becomes increasingly competitive. Engadget regularly tracks VPN pricing trends and this offer compares favorably with other current promotions. It also appears alongside NordVPN deals featured in Engadget’s ongoing roundup of the best VPN discounts available right now, which compares offers from multiple major providers. Those looking for additional security tools may also want to note that NordVPN’s Complete plan bundles in extra services beyond the VPN itself. One of those is NordPass, the company’s password management app. NordPass is also discounted as part of a separate promotion, if you’re primarily looking for a password manager rather than a VPN. The Premium tier is currently 50 percent off, bringing the price down to $36 for two years. NordPass Premium adds features such as cross-device password syncing, secure password sharing and breach monitoring, which alerts users if stored credentials appear in known data leaks. Both offers are available for a limited time, though Nord has not specified an end date for the promotion. If you’re still unsure whether NordVPN is right for you, it offers a 30-day money-back guarantee, so you can change your mind and get a full refund. This article originally appeared on Engadget at https://www.engadget.com/deals/two-years-of-the-nordvpn-complete-plan-is-70-percent-off-123000349.html?src=rss",
          "content": "NordVPN is having a big sale on its two-year plans right now. The Complete tier, for example is 70 percent off, bringing the price of 24 months down to just $130. NordVPN regularly appears on Engadget’s list of the best VPN services thanks to its wide server network, strong security tools and consistent performance across devices. NordVPN’s latest promotion puts one of its most comprehensive plans at a price that undercuts many competing premium VPN subscriptions. The Complete tier includes full access to NordVPN’s core VPN service, which encrypts internet traffic and masks a user’s IP address to help protect online activity on public Wi-Fi networks and at home. Subscribers can use the service on multiple devices, including phones, tablets, laptops and smart TVs, with apps available for major operating systems. It also includes access to NordPass (more on that below), an ad blocker and 1TB of cloud storage. You’ll find similar discounts on all of NordVPN’s other plans: Basic, Plus and Prime. Beyond the basics, NordVPN offers features like threat protection to help block malicious websites and trackers, as well as specialty servers designed for added privacy or faster performance in specific scenarios. In our NordVPN review, the service was praised for its evolving feature set and overall reliability, even as the VPN market becomes increasingly competitive. Engadget regularly tracks VPN pricing trends and this offer compares favorably with other current promotions. It also appears alongside NordVPN deals featured in Engadget’s ongoing roundup of the best VPN discounts available right now, which compares offers from multiple major providers. Those looking for additional security tools may also want to note that NordVPN’s Complete plan bundles in extra services beyond the VPN itself. One of those is NordPass, the company’s password management app. NordPass is also discounted as part of a separate promotion, if you’re primarily looking for a password manager rather than a VPN. The Premium tier is currently 50 percent off, bringing the price down to $36 for two years. NordPass Premium adds features such as cross-device password syncing, secure password sharing and breach monitoring, which alerts users if stored credentials appear in known data leaks. Both offers are available for a limited time, though Nord has not specified an end date for the promotion. If you’re still unsure whether NordVPN is right for you, it offers a 30-day money-back guarantee, so you can change your mind and get a full refund. This article originally appeared on Engadget at https://www.engadget.com/deals/two-years-of-the-nordvpn-complete-plan-is-70-percent-off-123000349.html?src=rss",
          "feed_position": 1
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/ai-agents-turned-super-bowl-viewers-into-one-high-iq-team-now-imagine-this",
          "published_at": "Fri, 13 Feb 2026 19:00:00 GMT",
          "title": "AI agents turned Super Bowl viewers into one high-IQ team — now imagine this in the enterprise",
          "standfirst": "The average Fortune 1000 company has more than 30,000 employees and engineering, sales and marketing teams with hundreds of members. Equally large teams exist in government, science and defense organizations. And yet, research shows that the ideal size for a productive real-time conversation is only about 4 to 7 people.The reason is simple: As groups grow larger, each person has less opportunity to speak and must wait longer to respond, increasing their frustration that their views are not sufficiently considered. This is true whether groups collaborate in person, by video or teleconference, or even by text chat (which buries users in a backlog of messages that reduce participation and undermine deliberation). Simply put, productive team conversations do not scale.So, what do you do if you have a large team and you want to leverage their knowledge, wisdom, insight and expertise? For many organizations, their only choice is to resort to polls, surveys or interviews. This will capture data about individual perspectives, but nobody will “feel heard” when the process is over, and it will rarely find optimal solutions.This is because polls, surveys and interviews are not deliberative instruments. There is no give and take as team members debate issues, provide reasons and rationales, present arguments and counterarguments and ultimately converge on solutions by virtue of their deliberative merits. Surveys treat people as over-simplified data points, while interactive conversations treat people as thoughtful data processors. This difference is profound.I have been studying this issue for more than a decade, and I’m convinced that the best way to unlock the true collective intelligence of large teams is through authentic real-time conversations at scale. I am talking about thoughtful discussions where scores of people can brainstorm, prioritize and forecast together, ultimately converging on solutions that genuinely leverage their combined knowledge, wisdom and insight.But conversations are impossible to scale, right?Wrong — over the last few years, a new communication technology, Hyperchat AI, has emerged. It enables large, distributed teams to hold productive discussions where they can debate issues, brainstorm ideas, prioritize alternatives, provide arguments and counterarguments and efficiently come up with solutions.Inspired by large natural systems, Hyperchat AI combines the biological principles of Swarm Intelligence with the emerging power of AI agents. It works by dividing any large, networked group into a set of small, interconnected subgroups, each sized for thoughtful real-time conversation by text, voice or video. The magical ingredient is a swarm of AI agents called “conversational surrogates” that participate in each local discussion and work to connect all the subgroups together into a single coherent deliberation.Using Hyperchat AI, groups of potentially any size can debate issues, brainstorm ideas, prioritize options, forecast outcomes and solve problems in real-time. And it works — research shows that when large teams hold conversations this way, they converge on smarter, faster and more accurate solutions. In one study I was personally involved in, groups connected by Hyperchat AI amplified their collective IQ to the 97th percentile. In another study, conducted in collaboration with Carnegie Mellon University, groups of 75 people holding conversations using Hyperchat AI technology said they felt more collaborative, productive and heard compared to traditional communication structures like Microsoft Teams, Google Meet or Slack. They also felt greater buy-in to the solutions that emerged.To test the virtues of Hyperchat AI in a fun and timely format, I asked the research team at Unanimous AI (developer of Thinkscape, a platform that uses Hyperchat AI) to bring together 100 members of the public who watched the Super Bowl this Sunday and debate which Super Bowl ad was the most effective, and why?I know this is not a question of grand social importance, but the Super Bowl is among the most watched events in the world, both for the athletic spectacle and the ads. This year, a 30-second spot cost between $8 to 10 million, not including production costs. With that level of investment, every brand is looking to stand out, yet only a few can achieve that. So, we brought together 110 random members of the public — their only qualification being that they watched the Super Bowl — and asked them to discuss and debate the ads. Sixty-six unique ads ran during the game. Did any of them stand out strongly above the rest, and if so, why was it so effective? The 110 participants were divided into 24 subgroups, each with 4 or 5 humans and a single AI agent. Each agent was tasked with observing their subgroup, identifying key insights in real time, then share those insights with AI agents in other subgroups. When agents received those outside insights, they then participated in their local conversation, expressing the insight as a member of their group. This process weaves all the deliberations together into a single real-time conversation that flows seamlessly and converges in unison.All told, the 110 human participants suggested 54 different ads for consideration, and they reached a decisive answer in only 10 minutes of hyper-connected discussion. And, because the AI agents were tracking the dynamics within all 24 local debates, the instant the conversation finished the system generated an ordered list of all 54 ads based on the conversational support across the full population. Here are the top ten as identified by the deliberating participants:As you can see, the Pepsi ad that used Coke’s polar bear was found to be the most effective of the night by a wide margin. In fact, the Thinkscape system reported that this was a statistically significant result for a population of randomly selected consumers (p<0.01).In addition, the system automatically tracks the reasons that emerge in every subgroup, and the reactions to those reasons (whether it swayed opinions of others, inspired counterarguments, or both). This enables the system to instantly produce a deliberative overview for every ad produced, assessing why the group viewed each ad the way it did.Here is the reasoning instantly generated for the Polar Bear ad: “Our collective perspective is that the most effective Super Bowl ad of 2026 was the Pepsi Polar Bears spot. We found it effective due to its humor, clever use of polar bears, jab at Coca-Cola, memorability, nostalgic elements, wide appeal, product focus and ability to spark conversations. While some of us criticized it for focusing on a feud, a large majority felt it successfully captured the essence of a classic Super Bowl ad.”For the record, the team at Unanimous AI also asked this real-time collective to consider a follow-up question, Which Super Bowl ad was the least effective and why? This is what the system reported after 10 minutes of deliberation: “Our collective perspective is that the worst 2026 Super Bowl ad was the Coinbase spot. We found it lacking in clarity, with confusing messaging and a failure to explain the product effectively. Additionally, the ad was found by many to be annoying, cringey and low-effort, with little promotion of the product and a disconnect from Coinbase&#x27;s services. Overall, it failed to build trust and was off-putting to many viewers.” Note: The selection of this ad was a statistically significant result (p<0.01) across the population. Again, this was just a fun example for engaging the public, not a large deliberation of grand importance. That said, I have observed large groups, from analysts in large financial institutions to scientists at the Department of Energy, discussing important issues using this technology — and in all cases the groups seem to converge with increased speed, accuracy and buy-in. For an overview of academic studies on Hyperchat AI, check out this recent paper.Louis Rosenberg earned his PhD from Stanford University, was a professor at California State University (Cal Poly) and has been awarded over 300 patents for his work in human-computer interaction, AI and collective intelligence.",
          "content": "The average Fortune 1000 company has more than 30,000 employees and engineering, sales and marketing teams with hundreds of members. Equally large teams exist in government, science and defense organizations. And yet, research shows that the ideal size for a productive real-time conversation is only about 4 to 7 people.The reason is simple: As groups grow larger, each person has less opportunity to speak and must wait longer to respond, increasing their frustration that their views are not sufficiently considered. This is true whether groups collaborate in person, by video or teleconference, or even by text chat (which buries users in a backlog of messages that reduce participation and undermine deliberation). Simply put, productive team conversations do not scale.So, what do you do if you have a large team and you want to leverage their knowledge, wisdom, insight and expertise? For many organizations, their only choice is to resort to polls, surveys or interviews. This will capture data about individual perspectives, but nobody will “feel heard” when the process is over, and it will rarely find optimal solutions.This is because polls, surveys and interviews are not deliberative instruments. There is no give and take as team members debate issues, provide reasons and rationales, present arguments and counterarguments and ultimately converge on solutions by virtue of their deliberative merits. Surveys treat people as over-simplified data points, while interactive conversations treat people as thoughtful data processors. This difference is profound.I have been studying this issue for more than a decade, and I’m convinced that the best way to unlock the true collective intelligence of large teams is through authentic real-time conversations at scale. I am talking about thoughtful discussions where scores of people can brainstorm, prioritize and forecast together, ultimately converging on solutions that genuinely leverage their combined knowledge, wisdom and insight.But conversations are impossible to scale, right?Wrong — over the last few years, a new communication technology, Hyperchat AI, has emerged. It enables large, distributed teams to hold productive discussions where they can debate issues, brainstorm ideas, prioritize alternatives, provide arguments and counterarguments and efficiently come up with solutions.Inspired by large natural systems, Hyperchat AI combines the biological principles of Swarm Intelligence with the emerging power of AI agents. It works by dividing any large, networked group into a set of small, interconnected subgroups, each sized for thoughtful real-time conversation by text, voice or video. The magical ingredient is a swarm of AI agents called “conversational surrogates” that participate in each local discussion and work to connect all the subgroups together into a single coherent deliberation.Using Hyperchat AI, groups of potentially any size can debate issues, brainstorm ideas, prioritize options, forecast outcomes and solve problems in real-time. And it works — research shows that when large teams hold conversations this way, they converge on smarter, faster and more accurate solutions. In one study I was personally involved in, groups connected by Hyperchat AI amplified their collective IQ to the 97th percentile. In another study, conducted in collaboration with Carnegie Mellon University, groups of 75 people holding conversations using Hyperchat AI technology said they felt more collaborative, productive and heard compared to traditional communication structures like Microsoft Teams, Google Meet or Slack. They also felt greater buy-in to the solutions that emerged.To test the virtues of Hyperchat AI in a fun and timely format, I asked the research team at Unanimous AI (developer of Thinkscape, a platform that uses Hyperchat AI) to bring together 100 members of the public who watched the Super Bowl this Sunday and debate which Super Bowl ad was the most effective, and why?I know this is not a question of grand social importance, but the Super Bowl is among the most watched events in the world, both for the athletic spectacle and the ads. This year, a 30-second spot cost between $8 to 10 million, not including production costs. With that level of investment, every brand is looking to stand out, yet only a few can achieve that. So, we brought together 110 random members of the public — their only qualification being that they watched the Super Bowl — and asked them to discuss and debate the ads. Sixty-six unique ads ran during the game. Did any of them stand out strongly above the rest, and if so, why was it so effective? The 110 participants were divided into 24 subgroups, each with 4 or 5 humans and a single AI agent. Each agent was tasked with observing their subgroup, identifying key insights in real time, then share those insights with AI agents in other subgroups. When agents received those outside insights, they then participated in their local conversation, expressing the insight as a member of their group. This process weaves all the deliberations together into a single real-time conversation that flows seamlessly and converges in unison.All told, the 110 human participants suggested 54 different ads for consideration, and they reached a decisive answer in only 10 minutes of hyper-connected discussion. And, because the AI agents were tracking the dynamics within all 24 local debates, the instant the conversation finished the system generated an ordered list of all 54 ads based on the conversational support across the full population. Here are the top ten as identified by the deliberating participants:As you can see, the Pepsi ad that used Coke’s polar bear was found to be the most effective of the night by a wide margin. In fact, the Thinkscape system reported that this was a statistically significant result for a population of randomly selected consumers (p<0.01).In addition, the system automatically tracks the reasons that emerge in every subgroup, and the reactions to those reasons (whether it swayed opinions of others, inspired counterarguments, or both). This enables the system to instantly produce a deliberative overview for every ad produced, assessing why the group viewed each ad the way it did.Here is the reasoning instantly generated for the Polar Bear ad: “Our collective perspective is that the most effective Super Bowl ad of 2026 was the Pepsi Polar Bears spot. We found it effective due to its humor, clever use of polar bears, jab at Coca-Cola, memorability, nostalgic elements, wide appeal, product focus and ability to spark conversations. While some of us criticized it for focusing on a feud, a large majority felt it successfully captured the essence of a classic Super Bowl ad.”For the record, the team at Unanimous AI also asked this real-time collective to consider a follow-up question, Which Super Bowl ad was the least effective and why? This is what the system reported after 10 minutes of deliberation: “Our collective perspective is that the worst 2026 Super Bowl ad was the Coinbase spot. We found it lacking in clarity, with confusing messaging and a failure to explain the product effectively. Additionally, the ad was found by many to be annoying, cringey and low-effort, with little promotion of the product and a disconnect from Coinbase&#x27;s services. Overall, it failed to build trust and was off-putting to many viewers.” Note: The selection of this ad was a statistically significant result (p<0.01) across the population. Again, this was just a fun example for engaging the public, not a large deliberation of grand importance. That said, I have observed large groups, from analysts in large financial institutions to scientists at the Department of Energy, discussing important issues using this technology — and in all cases the groups seem to converge with increased speed, accuracy and buy-in. For an overview of academic studies on Hyperchat AI, check out this recent paper.Louis Rosenberg earned his PhD from Stanford University, was a professor at California State University (Cal Poly) and has been awarded over 300 patents for his work in human-computer interaction, AI and collective intelligence.",
          "feed_position": 0,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/4xAnIbPYS8dOxnSgfkf6Cs/0829c970cca2705fec3e87c999640d7f/Header.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/apples-magic-mouse-is-down-to-68-right-now-152708925.html",
          "published_at": "Fri, 13 Feb 2026 18:05:35 +0000",
          "title": "Apple's Magic Mouse is down to $68 right now",
          "standfirst": "Apple's USB-C Magic Mouse is back on sale for about $11 off its usual retail price of $79. At $68, that's a savings of 14 percent for one of Apple's best accessories from a company that does not often run sales. The multi-touch mouse was first released in 2009 with a modest refresh released in 2015 and the addition of a USB-C port in 2024. The rechargeable mouse features gesture controls and automatically pairs with your Mac when connected via USB. The Magic Mouse can also be used with an iPad via Bluetooth, or with a Windows PC, though in that case, functionality would be limited. Famously, Jony Ive's design of the Magic Mouse sees its charge port on the underside of the body, rendering it unusable while charging. In 2024 there were rumors of a more comprehensive redesign coming but nothing has materialized since. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/apples-magic-mouse-is-down-to-68-right-now-152708925.html?src=rss",
          "content": "Apple's USB-C Magic Mouse is back on sale for about $11 off its usual retail price of $79. At $68, that's a savings of 14 percent for one of Apple's best accessories from a company that does not often run sales. The multi-touch mouse was first released in 2009 with a modest refresh released in 2015 and the addition of a USB-C port in 2024. The rechargeable mouse features gesture controls and automatically pairs with your Mac when connected via USB. The Magic Mouse can also be used with an iPad via Bluetooth, or with a Windows PC, though in that case, functionality would be limited. Famously, Jony Ive's design of the Magic Mouse sees its charge port on the underside of the body, rendering it unusable while charging. In 2024 there were rumors of a more comprehensive redesign coming but nothing has materialized since. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/apples-magic-mouse-is-down-to-68-right-now-152708925.html?src=rss",
          "feed_position": 3
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/security/how-to-test-openclaw-without-giving-an-autonomous-agent-shell-access-to-your",
          "published_at": "Fri, 13 Feb 2026 17:30:00 GMT",
          "title": "How to test OpenClaw without giving an autonomous agent shell access to your corporate laptop",
          "standfirst": "Your developers are already running OpenClaw at home. Censys tracked the open-source AI agent from roughly 1,000 instances to over 21,000 publicly exposed deployments in under a week. Bitdefender’s GravityZone telemetry, drawn specifically from business environments, confirmed the pattern security leaders feared: employees deploying OpenClaw on corporate machines with single-line install commands, granting autonomous agents shell access, file system privileges, and OAuth tokens to Slack, Gmail, and SharePoint.CVE-2026-25253, a one-click remote code execution flaw rated CVSS 8.8, lets attackers steal authentication tokens through a single malicious link and achieve full gateway compromise in milliseconds. A separate command injection vulnerability, CVE-2026-25157, allowed arbitrary command execution through the macOS SSH handler. A security analysis of 3,984 skills on the ClawHub marketplace found that 283, about 7.1% of the entire registry, contain critical security flaws that expose sensitive credentials in plaintext. And a separate Bitdefender audit found roughly 17% of skills it analyzed exhibited malicious behavior outright.The credential exposure extends beyond OpenClaw itself. Wiz researchers discovered that Moltbook, the AI agent social network built on OpenClaw infrastructure, left its entire Supabase database publicly accessible with no Row Level Security enabled. The breach exposed 1.5 million API authentication tokens, 35,000 email addresses, and private messages between agents that contained plaintext OpenAI API keys. A single misconfiguration gave anyone with a browser full read and write access to every agent credential on the platform.Setup guides say buy a Mac Mini. Security coverage says don’t touch it. Neither gives a security leader a controlled path to evaluation.And they’re coming fast. OpenAI’s Codex app hit 1 million downloads in its first week. Meta has been spotted testing OpenClaw integration in its AI platform codebase. A startup called ai.com spent $8 million on a Super Bowl ad to promote what turned out to be an OpenClaw wrapper, weeks after the project went viral. Security leaders need a middle path between ignoring OpenClaw and deploying it on production hardware. Cloudflare&#x27;s Moltworker framework provides one: ephemeral containers that isolate the agent, encrypted R2 storage for persistent state, and Zero Trust authentication on the admin interface.Why testing locally creates the risk it’s supposed to assessOpenClaw operates with the full privileges of its host user. Shell access. File system read/write. OAuth credentials for every connected service. A compromised agent inherits all of it instantly.Security researcher Simon Willison, who coined the term \"prompt injection,\" describes what he calls the “lethal trifecta” for AI agents: private data access, untrusted content exposure, and external communication capabilities combined in a single process. OpenClaw has all three — and by design. Organizational firewalls see HTTP 200. EDR systems are monitoring process behavior, not semantic content.A prompt injection embedded in a summarized web page or forwarded email can trigger data exfiltration that looks identical to normal user activity. Giskard researchers demonstrated exactly this attack path in January, exploiting shared session context to harvest API keys, environment variables, and credentials across messaging channels.Making matters worse, the OpenClaw gateway binds to 0.0.0.0:18789 by default, exposing its full API to any network interface. Localhost connections authenticate automatically without credentials. Deploy behind a reverse proxy on the same server, and the proxy collapses the authentication boundary entirely, forwarding external traffic as if it originated locally.Ephemeral containers change the mathCloudflare released Moltworker as an open-source reference implementation that decouples the agent’s brain from the execution environment. Instead of running on a machine you’re responsible for, OpenClaw’s logic runs inside a Cloudflare Sandbox, an isolated, ephemeral micro-VM that dies when the task ends.Four layers make up the architecture. A Cloudflare Worker at the edge handles routing and proxying. The OpenClaw runtime executes inside a sandboxed container running Ubuntu 24.04 with Node.js. R2 object storage handles encrypted persistence across container restarts. Cloudflare Access enforces Zero Trust authentication on every route to the admin interface.Containment is the security property that matters most. An agent hijacked through prompt injection gets trapped in a temporary container with zero access to your local network or files. The container dies, and the attack surface dies with it. There is nothing persistent to pivot from. No credentials sitting in a ~/.openclaw/ directory on your corporate laptop. Four steps to a running sandboxGetting a secure evaluation instance running takes an afternoon. Prior Cloudflare experience is not required.Step 1: Configure storage and billing. A Cloudflare account with a Workers Paid plan ($5/month) and an R2 subscription (free tier) covers it. The Workers plan includes access to Sandbox Containers. R2 provides encrypted persistence so conversation history and device pairings survive container restarts. For a pure security evaluation, you can skip R2 and run fully ephemeral. Data disappears on every restart, which may be exactly what you want.Step 2: Generate tokens and deploy. Clone the Moltworker repository, install dependencies, and set three secrets: your Anthropic API key, a randomly generated gateway token (openssl rand -hex 32), and optionally a Cloudflare AI Gateway configuration for provider-agnostic model routing. Run npm run deploy. The first request triggers container initialization with a one-to-two-minute cold start.Step 3: Enable Zero Trust authentication. This is where the sandbox diverges from every other OpenClaw deployment guide. Configure Cloudflare Access to protect the admin UI and all internal routes. Set your Access team domain and application audience tag as Wrangler secrets. Redeploy. Accessing the agent’s control interface now requires authentication through your identity provider. That single step eliminates the exposed admin panels and token-in-URL leakage that Censys and Shodan scans keep finding across the internet.Step 4: Connect a test messaging channel. Start with a burner Telegram account. Set the bot token as a Wrangler secret and redeploy. The agent is reachable through a messaging channel you control, running in an isolated container, with encrypted persistence and authenticated admin access.Total cost for a 24/7 evaluation instance runs roughly $7 to $10 per month. Compare that to a $599 Mac Mini sitting on your desk with full network access and plaintext credentials in its home directory.A 30-day stress test before expanding accessResist the impulse to connect anything real. The first 30 days should run exclusively on throwaway identities.Create a dedicated Telegram bot, and stand up a test calendar with synthetic data. If email integration matters, spin up a fresh account with no forwarding rules, no contacts, and no ties to corporate infrastructure. The point is watching how the agent handles scheduling, summarization, and web research without exposing data that would matter in a breach.Pay close attention to credential handling. OpenClaw stores configurations in plaintext Markdown and JSON files by default, the same formats commodity infostealers like RedLine, Lumma, and Vidar have been actively targeting on OpenClaw installations. In the sandbox, that risk stays contained. On a corporate laptop, those plaintext files are sitting ducks for any malware already present on the endpoint.The sandbox gives you a safe environment to run adversarial tests that are reckless and risky on production hardware, but there are exercises you could try:Send the agent links to pages containing embedded prompt injection instructions and observe whether it follows them. Giskard’s research showed that agents would silently append attacker-controlled instructions to their own workspace HEARTBEAT.md file and wait for further commands from an external server. That behavior should be reproducible in a sandbox where the consequences are zero.Grant limited tool access, and watch whether the agent requests or attempts broader permissions. Monitor the container’s outbound connections for traffic to endpoints you didn’t authorize.Test ClawHub skills before and after installation. OpenClaw recently integrated VirusTotal scanning on the marketplace, and every published skill gets scanned automatically now. Separately, Prompt Security’s ClawSec open-source suite adds drift detection for critical agent files like SOUL.md and checksum verification for skill artifacts, providing a second layer of validation.Feed the agent contradictory instructions from different channels. Try a calendar invite with hidden directives. Send a Telegram message that attempts to override the system prompt. Document everything. The sandbox exists so these experiments carry no production risk.Finally, confirm the sandbox boundary holds. Attempt to access resources outside the container. Verify that container termination kills all active connections. Check whether R2 persistence exposes state that should have been ephemeral.The playbook that outlasts OpenClawThis exercise produces something more durable than an opinion on one tool. The pattern of isolated execution, tiered integrations, and structured validation before expanding trust becomes your evaluation framework for every agentic AI deployment that follows.Building evaluation infrastructure now, before the next viral agent ships, means getting ahead of the shadow AI curve instead of documenting the breach it caused. The agentic AI security model you stand up in the next 30 days determines whether your organization captures the productivity gains or becomes the next disclosure.",
          "content": "Your developers are already running OpenClaw at home. Censys tracked the open-source AI agent from roughly 1,000 instances to over 21,000 publicly exposed deployments in under a week. Bitdefender’s GravityZone telemetry, drawn specifically from business environments, confirmed the pattern security leaders feared: employees deploying OpenClaw on corporate machines with single-line install commands, granting autonomous agents shell access, file system privileges, and OAuth tokens to Slack, Gmail, and SharePoint.CVE-2026-25253, a one-click remote code execution flaw rated CVSS 8.8, lets attackers steal authentication tokens through a single malicious link and achieve full gateway compromise in milliseconds. A separate command injection vulnerability, CVE-2026-25157, allowed arbitrary command execution through the macOS SSH handler. A security analysis of 3,984 skills on the ClawHub marketplace found that 283, about 7.1% of the entire registry, contain critical security flaws that expose sensitive credentials in plaintext. And a separate Bitdefender audit found roughly 17% of skills it analyzed exhibited malicious behavior outright.The credential exposure extends beyond OpenClaw itself. Wiz researchers discovered that Moltbook, the AI agent social network built on OpenClaw infrastructure, left its entire Supabase database publicly accessible with no Row Level Security enabled. The breach exposed 1.5 million API authentication tokens, 35,000 email addresses, and private messages between agents that contained plaintext OpenAI API keys. A single misconfiguration gave anyone with a browser full read and write access to every agent credential on the platform.Setup guides say buy a Mac Mini. Security coverage says don’t touch it. Neither gives a security leader a controlled path to evaluation.And they’re coming fast. OpenAI’s Codex app hit 1 million downloads in its first week. Meta has been spotted testing OpenClaw integration in its AI platform codebase. A startup called ai.com spent $8 million on a Super Bowl ad to promote what turned out to be an OpenClaw wrapper, weeks after the project went viral. Security leaders need a middle path between ignoring OpenClaw and deploying it on production hardware. Cloudflare&#x27;s Moltworker framework provides one: ephemeral containers that isolate the agent, encrypted R2 storage for persistent state, and Zero Trust authentication on the admin interface.Why testing locally creates the risk it’s supposed to assessOpenClaw operates with the full privileges of its host user. Shell access. File system read/write. OAuth credentials for every connected service. A compromised agent inherits all of it instantly.Security researcher Simon Willison, who coined the term \"prompt injection,\" describes what he calls the “lethal trifecta” for AI agents: private data access, untrusted content exposure, and external communication capabilities combined in a single process. OpenClaw has all three — and by design. Organizational firewalls see HTTP 200. EDR systems are monitoring process behavior, not semantic content.A prompt injection embedded in a summarized web page or forwarded email can trigger data exfiltration that looks identical to normal user activity. Giskard researchers demonstrated exactly this attack path in January, exploiting shared session context to harvest API keys, environment variables, and credentials across messaging channels.Making matters worse, the OpenClaw gateway binds to 0.0.0.0:18789 by default, exposing its full API to any network interface. Localhost connections authenticate automatically without credentials. Deploy behind a reverse proxy on the same server, and the proxy collapses the authentication boundary entirely, forwarding external traffic as if it originated locally.Ephemeral containers change the mathCloudflare released Moltworker as an open-source reference implementation that decouples the agent’s brain from the execution environment. Instead of running on a machine you’re responsible for, OpenClaw’s logic runs inside a Cloudflare Sandbox, an isolated, ephemeral micro-VM that dies when the task ends.Four layers make up the architecture. A Cloudflare Worker at the edge handles routing and proxying. The OpenClaw runtime executes inside a sandboxed container running Ubuntu 24.04 with Node.js. R2 object storage handles encrypted persistence across container restarts. Cloudflare Access enforces Zero Trust authentication on every route to the admin interface.Containment is the security property that matters most. An agent hijacked through prompt injection gets trapped in a temporary container with zero access to your local network or files. The container dies, and the attack surface dies with it. There is nothing persistent to pivot from. No credentials sitting in a ~/.openclaw/ directory on your corporate laptop. Four steps to a running sandboxGetting a secure evaluation instance running takes an afternoon. Prior Cloudflare experience is not required.Step 1: Configure storage and billing. A Cloudflare account with a Workers Paid plan ($5/month) and an R2 subscription (free tier) covers it. The Workers plan includes access to Sandbox Containers. R2 provides encrypted persistence so conversation history and device pairings survive container restarts. For a pure security evaluation, you can skip R2 and run fully ephemeral. Data disappears on every restart, which may be exactly what you want.Step 2: Generate tokens and deploy. Clone the Moltworker repository, install dependencies, and set three secrets: your Anthropic API key, a randomly generated gateway token (openssl rand -hex 32), and optionally a Cloudflare AI Gateway configuration for provider-agnostic model routing. Run npm run deploy. The first request triggers container initialization with a one-to-two-minute cold start.Step 3: Enable Zero Trust authentication. This is where the sandbox diverges from every other OpenClaw deployment guide. Configure Cloudflare Access to protect the admin UI and all internal routes. Set your Access team domain and application audience tag as Wrangler secrets. Redeploy. Accessing the agent’s control interface now requires authentication through your identity provider. That single step eliminates the exposed admin panels and token-in-URL leakage that Censys and Shodan scans keep finding across the internet.Step 4: Connect a test messaging channel. Start with a burner Telegram account. Set the bot token as a Wrangler secret and redeploy. The agent is reachable through a messaging channel you control, running in an isolated container, with encrypted persistence and authenticated admin access.Total cost for a 24/7 evaluation instance runs roughly $7 to $10 per month. Compare that to a $599 Mac Mini sitting on your desk with full network access and plaintext credentials in its home directory.A 30-day stress test before expanding accessResist the impulse to connect anything real. The first 30 days should run exclusively on throwaway identities.Create a dedicated Telegram bot, and stand up a test calendar with synthetic data. If email integration matters, spin up a fresh account with no forwarding rules, no contacts, and no ties to corporate infrastructure. The point is watching how the agent handles scheduling, summarization, and web research without exposing data that would matter in a breach.Pay close attention to credential handling. OpenClaw stores configurations in plaintext Markdown and JSON files by default, the same formats commodity infostealers like RedLine, Lumma, and Vidar have been actively targeting on OpenClaw installations. In the sandbox, that risk stays contained. On a corporate laptop, those plaintext files are sitting ducks for any malware already present on the endpoint.The sandbox gives you a safe environment to run adversarial tests that are reckless and risky on production hardware, but there are exercises you could try:Send the agent links to pages containing embedded prompt injection instructions and observe whether it follows them. Giskard’s research showed that agents would silently append attacker-controlled instructions to their own workspace HEARTBEAT.md file and wait for further commands from an external server. That behavior should be reproducible in a sandbox where the consequences are zero.Grant limited tool access, and watch whether the agent requests or attempts broader permissions. Monitor the container’s outbound connections for traffic to endpoints you didn’t authorize.Test ClawHub skills before and after installation. OpenClaw recently integrated VirusTotal scanning on the marketplace, and every published skill gets scanned automatically now. Separately, Prompt Security’s ClawSec open-source suite adds drift detection for critical agent files like SOUL.md and checksum verification for skill artifacts, providing a second layer of validation.Feed the agent contradictory instructions from different channels. Try a calendar invite with hidden directives. Send a Telegram message that attempts to override the system prompt. Document everything. The sandbox exists so these experiments carry no production risk.Finally, confirm the sandbox boundary holds. Attempt to access resources outside the container. Verify that container termination kills all active connections. Check whether R2 persistence exposes state that should have been ephemeral.The playbook that outlasts OpenClawThis exercise produces something more durable than an opinion on one tool. The pattern of isolated execution, tiered integrations, and structured validation before expanding trust becomes your evaluation framework for every agentic AI deployment that follows.Building evaluation infrastructure now, before the next viral agent ships, means getting ahead of the shadow AI curve instead of documenting the breach it caused. The agentic AI security model you stand up in the next 30 days determines whether your organization captures the productivity gains or becomes the next disclosure.",
          "feed_position": 1,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/Xir01lWrwgjJlhWiOFz4M/37bf5c51904ea815798f03a6e8a67e7c/hero_how_to_build_clawbot_FINAL.jpg?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/accessories/best-power-bank-143048526.html",
          "published_at": "Fri, 13 Feb 2026 17:00:36 +0000",
          "title": "The best power banks and portable chargers for every device in 2026",
          "standfirst": "Finding yourself far from a wall socket when your phone hits five percent is positively nervewracking. If you stash a portable battery in your bag, you can avoid that feeling altogether. But there are thousands of power banks out there and it can be tough to pick the right one for what you need. I’ve spent a few years testing dozens of batteries and found the best power banks for different scenarios. Whether you need a quick reup for your phone or a huge brick to keep your laptop alive, you’ll find something fitting here. Best power banks for 2026 What to look for in a portable battery pack Battery type Nearly every rechargeable power bank you can buy (and most portable devices) contain a lithium-ion battery. These beat other current battery types in terms of size-to-charge capacity, and have even increased in energy density by eight fold in the past 14 years. They also don’t suffer from a memory effect (where a battery's lifespan deteriorates due to partial charges). Flying with portable batteries You may have heard about lithium ion batteries overheating and catching fire — a recent Hong Kong flight was grounded after just such a thing happened in an overhead bin. Current restrictions implemented by the TSA still allow external batteries rated at 100Wh or less (which all of our recommendations are) to fly with you, but only in your carry-on luggage — they can’t be checked. Recently, Southwest Airlines was the first in the industry to take that rule one step further. Now, flyers on that airline must keep power banks in clear view when using them to recharge a device. If the portable charger isn’t actively in use, however, it can stay in your carry-on bag in the overhead bin. Capacity Power bank manufacturers almost always list a battery’s capacity in milliamp hours, or mAh. Smaller batteries with a 5,000mAh capacity make good phone chargers and can fill a smartphone to between 50 and 75 percent. Larger batteries that can recharge laptops and tablets, or give phones multiple charges, can exceed 25,000mAh and we have a separate guide that covers that entire category. Unsurprisingly, the prices on most batteries goes up as mAh capacity increases, and since batteries are physical storage units, size and weight go up with capacity as well. If you want more power, be prepared to spend more and carry around a heavier brick. You might think that a 10,000mAh power bank could charge a 5,000mAh phone to 100 percent twice, but that’s not the case. In addition to simple energy loss through heat dissipation, factors like voltage conversion also bring down the amount of juice that makes it into your phone. Most manufacturers list how many charges a battery can give a certain smartphone. In our tests, 10,000mAh of battery pack capacity translated to roughly 5,800mAh of device charge. 20,000mAh chargers delivered around 11,250mAh to a device, and 25,000mAh banks translated to about 16,200mAh of charge. That’s an average efficiency rate of around 60 percent. Wireless Wireless charging, whether through a bank or a plugged-in charging pad, is less efficient than wired connections. But it is convenient — and in most cases, you can carry around and use your phone as it refills with a magnetically attached power bank. Power banks with wireless charging are far better than they once were. Just a couple years ago, the ones I tested were too inefficient to recommend in this guide. When batteries adhering to the Qi2 wireless charging standard started arriving in 2023, performance markedly improved. To gain Qi2-certification, a device has to support speeds of up to 15 watts and include magnetic attachment points. The MagSafe technology on iPhones were once the only handsets that were Qi2-compatible, but now Google’s Pixelsnap tech brings both the higher speed and magnetic grip to Pixel 10 phones. Samsung may follow up with its own version in future releases. The latest wireless charging standard, Q12 25W, is supported by the new iPhone 17 phones as well as the Google Pixel 10 Pro XL. Battery packs that are Qi2 25W-enabled are starting to hit the market as well, and the Ugreen MagFlow was the first on the scene. Ports USB-C ports can deliver faster charges than USB-A ports, and most of the portable chargers we recommend here have Type-C connections. But Type-A jacks are still handy if you need to use a specialized cable for a certain device (my camera’s USB-A to micro USB cable comes to mind). There’s also variation among USB-C ports. Larger banks with more than one port will sometimes list different wattages for each. For example, a bank with three ports may have two 65W ports and one 100W port. There will also be at least one in/out port on the bank, which can be used to charge the battery itself or to deliver a charge to your device. Wattages and in/out labels are printed right next to the port — and always in the tiniest font possible (remember, your phone is an excellent magnifying glass if you ever have trouble reading them). As with standard wall chargers, the port’s wattage will determine what you can charge. A phone will happily charge off a 100W connection, but a 15W plug won’t do much for your laptop. And remember, the cable has to match the maximum wattage. A cable rated for 60W won’t deliver 100W speeds. Luckily, some of the best power banks include a built-in USB-C cable. That’ll not only ensure you have the right cord, it’s one less thing you have to remember to bring along. Design Once, most rechargeable batteries were black with a squared-off, brick-like design, but now they come in different colors and shapes with attractive finishes and detailing. While that doesn’t affect how they perform, it’s a consideration for something you’ll interact with regularly. Some portable power banks include extra features like MagSafe compatibility, a built-in wall plug or even a kickstand. Nearly all have some sort of indicator to let you know how much available charge your power bank has left, usually expressed with lighted pips near the power button. Some of the newer banks take that a step further with an LED display indicating remaining battery percentage. How we test best power banks First, I considered brands Engadget reviewers and staff have tried over the years and checked out customer ratings on retail sites like Amazon and Best Buy. Then, I acquired the most promising candidates and tested them in my home office. Amy Skorheim for Engadget For testing, I used each battery to charge both an iPhone and an Android phone, as well as an iPad and a MacBook Pro for the larger portable chargers. I let the devices get down to between zero and five percent and charged them until the devices were full or the power bank died. For reference, here are the battery capacities of the device I've used for testing over the years: iPhone 11: 3,110 mAh iPhone 14 Plus: 4,325 mAh iPhone 15: 3,349 mAh iPhone 16: 3,561* Galaxy S22 Ultra: 4,855mAh iPad Air: 7,729mAh 16-inch M1 Pro MacBook Pro: 27,027mAh *The iPhone 17 has a slightly larger battery at 3,692mAh I continuously update this guide as companies release new products. Other power banks we tested Here are a few picks that didn't quite make the cut, but are worth mentioning. Belkin Stage PowerGrip If you’re into iPhonography, this clever accessory could be worth a look. Belkin’s Stage PowerGrip is a 9,300mAh power bank that has both a wireless charging pad and built-in cable. But it’s also a Bluetooth shutter with a quarter-inch tripod thread. The design resembles a standard digital camera and provides a sturdy grip once you magnetically attach your phone (make sure you’re either using a MagSafe case or no case to ensure a solid connection). The shutter is conveniently placed and the remote speed was quick enough to capture the cute things my cat was doing. The accessory can even act as a stand while it charges in either landscape or portrait orientation. As a power bank, it’s slow, taking about two hours to get my iPhone 16 from three to 98 percent, but it has enough juice for a full refill plus a little more, which could help if you’re out taking pictures all day. Anker MagGo for Apple Watch power bank The Anker MagGo for Apple Watch power bank combines a 10K battery with a built-in USB-C cable and a pop-up Apple Watch charger. I didn’t formally test it as it’s a little too niche, but it deserves a mention for saving my keister on two occasions. Driving to a hike, my watch told me it was down to 10 percent. Thankfully, I had this and could refill the watch before I got to the trailhead. Later, on an interstate trip, I realized the travel charging station I’d brought was a dud. This kept my watch alive for the week I was away. It does a good job simply charging a phone via the handy on-board cable, too. But for those with an Apple Watch, it’s extra useful. HyperJuice 245W Hyper’s massive-but-sleek brick is one nice looking power bank. The HyperJuice 245W packs a hefty 27,000mAh capacity, enough to refill my tester phone about four times and get a MacBook Pro from near-dead to 75 percent. It only has USB-C ports, but you at least get four of them. USB-C only is probably fine for most situations, but a USB-A port would be nice for charging the occasional older peripheral. The 245 wattage is pretty high for a power bank and it was indeed speedy. It filled a Samsung Galaxy S24 Ultra in just over an hour. But it’s the same price and capacity as our Mophie Powerstation pick for laptop banks, and that one has a better variety of ports. Hyper’s battery is also comparable to Anker’s laptop battery, which is cheaper, has built-in cables and has nearly the same capacity. Plus, that bank is just as swanky looking. EcoFlow Rapid magnetic power bank I was curious to try out the first power bank from EcoFlow, a company that primarily makes larger power stations and whole-home backup batteries. The first offering in the brand’s Rapid series is a Qi2-enabled magnetic charger with a 5,000mAh capacity. It looks quite nice with shiny silver accents and soft-touch grey plastic on the MagSafe-compatible front. There’s a little pull-out leg that sturdily displays your phone as it charges and the attached USB-C cable lets you refill devices directly, then tucks out of the way when it’s not in use. But it didn’t outperform our top pick in the MagSafe category, in terms of both charging speeds and the amount of charge delivered. Mophie Snap+ Powerstation Mini The Mophie snap+ Powerstation Mini is terribly well-built. It feels premium with a rubberized contact point for the MagSafe charging pad and a stand that runs the entire width of the bank itself, making it extra sturdy. It’s compact, too, but only carries a 5,000mAh capacity, which gets you a partial charge on most newer or larger phones. Our current MagSafe/iPhone pick has double the capacity, a stand and a digital display — for just $20 more than the Powerstation Mini. Power bank FAQs What's the difference between a portable power bank and a portable charger? A slew of terms are used to describe power banks, including portable batteries, portable chargers, external battery packs and even, somewhat confusingly, USB chargers, which is what wall chargers are often called. They all mean the same thing: a lithium ion battery that stores a charge so you can refill a smartphone, tablet, earbuds, console controller, ereader, laptop, or just about any other device with its own built-in, rechargeable battery. There’s little difference between the terms, so the specs you’ll want to pay attention to are capacity (expressed in mAh), size and weight so you can find the right balance between recharging what you need and portability. Power stations, on the other hand, are distinct. These are bigger units (often around the size of a car battery) that can be used to charge multiple devices multiple times, but notably, they can’t be taken on airplanes. Does fast charging actually ruin your battery? Not exactly. The real enemy of a battery’s longevity is heat. The faster you charge a battery, the more heat is generated. Modern phones have features that keep the battery cool while charging, like physical heat shields and heat sinks, as well as software features that slow down processes that generate too much heat. Phone manufacturers are keen to promote a phone’s fast-charging abilities, so they had to figure out ways to make faster charging work. While there aren’t long-term studies on what fast charging does to a phone, a study on EV batteries (which use the same general concept of charged lithium ions flowing from one side of the battery to the other, absorbing or releasing a usable charge) showed a very slight decrease in capacity over time with only fast charging — though what actually made a larger difference was how hot the battery itself was, due to ambient temperatures, when it was charged. In short, fast charging could be slightly harder on your battery than normal charging. But the safeguards most smartphones have make that difference fairly negligible. To really ensure you’re optimizing charging capabilities, limit your phone's heat exposure overall. Can you use a power bank for all your devices? That depends on the size of the bank and the size of your device’s battery. A small 5,000mAh battery isn’t strong enough to charge laptops, but a portable charger with a 20,000mAh capacity will give your computer a partial refill. You also have to consider port compatibility. If your device has a USB port, you’ll be able to easily find a cable to connect it to a battery. If your device has a more unique port, such as a DC port, you won’t be able to use a battery. Devices with an AC cable and plug can be charged, and sometimes powered (such as in the case of a printer or speaker), by larger laptop batteries with AC ports.This article originally appeared on Engadget at https://www.engadget.com/computing/accessories/best-power-bank-143048526.html?src=rss",
          "content": "Finding yourself far from a wall socket when your phone hits five percent is positively nervewracking. If you stash a portable battery in your bag, you can avoid that feeling altogether. But there are thousands of power banks out there and it can be tough to pick the right one for what you need. I’ve spent a few years testing dozens of batteries and found the best power banks for different scenarios. Whether you need a quick reup for your phone or a huge brick to keep your laptop alive, you’ll find something fitting here. Best power banks for 2026 What to look for in a portable battery pack Battery type Nearly every rechargeable power bank you can buy (and most portable devices) contain a lithium-ion battery. These beat other current battery types in terms of size-to-charge capacity, and have even increased in energy density by eight fold in the past 14 years. They also don’t suffer from a memory effect (where a battery's lifespan deteriorates due to partial charges). Flying with portable batteries You may have heard about lithium ion batteries overheating and catching fire — a recent Hong Kong flight was grounded after just such a thing happened in an overhead bin. Current restrictions implemented by the TSA still allow external batteries rated at 100Wh or less (which all of our recommendations are) to fly with you, but only in your carry-on luggage — they can’t be checked. Recently, Southwest Airlines was the first in the industry to take that rule one step further. Now, flyers on that airline must keep power banks in clear view when using them to recharge a device. If the portable charger isn’t actively in use, however, it can stay in your carry-on bag in the overhead bin. Capacity Power bank manufacturers almost always list a battery’s capacity in milliamp hours, or mAh. Smaller batteries with a 5,000mAh capacity make good phone chargers and can fill a smartphone to between 50 and 75 percent. Larger batteries that can recharge laptops and tablets, or give phones multiple charges, can exceed 25,000mAh and we have a separate guide that covers that entire category. Unsurprisingly, the prices on most batteries goes up as mAh capacity increases, and since batteries are physical storage units, size and weight go up with capacity as well. If you want more power, be prepared to spend more and carry around a heavier brick. You might think that a 10,000mAh power bank could charge a 5,000mAh phone to 100 percent twice, but that’s not the case. In addition to simple energy loss through heat dissipation, factors like voltage conversion also bring down the amount of juice that makes it into your phone. Most manufacturers list how many charges a battery can give a certain smartphone. In our tests, 10,000mAh of battery pack capacity translated to roughly 5,800mAh of device charge. 20,000mAh chargers delivered around 11,250mAh to a device, and 25,000mAh banks translated to about 16,200mAh of charge. That’s an average efficiency rate of around 60 percent. Wireless Wireless charging, whether through a bank or a plugged-in charging pad, is less efficient than wired connections. But it is convenient — and in most cases, you can carry around and use your phone as it refills with a magnetically attached power bank. Power banks with wireless charging are far better than they once were. Just a couple years ago, the ones I tested were too inefficient to recommend in this guide. When batteries adhering to the Qi2 wireless charging standard started arriving in 2023, performance markedly improved. To gain Qi2-certification, a device has to support speeds of up to 15 watts and include magnetic attachment points. The MagSafe technology on iPhones were once the only handsets that were Qi2-compatible, but now Google’s Pixelsnap tech brings both the higher speed and magnetic grip to Pixel 10 phones. Samsung may follow up with its own version in future releases. The latest wireless charging standard, Q12 25W, is supported by the new iPhone 17 phones as well as the Google Pixel 10 Pro XL. Battery packs that are Qi2 25W-enabled are starting to hit the market as well, and the Ugreen MagFlow was the first on the scene. Ports USB-C ports can deliver faster charges than USB-A ports, and most of the portable chargers we recommend here have Type-C connections. But Type-A jacks are still handy if you need to use a specialized cable for a certain device (my camera’s USB-A to micro USB cable comes to mind). There’s also variation among USB-C ports. Larger banks with more than one port will sometimes list different wattages for each. For example, a bank with three ports may have two 65W ports and one 100W port. There will also be at least one in/out port on the bank, which can be used to charge the battery itself or to deliver a charge to your device. Wattages and in/out labels are printed right next to the port — and always in the tiniest font possible (remember, your phone is an excellent magnifying glass if you ever have trouble reading them). As with standard wall chargers, the port’s wattage will determine what you can charge. A phone will happily charge off a 100W connection, but a 15W plug won’t do much for your laptop. And remember, the cable has to match the maximum wattage. A cable rated for 60W won’t deliver 100W speeds. Luckily, some of the best power banks include a built-in USB-C cable. That’ll not only ensure you have the right cord, it’s one less thing you have to remember to bring along. Design Once, most rechargeable batteries were black with a squared-off, brick-like design, but now they come in different colors and shapes with attractive finishes and detailing. While that doesn’t affect how they perform, it’s a consideration for something you’ll interact with regularly. Some portable power banks include extra features like MagSafe compatibility, a built-in wall plug or even a kickstand. Nearly all have some sort of indicator to let you know how much available charge your power bank has left, usually expressed with lighted pips near the power button. Some of the newer banks take that a step further with an LED display indicating remaining battery percentage. How we test best power banks First, I considered brands Engadget reviewers and staff have tried over the years and checked out customer ratings on retail sites like Amazon and Best Buy. Then, I acquired the most promising candidates and tested them in my home office. Amy Skorheim for Engadget For testing, I used each battery to charge both an iPhone and an Android phone, as well as an iPad and a MacBook Pro for the larger portable chargers. I let the devices get down to between zero and five percent and charged them until the devices were full or the power bank died. For reference, here are the battery capacities of the device I've used for testing over the years: iPhone 11: 3,110 mAh iPhone 14 Plus: 4,325 mAh iPhone 15: 3,349 mAh iPhone 16: 3,561* Galaxy S22 Ultra: 4,855mAh iPad Air: 7,729mAh 16-inch M1 Pro MacBook Pro: 27,027mAh *The iPhone 17 has a slightly larger battery at 3,692mAh I continuously update this guide as companies release new products. Other power banks we tested Here are a few picks that didn't quite make the cut, but are worth mentioning. Belkin Stage PowerGrip If you’re into iPhonography, this clever accessory could be worth a look. Belkin’s Stage PowerGrip is a 9,300mAh power bank that has both a wireless charging pad and built-in cable. But it’s also a Bluetooth shutter with a quarter-inch tripod thread. The design resembles a standard digital camera and provides a sturdy grip once you magnetically attach your phone (make sure you’re either using a MagSafe case or no case to ensure a solid connection). The shutter is conveniently placed and the remote speed was quick enough to capture the cute things my cat was doing. The accessory can even act as a stand while it charges in either landscape or portrait orientation. As a power bank, it’s slow, taking about two hours to get my iPhone 16 from three to 98 percent, but it has enough juice for a full refill plus a little more, which could help if you’re out taking pictures all day. Anker MagGo for Apple Watch power bank The Anker MagGo for Apple Watch power bank combines a 10K battery with a built-in USB-C cable and a pop-up Apple Watch charger. I didn’t formally test it as it’s a little too niche, but it deserves a mention for saving my keister on two occasions. Driving to a hike, my watch told me it was down to 10 percent. Thankfully, I had this and could refill the watch before I got to the trailhead. Later, on an interstate trip, I realized the travel charging station I’d brought was a dud. This kept my watch alive for the week I was away. It does a good job simply charging a phone via the handy on-board cable, too. But for those with an Apple Watch, it’s extra useful. HyperJuice 245W Hyper’s massive-but-sleek brick is one nice looking power bank. The HyperJuice 245W packs a hefty 27,000mAh capacity, enough to refill my tester phone about four times and get a MacBook Pro from near-dead to 75 percent. It only has USB-C ports, but you at least get four of them. USB-C only is probably fine for most situations, but a USB-A port would be nice for charging the occasional older peripheral. The 245 wattage is pretty high for a power bank and it was indeed speedy. It filled a Samsung Galaxy S24 Ultra in just over an hour. But it’s the same price and capacity as our Mophie Powerstation pick for laptop banks, and that one has a better variety of ports. Hyper’s battery is also comparable to Anker’s laptop battery, which is cheaper, has built-in cables and has nearly the same capacity. Plus, that bank is just as swanky looking. EcoFlow Rapid magnetic power bank I was curious to try out the first power bank from EcoFlow, a company that primarily makes larger power stations and whole-home backup batteries. The first offering in the brand’s Rapid series is a Qi2-enabled magnetic charger with a 5,000mAh capacity. It looks quite nice with shiny silver accents and soft-touch grey plastic on the MagSafe-compatible front. There’s a little pull-out leg that sturdily displays your phone as it charges and the attached USB-C cable lets you refill devices directly, then tucks out of the way when it’s not in use. But it didn’t outperform our top pick in the MagSafe category, in terms of both charging speeds and the amount of charge delivered. Mophie Snap+ Powerstation Mini The Mophie snap+ Powerstation Mini is terribly well-built. It feels premium with a rubberized contact point for the MagSafe charging pad and a stand that runs the entire width of the bank itself, making it extra sturdy. It’s compact, too, but only carries a 5,000mAh capacity, which gets you a partial charge on most newer or larger phones. Our current MagSafe/iPhone pick has double the capacity, a stand and a digital display — for just $20 more than the Powerstation Mini. Power bank FAQs What's the difference between a portable power bank and a portable charger? A slew of terms are used to describe power banks, including portable batteries, portable chargers, external battery packs and even, somewhat confusingly, USB chargers, which is what wall chargers are often called. They all mean the same thing: a lithium ion battery that stores a charge so you can refill a smartphone, tablet, earbuds, console controller, ereader, laptop, or just about any other device with its own built-in, rechargeable battery. There’s little difference between the terms, so the specs you’ll want to pay attention to are capacity (expressed in mAh), size and weight so you can find the right balance between recharging what you need and portability. Power stations, on the other hand, are distinct. These are bigger units (often around the size of a car battery) that can be used to charge multiple devices multiple times, but notably, they can’t be taken on airplanes. Does fast charging actually ruin your battery? Not exactly. The real enemy of a battery’s longevity is heat. The faster you charge a battery, the more heat is generated. Modern phones have features that keep the battery cool while charging, like physical heat shields and heat sinks, as well as software features that slow down processes that generate too much heat. Phone manufacturers are keen to promote a phone’s fast-charging abilities, so they had to figure out ways to make faster charging work. While there aren’t long-term studies on what fast charging does to a phone, a study on EV batteries (which use the same general concept of charged lithium ions flowing from one side of the battery to the other, absorbing or releasing a usable charge) showed a very slight decrease in capacity over time with only fast charging — though what actually made a larger difference was how hot the battery itself was, due to ambient temperatures, when it was charged. In short, fast charging could be slightly harder on your battery than normal charging. But the safeguards most smartphones have make that difference fairly negligible. To really ensure you’re optimizing charging capabilities, limit your phone's heat exposure overall. Can you use a power bank for all your devices? That depends on the size of the bank and the size of your device’s battery. A small 5,000mAh battery isn’t strong enough to charge laptops, but a portable charger with a 20,000mAh capacity will give your computer a partial refill. You also have to consider port compatibility. If your device has a USB port, you’ll be able to easily find a cable to connect it to a battery. If your device has a more unique port, such as a DC port, you won’t be able to use a battery. Devices with an AC cable and plug can be charged, and sometimes powered (such as in the case of a printer or speaker), by larger laptop batteries with AC ports.This article originally appeared on Engadget at https://www.engadget.com/computing/accessories/best-power-bank-143048526.html?src=rss",
          "feed_position": 5,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2024-05/75724c60-0bf6-11ef-bbd1-90ceaffb685f"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/expressvpn-deal-two-year-plans-are-up-to-81-percent-off-right-now-180602064.html",
          "published_at": "Fri, 13 Feb 2026 16:45:35 +0000",
          "title": "ExpressVPN deal: Two-year plans are up to 81 percent off right now",
          "standfirst": "If you're looking to up your privacy game on the internet in the new year, you can do so for a little less than usual thanks to ExpressVPN's latest deal. Its two-year plans are up to 81 percent off right now: the Advanced tier is on sale for $88 for two years, plus four additional free months. The Basic plan is where you'll see the biggest discount: it's $68 for two years, plus the same four additional free months. We’ve consistently liked ExpressVPN because it’s fast, easy to use and widely available across a large global server network. In fact, it's our current pick for best premium VPN. One of the biggest drawbacks has always been its high cost, and this deal temporarily solves that issue. In our review we were able to get fast download and upload speeds, losing only 7 percent in the former and 2 percent in the latter worldwide. We found that it could unblock Netflix anywhere, and its mobile and desktop apps were simple to operate. We gave ExpressVPN an overall score of 85 out of 100. The virtual private network service now has three tiers. Basic is cheaper with fewer features, while Pro costs more and adds extra perks like support for 14 simultaneous devices and a password manager. Advanced sits in the middle and includes the password manager but only supports 12 devices.This article originally appeared on Engadget at https://www.engadget.com/deals/expressvpn-deal-two-year-plans-are-up-to-81-percent-off-right-now-180602064.html?src=rss",
          "content": "If you're looking to up your privacy game on the internet in the new year, you can do so for a little less than usual thanks to ExpressVPN's latest deal. Its two-year plans are up to 81 percent off right now: the Advanced tier is on sale for $88 for two years, plus four additional free months. The Basic plan is where you'll see the biggest discount: it's $68 for two years, plus the same four additional free months. We’ve consistently liked ExpressVPN because it’s fast, easy to use and widely available across a large global server network. In fact, it's our current pick for best premium VPN. One of the biggest drawbacks has always been its high cost, and this deal temporarily solves that issue. In our review we were able to get fast download and upload speeds, losing only 7 percent in the former and 2 percent in the latter worldwide. We found that it could unblock Netflix anywhere, and its mobile and desktop apps were simple to operate. We gave ExpressVPN an overall score of 85 out of 100. The virtual private network service now has three tiers. Basic is cheaper with fewer features, while Pro costs more and adds extra perks like support for 14 simultaneous devices and a password manager. Advanced sits in the middle and includes the password manager but only supports 12 devices.This article originally appeared on Engadget at https://www.engadget.com/deals/expressvpn-deal-two-year-plans-are-up-to-81-percent-off-right-now-180602064.html?src=rss",
          "feed_position": 6
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/pick-up-apples-iphone-air-magsafe-battery-pack-while-its-down-to-a-record-low-price-144516992.html",
          "published_at": "Fri, 13 Feb 2026 16:06:26 +0000",
          "title": "Pick up Apple's iPhone Air MagSafe battery pack while it's down to a record-low price",
          "standfirst": "Despite its supremely sleek design, the iPhone Air actually has a pretty respectable battery life, lasting for somewhere in the region of 27 hours if you’re continuously streaming video. But you’re still going to be wary of it dying on you if you’re on a trip or just having a particularly screen-heavy day. That’s where Apple’s iPhone Air MagSafe battery pack comes in, and it’s currently on sale for $79. This accessory only works with the iPhone Air, but much like the phone it attaches to, it’s extremely slim at 7.5mmm, so crucially doesn’t add so much bulk when attached that it defeats the point of having a thin phone in the first place. The MagSafe Battery isn’t enormous at 3,149mAh (enough to add an extra 65 percent of charge to the Air), but it can wirelessly charge the AirPods Pro 3 as well, making it an even more useful travel companion. You can also charge your iPhone while charging the battery pack. At its regular price of $99, the MagSafe battery pack is an admittedly pricey add-on to what is already an expensive phone, but for $20 off it’s well worth considering what Engadget’s Sam Rutherford called an \"essential accessory\" for some users in his iPhone Air review. Many Apple loyalists will always insist on having first-party accessories for their iPhone, but there are plenty of third-party MagSafe chargers out there too, a lot of them considerably cheaper than Apple’s lineup. Be sure to check out our guide for those. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/pick-up-apples-iphone-air-magsafe-battery-pack-while-its-down-to-a-record-low-price-144516992.html?src=rss",
          "content": "Despite its supremely sleek design, the iPhone Air actually has a pretty respectable battery life, lasting for somewhere in the region of 27 hours if you’re continuously streaming video. But you’re still going to be wary of it dying on you if you’re on a trip or just having a particularly screen-heavy day. That’s where Apple’s iPhone Air MagSafe battery pack comes in, and it’s currently on sale for $79. This accessory only works with the iPhone Air, but much like the phone it attaches to, it’s extremely slim at 7.5mmm, so crucially doesn’t add so much bulk when attached that it defeats the point of having a thin phone in the first place. The MagSafe Battery isn’t enormous at 3,149mAh (enough to add an extra 65 percent of charge to the Air), but it can wirelessly charge the AirPods Pro 3 as well, making it an even more useful travel companion. You can also charge your iPhone while charging the battery pack. At its regular price of $99, the MagSafe battery pack is an admittedly pricey add-on to what is already an expensive phone, but for $20 off it’s well worth considering what Engadget’s Sam Rutherford called an \"essential accessory\" for some users in his iPhone Air review. Many Apple loyalists will always insist on having first-party accessories for their iPhone, but there are plenty of third-party MagSafe chargers out there too, a lot of them considerably cheaper than Apple’s lineup. Be sure to check out our guide for those. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/pick-up-apples-iphone-air-magsafe-battery-pack-while-its-down-to-a-record-low-price-144516992.html?src=rss",
          "feed_position": 7
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/pick-up-this-samsung-microsd-express-card-while-its-on-sale-for-40-off-143849979.html",
          "published_at": "Fri, 13 Feb 2026 15:26:26 +0000",
          "title": "Pick up this Samsung microSD Express card while it's on sale for $40 off",
          "standfirst": "If you're looking to expand the storage on your Switch 2, the 512GB Samsung P9 microSD Express card is on sale right now for 33 percent off, marked down to $80 from $120. With component prices skyrocketing these days, it's getting increasingly rare to see good storage on sale, and 512GB for $80 is a much better deal than you'll currently find directly from Nintendo. The P9 boasts transfer speeds of up to 800MB/s, making moving games to the card that much faster. As for load times, in our testing we found that any microSD Express, the standard the Switch 2 requires, will offer roughly the same performance. This format is pretty new, so there aren't a ton of cards on the market. As such, the P9 makes our list of best microSD cards for the Nintendo Switch 2. The P9 microSD Express is also compatible with the Steam Deck or any other gaming console that accepts the format, as well as cameras and more. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/pick-up-this-samsung-microsd-express-card-while-its-on-sale-for-40-off-143849979.html?src=rss",
          "content": "If you're looking to expand the storage on your Switch 2, the 512GB Samsung P9 microSD Express card is on sale right now for 33 percent off, marked down to $80 from $120. With component prices skyrocketing these days, it's getting increasingly rare to see good storage on sale, and 512GB for $80 is a much better deal than you'll currently find directly from Nintendo. The P9 boasts transfer speeds of up to 800MB/s, making moving games to the card that much faster. As for load times, in our testing we found that any microSD Express, the standard the Switch 2 requires, will offer roughly the same performance. This format is pretty new, so there aren't a ton of cards on the market. As such, the P9 makes our list of best microSD cards for the Nintendo Switch 2. The P9 microSD Express is also compatible with the Steam Deck or any other gaming console that accepts the format, as well as cameras and more. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/pick-up-this-samsung-microsd-express-card-while-its-on-sale-for-40-off-143849979.html?src=rss",
          "feed_position": 9
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/the-latest-45w-anker-nano-charger-with-smart-display-is-10-off-right-now-160707685.html",
          "published_at": "Fri, 13 Feb 2026 14:51:26 +0000",
          "title": "The latest 45W Anker Nano charger with smart display is $10 off right now",
          "standfirst": "Anker introduced a nifty little charger at CES 2026, which is a refresh of the pre-existing Nano Charger. It's already on sale for $30, which is a discount of $10 or 25 percent. The 45W charger includes a smart display that shows real-time data like power flow, temperature and charging status. It also features \"fun animations to keep things cheerful.\" Anker says it can recognize what's being charged and automatically adjust certain metrics to ensure a longer battery lifespan. To that end, it works with just about everything. The company advertises that this charger is a good fit for the iPhone, Apple Watch, AirPods and Samsung devices, among others. The new Nano Charger is on the smaller side, with dual folding prongs that rotate to fit most outlets. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/the-latest-45w-anker-nano-charger-with-smart-display-is-10-off-right-now-160707685.html?src=rss",
          "content": "Anker introduced a nifty little charger at CES 2026, which is a refresh of the pre-existing Nano Charger. It's already on sale for $30, which is a discount of $10 or 25 percent. The 45W charger includes a smart display that shows real-time data like power flow, temperature and charging status. It also features \"fun animations to keep things cheerful.\" Anker says it can recognize what's being charged and automatically adjust certain metrics to ensure a longer battery lifespan. To that end, it works with just about everything. The company advertises that this charger is a good fit for the iPhone, Apple Watch, AirPods and Samsung devices, among others. The new Nano Charger is on the smaller side, with dual folding prongs that rotate to fit most outlets. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/the-latest-45w-anker-nano-charger-with-smart-display-is-10-off-right-now-160707685.html?src=rss",
          "feed_position": 10
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/presidents-day-sales-2026-the-best-tech-deals-to-shop-this-week-from-apple-sony-samsung-and-others-163000831.html",
          "published_at": "Fri, 13 Feb 2026 14:50:38 +0000",
          "title": "Presidents' Day sales 2026: The best tech deals to shop this week from Apple, Sony, Samsung and others",
          "standfirst": "You can find a lot of good deals for Presidents’ Day, but to say it’s a tech-deal boon would be an overstatement. The best Presidents’ Day deals are usually on mattresses, appliances and furniture, but you can find some decent tech sales thrown in as well. This year, Presidents’ Day comes right after Valentine’s Day and Super Bowl 2026, which means there are even more chances to save as sales and discounts overlap. If you’re looking for a new streaming device, a fresh iPad or an upgraded vacuum so you can enter the spring-cleaning season properly, we have you covered. These are the best President Day sales on tech we could find this year. Presidents’ Day deals under $50 Disney+ and Hulu bundle (one month) for $10 ($3 off): You can get one month of Disney+ and Hulu access for only $10 right now. That represents a small savings over the standard $13-per-month price for the bundle, but a 58-percent discount when you compare it to the price of paying for both services separately. It’s a good way to test out the bundle without paying too much before you decide if you want to subscribe for the long haul. Anker Nano 45W USB-C charger for $30 ($10 off): Anker’s latest 45W charger has a small smart display on it that can show you real-time charging stats. It’s compact design is great for travel, as are its foldable prongs. Waterpik cordless rechargeable water flosser for $40 (20 percent off): A water flosser like this one can make it easier (and less painful in some cases) to floss your teeth on the regular. This model from Waterpik includes two interchangeable tips and has two pressure settings. Its battery life should last up to four weeks with regular use as well. Amazon Fire TV Stick 4K Max for $40 ($20 off): Amazon’s most premium streaming dongle supports 4K HDR content, Dolby Vision and Wi-Fi 6E. You may even be able to get it for $10 less than the sale price listed, for a final price of $30, when using the code MAX4KFTV at checkout. Blink Mini 2K+ — 2 cameras for $45 (50 percent off): Blink’s latest plug-in security cameras support 2K video and improved audio quality. Like previous versions, these cameras have two-way talk, motion alerts and support for Alexa voice commands. Anker Nano 5K ultra-slim magnetic power bank for $46 (16 percent off): This Qi2 power bank measures less than a half inch thick and snaps onto the backs of the latest iPhones for wireless charging. Its 5K capacity will be enough to top up your phone when it’s close to empty, preventing you from searching for a charger or outlet. Presidents’ Day deals on Apple devices Apple iPhone Air MagSafe battery pack for $79 (20 percent off): This magnetic power bank will add up to 65 percent additional battery charge to the iPhone Air, but note that it only works with Apple’s new, ultra-slim smartphone. We’ve tested plenty of others that also work with other iPhone and smartphone models. Apple Magic Mouse for $68 (14 percent off): Apple’s sleek wireless mouse has a multi-touch surface that supports gesture control, and its battery should last about a month in between charges. And yes, it has a USB-C port. Apple Watch Series 11 for $299 ($100 off): The latest flagship Apple Watch has excellent performance, a boosted battery life and a lightweight design that you can comfortably wear all day long — and even into the night to track sleep. iPad mini (A17 Pro ) for $399 ($100 off): The updated iPad mini runs on the A17 Pro chip for improved performance, plus it has an 8.3-inch Liquid Retina display, a 12MP ultra wide camera with Center Stage, USB-C charging and compatibility with the Apple Pencil Pro. Beats Studio Pro for $170 (51 percent off): Beats updated these cans to have improved sound quality, and you can really hear the difference from models that came before it. These headphones also have solid Transparency mode, good voice performance and USB-C audio. Beats Solo 4 headphones for $130 (35 percent off): These on-ear headphones support spatial audio and dynamic head tracking, and they have up to 50 hours of battery life. The “fast fuel” feature allows them to get up to five hours of playback time with just a quick 10-minute power-up. Beats Studio Buds+ for $100 (41 percent off): These tiny buds have both active noise cancellation and transparency mode, and they’ll work just as well with either Apple or Android devices. More Presidents’ Day deals on tech Ring Battery Doorbell for $60 (40 percent off) Logitech MX Master 3S for $80 (20 percent off) Levoit Core 300-P air purifier for $85 (15 percent off) Sony WH-CH720N wireless headphones for $94 (48 percent off) MasterClass Premium (one year) for $120 (50 percent off) Shark Steam & Scrub steam mop for $125 (22 percent off) Google Pixel Buds Pro 2 earbuds for $179 (22 percent off) Sonos Beam Gen 2 soundbar for $369 ($130 off) Hisense 75-inch QD7 Mini-LED 4K smart TV for $548 (16 percent off) DJI Mini 3 Fly More Combo drone bundle for $575 (20 percent off) Breville Barista Touch espresso machine for $800 ($200 off) Motorola Razer Ultra (2025) for $800 (38 percent off) Google Pixel 10 Pro for $849 (23 percent off) This article originally appeared on Engadget at https://www.engadget.com/deals/presidents-day-sales-2026-the-best-tech-deals-to-shop-this-week-from-apple-sony-samsung-and-others-163000831.html?src=rss",
          "content": "You can find a lot of good deals for Presidents’ Day, but to say it’s a tech-deal boon would be an overstatement. The best Presidents’ Day deals are usually on mattresses, appliances and furniture, but you can find some decent tech sales thrown in as well. This year, Presidents’ Day comes right after Valentine’s Day and Super Bowl 2026, which means there are even more chances to save as sales and discounts overlap. If you’re looking for a new streaming device, a fresh iPad or an upgraded vacuum so you can enter the spring-cleaning season properly, we have you covered. These are the best President Day sales on tech we could find this year. Presidents’ Day deals under $50 Disney+ and Hulu bundle (one month) for $10 ($3 off): You can get one month of Disney+ and Hulu access for only $10 right now. That represents a small savings over the standard $13-per-month price for the bundle, but a 58-percent discount when you compare it to the price of paying for both services separately. It’s a good way to test out the bundle without paying too much before you decide if you want to subscribe for the long haul. Anker Nano 45W USB-C charger for $30 ($10 off): Anker’s latest 45W charger has a small smart display on it that can show you real-time charging stats. It’s compact design is great for travel, as are its foldable prongs. Waterpik cordless rechargeable water flosser for $40 (20 percent off): A water flosser like this one can make it easier (and less painful in some cases) to floss your teeth on the regular. This model from Waterpik includes two interchangeable tips and has two pressure settings. Its battery life should last up to four weeks with regular use as well. Amazon Fire TV Stick 4K Max for $40 ($20 off): Amazon’s most premium streaming dongle supports 4K HDR content, Dolby Vision and Wi-Fi 6E. You may even be able to get it for $10 less than the sale price listed, for a final price of $30, when using the code MAX4KFTV at checkout. Blink Mini 2K+ — 2 cameras for $45 (50 percent off): Blink’s latest plug-in security cameras support 2K video and improved audio quality. Like previous versions, these cameras have two-way talk, motion alerts and support for Alexa voice commands. Anker Nano 5K ultra-slim magnetic power bank for $46 (16 percent off): This Qi2 power bank measures less than a half inch thick and snaps onto the backs of the latest iPhones for wireless charging. Its 5K capacity will be enough to top up your phone when it’s close to empty, preventing you from searching for a charger or outlet. Presidents’ Day deals on Apple devices Apple iPhone Air MagSafe battery pack for $79 (20 percent off): This magnetic power bank will add up to 65 percent additional battery charge to the iPhone Air, but note that it only works with Apple’s new, ultra-slim smartphone. We’ve tested plenty of others that also work with other iPhone and smartphone models. Apple Magic Mouse for $68 (14 percent off): Apple’s sleek wireless mouse has a multi-touch surface that supports gesture control, and its battery should last about a month in between charges. And yes, it has a USB-C port. Apple Watch Series 11 for $299 ($100 off): The latest flagship Apple Watch has excellent performance, a boosted battery life and a lightweight design that you can comfortably wear all day long — and even into the night to track sleep. iPad mini (A17 Pro ) for $399 ($100 off): The updated iPad mini runs on the A17 Pro chip for improved performance, plus it has an 8.3-inch Liquid Retina display, a 12MP ultra wide camera with Center Stage, USB-C charging and compatibility with the Apple Pencil Pro. Beats Studio Pro for $170 (51 percent off): Beats updated these cans to have improved sound quality, and you can really hear the difference from models that came before it. These headphones also have solid Transparency mode, good voice performance and USB-C audio. Beats Solo 4 headphones for $130 (35 percent off): These on-ear headphones support spatial audio and dynamic head tracking, and they have up to 50 hours of battery life. The “fast fuel” feature allows them to get up to five hours of playback time with just a quick 10-minute power-up. Beats Studio Buds+ for $100 (41 percent off): These tiny buds have both active noise cancellation and transparency mode, and they’ll work just as well with either Apple or Android devices. More Presidents’ Day deals on tech Ring Battery Doorbell for $60 (40 percent off) Logitech MX Master 3S for $80 (20 percent off) Levoit Core 300-P air purifier for $85 (15 percent off) Sony WH-CH720N wireless headphones for $94 (48 percent off) MasterClass Premium (one year) for $120 (50 percent off) Shark Steam & Scrub steam mop for $125 (22 percent off) Google Pixel Buds Pro 2 earbuds for $179 (22 percent off) Sonos Beam Gen 2 soundbar for $369 ($130 off) Hisense 75-inch QD7 Mini-LED 4K smart TV for $548 (16 percent off) DJI Mini 3 Fly More Combo drone bundle for $575 (20 percent off) Breville Barista Touch espresso machine for $800 ($200 off) Motorola Razer Ultra (2025) for $800 (38 percent off) Google Pixel 10 Pro for $849 (23 percent off) This article originally appeared on Engadget at https://www.engadget.com/deals/presidents-day-sales-2026-the-best-tech-deals-to-shop-this-week-from-apple-sony-samsung-and-others-163000831.html?src=rss",
          "feed_position": 11
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/apples-first-gen-airtags-are-on-sale-for-64-for-a-four-pack-163619918.html",
          "published_at": "Fri, 13 Feb 2026 14:37:28 +0000",
          "title": "Apple's first-gen AirTags are on sale for $64 for a four-pack",
          "standfirst": "At this point, you can find discounts on AirTags fairly often but if you want to spend as little as possible, it's worth waiting for a discount like this. A four-pack of the first-gen Bluetooth trackers is on sale for $64, which is just about a record-low price (only $1 more). That's a 35 percent discount on the pack. Bear in mind that this deal brings the price per AirTag down to about $16 if you were to buy them individually, and when not on sale they usually cost $29. If you use Apple devices and consider yourself to be a serial thing-misplacer, AirTags are extremely useful. Adding one to your account takes a single tap, and with Apple’s Find My network so well established, locating missing items has never been easier. Using your iPhone you can trigger a sound from the AirTag’s built-in speaker, or alternatively Precision Finding can be used to pinpoint its location via Find My. You just follow the instructions on your iPhone, paying attention to the vibrations that signal you’re getting closer. A reminder again that the above deals apply to the first-generation AirTag only. Apple introduced a refreshed tracker with greater range and a louder speaker last month, which retails at the same price as its predecessor. For deals on the new AirTag, you may have to wait a bit. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/apples-first-gen-airtags-are-on-sale-for-64-for-a-four-pack-163619918.html?src=rss",
          "content": "At this point, you can find discounts on AirTags fairly often but if you want to spend as little as possible, it's worth waiting for a discount like this. A four-pack of the first-gen Bluetooth trackers is on sale for $64, which is just about a record-low price (only $1 more). That's a 35 percent discount on the pack. Bear in mind that this deal brings the price per AirTag down to about $16 if you were to buy them individually, and when not on sale they usually cost $29. If you use Apple devices and consider yourself to be a serial thing-misplacer, AirTags are extremely useful. Adding one to your account takes a single tap, and with Apple’s Find My network so well established, locating missing items has never been easier. Using your iPhone you can trigger a sound from the AirTag’s built-in speaker, or alternatively Precision Finding can be used to pinpoint its location via Find My. You just follow the instructions on your iPhone, paying attention to the vibrations that signal you’re getting closer. A reminder again that the above deals apply to the first-generation AirTag only. Apple introduced a refreshed tracker with greater range and a louder speaker last month, which retails at the same price as its predecessor. For deals on the new AirTag, you may have to wait a bit. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/apples-first-gen-airtags-are-on-sale-for-64-for-a-four-pack-163619918.html?src=rss",
          "feed_position": 13
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/apple-presidents-day-sales-get-the-apple-watch-series-11-for-299-plus-more-deals-151616971.html",
          "published_at": "Fri, 13 Feb 2026 14:34:45 +0000",
          "title": "Apple Presidents' Day sales: Get the Apple Watch Series 11 for $299, plus more deals",
          "standfirst": "Whether you're one of the few people still keeping up with New Year's resolutions or just want an upgraded smartwatch, now is a good time to get an Apple Watch. Currently, the Apple Watch Series 11 is on sale for $299 for Presidents' Day, down from $399. The 25 percent discount brings the 2025 model back down to its record-low price. A number of other Apple devices are on sale for the holiday as well. We named the Apple Watch Series 11 as our choice for best smartwatch overall. It scored a 90 in our review thanks to its 24 hours-plus of battery life and a thin, light design that's easy to wear. It also offers new health metrics, including Apple's hypertension alerts system and Sleep Score. The Apple Watch Series 11 deal is available on the 42mm case with a small/medium band. It also only includes GPS and four colorways: the Jet Black and Space Gray aluminum cases with a Black sport band, the Rose Gold aluminum case with a Light Blush sport band and the Silver aluminum case with a Purple Fog sport band. Among the other Presidents' Day Apple deals are mostly accessories: there are solid deals on AirPods, AirTags (the first-gen trackers, not the new, second-gen ones), the iPhone Air battery pack and even Apple's new crossbody straps that attach to the company's iPhone cases so you can essentially \"wear\" your iPhone like a bag. As with most Apple first-party accessories, you can find plenty of more affordable, third-party versions of them as alternatives. But if you're keen on outfitting your phone with Apple's own gear, it's best to wait for discounts like these. We've collected the best Presidents' Day sales on Apple gear below so you don't have to go searching for them. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/apple-presidents-day-sales-get-the-apple-watch-series-11-for-299-plus-more-deals-151616971.html?src=rss",
          "content": "Whether you're one of the few people still keeping up with New Year's resolutions or just want an upgraded smartwatch, now is a good time to get an Apple Watch. Currently, the Apple Watch Series 11 is on sale for $299 for Presidents' Day, down from $399. The 25 percent discount brings the 2025 model back down to its record-low price. A number of other Apple devices are on sale for the holiday as well. We named the Apple Watch Series 11 as our choice for best smartwatch overall. It scored a 90 in our review thanks to its 24 hours-plus of battery life and a thin, light design that's easy to wear. It also offers new health metrics, including Apple's hypertension alerts system and Sleep Score. The Apple Watch Series 11 deal is available on the 42mm case with a small/medium band. It also only includes GPS and four colorways: the Jet Black and Space Gray aluminum cases with a Black sport band, the Rose Gold aluminum case with a Light Blush sport band and the Silver aluminum case with a Purple Fog sport band. Among the other Presidents' Day Apple deals are mostly accessories: there are solid deals on AirPods, AirTags (the first-gen trackers, not the new, second-gen ones), the iPhone Air battery pack and even Apple's new crossbody straps that attach to the company's iPhone cases so you can essentially \"wear\" your iPhone like a bag. As with most Apple first-party accessories, you can find plenty of more affordable, third-party versions of them as alternatives. But if you're keen on outfitting your phone with Apple's own gear, it's best to wait for discounts like these. We've collected the best Presidents' Day sales on Apple gear below so you don't have to go searching for them. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/apple-presidents-day-sales-get-the-apple-watch-series-11-for-299-plus-more-deals-151616971.html?src=rss",
          "feed_position": 14
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/cameras/the-ridiculously-tiny-kodak-charmera-captured-our-hearts-and-lots-of-shoddy-pictures-140000245.html",
          "published_at": "Fri, 13 Feb 2026 14:00:00 +0000",
          "title": "The ridiculously tiny Kodak Charmera captured our hearts (and lots of shoddy pictures)",
          "standfirst": "Every once in a while, a product comes along that sparks a bit of joy in our jaded hearts. This is what happened with the Kodak Charmera, a $30 tiny toy camera that was nearly impossible to get ahold of in the first couple of months after its release, selling out immediately over waves of blind box restocks. Despite the gimmick of it all, the Charmera was just too cute for some of us to resist, and we sprang when they finally started becoming more readily available. A few of us on the Engadget team have one now, and even with all of its shortcomings, we kind of love this thing. Here's what two of our writers think about it. Lately, it feels like a chore to carry around a full-frame mirrorless camera. My Nikon definitely feels like the right tool to precisely capture a moment in time with fast autofocus and plenty of image resolution. Other times, that perfect moment is more casual, like catching up with friends over dim sum or killing time while you're snowed in at a cabin in Vermont. In these cases, there's no reason to carry around a hulking camera and lens to snap a flawless photo that I have to edit later. Instead, something light, discreet and playful feels like the right tool for the occasion. Jackson Chen for Engadget That's where the Kodak Charmera comes in. It's a toy camera with a 35mm lens with a fixed f/2.4 aperture and a 1/4-inch sensor. In other words, the photos this thing takes are about equivalent to what you would get with a crappy flip phone from the 2000s that also plays Snake. Kodak is clearly trying to wring out the longing for nostalgia within all of us, and has nailed it with the Charmera, which is even inspired by its old-school disposable Fling cameras. It's definitely not as good as the smartphone in your pocket, but there's something disarming about snapping a quick shot with a tiny block of plastic that's lighter than your keys. Playing around with the Charmera for a few weeks gave me a healthy reminder that the sillier and more transient parts of life don't need the technical prowess of an expensive camera. Obviously, the Chamera produces photos of terrible quality at 1.6 megapixels and can't really capture anything fast-moving or in low light, but it's undeniably fun and hard to resist shooting with. And sometimes, you and your friends are just doing wildly unserious things and you want a camera that matches that energy. — Jackson Chen, Contributing Reporter Every time I pull out the Kodak Charmera in public to snap a few pictures, I'm immediately met with a barrage of questions and squeals of delight from full-grown adults: \"What is that?\"; \"Is that a camera?\"; \"Does it really take pictures?\"; \"Can I see it?\" It is the kind of accessory that doubles as a conversation starter, an effect that's turned out to be as joyous as taking pictures with the camera itself. I've been trying really hard to spend less time on social media and my phone in general lately, and having a two-inch camera clipped to me has made for a pretty fun shift in how I document the day-to-day. As the resurgence of compact digital cameras has shown us, a lot of people are yearning for a time of simpler tech — when we had personal devices that could do useful things, like take decent photos and connect us to our friends, but didn't consume our lives entirely. Companies like Camp Snap have shaped their entire brands around recapturing that magic, and some consumers have shown that they're willing to sacrifice in areas like image quality in exchange for a taste of it, too. The Kodak Charmera isn't the kind of product you go into purchasing with high expectations. It is clearly a toy that is only going to be capable of so much. Cheyenne MacDonald for Engadget As Jackson noted, the low-resolution 1,440 x 1,080 pictures look about on par with those you'd have taken on a flip phone 15 or 20 years ago. In the right lighting conditions with a clearly defined subject, they're not so bad. But selfies, portraits and nature photos will generally look washed out. It can record videos too — and you should set similarly low expectations for these. Despite all that, I've been pleasantly surprised by how much I'm enjoying the Charmera experience. Its crunchy photos are just good enough to feel like they're successfully preserving a moment in time. And being so tiny, it's really convenient to bring everywhere. It even came with me to CES. The Charmera takes a microSD card (sold separately), allowing for tons of storage and easy transferring. There are a bunch of built-in filters you can apply, too, which have been fun to play around with. If I want high-quality photos, this isn't the camera I'm going to reach for. But it's great for low-stakes situations when all I care about is taking some pictures I can look back on fondly later. Consider me charmed. — Cheyenne MacDonald, Weekend Editor This article originally appeared on Engadget at https://www.engadget.com/cameras/the-ridiculously-tiny-kodak-charmera-captured-our-hearts-and-lots-of-shoddy-pictures-140000245.html?src=rss",
          "content": "Every once in a while, a product comes along that sparks a bit of joy in our jaded hearts. This is what happened with the Kodak Charmera, a $30 tiny toy camera that was nearly impossible to get ahold of in the first couple of months after its release, selling out immediately over waves of blind box restocks. Despite the gimmick of it all, the Charmera was just too cute for some of us to resist, and we sprang when they finally started becoming more readily available. A few of us on the Engadget team have one now, and even with all of its shortcomings, we kind of love this thing. Here's what two of our writers think about it. Lately, it feels like a chore to carry around a full-frame mirrorless camera. My Nikon definitely feels like the right tool to precisely capture a moment in time with fast autofocus and plenty of image resolution. Other times, that perfect moment is more casual, like catching up with friends over dim sum or killing time while you're snowed in at a cabin in Vermont. In these cases, there's no reason to carry around a hulking camera and lens to snap a flawless photo that I have to edit later. Instead, something light, discreet and playful feels like the right tool for the occasion. Jackson Chen for Engadget That's where the Kodak Charmera comes in. It's a toy camera with a 35mm lens with a fixed f/2.4 aperture and a 1/4-inch sensor. In other words, the photos this thing takes are about equivalent to what you would get with a crappy flip phone from the 2000s that also plays Snake. Kodak is clearly trying to wring out the longing for nostalgia within all of us, and has nailed it with the Charmera, which is even inspired by its old-school disposable Fling cameras. It's definitely not as good as the smartphone in your pocket, but there's something disarming about snapping a quick shot with a tiny block of plastic that's lighter than your keys. Playing around with the Charmera for a few weeks gave me a healthy reminder that the sillier and more transient parts of life don't need the technical prowess of an expensive camera. Obviously, the Chamera produces photos of terrible quality at 1.6 megapixels and can't really capture anything fast-moving or in low light, but it's undeniably fun and hard to resist shooting with. And sometimes, you and your friends are just doing wildly unserious things and you want a camera that matches that energy. — Jackson Chen, Contributing Reporter Every time I pull out the Kodak Charmera in public to snap a few pictures, I'm immediately met with a barrage of questions and squeals of delight from full-grown adults: \"What is that?\"; \"Is that a camera?\"; \"Does it really take pictures?\"; \"Can I see it?\" It is the kind of accessory that doubles as a conversation starter, an effect that's turned out to be as joyous as taking pictures with the camera itself. I've been trying really hard to spend less time on social media and my phone in general lately, and having a two-inch camera clipped to me has made for a pretty fun shift in how I document the day-to-day. As the resurgence of compact digital cameras has shown us, a lot of people are yearning for a time of simpler tech — when we had personal devices that could do useful things, like take decent photos and connect us to our friends, but didn't consume our lives entirely. Companies like Camp Snap have shaped their entire brands around recapturing that magic, and some consumers have shown that they're willing to sacrifice in areas like image quality in exchange for a taste of it, too. The Kodak Charmera isn't the kind of product you go into purchasing with high expectations. It is clearly a toy that is only going to be capable of so much. Cheyenne MacDonald for Engadget As Jackson noted, the low-resolution 1,440 x 1,080 pictures look about on par with those you'd have taken on a flip phone 15 or 20 years ago. In the right lighting conditions with a clearly defined subject, they're not so bad. But selfies, portraits and nature photos will generally look washed out. It can record videos too — and you should set similarly low expectations for these. Despite all that, I've been pleasantly surprised by how much I'm enjoying the Charmera experience. Its crunchy photos are just good enough to feel like they're successfully preserving a moment in time. And being so tiny, it's really convenient to bring everywhere. It even came with me to CES. The Charmera takes a microSD card (sold separately), allowing for tons of storage and easy transferring. There are a bunch of built-in filters you can apply, too, which have been fun to play around with. If I want high-quality photos, this isn't the camera I'm going to reach for. But it's great for low-stakes situations when all I care about is taking some pictures I can look back on fondly later. Consider me charmed. — Cheyenne MacDonald, Weekend Editor This article originally appeared on Engadget at https://www.engadget.com/cameras/the-ridiculously-tiny-kodak-charmera-captured-our-hearts-and-lots-of-shoddy-pictures-140000245.html?src=rss",
          "feed_position": 15,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/charmera2.jpeg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/social-media/meta-really-wants-you-to-believe-social-media-addiction-is-not-a-real-thing-130000257.html",
          "published_at": "Fri, 13 Feb 2026 13:00:00 +0000",
          "title": "Meta really wants you to believe social media addiction is 'not a real thing'",
          "standfirst": "Meta went to court this week in two major trials over alleged harms facilitated by its platform. In New Mexico, the state's attorney general has accused the company of facilitating child exploitation and harming children through addictive features. In a separate case in Los Angeles, a California woman sued the company over mental health harms she says she suffered as the result of addictive design choices from Meta and others.In both cases, Meta has disputed the idea that social media should be considered an \"addiction.\" On the stand this week, Instagram chief Adam Mosseri said that social media isn't \"clinically addictive,\" comparing it to being \"addicted\" to a Netflix show.In opening statements in the New Mexico trial, Meta's lawyer Kevin Huff went further. He told the jury that \"social media addiction is not a thing\" because it's not in the Diagnostic and Statistical Manual of Mental Disorders (DSM), the handbook used by mental health professionals in the US.\"According to the American Psychiatric Association, they don't recognize the concept of social media addiction in the same way as addiction to drugs and alcohol,\" Huff said during opening arguments that were broadcast by Courtroom View Network. \"What you see on the screen is what's called the DSM, which is basically the official manual for recognized mental disorders. The American Psychiatric Association studied this and decided that social media addiction is not a thing.\"But the American Psychiatric Association (APA) has never said that social media addiction doesn't exist. The organization provides information and resources about social media addiction on its website. \"Social media addiction is not currently listed as a diagnosis in the DSM-5-TR—but that does not mean it doesn’t exist,\" the APA said in a statement to Engadget.Dr. Tania Moretta, a clinical pyschophysiology researcher who has studied social media addiction, agrees. \"The absence of a DSM classification does not mean that a behavior cannot be addictive, maladaptive or clinically significant,\" she told Engadget. That argument, she said, \"reflects a misunderstanding\" of how psychiatry professionals define and classify conditions. \"Diagnostic manuals formalize scientific consensus; they do not define the boundaries of legitimate scientific inquiry. Many maladaptive behaviors and clinically significant symptom patterns are studied and treated well before receiving official classification.\"Meta's critics have long claimed that the company has profited from addictive features that hook children and teens. The trials in Los Angeles and New Mexico are just the start of several court battles over the issue. The social media company is also facing a high-profile trial with school districts in June, and lawsuits from 41 state attorneys general. Moretta said that social media addiction is a field that requires more study, but that there is already evidence that it can have harmful effects on some people. \"At present, from a scientific perspective, there is documented evidence that social media use disorder is associated with both psychophysiological alterations, including changes in reward/motivational and inhibitory/regulatory systems, and clinically significant negative impacts on functioning (e.g., sleep disturbances, psychological distress, impairment in social, academic, or occupational domains),\" she said. \"The key question is not whether all social media use is addictive, but whether a subset of users exhibits patterns consistent with behavioral addiction models and whether specific platform design features may exacerbate vulnerability in predisposed individuals.\"Both trials are ongoing and expected to last the next several weeks. In New Mexico, jurors have already heard from former employee turned whistleblower Arturo Bejar and former exec Brian Boland, both of whom have publicly criticized the company for not prioritizing safety. In Los Angeles, Mosseri's testimony has wrapped up, but Meta CEO Mark Zuckerberg is expected to testify next week. The trials will also feature extensive internal documents from Meta, including details about the company's own research into the mental health impacts of its platform on young people.This article originally appeared on Engadget at https://www.engadget.com/social-media/meta-really-wants-you-to-believe-social-media-addiction-is-not-a-real-thing-130000257.html?src=rss",
          "content": "Meta went to court this week in two major trials over alleged harms facilitated by its platform. In New Mexico, the state's attorney general has accused the company of facilitating child exploitation and harming children through addictive features. In a separate case in Los Angeles, a California woman sued the company over mental health harms she says she suffered as the result of addictive design choices from Meta and others.In both cases, Meta has disputed the idea that social media should be considered an \"addiction.\" On the stand this week, Instagram chief Adam Mosseri said that social media isn't \"clinically addictive,\" comparing it to being \"addicted\" to a Netflix show.In opening statements in the New Mexico trial, Meta's lawyer Kevin Huff went further. He told the jury that \"social media addiction is not a thing\" because it's not in the Diagnostic and Statistical Manual of Mental Disorders (DSM), the handbook used by mental health professionals in the US.\"According to the American Psychiatric Association, they don't recognize the concept of social media addiction in the same way as addiction to drugs and alcohol,\" Huff said during opening arguments that were broadcast by Courtroom View Network. \"What you see on the screen is what's called the DSM, which is basically the official manual for recognized mental disorders. The American Psychiatric Association studied this and decided that social media addiction is not a thing.\"But the American Psychiatric Association (APA) has never said that social media addiction doesn't exist. The organization provides information and resources about social media addiction on its website. \"Social media addiction is not currently listed as a diagnosis in the DSM-5-TR—but that does not mean it doesn’t exist,\" the APA said in a statement to Engadget.Dr. Tania Moretta, a clinical pyschophysiology researcher who has studied social media addiction, agrees. \"The absence of a DSM classification does not mean that a behavior cannot be addictive, maladaptive or clinically significant,\" she told Engadget. That argument, she said, \"reflects a misunderstanding\" of how psychiatry professionals define and classify conditions. \"Diagnostic manuals formalize scientific consensus; they do not define the boundaries of legitimate scientific inquiry. Many maladaptive behaviors and clinically significant symptom patterns are studied and treated well before receiving official classification.\"Meta's critics have long claimed that the company has profited from addictive features that hook children and teens. The trials in Los Angeles and New Mexico are just the start of several court battles over the issue. The social media company is also facing a high-profile trial with school districts in June, and lawsuits from 41 state attorneys general. Moretta said that social media addiction is a field that requires more study, but that there is already evidence that it can have harmful effects on some people. \"At present, from a scientific perspective, there is documented evidence that social media use disorder is associated with both psychophysiological alterations, including changes in reward/motivational and inhibitory/regulatory systems, and clinically significant negative impacts on functioning (e.g., sleep disturbances, psychological distress, impairment in social, academic, or occupational domains),\" she said. \"The key question is not whether all social media use is addictive, but whether a subset of users exhibits patterns consistent with behavioral addiction models and whether specific platform design features may exacerbate vulnerability in predisposed individuals.\"Both trials are ongoing and expected to last the next several weeks. In New Mexico, jurors have already heard from former employee turned whistleblower Arturo Bejar and former exec Brian Boland, both of whom have publicly criticized the company for not prioritizing safety. In Los Angeles, Mosseri's testimony has wrapped up, but Meta CEO Mark Zuckerberg is expected to testify next week. The trials will also feature extensive internal documents from Meta, including details about the company's own research into the mental health impacts of its platform on young people.This article originally appeared on Engadget at https://www.engadget.com/social-media/meta-really-wants-you-to-believe-social-media-addiction-is-not-a-real-thing-130000257.html?src=rss",
          "feed_position": 16
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/cybersecurity/vpn/why-does-my-vpn-keep-disconnecting-130000620.html",
          "published_at": "Fri, 13 Feb 2026 13:00:00 +0000",
          "title": "Why does my VPN keep disconnecting?",
          "standfirst": "One good thing about virtual private networks (VPNs) is that when they don't work, the problem is almost always solvable without technical training. Although it's aggravating when your VPN randomly drops your connection, the chances are good that you can handle the issue yourself without getting tech support involved.If your VPN is repeatedly disconnecting from the server, I recommend dealing with the problem immediately. When you have your kill switch on as good cybersecurity habits dictate, VPN drops will kick you off the internet. Without that feature enabled, it'll expose your real identity and location online. That’s not a big deal if you’re just aiming to, say, stream an international sporting event, but it could be an existential issue if you’re using the VPN as a workaround against government censorship. Either way, you can address the issue by working through the eight troubleshooting steps below and checking whether they've solved your problem.8 reasons your VPN keeps disconnectingI've organized these root causes in ascending order of how much effort the solution takes. Try the easier fixes before moving on to the more complex or expensive ones.1. You're using the VPN on too many devices at onceMost VPNs limit the number of devices you can connect at the same time on a single subscription. Some services, like Surfshark, claim to offer unlimited simultaneous connections, but they'll still cut you off if they see signs of abuse. Generally, you can install the VPN on as many devices as you like; it just can't be actively running on more than the limit.If you're trying to connect to the VPN on a new device and it repeatedly disconnects, check how many other phones, computers or smart TVs it's already running on. Pay attention to devices where you have the VPN set to auto-connect on startup, as you may have missed that it's running. Disconnect from the VPN on one of those devices and try again on the new one.2. Your VPN server is slow or overloadedThe problem often rests with the VPN server you're trying to connect to. Providers regularly shut down servers for routine maintenance. Sometimes, a server is technically online, but it's under such a heavy user load that it can't maintain a connection. It's also possible that the server is so physically far away from you that the connection keeps timing out.In cases like these, the answer is simple: use another server. Pick a different server by disconnecting the VPN and reconnecting to the same location. If the new server has the same problems, try another location, assuming you don't need an IP address in a specific country.3. You're using an unstable VPN protocolAs I explained in my article on how a VPN works, a VPN protocol is the set of instructions at the heart of everything a VPN does. Not all protocols are the same. For example, OpenVPN over TCP prioritizes speed over connection stability, causing more frequent disconnections. It's also possible for certain networks to block some VPN protocols but not others (see #8).If changing servers didn't help your unstable connection, try switching protocols. WireGuard, OpenVPN over UDP and IKEv2 are best for stability. You can almost always find the protocol options in the Settings page of your VPN app.4. Power-save settings are interferingA VPN almost always runs in the background. In some cases, a device's battery saver settings might shut down the VPN to stop the battery from draining. See if turning off power-save mode stops your VPN from disconnecting randomly (and maybe plug in your device while you're at it).5. Your internet connection isn't stableYour VPN needs to pass traffic through an ISP like any other online app — it just encrypts that traffic first. If you don't have a good internet connection, you won't have a good VPN connection. When you notice your VPN randomly disconnecting, check whether you have problems with your home internet connection. Resetting your modem by turning it off for at least 10 seconds may solve the problem, but you can also just wait for your internet to improve with time.6. Another program is interfering with the VPNOther security programs are a frequent cause of VPN disruptions. If you connect to an office VPN, for example, you likely won't be able to have a personal VPN running at the same time. Likewise, if you use an antivirus program or have a firewall on your device, it may be blocking your VPN from connecting. See if you can configure the firewall to allow traffic through a port used by a VPN protocol.7. Your software is out of dateIf none of the fixes have worked so far, you can often solve your connection problems by updating all the software involved. For optimal security, you should be installing updates the moment they're available anyway, so this will protect you even if it doesn't directly solve your VPN problem.Update your VPN client and your operating system, then try connecting again. If you're still having problems, try updating your router. You can reach its control panel by entering its default IP address into the URL bar of your browser. Update it as well, then try once more.8. Your network or ISP is blocking VPN trafficThere's a chance that your problem originates with your network or ISP, not on the VPN or any device you own. Some networks, especially at offices and schools, automatically block any VPN traffic they detect. These restrictions can even be imposed by entire countries, most infamously in China.Should this turn out to be your problem, turn on any obfuscation features that may be built into your VPN. Using an obfuscated protocol, connect to a server outside the location being censored, then use the internet as normal. This will be much more difficult if you're in a country where VPNs are illegal or restricted, but there's still hope — if you can safely send an email, contact a VPN provider and ask if they'll send you a configuration directly. Proton VPN is one company that's officially willing to do that.If you still find your VPN disconnecting mid-session, you may have a rare problem that doesn't show up on this list. Contact your VPN's support staff and do what they recommend. If possible, chat with a live support technician so you can tell them what you've already tried.This article originally appeared on Engadget at https://www.engadget.com/cybersecurity/vpn/why-does-my-vpn-keep-disconnecting-130000620.html?src=rss",
          "content": "One good thing about virtual private networks (VPNs) is that when they don't work, the problem is almost always solvable without technical training. Although it's aggravating when your VPN randomly drops your connection, the chances are good that you can handle the issue yourself without getting tech support involved.If your VPN is repeatedly disconnecting from the server, I recommend dealing with the problem immediately. When you have your kill switch on as good cybersecurity habits dictate, VPN drops will kick you off the internet. Without that feature enabled, it'll expose your real identity and location online. That’s not a big deal if you’re just aiming to, say, stream an international sporting event, but it could be an existential issue if you’re using the VPN as a workaround against government censorship. Either way, you can address the issue by working through the eight troubleshooting steps below and checking whether they've solved your problem.8 reasons your VPN keeps disconnectingI've organized these root causes in ascending order of how much effort the solution takes. Try the easier fixes before moving on to the more complex or expensive ones.1. You're using the VPN on too many devices at onceMost VPNs limit the number of devices you can connect at the same time on a single subscription. Some services, like Surfshark, claim to offer unlimited simultaneous connections, but they'll still cut you off if they see signs of abuse. Generally, you can install the VPN on as many devices as you like; it just can't be actively running on more than the limit.If you're trying to connect to the VPN on a new device and it repeatedly disconnects, check how many other phones, computers or smart TVs it's already running on. Pay attention to devices where you have the VPN set to auto-connect on startup, as you may have missed that it's running. Disconnect from the VPN on one of those devices and try again on the new one.2. Your VPN server is slow or overloadedThe problem often rests with the VPN server you're trying to connect to. Providers regularly shut down servers for routine maintenance. Sometimes, a server is technically online, but it's under such a heavy user load that it can't maintain a connection. It's also possible that the server is so physically far away from you that the connection keeps timing out.In cases like these, the answer is simple: use another server. Pick a different server by disconnecting the VPN and reconnecting to the same location. If the new server has the same problems, try another location, assuming you don't need an IP address in a specific country.3. You're using an unstable VPN protocolAs I explained in my article on how a VPN works, a VPN protocol is the set of instructions at the heart of everything a VPN does. Not all protocols are the same. For example, OpenVPN over TCP prioritizes speed over connection stability, causing more frequent disconnections. It's also possible for certain networks to block some VPN protocols but not others (see #8).If changing servers didn't help your unstable connection, try switching protocols. WireGuard, OpenVPN over UDP and IKEv2 are best for stability. You can almost always find the protocol options in the Settings page of your VPN app.4. Power-save settings are interferingA VPN almost always runs in the background. In some cases, a device's battery saver settings might shut down the VPN to stop the battery from draining. See if turning off power-save mode stops your VPN from disconnecting randomly (and maybe plug in your device while you're at it).5. Your internet connection isn't stableYour VPN needs to pass traffic through an ISP like any other online app — it just encrypts that traffic first. If you don't have a good internet connection, you won't have a good VPN connection. When you notice your VPN randomly disconnecting, check whether you have problems with your home internet connection. Resetting your modem by turning it off for at least 10 seconds may solve the problem, but you can also just wait for your internet to improve with time.6. Another program is interfering with the VPNOther security programs are a frequent cause of VPN disruptions. If you connect to an office VPN, for example, you likely won't be able to have a personal VPN running at the same time. Likewise, if you use an antivirus program or have a firewall on your device, it may be blocking your VPN from connecting. See if you can configure the firewall to allow traffic through a port used by a VPN protocol.7. Your software is out of dateIf none of the fixes have worked so far, you can often solve your connection problems by updating all the software involved. For optimal security, you should be installing updates the moment they're available anyway, so this will protect you even if it doesn't directly solve your VPN problem.Update your VPN client and your operating system, then try connecting again. If you're still having problems, try updating your router. You can reach its control panel by entering its default IP address into the URL bar of your browser. Update it as well, then try once more.8. Your network or ISP is blocking VPN trafficThere's a chance that your problem originates with your network or ISP, not on the VPN or any device you own. Some networks, especially at offices and schools, automatically block any VPN traffic they detect. These restrictions can even be imposed by entire countries, most infamously in China.Should this turn out to be your problem, turn on any obfuscation features that may be built into your VPN. Using an obfuscated protocol, connect to a server outside the location being censored, then use the internet as normal. This will be much more difficult if you're in a country where VPNs are illegal or restricted, but there's still hope — if you can safely send an email, contact a VPN provider and ask if they'll send you a configuration directly. Proton VPN is one company that's officially willing to do that.If you still find your VPN disconnecting mid-session, you may have a rare problem that doesn't show up on this list. Contact your VPN's support staff and do what they recommend. If possible, chat with a live support technician so you can tell them what you've already tried.This article originally appeared on Engadget at https://www.engadget.com/cybersecurity/vpn/why-does-my-vpn-keep-disconnecting-130000620.html?src=rss",
          "feed_position": 17
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/general/the-morning-after-meta-turned-threads-algorithm-complaints-into-an-official-feature-121500663.html",
          "published_at": "Fri, 13 Feb 2026 12:15:00 +0000",
          "title": "The Morning After: Meta turned Threads algorithm complaints into an official feature",
          "standfirst": "Threads users have complained about its recommendation algorithm since the dawn of time 2023. Users even started writing posts addressed to the algorithm, specifying the topics they wanted to see more of. Now, that’s part of the system: Users can write a post that begins with “dear algo” to adjust their preferences, officially.For example, you could write: “Dear algo, show me more posts about sous vide recipes.” You can also ask to see fewer posts about topics you don’t want to see, like “Dear algo, stop showing me posts about air fryers.” You can even retweet other users’ “dear algo” posts to have those topics reflected in your feed. “Dear algo” posts will work for Threads users in the US, UK, Australia and New Zealand, with more countries coming “soon.”— Mat SmithThe biggest stories in tech you might have missed.The first Control Resonant gameplay trailer shows a sideways NYC Apple’s Siri relaunch is reportedly behind schedule The next Metal Gear Solid remaster collection arrives this summerElon Musk’s latest scheme is a satellite catapult on the MoonI think that’s a Drag Race song.With a bigger focus on the Moon, Elon Musk is making some wild new plans. According to audio heard by The New York Times, Musk said xAI needed to build an AI satellite factory on the Moon with a gigantic catapult to launch the satellites into space. Sometimes you just want to be the Bond villain.“You have to go to the Moon” to build the required AI capabilities, Musk told employees. “It’s difficult to imagine what an intelligence of that scale would think about, but it’s going to be incredibly exciting to see it happen.” Such a catapult would certainly need to be powerful — though the Moon has only one-sixth Earth’s gravity, the minimum escape velocity required for orbit is still around 3,800 mph, or five times the speed of sound. That’s currently possible with electromagnetic railguns, but the satellites would have to withstand that force.Continue reading.Pokémon Pokopia is cosy AFStardew Valley + Animal Crossing X Pokémon.TMANintendoIn a bid to distract from a lot of things, Nintendo’s new Pokémon game is a gently paced game where, instead of playing as a generic trainer, you take control of a sole Ditto. As a Ditto, you can transform into other Pokémon, though the process is sort of incomplete, meaning you can only learn one skill from the monsters you befriend. Instead of using tools, you can transform into other Pokémon (like Lapras or Dragonite) to use their abilities to traverse obstacles or shape the world around you.Continue reading.Sony WF-1000XM6 headphones reviewFacing tougher competition.TMAEngadgetSony unveiled the latest entry in its best wireless earbud series, the WF-1000XM6, featuring yet another redesign, both inside and out. Once again, strong features and audio performance remain, but competition from all sides is tougher than ever. As Billy Steele explains in his review, if you want the strongest active noise cancellation, that will be Bose’s QuietComfort Ultra Earbuds. If the best sound quality is your goal, the Technics AZ100 is your best bet in this price range. I’ll also mention Sennheiser’s Momentum True Wireless 4, which offers great sound quality, respectable ANC and a comfier fit than the M6. The WF-1000XM6 is available now for $330.Continue reading.This article originally appeared on Engadget at https://www.engadget.com/general/the-morning-after-meta-turned-threads-algorithm-complaints-into-an-official-feature-121500663.html?src=rss",
          "content": "Threads users have complained about its recommendation algorithm since the dawn of time 2023. Users even started writing posts addressed to the algorithm, specifying the topics they wanted to see more of. Now, that’s part of the system: Users can write a post that begins with “dear algo” to adjust their preferences, officially.For example, you could write: “Dear algo, show me more posts about sous vide recipes.” You can also ask to see fewer posts about topics you don’t want to see, like “Dear algo, stop showing me posts about air fryers.” You can even retweet other users’ “dear algo” posts to have those topics reflected in your feed. “Dear algo” posts will work for Threads users in the US, UK, Australia and New Zealand, with more countries coming “soon.”— Mat SmithThe biggest stories in tech you might have missed.The first Control Resonant gameplay trailer shows a sideways NYC Apple’s Siri relaunch is reportedly behind schedule The next Metal Gear Solid remaster collection arrives this summerElon Musk’s latest scheme is a satellite catapult on the MoonI think that’s a Drag Race song.With a bigger focus on the Moon, Elon Musk is making some wild new plans. According to audio heard by The New York Times, Musk said xAI needed to build an AI satellite factory on the Moon with a gigantic catapult to launch the satellites into space. Sometimes you just want to be the Bond villain.“You have to go to the Moon” to build the required AI capabilities, Musk told employees. “It’s difficult to imagine what an intelligence of that scale would think about, but it’s going to be incredibly exciting to see it happen.” Such a catapult would certainly need to be powerful — though the Moon has only one-sixth Earth’s gravity, the minimum escape velocity required for orbit is still around 3,800 mph, or five times the speed of sound. That’s currently possible with electromagnetic railguns, but the satellites would have to withstand that force.Continue reading.Pokémon Pokopia is cosy AFStardew Valley + Animal Crossing X Pokémon.TMANintendoIn a bid to distract from a lot of things, Nintendo’s new Pokémon game is a gently paced game where, instead of playing as a generic trainer, you take control of a sole Ditto. As a Ditto, you can transform into other Pokémon, though the process is sort of incomplete, meaning you can only learn one skill from the monsters you befriend. Instead of using tools, you can transform into other Pokémon (like Lapras or Dragonite) to use their abilities to traverse obstacles or shape the world around you.Continue reading.Sony WF-1000XM6 headphones reviewFacing tougher competition.TMAEngadgetSony unveiled the latest entry in its best wireless earbud series, the WF-1000XM6, featuring yet another redesign, both inside and out. Once again, strong features and audio performance remain, but competition from all sides is tougher than ever. As Billy Steele explains in his review, if you want the strongest active noise cancellation, that will be Bose’s QuietComfort Ultra Earbuds. If the best sound quality is your goal, the Technics AZ100 is your best bet in this price range. I’ll also mention Sennheiser’s Momentum True Wireless 4, which offers great sound quality, respectable ANC and a comfier fit than the M6. The WF-1000XM6 is available now for $330.Continue reading.This article originally appeared on Engadget at https://www.engadget.com/general/the-morning-after-meta-turned-threads-algorithm-complaints-into-an-official-feature-121500663.html?src=rss",
          "feed_position": 19,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/Poke%CC%81mon_Pokopia_Media_Preview_Screenshot_1_EN.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/home/kitchen-tech/best-air-fryers-133047180.html",
          "published_at": "Fri, 13 Feb 2026 08:00:38 +0000",
          "title": "The 7 best air fryers for 2026, tested and reviewed",
          "standfirst": "Air fryers have gone from novelty appliances to everyday kitchen staples surprisingly fast. They’re quick to heat up, easy to use and well suited to everything from frozen snacks to roasted vegetables and simple desserts. For many people, they’ve replaced the oven for smaller meals, cutting down on cook time without adding extra cleanup.The category has also expanded well beyond basic basket-style models. Some air fryers are designed for small kitchens or single servings, while others offer larger capacities and preset cooking modes for roasting, reheating or dehydrating. After testing a wide range of machines, the Instant Vortex Plus continues to stand out for its reliable performance, straightforward controls and consistently good results.Below, we’ve gathered the best air fryers you can buy right now across different sizes and price points. Whether you’re replacing an older unit or trying one for the first time, these picks focus on appliances that are easy to live with and deliver crisp food without the need for deep frying. Best air fryers for 2026 What does an air fryer do? Let’s clear one thing up first: it’s not frying. Not really. Air fryers are more like smaller convection bake ovens, ones that are often pod-shaped. Most work by combining a heating element and fan, which means the hot air can usually better crisp the outside of food than other methods. They often reach higher top temperatures than toaster ovens – which is part of the appeal. For most recipes, a thin layer of oil (usually sprayed) helps to replicate that fried look and feel better. However, it will rarely taste precisely like the deep-fried or pan frying version when it comes out of the air fryer basket. Don’t let that put you off, though, because the air fryer, in its many forms, combines some of the best parts of other cooking processes and brings them together into an energy-efficient way of air fryer cooking dinner. Or breakfast. Or lunch. Buying guide for air fryers Convection ovens You can separate most of these machines into two types of air fryers, and each has different pros and cons. Convection ovens are usually ovens with air fryer functions and features. They might have higher temperature settings to ensure that food crisps and cooks more like actually fried food. Most convection ovens are larger than dedicated air fryers, defeating some of the purpose of those looking to shrink cooking appliance surface area. Still, they are often more versatile with multiple cooking functions, and most have finer controls for temperatures, timings and even fan speed. You may never need a built-in oven if you have a decent convection oven. They often have the volume to handle roasts, entire chickens or tray bakes, and simply cook more, capacity-wise, making them more versatile than the pod-shaped competition. The flip side of that is that you’ll need counter space in the kitchen to house them. It also means you can use traditional oven accessories, like baking trays or cake tins, that you might already own. Pod-shaped air fryers Pod-shaped air fryers are what you imagine when you think “air fryer.” They look like a cool, space-age kitchen gadget, bigger than a kettle but smaller than a toaster oven. Many use a drawer to hold ingredients while cooking, usually a mesh sheet or a more solid, non-stick tray with holes to allow the hot air to circulate. With a few exceptions, most require you to open the drawer while things cook and flip or shake half-cooked items to ensure the even distribution of heat and airflow to everything. That’s one of a few caveats. This type of air fryer typically doesn't have a window to see how things are cooking (with only a few exceptions), so you’ll need to closely scrutinize things as they cook, opening the device to check progress. Basket-style air fryers also generally use less energy – there’s less space to heat – and many have parts that can be put directly into a dishwasher. Some of the larger pod-shaped air fryers offer two separate compartments, which is especially useful for anyone planning to cook an entire meal with the appliance. You could cook a couple of tasty chicken wings or tenders while simultaneously rustling up enough frozen fries or veggies for everyone. Naturally, those options take up more space, and they’re usually heavy enough to stop you from storing them in cupboards or shelves elsewhere. As mentioned earlier, you might have to buy extra things to make these pod fryers work the way you want them to. Some of the bigger manufacturers, like Philips and Ninja, offer convenient additions, but you’ll have to pay for them. Air fryer pros and cons Beyond the strengths and weaknesses of individual models, air fryers are pretty easy to use from the outset. Most models come with a convenient cooking time booklet covering most of the major foods you’ll be air frying, so even beginners can master these machines. One of the early selling points is the ability to cook fries, wings, frozen foods and other delights with less fat than other methods like deep frying, which gets foods the crispiest. As air fryers work by circulating heated air, the trays and cooking plates have holes that can also let oil and fat drain out of meats, meaning less fat and crisper food when you finally plate things up. For most cooking situations, you will likely need to lightly spray food with vegetable oil. If you don’t, there’s the chance that things will burn or char. The oil will keep things moist on the surface, and we advise refreshing things with a dash of oil spray when you turn items during cooking. Most air fryers are easy to clean – especially in comparison to a shallow or deep fryer. We’ll get into cleaning guidance a little later. With a smaller space to heat, air fryers are generally more energy-efficient for cooking food than larger appliances like ovens. And if you don’t have an oven, air fryers are much more affordable – especially the pod options. There are, however, some drawbacks. While air fryers are easy enough to use, they take time to master. You will adjust cooking times for even the simplest types of food – like chicken nuggets, frozen French fries or brussels sprouts. If you’re the kind of person that loves to find inspiration from the internet, in our experience, you can pretty much throw their timings out of the window. There are a lot of air fryer options, and factors like how fast they heat and how well distributed that heat is can – and will – affect cooking. There’s also a space limitation to air fryers. This is not a TARDIS – there’s simply less space than most traditional ovens and many deep fat fryers. If you have a bigger family, you’ll probably want to go for a large capacity air fryer – possibly one that has multiple cooking areas. You also might want to consider a different kitchen appliance, like a multicooker, sous vide or slow cooker to meet your specific cooking needs. You may also struggle to cook many items through as the heat settings will cook the surface of dishes long before it’s cooked right through. If you’re planning to cook a whole chicken or a roast, please get a meat thermometer! Best air fryer accessories Beyond official accessories from the manufacturer, try to pick up silicone-tipped tools. Tongs are ideal, as is a silicon spatula to gently loosen food that might get stuck on the sides of the air fryer. These silicone mats will also help stop things from sticking to the wire racks on some air fryers. They have holes to ensure the heated air is still able to circulate around the food. Silicone trivets are also useful for resting any cooked food on while you sort out the rest of the meal. And if you find yourself needing oil spray, but don’t feel like repeatedly buying tiny bottles, you can decant your favorite vegetable oil into a permanent mister like this. How to clean an air fryer We’re keeping clean up simple here. Yes, you could use power cleaners from the grocery store, they could damage the surface of your air fryer. Likewise, metal scourers or brushes could strip away the non-stick coating. Remember to unplug the device and let it cool completely. Remove the trays, baskets and everything else from inside. If the manufacturer says the parts are dishwasher safe – and you have a dishwasher – the job is pretty much done. Otherwise, hand wash each part in a mixture of warm water, with a splash of Dawn or another strong dish soap. Use a soft-bristled brush to pull away any crumbs, greasy deposits or bits of food stuck to any surfaces. Remember to rinse everything. Otherwise, your next batch of wings could have a mild Dawn aftertaste. Trust us. Take a microfiber cloth and tackle the outer parts and handles that might also get a little messy after repeated uses. This is especially useful for oven-style air fryers – use the cloth to wipe down the inner sides. If Dawn isn’t shifting oily stains, try mixing a small amount of baking soda with enough water to make a paste, and apply that so that it doesn’t seep into any electrical parts or the heating element. Leave it to work for a few seconds before using a damp cloth to pull any greasy spots away. Rinse out the cloth and wipe everything down again, and you should be ready for the next time you need to air fry. How to find air fryer recipes Beyond fries, nuggets and – a revelation – frozen gyoza, there are a few ways to find recipes for air-fried foods. First, we found that the air fryer instruction manuals often have cooking guides and recipe suggestions for you to test out in your new kitchen gadget. The good thing with these is that they were made for your air fryer model, meaning success should be all but guaranteed. They are often a little unimaginative, however. Many of the top recipe sites and portals have no shortage of air fryer recipes, and there’s no harm in googling your favorite cuisine and adding the words “air fryer” on the end of the search string. We’ve picked up some reliable options from Delish, which also has a handy air fryer time converter for changing oven and traditional fryer recipes. BBC Good Food is also worth browsing for some simple ideas, as is NYT Cooking, with the ability to directly search for air fryer suggestions. Aside from that, you can also grab plenty of cookbooks from your local bookshop with lots of recipes that you can use in your favorite air fryer. And if you have a killer recipe or unique use for your air fryer, let us know in the comments. What’s the air fryer equivalent of the Instant Pot cheesecake? We’re ready to try it. How we test air fryers We put each air fryer we test through its paces by cooking a variety of foods in it including raw proteins like fish and chicken, raw vegetables like potatoes and cauliflower and frozen snacks like mozzarella sticks. We attempt to use each cooking method that the machine has pre-programmed, and when possible, follow a couple of recipes in any provided recipe booklets that come with the air fryer. We also clean the cooking basket and all other removable components as many times as possible, and will put those components into a dishwasher if they claim to be dishwasher-safe. We also make note of how loud the machine is when using different cooking settings and how warm the surrounding area becomes.This article originally appeared on Engadget at https://www.engadget.com/home/kitchen-tech/best-air-fryers-133047180.html?src=rss",
          "content": "Air fryers have gone from novelty appliances to everyday kitchen staples surprisingly fast. They’re quick to heat up, easy to use and well suited to everything from frozen snacks to roasted vegetables and simple desserts. For many people, they’ve replaced the oven for smaller meals, cutting down on cook time without adding extra cleanup.The category has also expanded well beyond basic basket-style models. Some air fryers are designed for small kitchens or single servings, while others offer larger capacities and preset cooking modes for roasting, reheating or dehydrating. After testing a wide range of machines, the Instant Vortex Plus continues to stand out for its reliable performance, straightforward controls and consistently good results.Below, we’ve gathered the best air fryers you can buy right now across different sizes and price points. Whether you’re replacing an older unit or trying one for the first time, these picks focus on appliances that are easy to live with and deliver crisp food without the need for deep frying. Best air fryers for 2026 What does an air fryer do? Let’s clear one thing up first: it’s not frying. Not really. Air fryers are more like smaller convection bake ovens, ones that are often pod-shaped. Most work by combining a heating element and fan, which means the hot air can usually better crisp the outside of food than other methods. They often reach higher top temperatures than toaster ovens – which is part of the appeal. For most recipes, a thin layer of oil (usually sprayed) helps to replicate that fried look and feel better. However, it will rarely taste precisely like the deep-fried or pan frying version when it comes out of the air fryer basket. Don’t let that put you off, though, because the air fryer, in its many forms, combines some of the best parts of other cooking processes and brings them together into an energy-efficient way of air fryer cooking dinner. Or breakfast. Or lunch. Buying guide for air fryers Convection ovens You can separate most of these machines into two types of air fryers, and each has different pros and cons. Convection ovens are usually ovens with air fryer functions and features. They might have higher temperature settings to ensure that food crisps and cooks more like actually fried food. Most convection ovens are larger than dedicated air fryers, defeating some of the purpose of those looking to shrink cooking appliance surface area. Still, they are often more versatile with multiple cooking functions, and most have finer controls for temperatures, timings and even fan speed. You may never need a built-in oven if you have a decent convection oven. They often have the volume to handle roasts, entire chickens or tray bakes, and simply cook more, capacity-wise, making them more versatile than the pod-shaped competition. The flip side of that is that you’ll need counter space in the kitchen to house them. It also means you can use traditional oven accessories, like baking trays or cake tins, that you might already own. Pod-shaped air fryers Pod-shaped air fryers are what you imagine when you think “air fryer.” They look like a cool, space-age kitchen gadget, bigger than a kettle but smaller than a toaster oven. Many use a drawer to hold ingredients while cooking, usually a mesh sheet or a more solid, non-stick tray with holes to allow the hot air to circulate. With a few exceptions, most require you to open the drawer while things cook and flip or shake half-cooked items to ensure the even distribution of heat and airflow to everything. That’s one of a few caveats. This type of air fryer typically doesn't have a window to see how things are cooking (with only a few exceptions), so you’ll need to closely scrutinize things as they cook, opening the device to check progress. Basket-style air fryers also generally use less energy – there’s less space to heat – and many have parts that can be put directly into a dishwasher. Some of the larger pod-shaped air fryers offer two separate compartments, which is especially useful for anyone planning to cook an entire meal with the appliance. You could cook a couple of tasty chicken wings or tenders while simultaneously rustling up enough frozen fries or veggies for everyone. Naturally, those options take up more space, and they’re usually heavy enough to stop you from storing them in cupboards or shelves elsewhere. As mentioned earlier, you might have to buy extra things to make these pod fryers work the way you want them to. Some of the bigger manufacturers, like Philips and Ninja, offer convenient additions, but you’ll have to pay for them. Air fryer pros and cons Beyond the strengths and weaknesses of individual models, air fryers are pretty easy to use from the outset. Most models come with a convenient cooking time booklet covering most of the major foods you’ll be air frying, so even beginners can master these machines. One of the early selling points is the ability to cook fries, wings, frozen foods and other delights with less fat than other methods like deep frying, which gets foods the crispiest. As air fryers work by circulating heated air, the trays and cooking plates have holes that can also let oil and fat drain out of meats, meaning less fat and crisper food when you finally plate things up. For most cooking situations, you will likely need to lightly spray food with vegetable oil. If you don’t, there’s the chance that things will burn or char. The oil will keep things moist on the surface, and we advise refreshing things with a dash of oil spray when you turn items during cooking. Most air fryers are easy to clean – especially in comparison to a shallow or deep fryer. We’ll get into cleaning guidance a little later. With a smaller space to heat, air fryers are generally more energy-efficient for cooking food than larger appliances like ovens. And if you don’t have an oven, air fryers are much more affordable – especially the pod options. There are, however, some drawbacks. While air fryers are easy enough to use, they take time to master. You will adjust cooking times for even the simplest types of food – like chicken nuggets, frozen French fries or brussels sprouts. If you’re the kind of person that loves to find inspiration from the internet, in our experience, you can pretty much throw their timings out of the window. There are a lot of air fryer options, and factors like how fast they heat and how well distributed that heat is can – and will – affect cooking. There’s also a space limitation to air fryers. This is not a TARDIS – there’s simply less space than most traditional ovens and many deep fat fryers. If you have a bigger family, you’ll probably want to go for a large capacity air fryer – possibly one that has multiple cooking areas. You also might want to consider a different kitchen appliance, like a multicooker, sous vide or slow cooker to meet your specific cooking needs. You may also struggle to cook many items through as the heat settings will cook the surface of dishes long before it’s cooked right through. If you’re planning to cook a whole chicken or a roast, please get a meat thermometer! Best air fryer accessories Beyond official accessories from the manufacturer, try to pick up silicone-tipped tools. Tongs are ideal, as is a silicon spatula to gently loosen food that might get stuck on the sides of the air fryer. These silicone mats will also help stop things from sticking to the wire racks on some air fryers. They have holes to ensure the heated air is still able to circulate around the food. Silicone trivets are also useful for resting any cooked food on while you sort out the rest of the meal. And if you find yourself needing oil spray, but don’t feel like repeatedly buying tiny bottles, you can decant your favorite vegetable oil into a permanent mister like this. How to clean an air fryer We’re keeping clean up simple here. Yes, you could use power cleaners from the grocery store, they could damage the surface of your air fryer. Likewise, metal scourers or brushes could strip away the non-stick coating. Remember to unplug the device and let it cool completely. Remove the trays, baskets and everything else from inside. If the manufacturer says the parts are dishwasher safe – and you have a dishwasher – the job is pretty much done. Otherwise, hand wash each part in a mixture of warm water, with a splash of Dawn or another strong dish soap. Use a soft-bristled brush to pull away any crumbs, greasy deposits or bits of food stuck to any surfaces. Remember to rinse everything. Otherwise, your next batch of wings could have a mild Dawn aftertaste. Trust us. Take a microfiber cloth and tackle the outer parts and handles that might also get a little messy after repeated uses. This is especially useful for oven-style air fryers – use the cloth to wipe down the inner sides. If Dawn isn’t shifting oily stains, try mixing a small amount of baking soda with enough water to make a paste, and apply that so that it doesn’t seep into any electrical parts or the heating element. Leave it to work for a few seconds before using a damp cloth to pull any greasy spots away. Rinse out the cloth and wipe everything down again, and you should be ready for the next time you need to air fry. How to find air fryer recipes Beyond fries, nuggets and – a revelation – frozen gyoza, there are a few ways to find recipes for air-fried foods. First, we found that the air fryer instruction manuals often have cooking guides and recipe suggestions for you to test out in your new kitchen gadget. The good thing with these is that they were made for your air fryer model, meaning success should be all but guaranteed. They are often a little unimaginative, however. Many of the top recipe sites and portals have no shortage of air fryer recipes, and there’s no harm in googling your favorite cuisine and adding the words “air fryer” on the end of the search string. We’ve picked up some reliable options from Delish, which also has a handy air fryer time converter for changing oven and traditional fryer recipes. BBC Good Food is also worth browsing for some simple ideas, as is NYT Cooking, with the ability to directly search for air fryer suggestions. Aside from that, you can also grab plenty of cookbooks from your local bookshop with lots of recipes that you can use in your favorite air fryer. And if you have a killer recipe or unique use for your air fryer, let us know in the comments. What’s the air fryer equivalent of the Instant Pot cheesecake? We’re ready to try it. How we test air fryers We put each air fryer we test through its paces by cooking a variety of foods in it including raw proteins like fish and chicken, raw vegetables like potatoes and cauliflower and frozen snacks like mozzarella sticks. We attempt to use each cooking method that the machine has pre-programmed, and when possible, follow a couple of recipes in any provided recipe booklets that come with the air fryer. We also clean the cooking basket and all other removable components as many times as possible, and will put those components into a dishwasher if they claim to be dishwasher-safe. We also make note of how loud the machine is when using different cooking settings and how warm the surrounding area becomes.This article originally appeared on Engadget at https://www.engadget.com/home/kitchen-tech/best-air-fryers-133047180.html?src=rss",
          "feed_position": 25,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2022-03/fcbb58a0-a9d4-11ec-97f7-1be0d263a8a8"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/nvidias-new-technique-cuts-llm-reasoning-costs-by-8x-without-losing-accuracy",
          "published_at": "Thu, 12 Feb 2026 22:00:00 GMT",
          "title": "Nvidia’s new technique cuts LLM reasoning costs by 8x without losing accuracy",
          "standfirst": "Researchers at Nvidia have developed a technique that can reduce the memory costs of large language model reasoning by up to eight times. Their technique, called dynamic memory sparsification (DMS), compresses the key value (KV) cache, the temporary memory LLMs generate and store as they process prompts and reason through problems and documents.While researchers have proposed various methods to compress this cache before, most struggle to do so without degrading the model&#x27;s intelligence. Nvidia&#x27;s approach manages to discard much of the cache while maintaining (and in some cases improving) the model&#x27;s reasoning capabilities.Experiments show that DMS enables LLMs to \"think\" longer and explore more solutions without the usual penalty in speed or memory costs.The bottleneck of reasoningLLMs improve their performance on complex tasks by generating \"chain-of-thought\" tokens, essentially writing out their reasoning steps before arriving at a final answer. Inference-time scaling techniques leverage this by giving the model a larger budget to generate these thinking tokens or to explore multiple potential reasoning paths in parallel.However, this improved reasoning comes with a significant computational cost. As the model generates more tokens, it builds up a KV cache. For real-world applications, the KV cache is a major bottleneck. As the reasoning chain grows, the cache grows linearly, consuming vast amounts of memory on GPUs. This forces the hardware to spend more time reading data from memory than actually computing, which slows down generation and increases latency. It also caps the number of users a system can serve simultaneously, as running out of VRAM causes the system to crash or slow to a crawl.Nvidia researchers frame this not just as a technical hurdle, but as a fundamental economic one for the enterprise.\"The question isn&#x27;t just about hardware quantity; it&#x27;s about whether your infrastructure is processing 100 reasoning threads or 800 threads for the same cost,\" Piotr Nawrot, Senior Deep Learning Engineer at Nvidia, told VentureBeat.Previous attempts to solve this focused on heuristics-based approaches. These methods use rigid rules, such as a \"sliding window\" that only caches the most recent tokens and deletes the rest. While this reduces memory usage, it often forces the model to discard critical information required for solving the problem, degrading the accuracy of the output.\"Standard eviction methods attempt to select old and unused tokens for eviction using heuristics,\" the researchers said. \"They simplify the problem, hoping that if they approximate the model&#x27;s internal mechanics, the answer will remain correct.\"Other solutions use paging to offload the unused parts of the KV cache to slower memory, but the constant swapping of data introduces latency overhead that makes real-time applications sluggish.Dynamic memory sparsificationDMS takes a different approach by \"retrofitting\" existing LLMs to intelligently manage their own memory. Rather than applying a fixed rule for what to delete, DMS trains the model to identify which tokens are essential for future reasoning and which are disposable.\"It doesn&#x27;t just guess importance; it learns a policy that explicitly preserves the model&#x27;s final output distribution,\" Nawrot said.The process transforms a standard, pre-trained LLM such as Llama 3 or Qwen 3 into a self-compressing model. Crucially, this does not require training the model from scratch, which would be prohibitively expensive. Instead, DMS repurposes existing neurons within the model’s attention layers to output a \"keep\" or \"evict\" signal for each token.For teams worried about the complexity of retrofitting, the researchers noted that the process is designed to be lightweight. \"To improve the efficiency of this process, the model&#x27;s weights can be frozen, which makes the process similar to Low-Rank Adaptation (LoRA),\" Nawrot said. This means a standard enterprise model like Qwen3-8B \"can be retrofitted with DMS within hours on a single DGX H100.\"One of the important parts of DMS is a mechanism called \"delayed eviction.\" In standard sparsification, if a token is deemed unimportant, it is deleted immediately. This is risky because the model might need a split second to integrate that token&#x27;s context into its current state.DMS mitigates this by flagging a token for eviction but keeping it accessible for a short window of time (e.g., a few hundred steps). This delay allows the model to \"extract\" any remaining necessary information from the token and merge it into the current context before the token is wiped from the KV cache.“The ‘delayed eviction’ mechanism is crucial because not all tokens are simply ‘important’ (keep forever) or ‘useless’ (delete immediately). Many fall in between — they carry some information, but not enough to justify occupying an entire slot in memory,” Nawrot said. “This is where the redundancy lies. By keeping these tokens in a local window for a short time before eviction, we allow the model to attend to them and redistribute their information into future tokens.”The researchers found that this retrofitting process is highly efficient. They could equip a pre-trained LLM with DMS in just 1,000 training steps, a tiny fraction of the compute required for the original training. The resulting models use standard kernels and can drop directly into existing high-performance inference stacks without custom hardware or complex software rewriting.DMS in actionTo validate the technique, the researchers applied DMS to several reasoning models, including the Qwen-R1 series (distilled from DeepSeek R1) and Llama 3.2, and tested them on difficult benchmarks like AIME 24 (math), GPQA Diamond (science), and LiveCodeBench (coding).The results show that DMS effectively moves the Pareto frontier, the optimal trade-off between cost and performance. On the AIME 24 math benchmark, a Qwen-R1 32B model equipped with DMS achieved a score 12.0 points higher than a standard model when constrained to the same memory bandwidth budget. By compressing the cache, the model could afford to \"think\" much deeper and wider than the standard model could for the same memory and compute budget.Perhaps most surprisingly, DMS defied the common wisdom that compression hurts long-context understanding. In \"needle-in-a-haystack\" tests, which measure a model&#x27;s ability to find a specific piece of information buried in a large document, DMS variants actually outperformed the standard models. By actively managing its memory rather than passively accumulating noise, the model maintained a cleaner, more useful context.For enterprise infrastructure, the efficiency gains translate directly to throughput and hardware savings. Because the memory cache is significantly smaller, the GPU spends less time fetching data, reducing the wait time for users. In tests with the Qwen3-8B model, DMS matched the accuracy of the vanilla model while delivering up to 5x higher throughput. This means a single server can handle five times as many customer queries per second without a drop in quality.The future of memoryNvidia has released DMS as part of its Model Optimizer framework. Regarding how enterprises can get started with DMS, Nawrot emphasized that the barrier to entry is low. \"The &#x27;minimum viable infrastructure&#x27; is standard Hugging Face pipelines — no custom CUDA kernels are required,\" Nawrot said, noting that the code is fully compatible with standard FlashAttention. Looking ahead, the team views DMS as part of a larger shift where memory management becomes a distinct, intelligent layer of the AI stack. Nawrot also confirmed that DMS is \"fully compatible\" with newer architectures like the Multi-Head Latent Attention (MLA) used in DeepSeek’s models, suggesting that combining these approaches could yield even greater efficiency gains.As enterprises move from simple chatbots to complex agentic systems that require extended reasoning, the cost of inference is becoming a primary concern. Techniques like DMS provide a path to scale these capabilities sustainably.\"We’ve barely scratched the surface of what is possible,\" Nawrot said, \"and we expect inference-time scaling to further evolve.\"",
          "content": "Researchers at Nvidia have developed a technique that can reduce the memory costs of large language model reasoning by up to eight times. Their technique, called dynamic memory sparsification (DMS), compresses the key value (KV) cache, the temporary memory LLMs generate and store as they process prompts and reason through problems and documents.While researchers have proposed various methods to compress this cache before, most struggle to do so without degrading the model&#x27;s intelligence. Nvidia&#x27;s approach manages to discard much of the cache while maintaining (and in some cases improving) the model&#x27;s reasoning capabilities.Experiments show that DMS enables LLMs to \"think\" longer and explore more solutions without the usual penalty in speed or memory costs.The bottleneck of reasoningLLMs improve their performance on complex tasks by generating \"chain-of-thought\" tokens, essentially writing out their reasoning steps before arriving at a final answer. Inference-time scaling techniques leverage this by giving the model a larger budget to generate these thinking tokens or to explore multiple potential reasoning paths in parallel.However, this improved reasoning comes with a significant computational cost. As the model generates more tokens, it builds up a KV cache. For real-world applications, the KV cache is a major bottleneck. As the reasoning chain grows, the cache grows linearly, consuming vast amounts of memory on GPUs. This forces the hardware to spend more time reading data from memory than actually computing, which slows down generation and increases latency. It also caps the number of users a system can serve simultaneously, as running out of VRAM causes the system to crash or slow to a crawl.Nvidia researchers frame this not just as a technical hurdle, but as a fundamental economic one for the enterprise.\"The question isn&#x27;t just about hardware quantity; it&#x27;s about whether your infrastructure is processing 100 reasoning threads or 800 threads for the same cost,\" Piotr Nawrot, Senior Deep Learning Engineer at Nvidia, told VentureBeat.Previous attempts to solve this focused on heuristics-based approaches. These methods use rigid rules, such as a \"sliding window\" that only caches the most recent tokens and deletes the rest. While this reduces memory usage, it often forces the model to discard critical information required for solving the problem, degrading the accuracy of the output.\"Standard eviction methods attempt to select old and unused tokens for eviction using heuristics,\" the researchers said. \"They simplify the problem, hoping that if they approximate the model&#x27;s internal mechanics, the answer will remain correct.\"Other solutions use paging to offload the unused parts of the KV cache to slower memory, but the constant swapping of data introduces latency overhead that makes real-time applications sluggish.Dynamic memory sparsificationDMS takes a different approach by \"retrofitting\" existing LLMs to intelligently manage their own memory. Rather than applying a fixed rule for what to delete, DMS trains the model to identify which tokens are essential for future reasoning and which are disposable.\"It doesn&#x27;t just guess importance; it learns a policy that explicitly preserves the model&#x27;s final output distribution,\" Nawrot said.The process transforms a standard, pre-trained LLM such as Llama 3 or Qwen 3 into a self-compressing model. Crucially, this does not require training the model from scratch, which would be prohibitively expensive. Instead, DMS repurposes existing neurons within the model’s attention layers to output a \"keep\" or \"evict\" signal for each token.For teams worried about the complexity of retrofitting, the researchers noted that the process is designed to be lightweight. \"To improve the efficiency of this process, the model&#x27;s weights can be frozen, which makes the process similar to Low-Rank Adaptation (LoRA),\" Nawrot said. This means a standard enterprise model like Qwen3-8B \"can be retrofitted with DMS within hours on a single DGX H100.\"One of the important parts of DMS is a mechanism called \"delayed eviction.\" In standard sparsification, if a token is deemed unimportant, it is deleted immediately. This is risky because the model might need a split second to integrate that token&#x27;s context into its current state.DMS mitigates this by flagging a token for eviction but keeping it accessible for a short window of time (e.g., a few hundred steps). This delay allows the model to \"extract\" any remaining necessary information from the token and merge it into the current context before the token is wiped from the KV cache.“The ‘delayed eviction’ mechanism is crucial because not all tokens are simply ‘important’ (keep forever) or ‘useless’ (delete immediately). Many fall in between — they carry some information, but not enough to justify occupying an entire slot in memory,” Nawrot said. “This is where the redundancy lies. By keeping these tokens in a local window for a short time before eviction, we allow the model to attend to them and redistribute their information into future tokens.”The researchers found that this retrofitting process is highly efficient. They could equip a pre-trained LLM with DMS in just 1,000 training steps, a tiny fraction of the compute required for the original training. The resulting models use standard kernels and can drop directly into existing high-performance inference stacks without custom hardware or complex software rewriting.DMS in actionTo validate the technique, the researchers applied DMS to several reasoning models, including the Qwen-R1 series (distilled from DeepSeek R1) and Llama 3.2, and tested them on difficult benchmarks like AIME 24 (math), GPQA Diamond (science), and LiveCodeBench (coding).The results show that DMS effectively moves the Pareto frontier, the optimal trade-off between cost and performance. On the AIME 24 math benchmark, a Qwen-R1 32B model equipped with DMS achieved a score 12.0 points higher than a standard model when constrained to the same memory bandwidth budget. By compressing the cache, the model could afford to \"think\" much deeper and wider than the standard model could for the same memory and compute budget.Perhaps most surprisingly, DMS defied the common wisdom that compression hurts long-context understanding. In \"needle-in-a-haystack\" tests, which measure a model&#x27;s ability to find a specific piece of information buried in a large document, DMS variants actually outperformed the standard models. By actively managing its memory rather than passively accumulating noise, the model maintained a cleaner, more useful context.For enterprise infrastructure, the efficiency gains translate directly to throughput and hardware savings. Because the memory cache is significantly smaller, the GPU spends less time fetching data, reducing the wait time for users. In tests with the Qwen3-8B model, DMS matched the accuracy of the vanilla model while delivering up to 5x higher throughput. This means a single server can handle five times as many customer queries per second without a drop in quality.The future of memoryNvidia has released DMS as part of its Model Optimizer framework. Regarding how enterprises can get started with DMS, Nawrot emphasized that the barrier to entry is low. \"The &#x27;minimum viable infrastructure&#x27; is standard Hugging Face pipelines — no custom CUDA kernels are required,\" Nawrot said, noting that the code is fully compatible with standard FlashAttention. Looking ahead, the team views DMS as part of a larger shift where memory management becomes a distinct, intelligent layer of the AI stack. Nawrot also confirmed that DMS is \"fully compatible\" with newer architectures like the Multi-Head Latent Attention (MLA) used in DeepSeek’s models, suggesting that combining these approaches could yield even greater efficiency gains.As enterprises move from simple chatbots to complex agentic systems that require extended reasoning, the cost of inference is becoming a primary concern. Techniques like DMS provide a path to scale these capabilities sustainably.\"We’ve barely scratched the surface of what is possible,\" Nawrot said, \"and we expect inference-time scaling to further evolve.\"",
          "feed_position": 2,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/6Op858lSN4iIkbMucN5ayA/a2b5ca432d5f5c7573cca25abb650546/Spase_attention.jpg?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/technology/minimaxs-new-open-m2-5-and-m2-5-lightning-near-state-of-the-art-while",
          "published_at": "Thu, 12 Feb 2026 20:28:00 GMT",
          "title": "MiniMax's new open M2.5 and M2.5 Lightning near state-of-the-art while costing 1/20th of Claude Opus 4.6",
          "standfirst": "Chinese AI startup MiniMax, headquartered in Shanghai, has sent shockwaves through the AI industry today with the release of its new M2.5 language model in two variants, which promise to make high-end artificial intelligence so cheap you might stop worrying about the bill entirely. It was made open source on Hugging Face under a modified MIT License requiring that those using the model (or custom variants) for commercial purposes \"prominently display &#x27;MiniMax M2.5&#x27; on the user interface of such product or service.\" But that&#x27;s almost beside the point given how cheap MiniMax is serving it through its API and those of partners.For the last few years, using the world’s most powerful AI was like hiring an expensive consultant—it was brilliant, but you watched the clock (and the token count) constantly. M2.5 changes that math, dropping the cost of the frontier by as much as 95%.By delivering performance that rivals the top-tier models from Google and Anthropic at a fraction of the cost, particularly in agentic tool use for enterprise tasks, including creating Microsoft Word, Excel and PowerPoint files, MiniMax is betting that the future isn&#x27;t just about how smart a model is, but how often you can afford to use it.Indeed, to this end, MiniMax says it worked \"with senior professionals in fields such as finance, law, and social sciences\" to ensure the model could perform real work up to their specifications and standards.This release matters because it signals a shift from AI as a \"chatbot\" to AI as a \"worker\". When intelligence becomes \"too cheap to meter,\" developers stop building simple Q&A tools and start building \"agents\"—software that can spend hours autonomously coding, researching, and organizing complex projects without breaking the bank.In fact, MiniMax has already deployed this model into its own operations. Currently, 30% of all tasks at MiniMax HQ are completed by M2.5, and a staggering 80% of their newly committed code is generated by M2.5!As the MiniMax team writes in their release blog post, \"we believe that M2.5 provides virtually limitless possibilities for the development and operation of agents in the economy.\"Technology: sparse power and the CISPO breakthroughThe secret to M2.5’s efficiency lies in its Mixture of Experts (MoE) architecture. Rather than running all of its 230 billion parameters for every single word it generates, the model only \"activates\" 10 billion. This allows it to maintain the reasoning depth of a massive model while moving with the agility of a much smaller one.To train this complex system, MiniMax developed a proprietary Reinforcement Learning (RL) framework called Forge. MiniMax engineer Olive Song stated on the ThursdAI podcast on YouTube that this technique was instrumental to scaling the performance even while using the relatively small number of parameters, and that the model was trained over a period of two months.Forge is designed to help the model learn from \"real-world environments\" — essentially letting the AI practice coding and using tools in thousands of simulated workspaces. \"What we realized is that there&#x27;s a lot of potential with a small model like this if we train reinforcement learning on it with a large amount of environments and agents,\" Song said. \"But it&#x27;s not a very easy thing to do,\" adding that was what they spent \"a lot of time\" on.To keep the model stable during this intense training, they used a mathematical approach called CISPO (Clipping Importance Sampling Policy Optimization) and shared the formula on their blog.This formula ensures the model doesn&#x27;t over-correct during training, allowing it to develop what MiniMax calls an \"Architect Mindset\". Instead of jumping straight into writing code, M2.5 has learned to proactively plan the structure, features, and interface of a project first.State-of-the-art (and near) benchmarksThe results of this architecture are reflected in the latest industry leaderboards. M2.5 hasn&#x27;t just improved; it has vaulted into the top tier of coding models, approaching Anthropic&#x27;s latest model, Claude Opus 4.6, released just a week ago, and showing that Chinese companies are now just days away from catching up to far better resourced (in terms of GPUs) U.S. labs.Here are some of the new MiniMax M2.5 benchmark highlights:SWE-Bench Verified: 80.2% — Matches Claude Opus 4.6 speedsBrowseComp: 76.3% — Industry-leading search & tool use.Multi-SWE-Bench: 51.3% — SOTA in multi-language codingBFCL (Tool Calling): 76.8% — High-precision agentic workflows.On the ThursdAI podcast, host Alex Volkov pointed out that MiniMax M2.5 operates extremely quickly and therefore uses less tokens to complete tasks, on the order $0.15 per task compared to $3.00 for Claude Opus 4.6.Breaking the cost barrierMiniMax is offering two versions of the model through its API, both focused on high-volume production use:M2.5-Lightning: Optimized for speed, delivering 100 tokens per second. It costs $0.30 per 1M input tokens and $2.40 per 1M output tokens.Standard M2.5: Optimized for cost, running at 50 tokens per second. It costs half as much as the Lightning version ($0.15 per 1M input tokens / $1.20 per 1M output tokens).In plain language: MiniMax claims you can run four \"agents\" (AI workers) continuously for an entire year for roughly $10,000. For enterprise users, this pricing is roughly 1/10th to 1/20th the cost of competing proprietary models like GPT-5 or Claude 4.6 Opus.ModelInputOutputTotal CostSourceQwen 3 Turbo$0.05$0.20$0.25Alibaba Clouddeepseek-chat (V3.2-Exp)$0.28$0.42$0.70DeepSeekdeepseek-reasoner (V3.2-Exp)$0.28$0.42$0.70DeepSeekGrok 4.1 Fast (reasoning)$0.20$0.50$0.70xAIGrok 4.1 Fast (non-reasoning)$0.20$0.50$0.70xAIMiniMax M2.5$0.15$1.20$1.35MiniMaxMiniMax M2.5-Lightning$0.30$2.40$2.70MiniMaxGemini 3 Flash Preview$0.50$3.00$3.50GoogleKimi-k2.5$0.60$3.00$3.60MoonshotGLM-5$1.00$3.20$4.20Z.aiERNIE 5.0$0.85$3.40$4.25BaiduClaude Haiku 4.5$1.00$5.00$6.00AnthropicQwen3-Max (2026-01-23)$1.20$6.00$7.20Alibaba CloudGemini 3 Pro (≤200K)$2.00$12.00$14.00GoogleGPT-5.2$1.75$14.00$15.75OpenAIClaude Sonnet 4.5$3.00$15.00$18.00AnthropicGemini 3 Pro (>200K)$4.00$18.00$22.00GoogleClaude Opus 4.6$5.00$25.00$30.00AnthropicGPT-5.2 Pro$21.00$168.00$189.00OpenAIStrategic implications for enterprises and leadersFor technical leaders, M2.5 represents more than just a cheaper API. It changes the operational playbook for enterprises right now.The pressure to \"optimize\" prompts to save money is gone. You can now deploy high-context, high-reasoning models for routine tasks that were previously cost-prohibitive.The 37% speed improvement in end-to-end task completion means the \"agentic\" pipelines valued by AI orchestrators — where models talk to other models — finally move fast enough for real-time user applications.In addition, M2.5’s high scores in financial modeling (74.4% on MEWC) suggest it can handle the \"tacit knowledge\" of specialized industries like law and finance with minimal oversight.Because M2.5 is positioned as an open-source model, organizations can potentially run intensive, automated code audits at a scale that was previously impossible without massive human intervention, all while maintaining better control over data privacy.MiniMax M2.5 is a signal that the frontier of AI is no longer just about who can build the biggest brain, but who can make that brain the most useful—and affordable—worker in the room.",
          "content": "Chinese AI startup MiniMax, headquartered in Shanghai, has sent shockwaves through the AI industry today with the release of its new M2.5 language model in two variants, which promise to make high-end artificial intelligence so cheap you might stop worrying about the bill entirely. It was made open source on Hugging Face under a modified MIT License requiring that those using the model (or custom variants) for commercial purposes \"prominently display &#x27;MiniMax M2.5&#x27; on the user interface of such product or service.\" But that&#x27;s almost beside the point given how cheap MiniMax is serving it through its API and those of partners.For the last few years, using the world’s most powerful AI was like hiring an expensive consultant—it was brilliant, but you watched the clock (and the token count) constantly. M2.5 changes that math, dropping the cost of the frontier by as much as 95%.By delivering performance that rivals the top-tier models from Google and Anthropic at a fraction of the cost, particularly in agentic tool use for enterprise tasks, including creating Microsoft Word, Excel and PowerPoint files, MiniMax is betting that the future isn&#x27;t just about how smart a model is, but how often you can afford to use it.Indeed, to this end, MiniMax says it worked \"with senior professionals in fields such as finance, law, and social sciences\" to ensure the model could perform real work up to their specifications and standards.This release matters because it signals a shift from AI as a \"chatbot\" to AI as a \"worker\". When intelligence becomes \"too cheap to meter,\" developers stop building simple Q&A tools and start building \"agents\"—software that can spend hours autonomously coding, researching, and organizing complex projects without breaking the bank.In fact, MiniMax has already deployed this model into its own operations. Currently, 30% of all tasks at MiniMax HQ are completed by M2.5, and a staggering 80% of their newly committed code is generated by M2.5!As the MiniMax team writes in their release blog post, \"we believe that M2.5 provides virtually limitless possibilities for the development and operation of agents in the economy.\"Technology: sparse power and the CISPO breakthroughThe secret to M2.5’s efficiency lies in its Mixture of Experts (MoE) architecture. Rather than running all of its 230 billion parameters for every single word it generates, the model only \"activates\" 10 billion. This allows it to maintain the reasoning depth of a massive model while moving with the agility of a much smaller one.To train this complex system, MiniMax developed a proprietary Reinforcement Learning (RL) framework called Forge. MiniMax engineer Olive Song stated on the ThursdAI podcast on YouTube that this technique was instrumental to scaling the performance even while using the relatively small number of parameters, and that the model was trained over a period of two months.Forge is designed to help the model learn from \"real-world environments\" — essentially letting the AI practice coding and using tools in thousands of simulated workspaces. \"What we realized is that there&#x27;s a lot of potential with a small model like this if we train reinforcement learning on it with a large amount of environments and agents,\" Song said. \"But it&#x27;s not a very easy thing to do,\" adding that was what they spent \"a lot of time\" on.To keep the model stable during this intense training, they used a mathematical approach called CISPO (Clipping Importance Sampling Policy Optimization) and shared the formula on their blog.This formula ensures the model doesn&#x27;t over-correct during training, allowing it to develop what MiniMax calls an \"Architect Mindset\". Instead of jumping straight into writing code, M2.5 has learned to proactively plan the structure, features, and interface of a project first.State-of-the-art (and near) benchmarksThe results of this architecture are reflected in the latest industry leaderboards. M2.5 hasn&#x27;t just improved; it has vaulted into the top tier of coding models, approaching Anthropic&#x27;s latest model, Claude Opus 4.6, released just a week ago, and showing that Chinese companies are now just days away from catching up to far better resourced (in terms of GPUs) U.S. labs.Here are some of the new MiniMax M2.5 benchmark highlights:SWE-Bench Verified: 80.2% — Matches Claude Opus 4.6 speedsBrowseComp: 76.3% — Industry-leading search & tool use.Multi-SWE-Bench: 51.3% — SOTA in multi-language codingBFCL (Tool Calling): 76.8% — High-precision agentic workflows.On the ThursdAI podcast, host Alex Volkov pointed out that MiniMax M2.5 operates extremely quickly and therefore uses less tokens to complete tasks, on the order $0.15 per task compared to $3.00 for Claude Opus 4.6.Breaking the cost barrierMiniMax is offering two versions of the model through its API, both focused on high-volume production use:M2.5-Lightning: Optimized for speed, delivering 100 tokens per second. It costs $0.30 per 1M input tokens and $2.40 per 1M output tokens.Standard M2.5: Optimized for cost, running at 50 tokens per second. It costs half as much as the Lightning version ($0.15 per 1M input tokens / $1.20 per 1M output tokens).In plain language: MiniMax claims you can run four \"agents\" (AI workers) continuously for an entire year for roughly $10,000. For enterprise users, this pricing is roughly 1/10th to 1/20th the cost of competing proprietary models like GPT-5 or Claude 4.6 Opus.ModelInputOutputTotal CostSourceQwen 3 Turbo$0.05$0.20$0.25Alibaba Clouddeepseek-chat (V3.2-Exp)$0.28$0.42$0.70DeepSeekdeepseek-reasoner (V3.2-Exp)$0.28$0.42$0.70DeepSeekGrok 4.1 Fast (reasoning)$0.20$0.50$0.70xAIGrok 4.1 Fast (non-reasoning)$0.20$0.50$0.70xAIMiniMax M2.5$0.15$1.20$1.35MiniMaxMiniMax M2.5-Lightning$0.30$2.40$2.70MiniMaxGemini 3 Flash Preview$0.50$3.00$3.50GoogleKimi-k2.5$0.60$3.00$3.60MoonshotGLM-5$1.00$3.20$4.20Z.aiERNIE 5.0$0.85$3.40$4.25BaiduClaude Haiku 4.5$1.00$5.00$6.00AnthropicQwen3-Max (2026-01-23)$1.20$6.00$7.20Alibaba CloudGemini 3 Pro (≤200K)$2.00$12.00$14.00GoogleGPT-5.2$1.75$14.00$15.75OpenAIClaude Sonnet 4.5$3.00$15.00$18.00AnthropicGemini 3 Pro (>200K)$4.00$18.00$22.00GoogleClaude Opus 4.6$5.00$25.00$30.00AnthropicGPT-5.2 Pro$21.00$168.00$189.00OpenAIStrategic implications for enterprises and leadersFor technical leaders, M2.5 represents more than just a cheaper API. It changes the operational playbook for enterprises right now.The pressure to \"optimize\" prompts to save money is gone. You can now deploy high-context, high-reasoning models for routine tasks that were previously cost-prohibitive.The 37% speed improvement in end-to-end task completion means the \"agentic\" pipelines valued by AI orchestrators — where models talk to other models — finally move fast enough for real-time user applications.In addition, M2.5’s high scores in financial modeling (74.4% on MEWC) suggest it can handle the \"tacit knowledge\" of specialized industries like law and finance with minimal oversight.Because M2.5 is positioned as an open-source model, organizations can potentially run intensive, automated code audits at a scale that was previously impossible without massive human intervention, all while maintaining better control over data privacy.MiniMax M2.5 is a signal that the frontier of AI is no longer just about who can build the biggest brain, but who can make that brain the most useful—and affordable—worker in the room.",
          "feed_position": 3,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/7BkiJw4Sda8kmGOMjm0AHC/d1258ce9ca1f941e68065f23464ce4a9/Zmf7qn_asvrC8yIjNKJqx_gtzOnyvS.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/audio/headphones/best-wireless-earbuds-120058222.html",
          "published_at": "Thu, 12 Feb 2026 20:00:35 +0000",
          "title": "The best wireless earbuds for 2026",
          "standfirst": "Wireless earbuds are now the default option for everyday listening, whether you’re heading out for a commute, fitting in a workout or just watching videos at home. The best wireless earbuds combine reliable connectivity, comfortable fits and sound quality that holds up across music, calls and podcasts, all without the hassle of cables. Most are small enough to disappear into a pocket and pair quickly with phones, tablets and laptops.What sets one pair apart from another often comes down to priorities. Some earbuds lean heavily on active noise cancellation, while others focus on long battery life, compact charging cases or lower prices. Features like water resistance, customizable controls and app support can also make a real difference day to day. This guide breaks down the best wireless earbuds available now to help you find the right match for how you listen. Best wireless earbuds of 2026 What to look for in the best wireless earbuds When it comes to shopping for earphones, the first thing to consider is design or wear style. Do you prefer a semi-open fit like AirPods or do you want something that completely closes off your ears? If you’re shopping for earbuds with active noise cancellation, you'll want the latter, but a case can be made for the former if you want to wear them all day or frequent places where you need to be tuned in to the ambient sounds. The overall shape of earbuds can determine whether you get a comfortable fit, so can the size and weight, so you’ll want to consider all that before deciding. And remember: audio companies aren’t perfect, so despite lots of research, the earbud shape they decided on may not fit you well. Don’t be afraid to return ill-fitting earbuds for something that’s more comfortable. As wireless earbuds have become the norm, they’re now more reliable for basic things like consistent Bluetooth connectivity. Companies are still in a race to pack as much as they can into increasingly smaller designs. This typically means a longer list of features on the more premium sets of earbuds with basic functionality on the cheapest models. Carefully consider what you can’t live without when selecting your next earbuds, and make sure key items like automatic pausing and multipoint connectivity are on the spec sheet. You’ll also want to investigate the volume and touch controls as you’ll often have to sacrifice access to something else to make that adjustment via on-board taps or swipes. Some earbuds even offer app settings to tweak the audio profiles or firmware updates to improve performance over time. For those in the Apple ecosystem, features like auto-pairing with devices, especially with AirPods Pro 3, can be an added advantage, while Android users may want to look for models that offer similar cross-device functionality. When it comes to battery life, the average set of earbuds lasts about five hours on a single charge. You can find sets that last longer, but this is likely enough to get you through a work day if you’re docking the buds during lunch or the occasional meeting. You’ll want to check on how many extra charges are available via the case and if it supports wireless charging. Companies will also make lofty claims about call quality on wireless earbuds. Despite lots of promises, the reality is most earbuds still leave you sounding like you’re on speakerphone. There are some sets that deliver, but don’t get your hopes up unless reviews confirm the claims. Sound can be subjective, so we recommend trying before you buy if at all possible. This is especially true if you're an audiophile. We understand this isn’t easy when most of us do a lot of shopping online, but trying on a set of earbuds and listening to them for a few minutes can save you from an expensive case of buyer's remorse. If a store doesn’t allow a quick demo, most retailers have return policies that will let you take earbuds back you don’t like. Of course, you have to be willing to temporarily part with funds in order to do this. We also recommend paying attention to things like Spatial Audio, Dolby Atmos, 360 Reality Audio and other immersive formats. Not all earbuds support them, so you’ll want to make sure a perspective pair does if that sort of thing excites you, especially if you plan to use them for playback of high-quality audio. How we test wireless earbuds The primary way we test earbuds is to wear them as much as possible. We prefer to do this over a one- to two-week period, but sometimes embargoes don’t allow it. During this time, we listen to a mix of music and podcasts, while also using the earbuds to take both voice and video calls. Since battery life for earbuds is typically less than a full day, we drain the battery with looping music and the volume set at a comfortable level (usually around 75 percent). To judge audio quality, we listen to a range of genres, noting any differences in the sound profile across the styles. We also test at both low and high volumes to check for consistency in the tuning. To assess call quality, we’ll record audio samples with the earbuds’ microphones as well as have third parties call us. When it comes to features, we do a thorough review of companion apps, testing each feature as we work through the software. Any holdovers from previous models are double checked for improvements or regression. If the earbuds we’re testing are an updated version of a previous model, we’ll spend time getting reacquainted with the older buds. Ditto for the closest competition for each new set of earbuds that we review. Other wireless Bluetooth earbuds we tested Sony WF-1000XM6 Since we established this best wireless earbuds guide, Sony’s current 1000X model has consistently been the top pick. However, with the WF-1000XM6, there are two key areas where the company’s latest flagship set doesn’t measure up well versus the competition. Overall ANC performance lags behind Bose, and even Sony’s own WF-1000XM5. Speaking of the M5, the company did well there to address the issues I had with fit when it switched to foam ear tips on the WF-1000XM4, but it regressed in that area on the M6. There’s still plenty to like in terms of features and sound quality, but there are also caveats to consider now that could be dealbreakers. Sony WF-C710N The WF-C710N is a set of compact and comfy earbuds that offer several of Sony’s best features. While the ANC performance is above average for this price ($120), sound quality isn’t as good as the company’s slightly more expensive options. Battery life fell below stated figures and call performance isn’t good enough to use these buds for work. Beats Powerbeats Pro 2 The newest version of the Powerbeats Pro have an improved, comfortable design, balanced bass and new H2 chips and a heart rate sensor inside. But heart rate support is currently limited on iOS. Samsung Galaxy Buds 3 The Galaxy Buds 3 combine ANC with an open-type design, which renders the noise-blocking abilities of the earbuds mostly useless. Still, there’s great low-end tone with ample bass when a track demands it. There are also lots of handy features, most of which require a Samsung phone. But at this price, there are better options from Google, Beats and Sony Sennheiser Momentum Sport I really like the overall shape of the Momentum Sport earbuds. They’re more comfortable than the Momentum True Wireless 4 and fit in my ears better. What’s more, the body temperature and heart rate sensors work well, sending those stats to a variety of apps. However, that sport-tracking feature works best with Polar’s app and devices, so there’s that consideration. Also, the audio quality and ANC performance isn’t as good as the MTW4, and these earbuds are pricey. Beats Solo Buds There’s a lot to like about the Solo Buds for $80. For me, the primary perk is they’re very comfortable to wear for long periods of time thanks to some thoughtful design considerations. You only get the basics here in terms of features and, as expected, the overall sound quality isn’t as good as the pricier models in the Beats lineup. You will get 18 hours of battery life though, since the company nixed the battery in the case and beefed up the listening time in the buds themselves. Bose Ultra Open Earbuds Bose created something very unique for this set of earbuds that allows you to stay in-tune with the world while listening to audio content. The clip-on design is very comfortable, but sound quality suffers due to the open-type fit, especially when it comes to bass and spatial audio. Audio-Technica ATH-TWX7 These stick buds have a compact design that’s comfortable to wear and the warm sound profile is great at times. However, overall audio performance is inconsistent and there’s no automatic pausing. Master & Dynamic MW09 Retooled audio, better ambient sound mode and reliable multipoint Bluetooth are the best things the MW09 has to offer. They’re expensive though, and you can find better ANC performance elsewhere. Wireless earbud FAQs What is considered good battery life for true wireless earbuds? Most wireless earbuds will last five hours on a single charge, at the least. You can find some pairs that have even better battery life, lasting between six and eight hours before they need more juice. All of the best wireless earbuds come with a charging case, which will provide additional hours of battery life — but you'll have to return each bud to the case in order to charge them up. Is sound quality better on headphones or earbuds? Comparing sound quality on earbuds and headphones is a bit like comparing apples and oranges. There are a lot of variables to consider and the differences in components make a direct comparison difficult. Personally, I prefer the audio quality from over-ear headphones, but I can tell you the sound from earbuds like Sennheiser’s Momentum True Wireless 3 is also outstanding. Which wireless earbuds have the longest battery life? With new models coming out all the time, tracking the hours of battery life for each this can be difficult to keep tabs on. The longest-lasting earbuds we’ve reviewed are Audio-Technica’s ATH-CKS5TW. The company states they last 15 hours, but the app was still showing 40 percent at that mark during our tests. The only downside is these earbuds debuted in 2019 and both technology and features have improved since. In terms of current models, Master & Dynamic’s MW08 offers 12 hours of use on a charge with ANC off (10 with ANC on) and JBL has multiple options with 10-hour batteries. What wireless earbuds are waterproof? There are plenty of options these days when it comes to increased water resistance. To determine the level of protection, you’ll want to look for an IP (ingress protection) rating. The first number indicates intrusion protection from things like dust. The second number is the level of moisture protection and you’ll want to make sure that figure is 7 or higher. At this water-resistance rating, earbuds can withstand full immersion for up to 30 minutes in depths up to one meter (3.28 feet). If either of the IP numbers is an X, that means it doesn’t have any special protection. For example, a pair of wireless earbuds that are IPX7 wouldn’t be built to avoid dust intrusion, but they would be ok if you dropped them in shallow water. Which earbuds stay in ears the best? A secure fit can vary wildly from person to person. All of our ears are different, so audio companies are designing their products to fit the most people they can with a single shape. This is why AirPods will easily fall out for some but stay put for others. Design touches like wing tips or fins typically come on fitness models and those elements can help keep things in place. You’ll likely just have to try earbuds on, and if they don’t fit well return them. What wireless earbuds work with PS5? PlayStation 5 doesn’t support Bluetooth audio without an adapter or dongle. Even Sony’s own gaming headsets come with a transmitter that connects to the console. There are universal options that allow you to use any headphones, headset or earbuds with a PS5. Once you have one, plug it into a USB port on the console and pair your earbuds with it. Recent updates February 2026: Updated to include new top picks. January 2026: Updated to ensure our top picks have remained the same. September 2025: Updated to add AirPods Pro 3 to our top picks. May 2025: Updated to ensure top picks and buying advice remain accurate. March 2025: Updated the top pick for the best sounding wireless earbuds - runner up. January 2025: Updated the top pick for best sounding wireless earbuds.This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/best-wireless-earbuds-120058222.html?src=rss",
          "content": "Wireless earbuds are now the default option for everyday listening, whether you’re heading out for a commute, fitting in a workout or just watching videos at home. The best wireless earbuds combine reliable connectivity, comfortable fits and sound quality that holds up across music, calls and podcasts, all without the hassle of cables. Most are small enough to disappear into a pocket and pair quickly with phones, tablets and laptops.What sets one pair apart from another often comes down to priorities. Some earbuds lean heavily on active noise cancellation, while others focus on long battery life, compact charging cases or lower prices. Features like water resistance, customizable controls and app support can also make a real difference day to day. This guide breaks down the best wireless earbuds available now to help you find the right match for how you listen. Best wireless earbuds of 2026 What to look for in the best wireless earbuds When it comes to shopping for earphones, the first thing to consider is design or wear style. Do you prefer a semi-open fit like AirPods or do you want something that completely closes off your ears? If you’re shopping for earbuds with active noise cancellation, you'll want the latter, but a case can be made for the former if you want to wear them all day or frequent places where you need to be tuned in to the ambient sounds. The overall shape of earbuds can determine whether you get a comfortable fit, so can the size and weight, so you’ll want to consider all that before deciding. And remember: audio companies aren’t perfect, so despite lots of research, the earbud shape they decided on may not fit you well. Don’t be afraid to return ill-fitting earbuds for something that’s more comfortable. As wireless earbuds have become the norm, they’re now more reliable for basic things like consistent Bluetooth connectivity. Companies are still in a race to pack as much as they can into increasingly smaller designs. This typically means a longer list of features on the more premium sets of earbuds with basic functionality on the cheapest models. Carefully consider what you can’t live without when selecting your next earbuds, and make sure key items like automatic pausing and multipoint connectivity are on the spec sheet. You’ll also want to investigate the volume and touch controls as you’ll often have to sacrifice access to something else to make that adjustment via on-board taps or swipes. Some earbuds even offer app settings to tweak the audio profiles or firmware updates to improve performance over time. For those in the Apple ecosystem, features like auto-pairing with devices, especially with AirPods Pro 3, can be an added advantage, while Android users may want to look for models that offer similar cross-device functionality. When it comes to battery life, the average set of earbuds lasts about five hours on a single charge. You can find sets that last longer, but this is likely enough to get you through a work day if you’re docking the buds during lunch or the occasional meeting. You’ll want to check on how many extra charges are available via the case and if it supports wireless charging. Companies will also make lofty claims about call quality on wireless earbuds. Despite lots of promises, the reality is most earbuds still leave you sounding like you’re on speakerphone. There are some sets that deliver, but don’t get your hopes up unless reviews confirm the claims. Sound can be subjective, so we recommend trying before you buy if at all possible. This is especially true if you're an audiophile. We understand this isn’t easy when most of us do a lot of shopping online, but trying on a set of earbuds and listening to them for a few minutes can save you from an expensive case of buyer's remorse. If a store doesn’t allow a quick demo, most retailers have return policies that will let you take earbuds back you don’t like. Of course, you have to be willing to temporarily part with funds in order to do this. We also recommend paying attention to things like Spatial Audio, Dolby Atmos, 360 Reality Audio and other immersive formats. Not all earbuds support them, so you’ll want to make sure a perspective pair does if that sort of thing excites you, especially if you plan to use them for playback of high-quality audio. How we test wireless earbuds The primary way we test earbuds is to wear them as much as possible. We prefer to do this over a one- to two-week period, but sometimes embargoes don’t allow it. During this time, we listen to a mix of music and podcasts, while also using the earbuds to take both voice and video calls. Since battery life for earbuds is typically less than a full day, we drain the battery with looping music and the volume set at a comfortable level (usually around 75 percent). To judge audio quality, we listen to a range of genres, noting any differences in the sound profile across the styles. We also test at both low and high volumes to check for consistency in the tuning. To assess call quality, we’ll record audio samples with the earbuds’ microphones as well as have third parties call us. When it comes to features, we do a thorough review of companion apps, testing each feature as we work through the software. Any holdovers from previous models are double checked for improvements or regression. If the earbuds we’re testing are an updated version of a previous model, we’ll spend time getting reacquainted with the older buds. Ditto for the closest competition for each new set of earbuds that we review. Other wireless Bluetooth earbuds we tested Sony WF-1000XM6 Since we established this best wireless earbuds guide, Sony’s current 1000X model has consistently been the top pick. However, with the WF-1000XM6, there are two key areas where the company’s latest flagship set doesn’t measure up well versus the competition. Overall ANC performance lags behind Bose, and even Sony’s own WF-1000XM5. Speaking of the M5, the company did well there to address the issues I had with fit when it switched to foam ear tips on the WF-1000XM4, but it regressed in that area on the M6. There’s still plenty to like in terms of features and sound quality, but there are also caveats to consider now that could be dealbreakers. Sony WF-C710N The WF-C710N is a set of compact and comfy earbuds that offer several of Sony’s best features. While the ANC performance is above average for this price ($120), sound quality isn’t as good as the company’s slightly more expensive options. Battery life fell below stated figures and call performance isn’t good enough to use these buds for work. Beats Powerbeats Pro 2 The newest version of the Powerbeats Pro have an improved, comfortable design, balanced bass and new H2 chips and a heart rate sensor inside. But heart rate support is currently limited on iOS. Samsung Galaxy Buds 3 The Galaxy Buds 3 combine ANC with an open-type design, which renders the noise-blocking abilities of the earbuds mostly useless. Still, there’s great low-end tone with ample bass when a track demands it. There are also lots of handy features, most of which require a Samsung phone. But at this price, there are better options from Google, Beats and Sony Sennheiser Momentum Sport I really like the overall shape of the Momentum Sport earbuds. They’re more comfortable than the Momentum True Wireless 4 and fit in my ears better. What’s more, the body temperature and heart rate sensors work well, sending those stats to a variety of apps. However, that sport-tracking feature works best with Polar’s app and devices, so there’s that consideration. Also, the audio quality and ANC performance isn’t as good as the MTW4, and these earbuds are pricey. Beats Solo Buds There’s a lot to like about the Solo Buds for $80. For me, the primary perk is they’re very comfortable to wear for long periods of time thanks to some thoughtful design considerations. You only get the basics here in terms of features and, as expected, the overall sound quality isn’t as good as the pricier models in the Beats lineup. You will get 18 hours of battery life though, since the company nixed the battery in the case and beefed up the listening time in the buds themselves. Bose Ultra Open Earbuds Bose created something very unique for this set of earbuds that allows you to stay in-tune with the world while listening to audio content. The clip-on design is very comfortable, but sound quality suffers due to the open-type fit, especially when it comes to bass and spatial audio. Audio-Technica ATH-TWX7 These stick buds have a compact design that’s comfortable to wear and the warm sound profile is great at times. However, overall audio performance is inconsistent and there’s no automatic pausing. Master & Dynamic MW09 Retooled audio, better ambient sound mode and reliable multipoint Bluetooth are the best things the MW09 has to offer. They’re expensive though, and you can find better ANC performance elsewhere. Wireless earbud FAQs What is considered good battery life for true wireless earbuds? Most wireless earbuds will last five hours on a single charge, at the least. You can find some pairs that have even better battery life, lasting between six and eight hours before they need more juice. All of the best wireless earbuds come with a charging case, which will provide additional hours of battery life — but you'll have to return each bud to the case in order to charge them up. Is sound quality better on headphones or earbuds? Comparing sound quality on earbuds and headphones is a bit like comparing apples and oranges. There are a lot of variables to consider and the differences in components make a direct comparison difficult. Personally, I prefer the audio quality from over-ear headphones, but I can tell you the sound from earbuds like Sennheiser’s Momentum True Wireless 3 is also outstanding. Which wireless earbuds have the longest battery life? With new models coming out all the time, tracking the hours of battery life for each this can be difficult to keep tabs on. The longest-lasting earbuds we’ve reviewed are Audio-Technica’s ATH-CKS5TW. The company states they last 15 hours, but the app was still showing 40 percent at that mark during our tests. The only downside is these earbuds debuted in 2019 and both technology and features have improved since. In terms of current models, Master & Dynamic’s MW08 offers 12 hours of use on a charge with ANC off (10 with ANC on) and JBL has multiple options with 10-hour batteries. What wireless earbuds are waterproof? There are plenty of options these days when it comes to increased water resistance. To determine the level of protection, you’ll want to look for an IP (ingress protection) rating. The first number indicates intrusion protection from things like dust. The second number is the level of moisture protection and you’ll want to make sure that figure is 7 or higher. At this water-resistance rating, earbuds can withstand full immersion for up to 30 minutes in depths up to one meter (3.28 feet). If either of the IP numbers is an X, that means it doesn’t have any special protection. For example, a pair of wireless earbuds that are IPX7 wouldn’t be built to avoid dust intrusion, but they would be ok if you dropped them in shallow water. Which earbuds stay in ears the best? A secure fit can vary wildly from person to person. All of our ears are different, so audio companies are designing their products to fit the most people they can with a single shape. This is why AirPods will easily fall out for some but stay put for others. Design touches like wing tips or fins typically come on fitness models and those elements can help keep things in place. You’ll likely just have to try earbuds on, and if they don’t fit well return them. What wireless earbuds work with PS5? PlayStation 5 doesn’t support Bluetooth audio without an adapter or dongle. Even Sony’s own gaming headsets come with a transmitter that connects to the console. There are universal options that allow you to use any headphones, headset or earbuds with a PS5. Once you have one, plug it into a USB port on the console and pair your earbuds with it. Recent updates February 2026: Updated to include new top picks. January 2026: Updated to ensure our top picks have remained the same. September 2025: Updated to add AirPods Pro 3 to our top picks. May 2025: Updated to ensure top picks and buying advice remain accurate. March 2025: Updated the top pick for the best sounding wireless earbuds - runner up. January 2025: Updated the top pick for best sounding wireless earbuds.This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/best-wireless-earbuds-120058222.html?src=rss",
          "feed_position": 35
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/surfshark-vpn-is-offering-up-to-87-percent-off-two-year-plans-123000279.html",
          "published_at": "Thu, 12 Feb 2026 18:30:00 +0000",
          "title": "Surfshark VPN is offering up to 87 percent off two-year plans",
          "standfirst": "Surfshark’s One plan is heavily discounted right now, with an 87-percent discount on the two-year package, plus three extra months. The promo price comes out to $2.29 per month, or $62 for the first 27 months. We’ve generally liked Surfshark as a straightforward, speedy service for everyday use, and it’s one of the picks in our guide to the best VPNs. In our Surfshark review, we found it delivered excellent speeds overall and reliably unblocked Netflix across most of our test servers, which makes this long-term deal worth a look if you want a VPN deal that also includes extras like antivirus, breach alerts and private search. In our Surfshark review, the VPN stood out for its excellent performance and approachable design, especially for people who want strong protection without constantly tweaking settings. During testing, it delivered some of the fastest speeds we’ve seen from a major VPN, with average download speeds dropping by just over five percent worldwide. Upload speeds also held up well, making it a solid option for streaming, browsing and everyday use. We gave Surfshark an overall score of 87 out of 100 and called it one of the best VPNs for casual users. This deal focuses on the Surfshark One plan, which bundles the VPN with a suite of extra security tools. In addition to the VPN itself, you get Alternative ID for masking your email and personal details, antivirus protection, breach monitoring through Surfshark Alert and a private search engine. It also supports unlimited simultaneous device connections, so you can protect all of your devices with a single subscription. Right now, the Surfshark One plan is discounted by 86 percent, bringing the price down to $67 total for two years plus three extra months. That works out to $2.49 per month for the first 27 months, billed upfront, with a 30-day money-back guarantee if you change your mind. If you want to compare it against other top services before committing, you can also check out our full Surfshark VPN review and our best VPN guide to see how it stacks up. We’ll be keeping our best VPN deals roundup updated regularly, too. This article originally appeared on Engadget at https://www.engadget.com/deals/surfshark-vpn-is-offering-up-to-87-percent-off-two-year-plans-123000279.html?src=rss",
          "content": "Surfshark’s One plan is heavily discounted right now, with an 87-percent discount on the two-year package, plus three extra months. The promo price comes out to $2.29 per month, or $62 for the first 27 months. We’ve generally liked Surfshark as a straightforward, speedy service for everyday use, and it’s one of the picks in our guide to the best VPNs. In our Surfshark review, we found it delivered excellent speeds overall and reliably unblocked Netflix across most of our test servers, which makes this long-term deal worth a look if you want a VPN deal that also includes extras like antivirus, breach alerts and private search. In our Surfshark review, the VPN stood out for its excellent performance and approachable design, especially for people who want strong protection without constantly tweaking settings. During testing, it delivered some of the fastest speeds we’ve seen from a major VPN, with average download speeds dropping by just over five percent worldwide. Upload speeds also held up well, making it a solid option for streaming, browsing and everyday use. We gave Surfshark an overall score of 87 out of 100 and called it one of the best VPNs for casual users. This deal focuses on the Surfshark One plan, which bundles the VPN with a suite of extra security tools. In addition to the VPN itself, you get Alternative ID for masking your email and personal details, antivirus protection, breach monitoring through Surfshark Alert and a private search engine. It also supports unlimited simultaneous device connections, so you can protect all of your devices with a single subscription. Right now, the Surfshark One plan is discounted by 86 percent, bringing the price down to $67 total for two years plus three extra months. That works out to $2.49 per month for the first 27 months, billed upfront, with a 30-day money-back guarantee if you change your mind. If you want to compare it against other top services before committing, you can also check out our full Surfshark VPN review and our best VPN guide to see how it stacks up. We’ll be keeping our best VPN deals roundup updated regularly, too. This article originally appeared on Engadget at https://www.engadget.com/deals/surfshark-vpn-is-offering-up-to-87-percent-off-two-year-plans-123000279.html?src=rss",
          "feed_position": 38
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/technology/openai-deploys-cerebras-chips-for-15x-faster-code-generation-in-first-major",
          "published_at": "Thu, 12 Feb 2026 18:00:00 GMT",
          "title": "OpenAI deploys Cerebras chips for 'near-instant' code generation in first major move beyond Nvidia",
          "standfirst": "OpenAI on Thursday launched GPT-5.3-Codex-Spark, a stripped-down coding model engineered for near-instantaneous response times, marking the company&#x27;s first significant inference partnership outside its traditional Nvidia-dominated infrastructure. The model runs on hardware from Cerebras Systems, a Sunnyvale-based chipmaker whose wafer-scale processors specialize in low-latency AI workloads.The partnership arrives at a pivotal moment for OpenAI. The company finds itself navigating a frayed relationship with longtime chip supplier Nvidia, mounting criticism over its decision to introduce advertisements into ChatGPT, a newly announced Pentagon contract, and internal organizational upheaval that has seen a safety-focused team disbanded and at least one researcher resign in protest.\"GPUs remain foundational across our training and inference pipelines and deliver the most cost effective tokens for broad usage,\" an OpenAI spokesperson told VentureBeat. \"Cerebras complements that foundation by excelling at workflows that demand extremely low latency, tightening the end-to-end loop so use cases such as real-time coding in Codex feel more responsive as you iterate.\"The careful framing — emphasizing that GPUs \"remain foundational\" while positioning Cerebras as a \"complement\" — underscores the delicate balance OpenAI must strike as it diversifies its chip suppliers without alienating Nvidia, the dominant force in AI accelerators.Speed gains come with capability tradeoffs that OpenAI says developers will acceptCodex-Spark represents OpenAI&#x27;s first model purpose-built for real-time coding collaboration. The company claims the model delivers more than 1000 tokens per second when served on ultra-low latency hardware, though it declined to provide specific latency metrics such as time-to-first-token figures.\"We aren&#x27;t able to share specific latency numbers, however Codex-Spark is optimized to feel near-instant — delivering more than 1000 tokens per second while remaining highly capable for real-world coding tasks,\" the OpenAI spokesperson said.The speed gains come with acknowledged capability tradeoffs. On SWE-Bench Pro and Terminal-Bench 2.0 — two industry benchmarks that evaluate AI systems&#x27; ability to perform complex software engineering tasks autonomously — Codex-Spark underperforms the full GPT-5.3-Codex model. OpenAI positions this as an acceptable exchange: developers get responses fast enough to maintain creative flow, even if the underlying model cannot tackle the most sophisticated multi-step programming challenges.The model launches with a 128,000-token context window and supports text only — no image or multimodal inputs. OpenAI has made it available as a research preview to ChatGPT Pro subscribers through the Codex app, command-line interface, and Visual Studio Code extension. A small group of enterprise partners will receive API access to evaluate integration possibilities.\"We are making Codex-Spark available in the API for a small set of design partners to understand how developers want to integrate Codex-Spark into their products,\" the spokesperson explained. \"We&#x27;ll expand access over the coming weeks as we continue tuning our integration under real workloads.\"Cerebras hardware eliminates bottlenecks that plague traditional GPU clustersThe technical architecture behind Codex-Spark tells a story about inference economics that increasingly matters as AI companies scale consumer-facing products. Cerebras&#x27;s Wafer Scale Engine 3 — a single chip roughly the size of a dinner plate containing 4 trillion transistors — eliminates much of the communication overhead that occurs when AI workloads spread across clusters of smaller processors.For training massive models, that distributed approach remains necessary and Nvidia&#x27;s GPUs excel at it. But for inference — the process of generating responses to user queries — Cerebras argues its architecture can deliver results with dramatically lower latency. Sean Lie, Cerebras&#x27;s CTO and co-founder, framed the partnership as an opportunity to reshape how developers interact with AI systems.\"What excites us most about GPT-5.3-Codex-Spark is partnering with OpenAI and the developer community to discover what fast inference makes possible — new interaction patterns, new use cases, and a fundamentally different model experience,\" Lie said in a statement. \"This preview is just the beginning.\"OpenAI&#x27;s infrastructure team did not limit its optimization work to the Cerebras hardware. The company announced latency improvements across its entire inference stack that benefit all Codex models regardless of underlying hardware, including persistent WebSocket connections and optimizations within the Responses API. The results: 80 percent reduction in overhead per client-server round trip, 30 percent reduction in per-token overhead, and 50 percent reduction in time-to-first-token.A $100 billion Nvidia megadeal has quietly fallen apart behind the scenesThe Cerebras partnership takes on additional significance given the increasingly complicated relationship between OpenAI and Nvidia. Last fall, when OpenAI announced its Stargate infrastructure initiative, Nvidia publicly committed to investing $100 billion to support OpenAI as it built out AI infrastructure. The announcement appeared to cement a strategic alliance between the world&#x27;s most valuable AI company and its dominant chip supplier.Five months later, that megadeal has effectively stalled, according to multiple reports. Nvidia CEO Jensen Huang has publicly denied tensions, telling reporters in late January that there is \"no drama\" and that Nvidia remains committed to participating in OpenAI&#x27;s current funding round. But the relationship has cooled considerably, with friction stemming from multiple sources.OpenAI has aggressively pursued partnerships with alternative chip suppliers, including the Cerebras deal and separate agreements with AMD and Broadcom. From Nvidia&#x27;s perspective, OpenAI may be using its influence to commoditize the very hardware that made its AI breakthroughs possible. From OpenAI&#x27;s perspective, reducing dependence on a single supplier represents prudent business strategy.\"We will continue working with the ecosystem on evaluating the most price-performant chips across all use cases on an ongoing basis,\" OpenAI&#x27;s spokesperson told VentureBeat. \"GPUs remain our priority for cost-sensitive and throughput-first use cases across research and inference.\" The statement reads as a careful effort to avoid antagonizing Nvidia while preserving flexibility — and reflects a broader reality that training frontier AI models still requires exactly the kind of massive parallel processing that Nvidia GPUs provide.Disbanded safety teams and researcher departures raise questions about OpenAI&#x27;s prioritiesThe Codex-Spark launch comes as OpenAI navigates a series of internal challenges that have intensified scrutiny of the company&#x27;s direction and values. Earlier this week, reports emerged that OpenAI disbanded its mission alignment team, a group established in September 2024 to promote the company&#x27;s stated goal of ensuring artificial general intelligence benefits humanity. The team&#x27;s seven members have been reassigned to other roles, with leader Joshua Achiam given a new title as OpenAI&#x27;s \"chief futurist.\"OpenAI previously disbanded another safety-focused group, the superalignment team, in 2024. That team had concentrated on long-term existential risks from AI. The pattern of dissolving safety-oriented teams has drawn criticism from researchers who argue that OpenAI&#x27;s commercial pressures are overwhelming its original non-profit mission.The company also faces fallout from its decision to introduce advertisements into ChatGPT. Researcher Zoë Hitzig resigned this week over what she described as the \"slippery slope\" of ad-supported AI, warning in a New York Times essay that ChatGPT&#x27;s archive of intimate user conversations creates unprecedented opportunities for manipulation. Anthropic seized on the controversy with a Super Bowl advertising campaign featuring the tagline: \"Ads are coming to AI. But not to Claude.\"Separately, the company agreed to provide ChatGPT to the Pentagon through Genai.mil, a new Department of Defense program that requires OpenAI to permit \"all lawful uses\" without company-imposed restrictions — terms that Anthropic reportedly rejected. And reports emerged that Ryan Beiermeister, OpenAI&#x27;s vice president of product policy who had expressed concerns about a planned explicit content feature, was terminated in January following a discrimination allegation she denies.OpenAI envisions AI coding assistants that juggle quick edits and complex autonomous tasksDespite the surrounding turbulence, OpenAI&#x27;s technical roadmap for Codex suggests ambitious plans. The company envisions a coding assistant that seamlessly blends rapid-fire interactive editing with longer-running autonomous tasks — an AI that handles quick fixes while simultaneously orchestrating multiple agents working on more complex problems in the background.\"Over time, the modes will blend — Codex can keep you in a tight interactive loop while delegating longer-running work to sub-agents in the background, or fanning out tasks to many models in parallel when you want breadth and speed, so you don&#x27;t have to choose a single mode up front,\" the OpenAI spokesperson told VentureBeat.This vision would require not just faster inference but sophisticated task decomposition and coordination across models of varying sizes and capabilities. Codex-Spark establishes the low-latency foundation for the interactive portion of that experience; future releases will need to deliver the autonomous reasoning and multi-agent coordination that would make the full vision possible.For now, Codex-Spark operates under separate rate limits from other OpenAI models, reflecting constrained Cerebras infrastructure capacity during the research preview. \"Because it runs on specialized low-latency hardware, usage is governed by a separate rate limit that may adjust based on demand during the research preview,\" the spokesperson noted. The limits are designed to be \"generous,\" with OpenAI monitoring usage patterns as it determines how to scale.The real test is whether faster responses translate into better softwareThe Codex-Spark announcement arrives amid intense competition for AI-powered developer tools. Anthropic&#x27;s Claude Cowork product triggered a selloff in traditional software stocks last week as investors considered whether AI assistants might displace conventional enterprise applications. Microsoft, Google, and Amazon continue investing heavily in AI coding capabilities integrated with their respective cloud platforms.OpenAI&#x27;s Codex app has demonstrated rapid adoption since launching ten days ago, with more than one million downloads and weekly active users growing 60 percent week-over-week. More than 325,000 developers now actively use Codex across free and paid tiers. But the fundamental question facing OpenAI — and the broader AI industry — is whether speed improvements like those promised by Codex-Spark translate into meaningful productivity gains or merely create more pleasant experiences without changing outcomes.Early evidence from AI coding tools suggests that faster responses encourage more iterative experimentation. Whether that experimentation produces better software remains contested among researchers and practitioners alike. What seems clear is that OpenAI views inference latency as a competitive frontier worth substantial investment, even as that investment takes it beyond its traditional Nvidia partnership into untested territory with alternative chip suppliers.The Cerebras deal is a calculated bet that specialized hardware can unlock use cases that general-purpose GPUs cannot cost-effectively serve. For a company simultaneously battling competitors, managing strained supplier relationships, and weathering internal dissent over its commercial direction, it is also a reminder that in the AI race, standing still is not an option. OpenAI built its reputation by moving fast and breaking conventions. Now it must prove it can move even faster — without breaking itself.",
          "content": "OpenAI on Thursday launched GPT-5.3-Codex-Spark, a stripped-down coding model engineered for near-instantaneous response times, marking the company&#x27;s first significant inference partnership outside its traditional Nvidia-dominated infrastructure. The model runs on hardware from Cerebras Systems, a Sunnyvale-based chipmaker whose wafer-scale processors specialize in low-latency AI workloads.The partnership arrives at a pivotal moment for OpenAI. The company finds itself navigating a frayed relationship with longtime chip supplier Nvidia, mounting criticism over its decision to introduce advertisements into ChatGPT, a newly announced Pentagon contract, and internal organizational upheaval that has seen a safety-focused team disbanded and at least one researcher resign in protest.\"GPUs remain foundational across our training and inference pipelines and deliver the most cost effective tokens for broad usage,\" an OpenAI spokesperson told VentureBeat. \"Cerebras complements that foundation by excelling at workflows that demand extremely low latency, tightening the end-to-end loop so use cases such as real-time coding in Codex feel more responsive as you iterate.\"The careful framing — emphasizing that GPUs \"remain foundational\" while positioning Cerebras as a \"complement\" — underscores the delicate balance OpenAI must strike as it diversifies its chip suppliers without alienating Nvidia, the dominant force in AI accelerators.Speed gains come with capability tradeoffs that OpenAI says developers will acceptCodex-Spark represents OpenAI&#x27;s first model purpose-built for real-time coding collaboration. The company claims the model delivers more than 1000 tokens per second when served on ultra-low latency hardware, though it declined to provide specific latency metrics such as time-to-first-token figures.\"We aren&#x27;t able to share specific latency numbers, however Codex-Spark is optimized to feel near-instant — delivering more than 1000 tokens per second while remaining highly capable for real-world coding tasks,\" the OpenAI spokesperson said.The speed gains come with acknowledged capability tradeoffs. On SWE-Bench Pro and Terminal-Bench 2.0 — two industry benchmarks that evaluate AI systems&#x27; ability to perform complex software engineering tasks autonomously — Codex-Spark underperforms the full GPT-5.3-Codex model. OpenAI positions this as an acceptable exchange: developers get responses fast enough to maintain creative flow, even if the underlying model cannot tackle the most sophisticated multi-step programming challenges.The model launches with a 128,000-token context window and supports text only — no image or multimodal inputs. OpenAI has made it available as a research preview to ChatGPT Pro subscribers through the Codex app, command-line interface, and Visual Studio Code extension. A small group of enterprise partners will receive API access to evaluate integration possibilities.\"We are making Codex-Spark available in the API for a small set of design partners to understand how developers want to integrate Codex-Spark into their products,\" the spokesperson explained. \"We&#x27;ll expand access over the coming weeks as we continue tuning our integration under real workloads.\"Cerebras hardware eliminates bottlenecks that plague traditional GPU clustersThe technical architecture behind Codex-Spark tells a story about inference economics that increasingly matters as AI companies scale consumer-facing products. Cerebras&#x27;s Wafer Scale Engine 3 — a single chip roughly the size of a dinner plate containing 4 trillion transistors — eliminates much of the communication overhead that occurs when AI workloads spread across clusters of smaller processors.For training massive models, that distributed approach remains necessary and Nvidia&#x27;s GPUs excel at it. But for inference — the process of generating responses to user queries — Cerebras argues its architecture can deliver results with dramatically lower latency. Sean Lie, Cerebras&#x27;s CTO and co-founder, framed the partnership as an opportunity to reshape how developers interact with AI systems.\"What excites us most about GPT-5.3-Codex-Spark is partnering with OpenAI and the developer community to discover what fast inference makes possible — new interaction patterns, new use cases, and a fundamentally different model experience,\" Lie said in a statement. \"This preview is just the beginning.\"OpenAI&#x27;s infrastructure team did not limit its optimization work to the Cerebras hardware. The company announced latency improvements across its entire inference stack that benefit all Codex models regardless of underlying hardware, including persistent WebSocket connections and optimizations within the Responses API. The results: 80 percent reduction in overhead per client-server round trip, 30 percent reduction in per-token overhead, and 50 percent reduction in time-to-first-token.A $100 billion Nvidia megadeal has quietly fallen apart behind the scenesThe Cerebras partnership takes on additional significance given the increasingly complicated relationship between OpenAI and Nvidia. Last fall, when OpenAI announced its Stargate infrastructure initiative, Nvidia publicly committed to investing $100 billion to support OpenAI as it built out AI infrastructure. The announcement appeared to cement a strategic alliance between the world&#x27;s most valuable AI company and its dominant chip supplier.Five months later, that megadeal has effectively stalled, according to multiple reports. Nvidia CEO Jensen Huang has publicly denied tensions, telling reporters in late January that there is \"no drama\" and that Nvidia remains committed to participating in OpenAI&#x27;s current funding round. But the relationship has cooled considerably, with friction stemming from multiple sources.OpenAI has aggressively pursued partnerships with alternative chip suppliers, including the Cerebras deal and separate agreements with AMD and Broadcom. From Nvidia&#x27;s perspective, OpenAI may be using its influence to commoditize the very hardware that made its AI breakthroughs possible. From OpenAI&#x27;s perspective, reducing dependence on a single supplier represents prudent business strategy.\"We will continue working with the ecosystem on evaluating the most price-performant chips across all use cases on an ongoing basis,\" OpenAI&#x27;s spokesperson told VentureBeat. \"GPUs remain our priority for cost-sensitive and throughput-first use cases across research and inference.\" The statement reads as a careful effort to avoid antagonizing Nvidia while preserving flexibility — and reflects a broader reality that training frontier AI models still requires exactly the kind of massive parallel processing that Nvidia GPUs provide.Disbanded safety teams and researcher departures raise questions about OpenAI&#x27;s prioritiesThe Codex-Spark launch comes as OpenAI navigates a series of internal challenges that have intensified scrutiny of the company&#x27;s direction and values. Earlier this week, reports emerged that OpenAI disbanded its mission alignment team, a group established in September 2024 to promote the company&#x27;s stated goal of ensuring artificial general intelligence benefits humanity. The team&#x27;s seven members have been reassigned to other roles, with leader Joshua Achiam given a new title as OpenAI&#x27;s \"chief futurist.\"OpenAI previously disbanded another safety-focused group, the superalignment team, in 2024. That team had concentrated on long-term existential risks from AI. The pattern of dissolving safety-oriented teams has drawn criticism from researchers who argue that OpenAI&#x27;s commercial pressures are overwhelming its original non-profit mission.The company also faces fallout from its decision to introduce advertisements into ChatGPT. Researcher Zoë Hitzig resigned this week over what she described as the \"slippery slope\" of ad-supported AI, warning in a New York Times essay that ChatGPT&#x27;s archive of intimate user conversations creates unprecedented opportunities for manipulation. Anthropic seized on the controversy with a Super Bowl advertising campaign featuring the tagline: \"Ads are coming to AI. But not to Claude.\"Separately, the company agreed to provide ChatGPT to the Pentagon through Genai.mil, a new Department of Defense program that requires OpenAI to permit \"all lawful uses\" without company-imposed restrictions — terms that Anthropic reportedly rejected. And reports emerged that Ryan Beiermeister, OpenAI&#x27;s vice president of product policy who had expressed concerns about a planned explicit content feature, was terminated in January following a discrimination allegation she denies.OpenAI envisions AI coding assistants that juggle quick edits and complex autonomous tasksDespite the surrounding turbulence, OpenAI&#x27;s technical roadmap for Codex suggests ambitious plans. The company envisions a coding assistant that seamlessly blends rapid-fire interactive editing with longer-running autonomous tasks — an AI that handles quick fixes while simultaneously orchestrating multiple agents working on more complex problems in the background.\"Over time, the modes will blend — Codex can keep you in a tight interactive loop while delegating longer-running work to sub-agents in the background, or fanning out tasks to many models in parallel when you want breadth and speed, so you don&#x27;t have to choose a single mode up front,\" the OpenAI spokesperson told VentureBeat.This vision would require not just faster inference but sophisticated task decomposition and coordination across models of varying sizes and capabilities. Codex-Spark establishes the low-latency foundation for the interactive portion of that experience; future releases will need to deliver the autonomous reasoning and multi-agent coordination that would make the full vision possible.For now, Codex-Spark operates under separate rate limits from other OpenAI models, reflecting constrained Cerebras infrastructure capacity during the research preview. \"Because it runs on specialized low-latency hardware, usage is governed by a separate rate limit that may adjust based on demand during the research preview,\" the spokesperson noted. The limits are designed to be \"generous,\" with OpenAI monitoring usage patterns as it determines how to scale.The real test is whether faster responses translate into better softwareThe Codex-Spark announcement arrives amid intense competition for AI-powered developer tools. Anthropic&#x27;s Claude Cowork product triggered a selloff in traditional software stocks last week as investors considered whether AI assistants might displace conventional enterprise applications. Microsoft, Google, and Amazon continue investing heavily in AI coding capabilities integrated with their respective cloud platforms.OpenAI&#x27;s Codex app has demonstrated rapid adoption since launching ten days ago, with more than one million downloads and weekly active users growing 60 percent week-over-week. More than 325,000 developers now actively use Codex across free and paid tiers. But the fundamental question facing OpenAI — and the broader AI industry — is whether speed improvements like those promised by Codex-Spark translate into meaningful productivity gains or merely create more pleasant experiences without changing outcomes.Early evidence from AI coding tools suggests that faster responses encourage more iterative experimentation. Whether that experimentation produces better software remains contested among researchers and practitioners alike. What seems clear is that OpenAI views inference latency as a competitive frontier worth substantial investment, even as that investment takes it beyond its traditional Nvidia partnership into untested territory with alternative chip suppliers.The Cerebras deal is a calculated bet that specialized hardware can unlock use cases that general-purpose GPUs cannot cost-effectively serve. For a company simultaneously battling competitors, managing strained supplier relationships, and weathering internal dissent over its commercial direction, it is also a reminder that in the AI race, standing still is not an option. OpenAI built its reputation by moving fast and breaking conventions. Now it must prove it can move even faster — without breaking itself.",
          "feed_position": 4,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/7MjHYzZPCTPOi36CDs5heb/2e9b08153059f61306abd7a467cb2274/nuneybits_Vector_art_of_retro_CRT_monitor_displaying_cascading__4c1978f2-debf-4c64-bcac-269b5f7df6ca.webp?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/infrastructure/google-chrome-ships-webmcp-in-early-preview-turning-every-website-into-a",
          "published_at": "Thu, 12 Feb 2026 16:30:00 GMT",
          "title": "Google Chrome ships WebMCP in early preview, turning every website into a structured tool for AI agents",
          "standfirst": "When an AI agent visits a website, it’s essentially a tourist who doesn’t speak the local language. Whether built on LangChain, Claude Code, or the increasingly popular OpenClaw framework, the agent is reduced to guessing which buttons to press: scraping raw HTML, firing off screenshots to multimodal models, and burning through thousands of tokens just to figure out where a search bar is.That era may be ending. Earlier this week, the Google Chrome team launched WebMCP — Web Model Context Protocol — as an early preview in Chrome 146 Canary. WebMCP, which was developed jointly by engineers at Google and Microsoft and incubated through the W3C&#x27;s Web Machine Learning community group, is a proposed web standard that lets any website expose structured, callable tools directly to AI agents through a new browser API: navigator.modelContext.The implications for enterprise IT are significant. Instead of building and maintaining separate back-end MCP servers in Python or Node.js to connect their web applications to AI platforms, development teams can now wrap their existing client-side JavaScript logic into agent-readable tools — without re-architecting a single page.AI agents are expensive, fragile tourists on the webThe cost and reliability issues with current approaches to web-agent (browser agents) interaction are well understood by anyone who has deployed them at scale. The two dominant methods — visual screen-scraping and DOM parsing — both suffer from fundamental inefficiencies that directly affect enterprise budgets. With screenshot-based approaches, agents pass images into multimodal models (like Claude and Gemini) and hope the model can identify not only what is on the screen, but where buttons, form fields, and interactive elements are located. Each image consumes thousands of tokens and can have a long latency. With DOM-based approaches, agents ingest raw HTML and JavaScript — a foreign language full of various tags, CSS rules, and structural markup that is irrelevant to the task at hand but still consumes context window space and inference cost.In both cases, the agent is translating between what the website was designed for (human eyes) and what the model needs (structured data about available actions). A single product search that a human completes in seconds can require dozens of sequential agent interactions — clicking filters, scrolling pages, parsing results — each one an inference call that adds latency and cost.How WebMCP works: Two APIs, one standardWebMCP proposes two complementary APIs that serve as a bridge between websites and AI agents.The Declarative API handles standard actions that can be defined directly in existing HTML forms. For organizations with well-structured forms already in production, this pathway requires minimal additional work; by adding tool names and descriptions to existing form markup, developers can make those forms callable by agents. If your HTML forms are already clean and well-structured, you are probably already 80% of the way there.The Imperative API handles more complex, dynamic interactions that require JavaScript execution. This is where developers define richer tool schemas — conceptually similar to the tool definitions sent to the OpenAI or Anthropic API endpoints, but running entirely client-side in the browser. Through the registerTool(), a website can expose functions like searchProducts(query, filters) or orderPrints(copies, page_size) with full parameter schemas and natural language descriptions.The key insight is that a single tool call through WebMCP can replace what might have been dozens of browser-use interactions. An e-commerce site that registers a searchProducts tool lets the agent make one structured function call and receive structured JSON results, rather than having the agent click through filter dropdowns, scroll through paginated results, and screenshot each page.The enterprise case: Cost, reliability, and the end of fragile scrapingFor IT decision makers evaluating agentic AI deployments, WebMCP addresses three persistent pain points simultaneously.Cost reduction is the most immediately quantifiable benefit. By replacing sequences of screenshot captures, multimodal inference calls, and iterative DOM parsing with single structured tool calls, organizations can expect significant reductions in token consumption. Reliability improves because agents are no longer guessing about page structure. When a website explicitly publishes a tool contract — \"here are the functions I support, here are their parameters, here is what they return\" — the agent operates with certainty rather than inference. Failed interactions due to UI changes, dynamic content loading, or ambiguous element identification are largely eliminated for any interaction covered by a registered tool.Development velocity accelerates because web teams can leverage their existing front-end JavaScript rather than standing up separate backend infrastructure. The specification emphasizes that any task a user can accomplish through a page&#x27;s UI can be made into a tool by reusing much of the page&#x27;s existing JavaScript code. Teams do not need to learn new server frameworks or maintain separate API surfaces for agent consumers.Human-in-the-loop by design, not an afterthoughtA critical architectural decision separates WebMCP from the fully autonomous agent paradigm that has dominated recent headlines. The standard is explicitly designed around cooperative, human-in-the-loop workflows — not unsupervised automation.According to Khushal Sagar, a staff software engineer for Chrome, the WebMCP specification identifies three pillars that underpin this philosophy. Context: All the data agents need to understand what the user is doing, including content that is often not currently visible on screen. Capabilities: Actions the agent can take on the user&#x27;s behalf, from answering questions to filling out forms. Coordination: Controlling the handoff between user and agent when the agent encounters situations it cannot resolve autonomously.The specification&#x27;s authors at Google and Microsoft illustrate this with a shopping scenario: a user named Maya asks her AI assistant to help find an eco-friendly dress for a wedding. The agent suggests vendors, opens a browser to a dress site, and discovers the page exposes WebMCP tools like getDresses() and showDresses(). When Maya&#x27;s criteria go beyond the site&#x27;s basic filters, the agent calls those tools to fetch product data, uses its own reasoning to filter for \"cocktail-attire appropriate,\" and then calls showDresses()to update the page with only the relevant results. It&#x27;s a fluid loop of human taste and agent capability, exactly the kind of collaborative browsing that WebMCP is designed to enable.This is not a headless browsing standard. The specification explicitly states that headless and fully autonomous scenarios are non-goals. For those use cases, the authors point to existing protocols like Google&#x27;s Agent-to-Agent (A2A) protocol. WebMCP is about the browser — where the user is present, watching, and collaborating.Not a replacement for MCP, but a complementWebMCP is not a replacement for Anthropic&#x27;s Model Context Protocol, despite sharing a conceptual lineage and a portion of its name. It does not follow the JSON-RPC specification that MCP uses for client-server communication. Where MCP operates as a back-end protocol connecting AI platforms to service providers through hosted servers, WebMCP operates entirely client-side within the browser.The relationship is complementary. A travel company might maintain a back-end MCP server for direct API integrations with AI platforms like ChatGPT or Claude, while simultaneously implementing WebMCP tools on its consumer-facing website so that browser-based agents can interact with its booking flow in the context of a user&#x27;s active session. The two standards serve different interaction patterns without conflict.The distinction matters for enterprise architects. Back-end MCP integrations are appropriate for service-to-service automation where no browser UI is needed. WebMCP is appropriate when the user is present and the interaction benefits from shared visual context — which describes the majority of consumer-facing web interactions that enterprises care about.What comes next: From flag to standardWebMCP is currently available in Chrome 146 Canary behind the \"WebMCP for testing\" flag at chrome://flags. Developers can join the Chrome Early Preview Program for access to documentation and demos. Other browsers have not yet announced implementation timelines, though Microsoft&#x27;s active co-authorship of the specification suggests Edge support is likely.Industry observers expect formal browser announcements by mid-to-late 2026, with Google Cloud Next and Google I/O as probable venues for broader rollout announcements. The specification is transitioning from community incubation within the W3C to a formal draft — a process that historically takes months but signals serious institutional commitment.The comparison that Sagar has drawn is instructive: WebMCP aims to become the USB-C of AI agent interactions with the web. A single, standardized interface that any agent can plug into, replacing the current tangle of bespoke scraping strategies and fragile automation scripts.Whether that vision is realized depends on adoption — by both browser vendors and web developers. But with Google and Microsoft jointly shipping code, the W3C providing institutional scaffolding, and Chrome 146 already running the implementation behind a flag, WebMCP has cleared the most difficult hurdle any web standard faces: getting from proposal to working software.",
          "content": "When an AI agent visits a website, it’s essentially a tourist who doesn’t speak the local language. Whether built on LangChain, Claude Code, or the increasingly popular OpenClaw framework, the agent is reduced to guessing which buttons to press: scraping raw HTML, firing off screenshots to multimodal models, and burning through thousands of tokens just to figure out where a search bar is.That era may be ending. Earlier this week, the Google Chrome team launched WebMCP — Web Model Context Protocol — as an early preview in Chrome 146 Canary. WebMCP, which was developed jointly by engineers at Google and Microsoft and incubated through the W3C&#x27;s Web Machine Learning community group, is a proposed web standard that lets any website expose structured, callable tools directly to AI agents through a new browser API: navigator.modelContext.The implications for enterprise IT are significant. Instead of building and maintaining separate back-end MCP servers in Python or Node.js to connect their web applications to AI platforms, development teams can now wrap their existing client-side JavaScript logic into agent-readable tools — without re-architecting a single page.AI agents are expensive, fragile tourists on the webThe cost and reliability issues with current approaches to web-agent (browser agents) interaction are well understood by anyone who has deployed them at scale. The two dominant methods — visual screen-scraping and DOM parsing — both suffer from fundamental inefficiencies that directly affect enterprise budgets. With screenshot-based approaches, agents pass images into multimodal models (like Claude and Gemini) and hope the model can identify not only what is on the screen, but where buttons, form fields, and interactive elements are located. Each image consumes thousands of tokens and can have a long latency. With DOM-based approaches, agents ingest raw HTML and JavaScript — a foreign language full of various tags, CSS rules, and structural markup that is irrelevant to the task at hand but still consumes context window space and inference cost.In both cases, the agent is translating between what the website was designed for (human eyes) and what the model needs (structured data about available actions). A single product search that a human completes in seconds can require dozens of sequential agent interactions — clicking filters, scrolling pages, parsing results — each one an inference call that adds latency and cost.How WebMCP works: Two APIs, one standardWebMCP proposes two complementary APIs that serve as a bridge between websites and AI agents.The Declarative API handles standard actions that can be defined directly in existing HTML forms. For organizations with well-structured forms already in production, this pathway requires minimal additional work; by adding tool names and descriptions to existing form markup, developers can make those forms callable by agents. If your HTML forms are already clean and well-structured, you are probably already 80% of the way there.The Imperative API handles more complex, dynamic interactions that require JavaScript execution. This is where developers define richer tool schemas — conceptually similar to the tool definitions sent to the OpenAI or Anthropic API endpoints, but running entirely client-side in the browser. Through the registerTool(), a website can expose functions like searchProducts(query, filters) or orderPrints(copies, page_size) with full parameter schemas and natural language descriptions.The key insight is that a single tool call through WebMCP can replace what might have been dozens of browser-use interactions. An e-commerce site that registers a searchProducts tool lets the agent make one structured function call and receive structured JSON results, rather than having the agent click through filter dropdowns, scroll through paginated results, and screenshot each page.The enterprise case: Cost, reliability, and the end of fragile scrapingFor IT decision makers evaluating agentic AI deployments, WebMCP addresses three persistent pain points simultaneously.Cost reduction is the most immediately quantifiable benefit. By replacing sequences of screenshot captures, multimodal inference calls, and iterative DOM parsing with single structured tool calls, organizations can expect significant reductions in token consumption. Reliability improves because agents are no longer guessing about page structure. When a website explicitly publishes a tool contract — \"here are the functions I support, here are their parameters, here is what they return\" — the agent operates with certainty rather than inference. Failed interactions due to UI changes, dynamic content loading, or ambiguous element identification are largely eliminated for any interaction covered by a registered tool.Development velocity accelerates because web teams can leverage their existing front-end JavaScript rather than standing up separate backend infrastructure. The specification emphasizes that any task a user can accomplish through a page&#x27;s UI can be made into a tool by reusing much of the page&#x27;s existing JavaScript code. Teams do not need to learn new server frameworks or maintain separate API surfaces for agent consumers.Human-in-the-loop by design, not an afterthoughtA critical architectural decision separates WebMCP from the fully autonomous agent paradigm that has dominated recent headlines. The standard is explicitly designed around cooperative, human-in-the-loop workflows — not unsupervised automation.According to Khushal Sagar, a staff software engineer for Chrome, the WebMCP specification identifies three pillars that underpin this philosophy. Context: All the data agents need to understand what the user is doing, including content that is often not currently visible on screen. Capabilities: Actions the agent can take on the user&#x27;s behalf, from answering questions to filling out forms. Coordination: Controlling the handoff between user and agent when the agent encounters situations it cannot resolve autonomously.The specification&#x27;s authors at Google and Microsoft illustrate this with a shopping scenario: a user named Maya asks her AI assistant to help find an eco-friendly dress for a wedding. The agent suggests vendors, opens a browser to a dress site, and discovers the page exposes WebMCP tools like getDresses() and showDresses(). When Maya&#x27;s criteria go beyond the site&#x27;s basic filters, the agent calls those tools to fetch product data, uses its own reasoning to filter for \"cocktail-attire appropriate,\" and then calls showDresses()to update the page with only the relevant results. It&#x27;s a fluid loop of human taste and agent capability, exactly the kind of collaborative browsing that WebMCP is designed to enable.This is not a headless browsing standard. The specification explicitly states that headless and fully autonomous scenarios are non-goals. For those use cases, the authors point to existing protocols like Google&#x27;s Agent-to-Agent (A2A) protocol. WebMCP is about the browser — where the user is present, watching, and collaborating.Not a replacement for MCP, but a complementWebMCP is not a replacement for Anthropic&#x27;s Model Context Protocol, despite sharing a conceptual lineage and a portion of its name. It does not follow the JSON-RPC specification that MCP uses for client-server communication. Where MCP operates as a back-end protocol connecting AI platforms to service providers through hosted servers, WebMCP operates entirely client-side within the browser.The relationship is complementary. A travel company might maintain a back-end MCP server for direct API integrations with AI platforms like ChatGPT or Claude, while simultaneously implementing WebMCP tools on its consumer-facing website so that browser-based agents can interact with its booking flow in the context of a user&#x27;s active session. The two standards serve different interaction patterns without conflict.The distinction matters for enterprise architects. Back-end MCP integrations are appropriate for service-to-service automation where no browser UI is needed. WebMCP is appropriate when the user is present and the interaction benefits from shared visual context — which describes the majority of consumer-facing web interactions that enterprises care about.What comes next: From flag to standardWebMCP is currently available in Chrome 146 Canary behind the \"WebMCP for testing\" flag at chrome://flags. Developers can join the Chrome Early Preview Program for access to documentation and demos. Other browsers have not yet announced implementation timelines, though Microsoft&#x27;s active co-authorship of the specification suggests Edge support is likely.Industry observers expect formal browser announcements by mid-to-late 2026, with Google Cloud Next and Google I/O as probable venues for broader rollout announcements. The specification is transitioning from community incubation within the W3C to a formal draft — a process that historically takes months but signals serious institutional commitment.The comparison that Sagar has drawn is instructive: WebMCP aims to become the USB-C of AI agent interactions with the web. A single, standardized interface that any agent can plug into, replacing the current tangle of bespoke scraping strategies and fragile automation scripts.Whether that vision is realized depends on adoption — by both browser vendors and web developers. But with Google and Microsoft jointly shipping code, the W3C providing institutional scaffolding, and Chrome 146 already running the implementation behind a flag, WebMCP has cleared the most difficult hurdle any web standard faces: getting from proposal to working software.",
          "feed_position": 5,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/1qICIKh5QjKnFUVNWBfR1s/3e006949fd944a8ef8fb6e3ab0db67b9/webmcp-story.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/get-two-years-of-proton-vpn-for-70-percent-off-right-now-123000652.html",
          "published_at": "Thu, 12 Feb 2026 16:15:00 +0000",
          "title": "Get two years of Proton VPN for 70 percent off right now",
          "standfirst": "Proton VPN is offering a steep discount on its Proton VPN Plus subscription, with the two-year plan currently priced at $2.99 per month. You’ll pay $72 upfront for 24 months of service, which amounts to 70 percent off the usual monthly rate and brings the long-term cost well below what many premium VPNs typically charge.We’ve consistently been impressed by Proton VPN’s focus on privacy, its nonprofit ownership structure and the way it balances security features with strong real-world speeds. It’s a top pick in our best VPN guide, and this promotion also appears in our running list of the best VPN deals. If you’re planning to commit to a VPN for the long haul, this pricing makes Proton VPN Plus one of the more compelling options available right now.In our Proton VPN review, the service impressed us with consistently fast performance and strong privacy protections. We measured average download speeds at 88 percent of our unprotected connection and upload speeds at 98 percent, which is more than enough for 4K streaming, gaming and torrenting. It also unblocked Netflix in every region we tested, and while its Mac and iOS apps aren’t quite as polished as the Windows and Android versions, the service is still easy to install and largely set-it-and-forget-it across platforms. We gave Proton VPN a score of 90 out of 100.Proton VPN Plus is the company’s premium tier and includes access to its full server network, which now spans more than 15,000 servers across 120-plus countries. A single subscription covers up to 10 devices at once and unlocks features like NetShield ad and malware blocking, Secure Core “double hop” connections, split tunneling, custom DNS controls and priority customer support. Proton VPN Plus also supports fast P2P traffic on nearly all paid servers and includes VPN Accelerator, which helps maintain high speeds over long-distance connections.Right now, Proton VPN Plus is discounted to $2.99 per month when you commit to two years, billed as $72 upfront for the first 24 months. After that, the plan renews annually at $83.88. That’s a 70 percent discount compared to the standard monthly rate. As with Proton’s other paid plans, the subscription comes with a 30-day money-back guarantee, so you can try it risk-free if you’re not ready to lock in long term.This article originally appeared on Engadget at https://www.engadget.com/deals/get-two-years-of-proton-vpn-for-70-percent-off-right-now-123000652.html?src=rss",
          "content": "Proton VPN is offering a steep discount on its Proton VPN Plus subscription, with the two-year plan currently priced at $2.99 per month. You’ll pay $72 upfront for 24 months of service, which amounts to 70 percent off the usual monthly rate and brings the long-term cost well below what many premium VPNs typically charge.We’ve consistently been impressed by Proton VPN’s focus on privacy, its nonprofit ownership structure and the way it balances security features with strong real-world speeds. It’s a top pick in our best VPN guide, and this promotion also appears in our running list of the best VPN deals. If you’re planning to commit to a VPN for the long haul, this pricing makes Proton VPN Plus one of the more compelling options available right now.In our Proton VPN review, the service impressed us with consistently fast performance and strong privacy protections. We measured average download speeds at 88 percent of our unprotected connection and upload speeds at 98 percent, which is more than enough for 4K streaming, gaming and torrenting. It also unblocked Netflix in every region we tested, and while its Mac and iOS apps aren’t quite as polished as the Windows and Android versions, the service is still easy to install and largely set-it-and-forget-it across platforms. We gave Proton VPN a score of 90 out of 100.Proton VPN Plus is the company’s premium tier and includes access to its full server network, which now spans more than 15,000 servers across 120-plus countries. A single subscription covers up to 10 devices at once and unlocks features like NetShield ad and malware blocking, Secure Core “double hop” connections, split tunneling, custom DNS controls and priority customer support. Proton VPN Plus also supports fast P2P traffic on nearly all paid servers and includes VPN Accelerator, which helps maintain high speeds over long-distance connections.Right now, Proton VPN Plus is discounted to $2.99 per month when you commit to two years, billed as $72 upfront for the first 24 months. After that, the plan renews annually at $83.88. That’s a 70 percent discount compared to the standard monthly rate. As with Proton’s other paid plans, the subscription comes with a 30-day money-back guarantee, so you can try it risk-free if you’re not ready to lock in long term.This article originally appeared on Engadget at https://www.engadget.com/deals/get-two-years-of-proton-vpn-for-70-percent-off-right-now-123000652.html?src=rss",
          "feed_position": 44
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/infrastructure/ai-inference-costs-dropped-up-to-10x-on-nvidias-blackwell-but-hardware-is",
          "published_at": "Thu, 12 Feb 2026 16:00:00 GMT",
          "title": "AI inference costs dropped up to 10x on Nvidia's Blackwell — but hardware is only half the equation",
          "standfirst": "Lowering the cost of inference is typically a combination of hardware and software. A new analysis released Thursday by Nvidia details how four leading inference providers are reporting 4x to 10x reductions in cost per token.The dramatic cost reductions were achieved using Nvidia&#x27;s Blackwell platform with open-source models. Production deployment data from Baseten, DeepInfra, Fireworks AI and Together AI shows significant cost improvements across healthcare, gaming, agentic chat, and customer service as enterprises scale AI from pilot projects to millions of users.The 4x to 10x cost reductions reported by inference providers required combining Blackwell hardware with two other elements: optimized software stacks and switching from proprietary to open-source models that now match frontier-level intelligence. Hardware improvements alone delivered 2x gains in some deployments, according to the analysis. Reaching larger cost reductions required adopting low-precision formats like NVFP4 and moving away from closed source APIs that charge premium rates.The economics prove counterintuitive. Reducing inference costs requires investing in higher-performance infrastructure because throughput improvements translate directly into lower per-token costs.\"Performance is what drives down the cost of inference,\" Dion Harris, senior director of HPC and AI hyperscaler solutions at Nvidia, told VentureBeat in an exclusive interview. \"What we&#x27;re seeing in inference is that throughput literally translates into real dollar value and driving down the cost.\"Production deployments show 4x to 10x cost reductionsNvidia detailed four customer deployments in a blog post showing how the combination of Blackwell infrastructure, optimized software stacks and open-source models delivers cost reductions across different industry workloads. The case studies span high-volume applications where inference economics directly determines business viability.Sully.ai cut healthcare AI inference costs by 90% (a 10x reduction) while improving response times 65% by switching from proprietary models to open-source models running on Baseten&#x27;s Blackwell-powered platform, according to Nvidia. The company returned over 30 million minutes to physicians by automating medical coding and note-taking tasks that previously required manual data entry.Nvidia also reported that Latitude reduced gaming inference costs 4x for its AI Dungeon platform by running large mixture-of-experts (MoE) models on DeepInfra&#x27;s Blackwell deployment. Cost per million tokens dropped from 20 cents on Nvidia&#x27;s previous Hopper platform to 10 cents on Blackwell, then to 5 cents after adopting Blackwell&#x27;s native NVFP4 low-precision format. Hardware alone delivered 2x improvement, but reaching 4x required the precision format change.Sentient Foundation achieved 25% to 50% better cost efficiency for its agentic chat platform using Fireworks AI&#x27;s Blackwell-optimized inference stack, according to Nvidia. The platform orchestrates complex multi-agent workflows and processed 5.6 million queries in a single week during its viral launch while maintaining low latency.Nvidia said Decagon saw 6x cost reduction per query for AI-powered voice customer support by running its multimodel stack on Together AI&#x27;s Blackwell infrastructure. Response times stayed under 400 milliseconds, even when processing thousands of tokens per query, critical for voice interactions where delays cause users to hang up or lose trust.Technical factors driving 4x versus 10x improvementsThe range from 4x to 10x cost reductions across deployments reflects different combinations of technical optimizations rather than just hardware differences. Three factors emerge as primary drivers: precision format adoption, model architecture choices, and software stack integration.Precision formats show the clearest impact. Latitude&#x27;s case demonstrates this directly. Moving from Hopper to Blackwell delivered 2x cost reduction through hardware improvements. Adopting NVFP4, Blackwell&#x27;s native low-precision format, doubled that improvement to 4x total. NVFP4 reduces the number of bits required to represent model weights and activations, allowing more computation per GPU cycle while maintaining accuracy. The format works particularly well for MoE models where only a subset of the model activates for each inference request.Model architecture matters. MoE models, which activate different specialized sub-models based on input, benefit from Blackwell&#x27;s NVLink fabric that enables rapid communication between experts. \"Having those experts communicate across that NVLink fabric allows you to reason very quickly,\" Harris said. Dense models that activate all parameters for every inference don&#x27;t leverage this architecture as effectively.Software stack integration creates additional performance deltas. Harris said that Nvidia&#x27;s co-design approach — where Blackwell hardware, NVL72 scale-up architecture, and software like Dynamo and TensorRT-LLM are optimized together — also makes a difference. Baseten&#x27;s deployment for Sully.ai used this integrated stack, combining NVFP4, TensorRT-LLM and Dynamo to achieve the 10x cost reduction. Providers running alternative frameworks like vLLM may see lower gains.Workload characteristics matter. Reasoning models show particular advantages on Blackwell because they generate significantly more tokens to reach better answers. The platform&#x27;s ability to process these extended token sequences efficiently through disaggregated serving, where context prefill and token generation are handled separately, makes reasoning workloads cost-effective.Teams evaluating potential cost reductions should examine their workload profiles against these factors. High token generation workloads using mixture-of-experts models with the integrated Blackwell software stack will approach the 10x range. Lower token volumes using dense models on alternative frameworks will land closer to 4x. What teams should test before migratingWhile these case studies focus on Nvidia Blackwell deployments, enterprises have multiple paths to reducing inference costs. AMD&#x27;s MI300 series, Google TPUs, and specialized inference accelerators from Groq and Cerebras offer alternative architectures. Cloud providers also continue optimizing their inference services. The question isn&#x27;t whether Blackwell is the only option but whether the specific combination of hardware, software and models fits particular workload requirements.Enterprises considering Blackwell-based inference should start by calculating whether their workloads justify infrastructure changes. \"Enterprises need to work back from their workloads and use case and cost constraints,\" Shruti Koparkar, AI product marketing at Nvidia, told VentureBeat.The deployments achieving 6x to 10x improvements all involved high-volume, latency-sensitive applications processing millions of requests monthly. Teams running lower volumes or applications with latency budgets exceeding one second should explore software optimization or model switching before considering infrastructure upgrades.Testing matters more than provider specifications. Koparkar emphasizes that providers publish throughput and latency metrics, but these represent ideal conditions. \"If it&#x27;s a highly latency-sensitive workload, they might want to test a couple of providers and see who meets the minimum they need while keeping the cost down,\" she said. Teams should run actual production workloads across multiple Blackwell providers to measure real performance under their specific usage patterns and traffic spikes rather than relying on published benchmarks.The staged approach Latitude used provides a model for evaluation. The company first moved to Blackwell hardware and measured 2x improvement, then adopted NVFP4 format to reach 4x total reduction. Teams currently on Hopper or other infrastructure can test whether precision format changes and software optimization on existing hardware capture meaningful savings before committing to full infrastructure migrations. Running open source models on current infrastructure might deliver half the potential cost reduction without new hardware investments.Provider selection requires understanding software stack differences. While multiple providers offer Blackwell infrastructure, their software implementations vary. Some run Nvidia&#x27;s integrated stack using Dynamo and TensorRT-LLM, while others use frameworks like vLLM. Harris acknowledges performance deltas exist between these configurations. Teams should evaluate what each provider actually runs and how it matches their workload requirements rather than assuming all Blackwell deployments perform identically.The economic equation extends beyond cost per token. Specialized inference providers like Baseten, DeepInfra, Fireworks and Together offer optimized deployments but require managing additional vendor relationships. Managed services from AWS, Azure or Google Cloud may have higher per-token costs but lower operational complexity. Teams should calculate total cost including operational overhead, not just inference pricing, to determine which approach delivers better economics for their specific situation.",
          "content": "Lowering the cost of inference is typically a combination of hardware and software. A new analysis released Thursday by Nvidia details how four leading inference providers are reporting 4x to 10x reductions in cost per token.The dramatic cost reductions were achieved using Nvidia&#x27;s Blackwell platform with open-source models. Production deployment data from Baseten, DeepInfra, Fireworks AI and Together AI shows significant cost improvements across healthcare, gaming, agentic chat, and customer service as enterprises scale AI from pilot projects to millions of users.The 4x to 10x cost reductions reported by inference providers required combining Blackwell hardware with two other elements: optimized software stacks and switching from proprietary to open-source models that now match frontier-level intelligence. Hardware improvements alone delivered 2x gains in some deployments, according to the analysis. Reaching larger cost reductions required adopting low-precision formats like NVFP4 and moving away from closed source APIs that charge premium rates.The economics prove counterintuitive. Reducing inference costs requires investing in higher-performance infrastructure because throughput improvements translate directly into lower per-token costs.\"Performance is what drives down the cost of inference,\" Dion Harris, senior director of HPC and AI hyperscaler solutions at Nvidia, told VentureBeat in an exclusive interview. \"What we&#x27;re seeing in inference is that throughput literally translates into real dollar value and driving down the cost.\"Production deployments show 4x to 10x cost reductionsNvidia detailed four customer deployments in a blog post showing how the combination of Blackwell infrastructure, optimized software stacks and open-source models delivers cost reductions across different industry workloads. The case studies span high-volume applications where inference economics directly determines business viability.Sully.ai cut healthcare AI inference costs by 90% (a 10x reduction) while improving response times 65% by switching from proprietary models to open-source models running on Baseten&#x27;s Blackwell-powered platform, according to Nvidia. The company returned over 30 million minutes to physicians by automating medical coding and note-taking tasks that previously required manual data entry.Nvidia also reported that Latitude reduced gaming inference costs 4x for its AI Dungeon platform by running large mixture-of-experts (MoE) models on DeepInfra&#x27;s Blackwell deployment. Cost per million tokens dropped from 20 cents on Nvidia&#x27;s previous Hopper platform to 10 cents on Blackwell, then to 5 cents after adopting Blackwell&#x27;s native NVFP4 low-precision format. Hardware alone delivered 2x improvement, but reaching 4x required the precision format change.Sentient Foundation achieved 25% to 50% better cost efficiency for its agentic chat platform using Fireworks AI&#x27;s Blackwell-optimized inference stack, according to Nvidia. The platform orchestrates complex multi-agent workflows and processed 5.6 million queries in a single week during its viral launch while maintaining low latency.Nvidia said Decagon saw 6x cost reduction per query for AI-powered voice customer support by running its multimodel stack on Together AI&#x27;s Blackwell infrastructure. Response times stayed under 400 milliseconds, even when processing thousands of tokens per query, critical for voice interactions where delays cause users to hang up or lose trust.Technical factors driving 4x versus 10x improvementsThe range from 4x to 10x cost reductions across deployments reflects different combinations of technical optimizations rather than just hardware differences. Three factors emerge as primary drivers: precision format adoption, model architecture choices, and software stack integration.Precision formats show the clearest impact. Latitude&#x27;s case demonstrates this directly. Moving from Hopper to Blackwell delivered 2x cost reduction through hardware improvements. Adopting NVFP4, Blackwell&#x27;s native low-precision format, doubled that improvement to 4x total. NVFP4 reduces the number of bits required to represent model weights and activations, allowing more computation per GPU cycle while maintaining accuracy. The format works particularly well for MoE models where only a subset of the model activates for each inference request.Model architecture matters. MoE models, which activate different specialized sub-models based on input, benefit from Blackwell&#x27;s NVLink fabric that enables rapid communication between experts. \"Having those experts communicate across that NVLink fabric allows you to reason very quickly,\" Harris said. Dense models that activate all parameters for every inference don&#x27;t leverage this architecture as effectively.Software stack integration creates additional performance deltas. Harris said that Nvidia&#x27;s co-design approach — where Blackwell hardware, NVL72 scale-up architecture, and software like Dynamo and TensorRT-LLM are optimized together — also makes a difference. Baseten&#x27;s deployment for Sully.ai used this integrated stack, combining NVFP4, TensorRT-LLM and Dynamo to achieve the 10x cost reduction. Providers running alternative frameworks like vLLM may see lower gains.Workload characteristics matter. Reasoning models show particular advantages on Blackwell because they generate significantly more tokens to reach better answers. The platform&#x27;s ability to process these extended token sequences efficiently through disaggregated serving, where context prefill and token generation are handled separately, makes reasoning workloads cost-effective.Teams evaluating potential cost reductions should examine their workload profiles against these factors. High token generation workloads using mixture-of-experts models with the integrated Blackwell software stack will approach the 10x range. Lower token volumes using dense models on alternative frameworks will land closer to 4x. What teams should test before migratingWhile these case studies focus on Nvidia Blackwell deployments, enterprises have multiple paths to reducing inference costs. AMD&#x27;s MI300 series, Google TPUs, and specialized inference accelerators from Groq and Cerebras offer alternative architectures. Cloud providers also continue optimizing their inference services. The question isn&#x27;t whether Blackwell is the only option but whether the specific combination of hardware, software and models fits particular workload requirements.Enterprises considering Blackwell-based inference should start by calculating whether their workloads justify infrastructure changes. \"Enterprises need to work back from their workloads and use case and cost constraints,\" Shruti Koparkar, AI product marketing at Nvidia, told VentureBeat.The deployments achieving 6x to 10x improvements all involved high-volume, latency-sensitive applications processing millions of requests monthly. Teams running lower volumes or applications with latency budgets exceeding one second should explore software optimization or model switching before considering infrastructure upgrades.Testing matters more than provider specifications. Koparkar emphasizes that providers publish throughput and latency metrics, but these represent ideal conditions. \"If it&#x27;s a highly latency-sensitive workload, they might want to test a couple of providers and see who meets the minimum they need while keeping the cost down,\" she said. Teams should run actual production workloads across multiple Blackwell providers to measure real performance under their specific usage patterns and traffic spikes rather than relying on published benchmarks.The staged approach Latitude used provides a model for evaluation. The company first moved to Blackwell hardware and measured 2x improvement, then adopted NVFP4 format to reach 4x total reduction. Teams currently on Hopper or other infrastructure can test whether precision format changes and software optimization on existing hardware capture meaningful savings before committing to full infrastructure migrations. Running open source models on current infrastructure might deliver half the potential cost reduction without new hardware investments.Provider selection requires understanding software stack differences. While multiple providers offer Blackwell infrastructure, their software implementations vary. Some run Nvidia&#x27;s integrated stack using Dynamo and TensorRT-LLM, while others use frameworks like vLLM. Harris acknowledges performance deltas exist between these configurations. Teams should evaluate what each provider actually runs and how it matches their workload requirements rather than assuming all Blackwell deployments perform identically.The economic equation extends beyond cost per token. Specialized inference providers like Baseten, DeepInfra, Fireworks and Together offer optimized deployments but require managing additional vendor relationships. Managed services from AWS, Azure or Google Cloud may have higher per-token costs but lower operational complexity. Teams should calculate total cost including operational overhead, not just inference pricing, to determine which approach delivers better economics for their specific situation.",
          "feed_position": 6,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/3Tdn1sg9y8jVdlZmX8vyr4/93adf89349f5fd9043ae7b454886f7c1/cost-of-inference-smk1.jpg?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/audio/headphones/sony-wf-1000xm6-review-facing-tougher-competition-160000652.html",
          "published_at": "Thu, 12 Feb 2026 16:00:00 +0000",
          "title": "Sony WF-1000XM6 review: Facing tougher competition",
          "standfirst": "Sony’s 1000X earbuds have been at the top of Engadget’s best wireless earbuds list since we first published it. With each new generation, the company managed to retain its crown, primarily thanks to a massive collection of features and an effective mix of sound quality and active noise cancellation (ANC) performance. Today, Sony revealed the latest entry in the series, the WF-1000XM6, delivering yet another redesign both inside and out. The company’s tried and true formula of features and audio performance remains, but it may no longer be enough to elevate the M6 above the competition. Design For the third time in a row, Sony overhauled the 1000X earbuds’ design. While the WF-1000XM5 was a clear revision of the WF-1000XM4, the M6 is a departure from both of them. The company managed to reduce overall size even further by using a rounder, pill-shaped enclosure for the earbuds’ main housing. I certainly applaud Sony for making these as tiny as possible, but I’m still not a fan of the company’s foam ear tips. Sony introduced foam ear tips on the 1000XM4 earbuds and that led to an unstable fit during my testing. In fact, I ended up switching to the silicone M3 tips for a better feel. Things were slightly better on the M5, but the company regressed here on the M6. I tried every size of ear tips in the box and the fit test in the Sound Connect app only ever confirmed an air-tight seal in my right ear. This can impact sound quality and ANC performance, and the earbuds don’t feel like they’re sitting far enough inside my ears. I never got used to the fit in my three weeks of testing. The exterior panel of the WF-1000XM6 is still touch sensitive, accepting a variety of taps for playback controls, calls, noise settings and more. Sony also included a repeated tapping gesture that’s used for volume control. Keep tapping on the right earbud to raise the volume and do so on the left to lower it. My disdain for touch controls is well-documented at this point, but the M6 reliably and quickly responded without me having to repeat a tap sequence. WF-1000XM6 features The WF-1000XM6 accepts taps for touch-based controls. As is typically the case with its 1000X earbuds, Sony has loaded the M6 with features. Nearly all of these are holdovers from previous models, including Adaptive Sound Control that can automatically adjust settings based on your activity or location. Speak-to-Chat still pauses audio and activates ambient sound when you start talking, but it’s also still easily duped by coughs or clearing your throat. A quick access feature can put Amazon Music, Apple Music, Endel, Spotify and YouTube Music two or three taps away, depending on how you configure it. The M6 earbuds also allow you to accept and reject calls with head gestures and you’ll have the option to pipe in your own voice during a call. Sony retained its existing option of operating the earbuds with voice commands: If you say “Assistant,” you can then ask it to play, pause, skip and replay songs. It will also adjust the volume for you, but that’s the extent of its abilities. Sony included some handy power management features as well. First, there’s an Auto Power Save mode that will disable any custom EQ settings, DSEE Extreme upscaling, Speak-to-Chat and voice control/voice assistant to reduce power consumption when the M6 hits 20 percent battery remaining. A Battery Care tool will extend the life of the earbuds’ battery by stopping charging before it reaches 100 percent. Lastly, Automatic Power Off will turn the earbuds off when they’re outside of the case and haven’t been worn for some time. Basic conveniences like multipoint Bluetooth, wireless charging and IPX4 water resistance are also here. Wear detection is onboard and you can use Sony’s EQ presets to alter the sound profile, or make your own and save them for future use. The Sound Connect app puts the battery levels of the individual earbuds and the case front and center, and you can edit the main screen to hide the features displayed there if you don’t need them. Sound quality and ANC performance Sound quality is one of Sony's strengths and that continues on the M6. Billy Steele for Engadget If Sony’s long list of features is its top advantage over the competition, overall sound quality is number two. For the WF-1000XM6, the company built new drivers with soft edges for deeper bass and a more rigid, lightweight dome for clearer treble. There are also notches around the edges for “clearer and smoother” sound quality overall, according to Sony. And of course, DSEE Extreme upscaling helps to recover details lost to compression while 360 Reality Audio and Spatial Sound Optimization are available for more immersive listening. I found the M6 earbuds at their best with the stock EQ and DSEE Extreme active, much like I have on previous 1000X models. The sound is deep and warm, with thick bass that’s adequate without ever overpowering the mix. Highs cut through and there’s ample midrange, keeping those finer details from getting lost. Erika de Casier’s atmospheric Lifetime is a great example of what the WF-1000XM6 can do. Vocals seem to float over the top of the bassline and drums, with percussive piano chopping though and subtle synth details popping up throughout. When strings arrive on “Seasons,” the M6 ushers them into a prominent position rather than relegating them behind the beat. On the WF-1000XM6, the chaos of Spiritbox’s “Holy Roller” doesn’t get condensed to a messy heavy metal roar either. And there’s plenty of texture in the synth-driven noise of Nine Inch Nails’ “As Alive As You Need Me To Be.” Even more straightforward rock tracks like Jimmy Eat World’s “Bleed American” have ample punch, with a wide soundstage that never feels claustrophobic or sounds compressed. Overall, the WF-1000XM6 holds its own against the best-sounding earbuds you can buy right now, though some of the competition, like Technics, have an edge in the way they handle the subtlest of nuances in songs. If you were hoping for knock-out ANC abilities, I must report that the WF-1000XM6 isn’t the noise-canceling powerhouse that is Bose’s QC Ultra Earbuds. The M6 struggles mightily with human voices. While that’s the downfall of many ANC earbuds, you’ll want to keep it in mind if you plan to wear these in the office. I found I could also still hear constant noise sources like fans and white noise machines when wearing the M6 — items that the QC Ultra Earbuds combat effectively. Using the WF-1000XM6 for calls The WF-1000XM6 isn't as adept at calls as Sony advertises. Billy Steele for Engadget For calls, Sony says the M6 uses AI for both background noise reduction and voice capture with the beamforming microphones. What’s more, the earbuds are equipped with eight total mics for ANC and calls, plus bone conduction tech for improved voice pickup. Unfortunately, all of that doesn’t lead to stellar performance during calls. While the WF-1000XM6 is perfectly usable for voice and video calls, the overall quality is far from pristine. To make matters worse, the earbuds make you sound overly processed when you encounter significant background noise. Since the company prided itself on the upgrades here, the results are disappointing. Battery life Sony says the WF-1000XM6 will last up to eight hours on a charge or 24 hours when you factor in the full longevity of the charging case. During a battery test that I mostly ran with ANC active, I had no trouble hitting that single-charge figure. That’s with the volume around 75-80 percent and includes calls and virtual meetings where I switched over to ambient sound mode. It’s worth noting that I had DSEE Extreme upscaling active the entire time, which can impact battery life. Plus, if you use the aforementioned Auto Power Save mode, you can extend play time when you have about a quarter of a tank left. Going without some of the M6’s best features in the interest of having tunes for a workout or commute is a fair trade in my book. The competition The WF-1000XM6 is still a compelling option, but it's not the clear favorite anymore. Billy Steele for Engadget When sizing up the competition for the WF-1000XM6, you have to choose your priorities. Simply put, no other company offers the comprehensive suite of features that Sony does. That’s been true for a while now and it continues with this model. If you want the strongest active noise cancellation, that will be Bose’s second-generation QuietComfort Ultra Earbuds. If the best sound quality is your goal, the Technics AZ100 is your best bet in this price range. I’ll also mention Sennheiser’s Momentum True Wireless 4 which offers great sound quality, respectable ANC and a comfier fit than the M6, but that set is almost two years old at this point. Wrap-up Sony continues its run of great earbuds with the WF-1000XM6, but this model isn’t the polished package that some of its predecessors were. The two most obvious places the company is lagging behind the competition is ANC performance and overall voice quality, not to mention my continued dissatisfaction with the fit that Sony’s foam tips provide. The M6 is also more expensive than the previous version was at launch, which makes it even harder to overlook any flaws. What you will get on the WF-1000XM6 is a ton of features, great sound quality and reliable touch controls in a smaller package. And for some, that might be enough to make you forget about the rest. The WF-1000XM6 is available today in silver and black for $330.This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/sony-wf-1000xm6-review-facing-tougher-competition-160000652.html?src=rss",
          "content": "Sony’s 1000X earbuds have been at the top of Engadget’s best wireless earbuds list since we first published it. With each new generation, the company managed to retain its crown, primarily thanks to a massive collection of features and an effective mix of sound quality and active noise cancellation (ANC) performance. Today, Sony revealed the latest entry in the series, the WF-1000XM6, delivering yet another redesign both inside and out. The company’s tried and true formula of features and audio performance remains, but it may no longer be enough to elevate the M6 above the competition. Design For the third time in a row, Sony overhauled the 1000X earbuds’ design. While the WF-1000XM5 was a clear revision of the WF-1000XM4, the M6 is a departure from both of them. The company managed to reduce overall size even further by using a rounder, pill-shaped enclosure for the earbuds’ main housing. I certainly applaud Sony for making these as tiny as possible, but I’m still not a fan of the company’s foam ear tips. Sony introduced foam ear tips on the 1000XM4 earbuds and that led to an unstable fit during my testing. In fact, I ended up switching to the silicone M3 tips for a better feel. Things were slightly better on the M5, but the company regressed here on the M6. I tried every size of ear tips in the box and the fit test in the Sound Connect app only ever confirmed an air-tight seal in my right ear. This can impact sound quality and ANC performance, and the earbuds don’t feel like they’re sitting far enough inside my ears. I never got used to the fit in my three weeks of testing. The exterior panel of the WF-1000XM6 is still touch sensitive, accepting a variety of taps for playback controls, calls, noise settings and more. Sony also included a repeated tapping gesture that’s used for volume control. Keep tapping on the right earbud to raise the volume and do so on the left to lower it. My disdain for touch controls is well-documented at this point, but the M6 reliably and quickly responded without me having to repeat a tap sequence. WF-1000XM6 features The WF-1000XM6 accepts taps for touch-based controls. As is typically the case with its 1000X earbuds, Sony has loaded the M6 with features. Nearly all of these are holdovers from previous models, including Adaptive Sound Control that can automatically adjust settings based on your activity or location. Speak-to-Chat still pauses audio and activates ambient sound when you start talking, but it’s also still easily duped by coughs or clearing your throat. A quick access feature can put Amazon Music, Apple Music, Endel, Spotify and YouTube Music two or three taps away, depending on how you configure it. The M6 earbuds also allow you to accept and reject calls with head gestures and you’ll have the option to pipe in your own voice during a call. Sony retained its existing option of operating the earbuds with voice commands: If you say “Assistant,” you can then ask it to play, pause, skip and replay songs. It will also adjust the volume for you, but that’s the extent of its abilities. Sony included some handy power management features as well. First, there’s an Auto Power Save mode that will disable any custom EQ settings, DSEE Extreme upscaling, Speak-to-Chat and voice control/voice assistant to reduce power consumption when the M6 hits 20 percent battery remaining. A Battery Care tool will extend the life of the earbuds’ battery by stopping charging before it reaches 100 percent. Lastly, Automatic Power Off will turn the earbuds off when they’re outside of the case and haven’t been worn for some time. Basic conveniences like multipoint Bluetooth, wireless charging and IPX4 water resistance are also here. Wear detection is onboard and you can use Sony’s EQ presets to alter the sound profile, or make your own and save them for future use. The Sound Connect app puts the battery levels of the individual earbuds and the case front and center, and you can edit the main screen to hide the features displayed there if you don’t need them. Sound quality and ANC performance Sound quality is one of Sony's strengths and that continues on the M6. Billy Steele for Engadget If Sony’s long list of features is its top advantage over the competition, overall sound quality is number two. For the WF-1000XM6, the company built new drivers with soft edges for deeper bass and a more rigid, lightweight dome for clearer treble. There are also notches around the edges for “clearer and smoother” sound quality overall, according to Sony. And of course, DSEE Extreme upscaling helps to recover details lost to compression while 360 Reality Audio and Spatial Sound Optimization are available for more immersive listening. I found the M6 earbuds at their best with the stock EQ and DSEE Extreme active, much like I have on previous 1000X models. The sound is deep and warm, with thick bass that’s adequate without ever overpowering the mix. Highs cut through and there’s ample midrange, keeping those finer details from getting lost. Erika de Casier’s atmospheric Lifetime is a great example of what the WF-1000XM6 can do. Vocals seem to float over the top of the bassline and drums, with percussive piano chopping though and subtle synth details popping up throughout. When strings arrive on “Seasons,” the M6 ushers them into a prominent position rather than relegating them behind the beat. On the WF-1000XM6, the chaos of Spiritbox’s “Holy Roller” doesn’t get condensed to a messy heavy metal roar either. And there’s plenty of texture in the synth-driven noise of Nine Inch Nails’ “As Alive As You Need Me To Be.” Even more straightforward rock tracks like Jimmy Eat World’s “Bleed American” have ample punch, with a wide soundstage that never feels claustrophobic or sounds compressed. Overall, the WF-1000XM6 holds its own against the best-sounding earbuds you can buy right now, though some of the competition, like Technics, have an edge in the way they handle the subtlest of nuances in songs. If you were hoping for knock-out ANC abilities, I must report that the WF-1000XM6 isn’t the noise-canceling powerhouse that is Bose’s QC Ultra Earbuds. The M6 struggles mightily with human voices. While that’s the downfall of many ANC earbuds, you’ll want to keep it in mind if you plan to wear these in the office. I found I could also still hear constant noise sources like fans and white noise machines when wearing the M6 — items that the QC Ultra Earbuds combat effectively. Using the WF-1000XM6 for calls The WF-1000XM6 isn't as adept at calls as Sony advertises. Billy Steele for Engadget For calls, Sony says the M6 uses AI for both background noise reduction and voice capture with the beamforming microphones. What’s more, the earbuds are equipped with eight total mics for ANC and calls, plus bone conduction tech for improved voice pickup. Unfortunately, all of that doesn’t lead to stellar performance during calls. While the WF-1000XM6 is perfectly usable for voice and video calls, the overall quality is far from pristine. To make matters worse, the earbuds make you sound overly processed when you encounter significant background noise. Since the company prided itself on the upgrades here, the results are disappointing. Battery life Sony says the WF-1000XM6 will last up to eight hours on a charge or 24 hours when you factor in the full longevity of the charging case. During a battery test that I mostly ran with ANC active, I had no trouble hitting that single-charge figure. That’s with the volume around 75-80 percent and includes calls and virtual meetings where I switched over to ambient sound mode. It’s worth noting that I had DSEE Extreme upscaling active the entire time, which can impact battery life. Plus, if you use the aforementioned Auto Power Save mode, you can extend play time when you have about a quarter of a tank left. Going without some of the M6’s best features in the interest of having tunes for a workout or commute is a fair trade in my book. The competition The WF-1000XM6 is still a compelling option, but it's not the clear favorite anymore. Billy Steele for Engadget When sizing up the competition for the WF-1000XM6, you have to choose your priorities. Simply put, no other company offers the comprehensive suite of features that Sony does. That’s been true for a while now and it continues with this model. If you want the strongest active noise cancellation, that will be Bose’s second-generation QuietComfort Ultra Earbuds. If the best sound quality is your goal, the Technics AZ100 is your best bet in this price range. I’ll also mention Sennheiser’s Momentum True Wireless 4 which offers great sound quality, respectable ANC and a comfier fit than the M6, but that set is almost two years old at this point. Wrap-up Sony continues its run of great earbuds with the WF-1000XM6, but this model isn’t the polished package that some of its predecessors were. The two most obvious places the company is lagging behind the competition is ANC performance and overall voice quality, not to mention my continued dissatisfaction with the fit that Sony’s foam tips provide. The M6 is also more expensive than the previous version was at launch, which makes it even harder to overlook any flaws. What you will get on the WF-1000XM6 is a ton of features, great sound quality and reliable touch controls in a smaller package. And for some, that might be enough to make you forget about the rest. The WF-1000XM6 is available today in silver and black for $330.This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/sony-wf-1000xm6-review-facing-tougher-competition-160000652.html?src=rss",
          "feed_position": 45,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/DSC_5869.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/our-favorite-wireless-headphones-are-down-to-a-record-low-price-175038190.html",
          "published_at": "Thu, 12 Feb 2026 14:56:26 +0000",
          "title": "Our favorite wireless headphones are down to a record-low price",
          "standfirst": "Now's a great time to consider upgrading your wireless headphones since you can get our favorites at their best price yet. The Sony WH-1000XM6 headphones are down to $398, which is $62 off and the best discount we've seen since their debut. The sale applies to all three colorways. These easily topped our list of the best wireless headphones. They are, in a word, fantastic. The headphones are packed with premium features, like advanced ANC. There are a whopping 12 ANC microphones throughout and a brand-new chip to power the feature. The end result? It successfully blocks background noise at medium and high frequencies, including the human voice. The sound quality is extremely pleasing to the ears, thanks to new audio drivers and a team of mastering engineers that assisted with tuning. There are perforations in the driver's voice coil, which extends high frequency reproduction. The design has been upgraded from the previous iteration and we found them extremely comfortable to wear for long periods of time, which is important with headphones. The battery gets around 30 hours, which is a fairly standard metric for this type of thing. The only real major nitpick here is the original asking price. It's tough to recommend any pair of headphones for $460, but a bit easier at under $400. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/our-favorite-wireless-headphones-are-down-to-a-record-low-price-175038190.html?src=rss",
          "content": "Now's a great time to consider upgrading your wireless headphones since you can get our favorites at their best price yet. The Sony WH-1000XM6 headphones are down to $398, which is $62 off and the best discount we've seen since their debut. The sale applies to all three colorways. These easily topped our list of the best wireless headphones. They are, in a word, fantastic. The headphones are packed with premium features, like advanced ANC. There are a whopping 12 ANC microphones throughout and a brand-new chip to power the feature. The end result? It successfully blocks background noise at medium and high frequencies, including the human voice. The sound quality is extremely pleasing to the ears, thanks to new audio drivers and a team of mastering engineers that assisted with tuning. There are perforations in the driver's voice coil, which extends high frequency reproduction. The design has been upgraded from the previous iteration and we found them extremely comfortable to wear for long periods of time, which is important with headphones. The battery gets around 30 hours, which is a fairly standard metric for this type of thing. The only real major nitpick here is the original asking price. It's tough to recommend any pair of headphones for $460, but a bit easier at under $400. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/our-favorite-wireless-headphones-are-down-to-a-record-low-price-175038190.html?src=rss",
          "feed_position": 46
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/the-disney-hulu-bundle-is-down-to-only-10-for-one-month-192814350.html",
          "published_at": "Thu, 12 Feb 2026 14:05:37 +0000",
          "title": "The Disney+ Hulu bundle is down to only $10 for one month",
          "standfirst": "You have the best chance to save on streaming services during the holiday shopping season, but throughout the year, the occasional deal pops up that's worth considering. Case in point: this new Disney+ deal. New and eligible returning subscribers can sign up for the Disney+ Hulu bundle (with ads) for $10 for one month of access. That's $3 off the usual price of the bundle for one month, and more than 58 percent off if you consider the cost of each service individually (Disney+ at $12 per month and, separately, Hulu also at $12 per month). We'd be remiss if we didn't mention that this isn't quite as good as the Black Friday deal we saw last year, which offered the same bundle for $5 per month for one year. However, if you missed that offer or just want to try out Disney+ and Hulu for a brief period of time, this is a good way to do so. Disney+ and Hulu make one of the most balanced streaming pairs available, blending family-friendly favorites with acclaimed originals and network TV staples. Disney+ brings a vast library of animated classics, blockbuster franchises and exclusive content from Marvel, Pixar, Star Wars and National Geographic. It’s the place to stream nearly every Star Wars film and series, plus the full Marvel Cinematic Universe lineup and Disney’s most recent theatrical releases. Hulu balances things out with a more adult-oriented lineup of current TV shows, next-day network episodes and a growing roster of award-winning originals. The platform hosts series like The Bear, The Handmaid’s Tale and Only Murders in the Building, alongside comedies, thrillers and documentaries that regularly feature in awards conversations. It’s also the home for next-day streaming of ABC and FX shows, making it especially useful if you’ve already cut the cable cord but still want to keep up with primetime TV. The Duo Basic bundle ties these two services together under a single subscription, offering a simple way to expand your library without juggling multiple accounts. This tier includes ads on both platforms, but the trade-off is significant savings compared with paying for each service separately. For many households, that’s an acceptable compromise when it means access to such a wide range of content. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/the-disney-hulu-bundle-is-down-to-only-10-for-one-month-192814350.html?src=rss",
          "content": "You have the best chance to save on streaming services during the holiday shopping season, but throughout the year, the occasional deal pops up that's worth considering. Case in point: this new Disney+ deal. New and eligible returning subscribers can sign up for the Disney+ Hulu bundle (with ads) for $10 for one month of access. That's $3 off the usual price of the bundle for one month, and more than 58 percent off if you consider the cost of each service individually (Disney+ at $12 per month and, separately, Hulu also at $12 per month). We'd be remiss if we didn't mention that this isn't quite as good as the Black Friday deal we saw last year, which offered the same bundle for $5 per month for one year. However, if you missed that offer or just want to try out Disney+ and Hulu for a brief period of time, this is a good way to do so. Disney+ and Hulu make one of the most balanced streaming pairs available, blending family-friendly favorites with acclaimed originals and network TV staples. Disney+ brings a vast library of animated classics, blockbuster franchises and exclusive content from Marvel, Pixar, Star Wars and National Geographic. It’s the place to stream nearly every Star Wars film and series, plus the full Marvel Cinematic Universe lineup and Disney’s most recent theatrical releases. Hulu balances things out with a more adult-oriented lineup of current TV shows, next-day network episodes and a growing roster of award-winning originals. The platform hosts series like The Bear, The Handmaid’s Tale and Only Murders in the Building, alongside comedies, thrillers and documentaries that regularly feature in awards conversations. It’s also the home for next-day streaming of ABC and FX shows, making it especially useful if you’ve already cut the cable cord but still want to keep up with primetime TV. The Duo Basic bundle ties these two services together under a single subscription, offering a simple way to expand your library without juggling multiple accounts. This tier includes ads on both platforms, but the trade-off is significant savings compared with paying for each service separately. For many households, that’s an acceptable compromise when it means access to such a wide range of content. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/the-disney-hulu-bundle-is-down-to-only-10-for-one-month-192814350.html?src=rss",
          "feed_position": 47
        }
      ],
      "featured_image": "https://images.ctfassets.net/jdtwqhzvc2n1/4xAnIbPYS8dOxnSgfkf6Cs/0829c970cca2705fec3e87c999640d7f/Header.png?w=300&q=30",
      "popularity_score": 2004.7918463888889
    },
    {
      "id": "cluster_26",
      "coverage": 1,
      "updated_at": "Fri, 13 Feb 2026 23:03:08 +0000",
      "title": "Aided by AI, California beach town broadens hunt for bike lane blockers",
      "neutral_headline": "Aided by AI, California beach town broadens hunt for bike lane blockers",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/02/santa-monica-deploys-ai-powered-parking-cameras-to-protect-bike-lanes/",
          "published_at": "Fri, 13 Feb 2026 23:03:08 +0000",
          "title": "Aided by AI, California beach town broadens hunt for bike lane blockers",
          "standfirst": "Hayden AI's cameras will scan for violations from 7 city vehicles.",
          "content": "This spring, a Southern California beach town will become the first city in the country where municipal parking enforcement vehicles will use an AI system looking for potential bike lane violations. Beginning in April, the City of Santa Monica will bring Hayden AI’s scanning technology to seven cars in its parking enforcement fleet, expanding beyond similar cameras already mounted on city buses. “The more we can reduce the amount of illegal parking, the safer we can make it for bike riders,” Charley Territo, chief growth officer at Hayden AI, told Ars.Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/hayden-ai-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/hayden-ai-1152x648.jpg",
      "popularity_score": 345.76073527777777
    },
    {
      "id": "cluster_24",
      "coverage": 1,
      "updated_at": "Fri, 13 Feb 2026 23:16:48 +0000",
      "title": "WHO slams US-funded newborn vaccine trial as \"unethical\"",
      "neutral_headline": "WHO slams US-funded newborn vaccine trial as \"unethical\"",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2026/02/who-slams-us-funded-newborn-vaccine-trial-as-unethical/",
          "published_at": "Fri, 13 Feb 2026 23:16:48 +0000",
          "title": "WHO slams US-funded newborn vaccine trial as \"unethical\"",
          "standfirst": "CDC awarded $1.6 million for study birth dose of hepatitis B vaccine in Guinea-Bissau.",
          "content": "The World Health Organization on Friday released a formal statement blasting a US-funded vaccine trial as \"unethical,\" because it would withhold an established, safe, and potentially lifesaving vaccine against hepatitis B from some newborns in Guinea-Bissau, Africa. \"In its current form, and based on publicly available information, the trial is inconsistent with established ethical and scientific principles,\" the WHO concluded, after providing a bullet-point list of reasons the trial was harmful and low quality. The trial has drawn widespread condemnation from health experts since notice of the US funding was published in the Federal Register in December. The notice revealed that the Centers for Disease Control and Prevention—under anti-vaccine Health Secretary Robert F. Kennedy Jr.—had awarded $1.6 million to Danish researchers for their non-competitive, unsolicited proposal to conduct the trial.Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-629400903-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-629400903-1152x648.jpg",
      "popularity_score": 340.98851305555553
    },
    {
      "id": "cluster_27",
      "coverage": 1,
      "updated_at": "Fri, 13 Feb 2026 22:13:27 +0000",
      "title": "Verizon imposes new roadblock on users trying to unlock paid-off phones",
      "neutral_headline": "Verizon imposes new roadblock on users trying to unlock paid-off phones",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/02/verizon-makes-customers-wait-35-days-to-unlock-fully-paid-off-phones/",
          "published_at": "Fri, 13 Feb 2026 22:13:27 +0000",
          "title": "Verizon imposes new roadblock on users trying to unlock paid-off phones",
          "standfirst": "Verizon unlocks have 35-day waiting period after paying off device plan online.",
          "content": "Verizon this week imposed a new roadblock for people who want to pay off device installment plans early in order to get their phones unlocked. The latest version of Verizon's device unlocking policy for postpaid customers imposes a 35-day waiting period when a customer pays off their device installment plan online or in the Verizon app. Payments made over the phone also trigger a 35-day waiting period, as do payments made at Verizon Authorized Retailers. Getting an immediate unlock apparently requires paying off the device plan at a Verizon corporate store. Unlocking a phone allows it to be used on another network, letting customers switch from one carrier to another. Previously, the 35-day waiting period for unlocks was only applied when a customer paid off the plan with a Verizon gift card.Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/verizon-jerks-locked-phone-1152x648-1765486982.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/verizon-jerks-locked-phone-1152x648-1765486982.jpg",
      "popularity_score": 334.93267972222225
    },
    {
      "id": "cluster_37",
      "coverage": 1,
      "updated_at": "Fri, 13 Feb 2026 20:58:25 +0000",
      "title": "The first Android 17 beta is now available on Pixel devices",
      "neutral_headline": "The first Android 17 beta is now available on Pixel devices",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/02/the-first-android-17-beta-is-now-available-on-pixel-devices/",
          "published_at": "Fri, 13 Feb 2026 20:58:25 +0000",
          "title": "The first Android 17 beta is now available on Pixel devices",
          "standfirst": "Don't expect big changes yet.",
          "content": "You might have noticed some reporting a few days ago that Android 17 was rolling out in beta form, but that didn't happen. For reasons Google still has not explained, the release was canceled. Two days later, Android 17 is here for real. If you've got a recent Pixel device, you can try the latest version today, but don't expect big changes just yet—there's still a long way to go before release. Google will probably have more to say about feature changes for Android 17 in the coming months, but this first wide release is aimed mostly at testing system and API changes. One of the biggest changes in the beta is expanded support for adaptive apps, which ensures that apps can scale to different screen sizes. That makes apps more usable on large-screen devices like tablets and foldables with multiple displays. We first saw this last year in Android 16, but developers were permitted to opt out of support. The new adaptive app roadmap puts an end to that. Any app that targets Android 17 (API level 37) must support resizing and windowed multitasking. Apps can continue to target the older API for the time being, but Google filters apps from the Play Store if they don't keep up.Read full article Comments",
          "feed_position": 4,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/06/Android-IO-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/06/Android-IO-1152x648.jpg",
      "popularity_score": 319.68212416666665
    },
    {
      "id": "cluster_31",
      "coverage": 1,
      "updated_at": "Fri, 13 Feb 2026 21:39:29 +0000",
      "title": "Ring cancels Flock deal after dystopian Super Bowl ad prompts mass outrage",
      "neutral_headline": "Ring cancels Flock deal after dystopian Super Bowl ad prompts mass outrage",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/02/after-creepy-super-bowl-ad-sparks-outrage-ring-abandons-flock-deal/",
          "published_at": "Fri, 13 Feb 2026 21:39:29 +0000",
          "title": "Ring cancels Flock deal after dystopian Super Bowl ad prompts mass outrage",
          "standfirst": "“This is definitely not about dogs,” senator says, urging a pause on Ring face scans.",
          "content": "Amazon and Flock Safety have ended a partnership that would've given law enforcement access to a vast web of Ring cameras. The decision came after Amazon faced substantial backlash for airing a Super Bowl ad that was meant to be warm and fuzzy, but instead came across as disturbing and dystopian. The ad begins with a young girl surprised to receive a puppy as a gift. It then warns that 10 million dogs go missing annually. Showing a series of lost dog posters, the ad introduces a new \"Search Party\" feature for Ring cameras that promises to revolutionize how neighbors come together to locate missing pets.Read full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-1287659332-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-1287659332-1152x648.jpg",
      "popularity_score": 309.3665686111111
    },
    {
      "id": "cluster_60",
      "coverage": 1,
      "updated_at": "Fri, 13 Feb 2026 17:52:35 +0000",
      "title": "$1.8 million MST3K Kickstarter brings in (almost) everyone from the old show",
      "neutral_headline": "$1.8 million MST3K Kickstarter brings in (almost) everyone from the old show",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/culture/2026/02/1-8-million-mst3k-kickstarter-brings-in-almost-everyone-from-the-old-show/",
          "published_at": "Fri, 13 Feb 2026 17:52:35 +0000",
          "title": "$1.8 million MST3K Kickstarter brings in (almost) everyone from the old show",
          "standfirst": "MST3K's 2010s revival looked forward; this one is emphatically looking backward.",
          "content": "Longtime fans of the cult TV show Mystery Science Theater 3000 know that the series’ one constant is change (well, that and bad movies). The show’s cast and crew were in a near-constant state of flux, a byproduct of the show's existence as a perennial bubble show produced in the Twin Cities rather than a TV-and-comedy hub like New York or LA. It was rare, especially toward the middle of its 10-season original run on national TV, for the performers in front of the camera (and the writers’ room, since they were all the same people) to stay the same for more than a season or two. Series creator Joel Hodgson embraced that spirit of change for the show's Kickstarter-funded, Netflix-aired revival in the mid-2010s, featuring a brand-new cast and mostly new writers. And that change only accelerated in the show's brief post-Netflix \"Gizmoplex\" era, which featured a revolving cast of performers that could change from episode to episode. Hodgson leaned into the idea that as long as there were silhouettes and puppets talking in front of a bad movie, it didn't matter much who was doing the talking.Read full article Comments",
          "feed_position": 5,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/mst3k-mike-puppets-1152x648.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/mst3k-mike-puppets-1152x648.jpeg",
      "popularity_score": 291.5849019444444
    },
    {
      "id": "cluster_65",
      "coverage": 1,
      "updated_at": "Fri, 13 Feb 2026 17:29:51 +0000",
      "title": "Tiny, 45 base long RNA can make copies of itself",
      "neutral_headline": "Tiny, 45 base long RNA can make copies of itself",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/02/researchers-find-small-rnas-that-can-make-copies-of-themselves/",
          "published_at": "Fri, 13 Feb 2026 17:29:51 +0000",
          "title": "Tiny, 45 base long RNA can make copies of itself",
          "standfirst": "Self-copying RNAs may have been a key stop along the pathway to life.",
          "content": "There are plenty of unanswered questions about the origin of life on Earth. But the research community has largely reached consensus that one of the key steps was the emergence of an RNA molecule that could replicate itself. RNA, like its more famous relative DNA, can carry genetic information. But it can also fold up into three-dimensional structures that act as catalysts. These two features have led to the suggestion that early life was protein-free, with RNA handling both heredity and catalyzing a simple metabolism. For this to work, one of the reactions that the early RNAs would need to catalyze is the copying of RNA molecules, without which any sort of heritability would be impossible. While we've found a number of catalytic RNAs that can copy other molecules, none have been able to perform a key reaction: making a copy of themselves. Now, however, a team has found an incredibly short piece of RNA—just 45 bases long—that can make a copy of itself. Finding an RNA polymerase We have identified a large number of catalytic RNAs (generically called ribozymes, for RNA-based enzymes), and some of them can catalyze reactions involving other RNAs. A handful of these are ligases, which link together two RNA molecules. In some cases, they need these molecules to be held together by a third RNA molecule that base pairs with both of them. We've only identified a few that can act as polymerases, which add RNA bases to a growing molecule, one at a time, with each new addition base pairing with a template molecule.Read full article Comments",
          "feed_position": 6,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-185759512-e1771001074630-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-185759512-e1771001074630-1152x648.jpg",
      "popularity_score": 272.20601305555556
    },
    {
      "id": "cluster_83",
      "coverage": 1,
      "updated_at": "Fri, 13 Feb 2026 15:32:01 +0000",
      "title": "What if riders don't close a robotaxi door after a ride? Try DoorDash.",
      "neutral_headline": "What if riders don't close a robotaxi door after a ride? Try DoorDash.",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2026/02/what-if-riders-dont-close-a-robotaxi-door-after-a-ride-try-doordash/",
          "published_at": "Fri, 13 Feb 2026 15:32:01 +0000",
          "title": "What if riders don't close a robotaxi door after a ride? Try DoorDash.",
          "standfirst": "Robotaxis can't escape the gig economy as Waymo tries to solve a human problem.",
          "content": "Autonomous vehicles have a lot of potential. As long as you program them right, they won't speed, won't break traffic laws, and won't get drunk, high, abusive, or violent. And the technology has been getting much more capable, even as some of the hype has died down, taking some of the related companies with it. Waymo still easily leads the field and is already operating commercially in six cities across America, with a dozen more (plus London) coming soon. Waymos can even drop you off and pick you up at the airport in Phoenix and San Francisco. Soon, Waymo will begin deploying its sixth-generation Waymo Driver, using upfitted Zeekr Ojai minivans, adding to the Jaguar I-Paces that have become so common on San Francisco streets and to its fleet of Hyundai Ioniq 5 electric vehicles. It has upgraded the cameras, lidar, and radar, meaning the cars can better sense their environments at night and in inclement weather. There are even microphones that can pick up sounds like sirens to better inform the robotaxi of the direction the emergency vehicle(s) are coming from. But even with all these advances since the pod-like two-seater that predates even the Waymo name, there are still a few things that remain beyond a robotaxi's capabilities. Like closing a door a passenger left open on their way out. All the sophisticated sensors and high-powered computer processing in the world are useless if the car can't move until the door closes and there's no one there to give it a hand.Read full article Comments",
          "feed_position": 7,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/unnamed-2-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/unnamed-2-1152x648.jpg",
      "popularity_score": 263.24212416666666
    },
    {
      "id": "cluster_84",
      "coverage": 1,
      "updated_at": "Fri, 13 Feb 2026 15:19:49 +0000",
      "title": "Why is Bezos trolling Musk on X with turtle pics? Because he has a new Moon plan.",
      "neutral_headline": "Why is Bezos trolling Musk on X with turtle pics? Because he has a new Moon plan.",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2026/02/why-is-bezos-trolling-musk-on-x-with-turtle-pics-because-he-has-a-new-moon-plan/",
          "published_at": "Fri, 13 Feb 2026 15:19:49 +0000",
          "title": "Why is Bezos trolling Musk on X with turtle pics? Because he has a new Moon plan.",
          "standfirst": "\"It’s time to go back to the Moon—this time to stay.\"",
          "content": "The founder of Amazon, Jeff Bezos, does not often post on the social media site owned by his rival Elon Musk. But on Monday, Bezos did, sharing a black-and-white image of a turtle emerging from the shadows on X. The photo, which included no text, may have stumped some observers. Yet for anyone familiar with Bezos' privately owned space company, Blue Origin, the message was clear. The company’s coat of arms prominently features two turtles, a reference to one of Aesop’s Fables, \"The Tortoise and the Hare,\" in which the slow and steady tortoise wins the race over a quicker but overconfident hare. Bezos' foray into social media turtle trolling came about 12 hours after Musk made major waves in the space community by announcing that SpaceX was pivoting toward the Moon, rather than Mars, as a near-term destination. It represented a huge shift in Musk's thinking, as the SpaceX founder has long spoken of building a multi-planetary civilization on Mars.Read full article Comments",
          "feed_position": 8,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/turtle-twitter-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/turtle-twitter-1152x648.jpg",
      "popularity_score": 253.03879083333334
    },
    {
      "id": "cluster_89",
      "coverage": 1,
      "updated_at": "Fri, 13 Feb 2026 14:41:21 +0000",
      "title": "I spent two days gigging at RentAHuman and didn't make a single cent",
      "neutral_headline": "I spent two days gigging at RentAHuman and didn't make a single cent",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2026/02/i-spent-two-days-gigging-at-rentahuman-and-didnt-make-a-single-cent/",
          "published_at": "Fri, 13 Feb 2026 14:41:21 +0000",
          "title": "I spent two days gigging at RentAHuman and didn't make a single cent",
          "standfirst": "These bots supposedly need a human body to accomplish great things in meatspace.",
          "content": "I’m not above doing some gig work to make ends meet. In my life, I’ve worked snack food pop-ups in a grocery store, ran the cash register for random merch booths, and even hawked my own plasma at $35 per vial. So, when I saw RentAHuman, a new site where AI agents hire humans to perform physical work in the real world on behalf of the virtual bots, I was eager to see how these AI overlords would compare to my past experiences with the gig economy. Launched in early February, RentAHuman was developed by software engineer Alexander Liteplo and his cofounder, Patricia Tani. The site looks like a bare-bones version of other well-known freelance sites like Fiverr and UpWork.Read full article Comments",
          "feed_position": 9,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/inflatableman-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/inflatableman-1152x648.jpg",
      "popularity_score": 243
    },
    {
      "id": "cluster_117",
      "coverage": 1,
      "updated_at": "Thu, 12 Feb 2026 22:56:02 +0000",
      "title": "OpenAI sidesteps Nvidia with unusually fast coding model on plate-sized chips",
      "neutral_headline": "OpenAI sidesteps Nvidia with unusually fast coding model on plate-sized chips",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2026/02/openai-sidesteps-nvidia-with-unusually-fast-coding-model-on-plate-sized-chips/",
          "published_at": "Thu, 12 Feb 2026 22:56:02 +0000",
          "title": "OpenAI sidesteps Nvidia with unusually fast coding model on plate-sized chips",
          "standfirst": "OpenAI's new GPT‑5.3‑Codex‑Spark is 15 times faster at coding than its predecessor.",
          "content": "On Thursday, OpenAI released its first production AI model to run on non-Nvidia hardware, deploying the new GPT-5.3-Codex-Spark coding model on chips from Cerebras. The model delivers code at more than 1,000 tokens (chunks of data) per second, which is reported to be roughly 15 times faster than its predecessor. To compare, Anthropic's Claude Opus 4.6 in its new premium-priced fast mode reaches about 2.5 times its standard speed of 68.2 tokens per second, although it is a larger and more capable model than Spark. \"Cerebras has been a great engineering partner, and we're excited about adding fast inference as a new platform capability,\" Sachin Katti, head of compute at OpenAI, said in a statement. Codex-Spark is a research preview available to ChatGPT Pro subscribers ($200/month) through the Codex app, command-line interface, and VS Code extension. OpenAI is rolling out API access to select design partners. The model ships with a 128,000-token context window and handles text only at launch.Read full article Comments",
          "feed_position": 13,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-2225076517_resize-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-2225076517_resize-1152x648.jpg",
      "popularity_score": 148
    },
    {
      "id": "cluster_126",
      "coverage": 1,
      "updated_at": "Thu, 12 Feb 2026 20:30:38 +0000",
      "title": "Trump FTC wants Apple News to promote more Fox News and Breitbart stories",
      "neutral_headline": "Trump FTC wants Apple News to promote more Fox News and Breitbart stories",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/02/trump-ftc-denies-being-speech-police-but-says-apple-news-is-too-liberal/",
          "published_at": "Thu, 12 Feb 2026 20:30:38 +0000",
          "title": "Trump FTC wants Apple News to promote more Fox News and Breitbart stories",
          "standfirst": "FTC claims Apple News suppresses conservatives, cites study by pro-Trump group.",
          "content": "Federal Trade Commission Chairman Andrew Ferguson has accused Apple of violating US law by suppressing conservative-leaning news outlets on Apple News. Ferguson pointed to research by a pro-Trump group that accused Apple News of suppressing articles by Fox News, the New York Post, Daily Mail, Breitbart, and The Gateway Pundit. The FTC chair claims that Apple News might be violating promises made to consumers in its terms of service, but his letter doesn't cite any specific provisions from the Apple terms that might have been violated. \"Recently, there have been reports that Apple News has systematically promoted news articles from left-wing news outlets and suppressed news articles from more conservative publications,\" Ferguson wrote in the letter to Apple CEO Tim Cook yesterday. He said the \"reports raise serious questions about whether Apple News is acting in accordance with its terms of service and its representations to consumers, as well as the reasonable consumer expectations of the tens of millions of Americans who use Apple News.\"Read full article Comments",
          "feed_position": 18,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/apple-news-app-1152x648-1770927170.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/apple-news-app-1152x648-1770927170.jpg",
      "popularity_score": 145
    },
    {
      "id": "cluster_96",
      "coverage": 1,
      "updated_at": "Fri, 13 Feb 2026 12:00:09 +0000",
      "title": "Rocket Report: Say cheerio to Orbex; China is getting good at booster landings",
      "neutral_headline": "Rocket Report: Say cheerio to Orbex; China is getting good at booster landings",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2026/02/rocket-report-say-cheerio-to-orbex-china-is-getting-good-at-booster-landings/",
          "published_at": "Fri, 13 Feb 2026 12:00:09 +0000",
          "title": "Rocket Report: Say cheerio to Orbex; China is getting good at booster landings",
          "standfirst": "\"You absolutely have to have a plan to compete with SpaceX on price.\"",
          "content": "Welcome to Edition 8.29 of the Rocket Report! We have a stuffed report this week with news from across the launch spectrum. Long-term, probably the most significant development this week was a subscale version of the Long March 10 rocket successfully launching and then executing a picture-perfect ocean landing. China is catching up rapidly to the United States when it comes to reusable launch. As always, we welcome reader submissions, and if you don't want to miss an issue, please subscribe using the box below (the form will not appear on AMP-enabled versions of the site). Each report will include information on small-, medium-, and heavy-lift rockets as well as a quick look ahead at the next three launches on the calendar. Orbex is going away. The UK-based launch company Orbex has entered insolvency proceedings after a planned takeover by European space logistics startup The Exploration Company fell through, European Spaceflight reports. In a statement, Orbex said the decision came after all \"fundraising, merger and acquisition opportunities had all concluded unsuccessfully.\" For anyone paying attention, this decision should not come as a surprise. A decade into its existence, Orbex had yet to produce demonstrable, ready-for-flight hardware.Read full article Comments",
          "feed_position": 10,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/ariane-64-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/ariane-64-1152x648.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_97",
      "coverage": 1,
      "updated_at": "Fri, 13 Feb 2026 12:00:07 +0000",
      "title": "Platforms bend over backward to help DHS censor ICE critics, advocates say",
      "neutral_headline": "Platforms bend over backward to help DHS censor ICE critics, advocates say",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/02/platforms-bend-over-backward-to-help-dhs-censor-ice-critics-advocates-say/",
          "published_at": "Fri, 13 Feb 2026 12:00:07 +0000",
          "title": "Platforms bend over backward to help DHS censor ICE critics, advocates say",
          "standfirst": "Pam Bondi and Kristi Noem sued for coercing platforms into censoring ICE posts.",
          "content": "Pressure is mounting on tech companies to shield users from unlawful government requests that advocates say are making it harder to reliably share information about Immigration and Customs Enforcement (ICE) online. Alleging that ICE officers are being doxed or otherwise endangered, Trump officials have spent the last year targeting an unknown number of users and platforms with demands to censor content. Early lawsuits show that platforms have caved, even though experts say they could refuse these demands without a court order. In a lawsuit filed on Wednesday, the Foundation for Individual Rights and Expression (FIRE) accused Attorney General Pam Bondi and Department of Homeland Security Secretary Kristi Noem of coercing tech companies into removing a wide range of content \"to control what the public can see, hear, or say about ICE operations.\"Read full article Comments",
          "feed_position": 11,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/meta-google-apple-ICE-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/meta-google-apple-ICE-1152x648.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_113",
      "coverage": 1,
      "updated_at": "Fri, 13 Feb 2026 00:34:29 +0000",
      "title": "When Amazon badly needed a ride, Europe's Ariane 6 rocket delivered",
      "neutral_headline": "When Amazon badly needed a ride, Europe's Ariane 6 rocket delivered",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2026/02/when-amazon-badly-needed-a-ride-europes-ariane-6-rocket-delivered/",
          "published_at": "Fri, 13 Feb 2026 00:34:29 +0000",
          "title": "When Amazon badly needed a ride, Europe's Ariane 6 rocket delivered",
          "standfirst": "This was the first launch of the Ariane 64, the most powerful rocket in European space history.",
          "content": "The heavy version of Europe's Ariane 6 rocket launched for the first time Thursday, hauling 32 spacecraft to low-Earth orbit for Amazon's satellite broadband constellation. The Ariane 6 rocket lifted off from the Guiana Space Center on the northeastern coast of South America at 11:45 am EST (16:45 UTC), quickly soaring into a clear sky at the tropical spaceport on the power of a hydrogen-fueled main engine and four strap-on solid rocket boosters. This Ariane 6 configuration, called Ariane 64, is the first to use the rocket's full complement of four boosters. Collectively, the rocket generated more than 3.4 million pounds of thrust (15,400 kilonewtons) of thrust as it steered northeast over the Atlantic Ocean. Less than two hours later, the rocket's upper stage released all 32 of Amazon's satellites into an on-target orbit at an altitude of 289 miles (465 kilometers).Read full article Comments",
          "feed_position": 12,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/HA-evg8WgAAY3tl-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/HA-evg8WgAAY3tl-1152x648.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_121",
      "coverage": 1,
      "updated_at": "Thu, 12 Feb 2026 22:36:33 +0000",
      "title": "Trump official overruled FDA scientists to reject Moderna's flu shot",
      "neutral_headline": "Trump official overruled FDA scientists to reject Moderna's flu shot",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2026/02/trump-official-overruled-fda-scientists-to-reject-modernas-flu-shot/",
          "published_at": "Thu, 12 Feb 2026 22:36:33 +0000",
          "title": "Trump official overruled FDA scientists to reject Moderna's flu shot",
          "standfirst": "FDA's top vaccine regulator, Vinay Prasad, is known for overruling scientists.",
          "content": "Vinay Prasad, the Trump administration's top vaccine regulator at the Food and Drug Administration, single-handedly decided to refuse to review Moderna's mRNA flu vaccine, overruling agency scientists, according to reports from Stat News and The Wall Street Journal. Stat was first to report, based on unnamed FDA sources, that a team of career scientists at the agency was ready to review the vaccine and that David Kaslow, a top career official who reviews vaccines, even wrote a memo objecting to Prasad’s rejection. The memo reportedly included a detailed explanation of why the review should proceed. The Wall Street Journal confirmed the report with its own sources, who added that FDA scientists attended an hourlong meeting with Prasad in early January, in which they laid out their objections to Prasad's plans to block the vaccine review. They reportedly told Prasad—a political appointee known for causing turmoil and espousing anti-vaccine rhetoric—that it was the wrong approach.Read full article Comments",
          "feed_position": 14,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/05/GettyImages-628879332-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/05/GettyImages-628879332-1152x648.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_122",
      "coverage": 1,
      "updated_at": "Thu, 12 Feb 2026 22:14:53 +0000",
      "title": "Spider-Noir teaser comes in colorized \"True Hue\" and black and white",
      "neutral_headline": "Spider-Noir teaser comes in colorized \"True Hue\" and black and white",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/culture/2026/02/spider-noir-teaser-comes-in-colorized-true-hue-and-black-and-white/",
          "published_at": "Thu, 12 Feb 2026 22:14:53 +0000",
          "title": "Spider-Noir teaser comes in colorized \"True Hue\" and black and white",
          "standfirst": "Nicolas Cage described his character as \"70 percent Humphrey Bogart and 30 percent Bugs Bunny.\"",
          "content": "Nicolas Cage has carved out a quirky niche for himself in recent years with such films as Color Out of Space (2019), Pig (2021), The Unbearable Weight of Massive Talent (2022), Dream Scenario (2023), and Longlegs (2024), among others. Now he's starring in Spider-Noir, a new live-action series based on the Marvel Comics character. Cage plays an aging private investigator and disillusioned superhero in 1930s New York. Prime Video released the first teaser in two forms: one in black and white—very Raymond Chandler-esque—and another in color, which the showrunners are calling \"True Hue.\" Marvel Comics created its \"noir\" line in 2009, reinterpreting familiar Marvel characters in an alternate universe, usually set during the Great Depression in the US. A version of the Spider-Noir character, voiced by Cage, briefly appeared in the animated masterpieces, Spider-Man: Into the Spider-Verse (2018) and Across the Spider-Verse (2023). (He is set to reprise that role in the upcoming Beyond the Spider-Verse.) Co-showrunner (with Steve Lightfoot) Oren Uziel is a film noir fan, so that Marvel series naturally appealed to him. The live-action series is still set in 1930s New York, but the spidery superhero is not Peter Parker. (Uziel thought the Parker character was too associated with a boyish high school type, which didn't really fit the noir vibe.) So Cage is playing Ben Reilly, a hard-boiled PI with a secret superhero identity, The Spider. Cage has described his portrayal as \"70 percent Humphrey Bogart [specifically The Big Sleep] and 30 percent Bugs Bunny,\" which seems pretty on point for Cage's distinctively flamboyant style.Read full article Comments",
          "feed_position": 15,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/noirTOP-1152x648-1770930363.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/noirTOP-1152x648-1770930363.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_124",
      "coverage": 1,
      "updated_at": "Thu, 12 Feb 2026 21:33:13 +0000",
      "title": "ULA's Vulcan rocket suffers another booster problem on the way to orbit",
      "neutral_headline": "ULA's Vulcan rocket suffers another booster problem on the way to orbit",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2026/02/ulas-vulcan-launcher-still-has-a-solid-rocket-booster-problem/",
          "published_at": "Thu, 12 Feb 2026 21:33:13 +0000",
          "title": "ULA's Vulcan rocket suffers another booster problem on the way to orbit",
          "standfirst": "Vulcan's Blue Origin-made BE-4 engines appear to have saved the rocket from failure.",
          "content": "Moments after liftoff from Florida's Space Coast early Thursday morning, a shower of sparks emerged in the exhaust plume of United Launch Alliance's Vulcan rocket. Seconds later, the rocket twisted on its axis before recovering and continuing the climb into orbit with a batch of US military satellites. The sight may have appeared familiar to seasoned rocket watchers. Sixteen months ago, a Vulcan rocket lost one of its booster nozzles shortly after launch from Cape Canaveral Space Force Station. The rocket recovered from the malfunction and still reached the mission's planned orbit. Details of Thursday's booster problem remain unclear. An investigation into the matter is underway, according to ULA, a 50-50 joint venture between Boeing and Lockheed Martin. But the circumstances resemble those of the booster malfunction in October 2024. Closeup video from Thursday's launch shows a fiery plume near the throat of one of the rocket's four solid-fueled boosters, the area where the motor's propellant casing connects to its bell-shaped exhaust nozzle. The throat drives super-hot gas from the burning solid propellant through the nozzle to generate thrust.Read full article Comments",
          "feed_position": 16,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/v004plume-1152x648-1770930283.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/v004plume-1152x648-1770930283.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_127",
      "coverage": 1,
      "updated_at": "Thu, 12 Feb 2026 20:03:58 +0000",
      "title": "DIY PC maker Framework has needed monthly price hikes to navigate the RAM shortage",
      "neutral_headline": "DIY PC maker Framework has needed monthly price hikes to navigate the RAM shortage",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/02/frameworks-ram-prices-climbing-on-a-monthly-cadence-with-more-hikes-to-come/",
          "published_at": "Thu, 12 Feb 2026 20:03:58 +0000",
          "title": "DIY PC maker Framework has needed monthly price hikes to navigate the RAM shortage",
          "standfirst": "And Framework expects things to get worse before they get better.",
          "content": "AI-driven memory and storage price hikes have been the defining feature of the PC industry in 2026, and hobbyists have been hit the hardest—companies like Apple with lots of buying power have been able to limit the price increases for their PCs, phones, and other gadgets so far, but smaller outfits like Valve and Raspberry Pi haven't been so lucky. Framework, the company behind repairable and upgradeable computer designs like the Laptop 13, Laptop 16, and Laptop 12, is also taking a hard hit by price increases. The company stopped selling standalone RAM sticks in November 2025 and has increased prices on one or more of its systems every month since then; this week's increases are hitting the Framework Desktop and the DIY Editions of its various laptops particularly hard. The price increases are affecting both standalone SODIMM memory modules and the soldered-down LPDDR5X memory used in the Framework Desktop. Patel says that standalone RAM sticks are being priced \"as close as we can to the weighted average cost of our purchases from suppliers.\" In September, buying an 8GB stick of RAM with a Framework Laptop 13 cost $40; it currently costs $130. A 96GB DDR5 kit of two 48GB sticks costs $1,340, up from $480 in September.Read full article Comments",
          "feed_position": 19,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/IMG_2928-1152x648.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/IMG_2928-1152x648.jpeg",
      "popularity_score": 133
    },
    {
      "id": "cluster_125",
      "coverage": 1,
      "updated_at": "Thu, 12 Feb 2026 21:04:22 +0000",
      "title": "EPA kills foundation of greenhouse gas regulations",
      "neutral_headline": "EPA kills foundation of greenhouse gas regulations",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/02/as-expected-trumps-epa-guts-climate-endangerment-finding/",
          "published_at": "Thu, 12 Feb 2026 21:04:22 +0000",
          "title": "EPA kills foundation of greenhouse gas regulations",
          "standfirst": "The agency is betting the the Supreme Court will reverse a prior ruling.",
          "content": "In a widely expected move, the Environmental Protection Agency has announced that it is revoking an analysis of greenhouse gases that laid the foundation for regulating their emissions by cars, power plants, and industrial sources. The analysis, called an endangerment finding, was initially ordered by the US Supreme Court in 2007 and completed during the Obama administration; it has, in theory, served as the basis of all government regulations of carbon dioxide emissions since. In practice, lawsuits and policy changes between Democratic and Republican administrations have meant it has had little impact. In fact, the first Trump administration left the endangerment finding in place, deciding it was easier to respond to it with weak regulations than it was to challenge its scientific foundations, given the strength of the evidence for human-driven climate change. Legal tactics The second Trump administration, however, was prepared to tackle the science head-on, gathering a group of contrarians to write a report questioning that evidence. It did not go well, either scientifically or legally.Read full article Comments",
          "feed_position": 17,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2020/03/sad-epa-smog.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2020/03/sad-epa-smog.jpg",
      "popularity_score": 130
    }
  ]
}