{
  "updated_at": "2026-02-26T07:46:24.853Z",
  "clusters": [
    {
      "id": "cluster_22",
      "coverage": 4,
      "updated_at": "Thu, 26 Feb 2026 02:11:00 GMT",
      "title": "How to preorder the Samsung Galaxy S26 Ultra (and other models) - plus the best deals",
      "neutral_headline": "Samsung Galaxy S26 Ultra vs. S26 Plus vs. S26: I compared the key differences",
      "bullet_summary": [
        "We found where you can preorder the new devices and see all the deals available",
        "Samsung just announced the latest lineup of Galaxy S26 phones, and right now at Verizon, you can get the Galaxy S26 Plus for free with select Unlimited plans"
      ],
      "items": [
        {
          "source": "ZDNet",
          "url": "https://www.zdnet.com/article/how-to-preorder-the-samsung-galaxy-s26-series-and-the-new-galaxy-buds-4-pro/",
          "published_at": "Thu, 26 Feb 2026 02:11:00 GMT",
          "title": "How to preorder the Samsung Galaxy S26 Ultra (and other models) - plus the best deals",
          "standfirst": "Samsung has unveiled the new Galaxy S26 series and the Galaxy Buds 4. We found where you can preorder the new devices and see all the deals available.",
          "content": "Samsung has unveiled the new Galaxy S26 series and the Galaxy Buds 4. We found where you can preorder the new devices and see all the deals available.",
          "feed_position": 4
        },
        {
          "source": "ZDNet",
          "url": "https://www.zdnet.com/article/samsung-galaxy-s26-ultra-att-preorder-deal/",
          "published_at": "Thu, 26 Feb 2026 02:10:00 GMT",
          "title": "The best AT&T deal for the Samsung Galaxy S26 Ultra I found can save you up to $1,300",
          "standfirst": "Samsung's new Galaxy S26 lineup just dropped, and AT&T wants you to upgrade your phone for 'free.' Here's the catch.",
          "content": "Samsung's new Galaxy S26 lineup just dropped, and AT&T wants you to upgrade your phone for 'free.' Here's the catch.",
          "feed_position": 5
        },
        {
          "source": "ZDNet",
          "url": "https://www.zdnet.com/article/verizon-samsung-galaxy-s26-plus-preorder-deal/",
          "published_at": "Thu, 26 Feb 2026 02:09:00 GMT",
          "title": "Get the new Samsung Galaxy S26 Plus for free at Verizon right now - here's to qualify",
          "standfirst": "Samsung just announced the latest lineup of Galaxy S26 phones, and right now at Verizon, you can get the Galaxy S26 Plus for free with select Unlimited plans.",
          "content": "Samsung just announced the latest lineup of Galaxy S26 phones, and right now at Verizon, you can get the Galaxy S26 Plus for free with select Unlimited plans.",
          "feed_position": 6
        },
        {
          "source": "ZDNet",
          "url": "https://www.zdnet.com/article/t-mobile-samsung-galaxy-s26-ultra-preorder-deal/",
          "published_at": "Thu, 26 Feb 2026 02:08:00 GMT",
          "title": "T-Mobile's latest free Samsung Galaxy S26 Ultra deal is tempting - no trade-in required",
          "standfirst": "Right now at T-Mobile, you can get the Galaxy S26 Ultra for free with any new Experience Beyond plan or line.",
          "content": "Right now at T-Mobile, you can get the Galaxy S26 Ultra for free with any new Experience Beyond plan or line.",
          "feed_position": 7
        },
        {
          "source": "ZDNet",
          "url": "https://www.zdnet.com/article/samsung-unpacked-02-25-2026-live-blog/",
          "published_at": "Thu, 26 Feb 2026 02:00:38 GMT",
          "title": "Every announced at Samsung Unpacked 2026: Galaxy S26 Ultra, Privacy Display, preorder deals",
          "standfirst": "From the Galaxy S26 to new earbuds and AI deals, here's everything unveiled at Samsung Unpacked today.",
          "content": "From the Galaxy S26 to new earbuds and AI deals, here's everything unveiled at Samsung Unpacked today.",
          "feed_position": 8
        },
        {
          "source": "ZDNet",
          "url": "https://www.zdnet.com/article/samsung-galaxy-s26-ultra-vs-iphone-17-pro-max/",
          "published_at": "Thu, 26 Feb 2026 01:55:00 GMT",
          "title": "Samsung Galaxy S26 Ultra vs. iPhone 17 Pro Max: Which premium flagship should you buy?",
          "standfirst": "Samsung's latest flagship offers some impressive features, but how does it compare to the most powerful iPhone?",
          "content": "Samsung's latest flagship offers some impressive features, but how does it compare to the most powerful iPhone?",
          "feed_position": 9
        },
        {
          "source": "ZDNet",
          "url": "https://www.zdnet.com/article/samsung-galaxy-s26-ultra-vs-google-pixel-10-pro-xl/",
          "published_at": "Thu, 26 Feb 2026 01:50:00 GMT",
          "title": "Samsung Galaxy S26 Ultra vs. Google Pixel 10 Pro XL: How to choose the right Android flagship",
          "standfirst": "Between Samsung and Google's best phones to start 2026, here's which one you should buy.",
          "content": "Between Samsung and Google's best phones to start 2026, here's which one you should buy.",
          "feed_position": 10
        },
        {
          "source": "ZDNet",
          "url": "https://www.zdnet.com/article/samsung-galaxy-s26-ultra-vs-galaxy-s24-ultra/",
          "published_at": "Thu, 26 Feb 2026 01:38:00 GMT",
          "title": "Samsung Galaxy S26 Ultra vs. S24 Ultra: How to decide if the 2-year upgrade is worth it",
          "standfirst": "Wondering how the Samsung Galaxy S24 Ultra from 2024 holds up to the latest Ultra flagship? The differences aren't as big as you might think.",
          "content": "Wondering how the Samsung Galaxy S24 Ultra from 2024 holds up to the latest Ultra flagship? The differences aren't as big as you might think.",
          "feed_position": 11
        },
        {
          "source": "ZDNet",
          "url": "https://www.zdnet.com/article/samsung-galaxy-s26-ultra-hands-on-unpacked-2026/",
          "published_at": "Thu, 26 Feb 2026 01:18:00 GMT",
          "title": "Samsung Galaxy S26 Ultra hands-on: I need the Privacy Display feature on my iPhone ASAP",
          "standfirst": "Samsung's flagship phone of 2026 offers modest upgrades across its design, cameras, and performance, but one display feature sets it apart from the competition.",
          "content": "Samsung's flagship phone of 2026 offers modest upgrades across its design, cameras, and performance, but one display feature sets it apart from the competition.",
          "feed_position": 12
        },
        {
          "source": "ZDNet",
          "url": "https://www.zdnet.com/article/samsung-galaxy-s26-phones-compared-unpacked-2026/",
          "published_at": "Thu, 26 Feb 2026 01:16:00 GMT",
          "title": "Samsung Galaxy S26 Ultra vs. S26 Plus vs. S26: I compared the key differences",
          "standfirst": "Samsung's new lineup of Galaxy phones includes the S26, S26 Plus, and S26 Ultra. Here are the key differences to consider as you decide which one to buy.",
          "content": "Samsung's new lineup of Galaxy phones includes the S26, S26 Plus, and S26 Ultra. Here are the key differences to consider as you decide which one to buy.",
          "feed_position": 13
        },
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/02/samsung-reveals-galaxy-s26-lineup-with-privacy-display-and-exclusive-gemini-smarts/",
          "published_at": "Wed, 25 Feb 2026 21:41:27 +0000",
          "title": "The Galaxy S26 is faster, more expensive, and even more chock-full of AI",
          "standfirst": "Samsung's Galaxy S26 series is available for preorder today and ships on March 11.",
          "content": "There used to be countless companies making flagship Android phones, but a combination of factors has narrowed the field over time. Today, Samsung is the undisputed king of the Android device ecosystem with its Galaxy S line. So we can safely assume today's Unpacked has revealed the most popular Android phones for the next year—the Galaxy S26 Ultra, Galaxy S26+, and Galaxy S26. Samsung didn't swing for the fences this time around, producing phones with a few cosmetic tweaks and upgraded internals. Meanwhile, Samsung is investing even more in AI, saying the S26 series includes the first \"Agentic AI phones.\" Despite limited hardware upgrades, the realities of component prices in the age of AI mean the prices of the two cheaper models have gone up by $100 this year. The Ultra remains at an already eye-watering $1,300. Faster and more private Looking at the Galaxy S26 family, you'd be hard-pressed to tell them apart from last year's phones. The camera surround is different, and the measurements of the smallest and largest phone are ever so slightly different. You probably won't be able to tell just by looking, but the S26 Ultra has regressed from titanium to aluminum, a reversion Apple also made with its latest high-end phones. This phone also retains its S Pen stylus.Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/Samsung-Mobile-Galaxy-Unpacked-2026-Galaxy-S26-Series-A-First-Look_dl2-1152x648.jpg"
        },
        {
          "source": "ZDNet",
          "url": "https://www.zdnet.com/article/samsung-galaxy-s26-ultra-vs-samsung-galaxy-s25-ultra/",
          "published_at": "Wed, 25 Feb 2026 21:28:00 GMT",
          "title": "Samsung Galaxy S26 Ultra vs. S25 Ultra: I compared both models, here's who should upgrade",
          "standfirst": "On paper, Samsung's latest flagship phone is very similar to the previous generation, except for a few important features.",
          "content": "On paper, Samsung's latest flagship phone is very similar to the previous generation, except for a few important features.",
          "feed_position": 17
        },
        {
          "source": "ZDNet",
          "url": "https://www.zdnet.com/article/samsung-galaxy-s26-amazon-deal/",
          "published_at": "Wed, 25 Feb 2026 21:17:00 GMT",
          "title": "Amazon will give you a free $200 gift card with its Galaxy S26 preorder deal - plus $400 off",
          "standfirst": "Preorder the new Samsung Galaxy S26, S26 Plus, or S26 Ultra from Amazon at a discount, and get a free gift card. We break down the details.",
          "content": "Preorder the new Samsung Galaxy S26, S26 Plus, or S26 Ultra from Amazon at a discount, and get a free gift card. We break down the details.",
          "feed_position": 18
        },
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/gadgets/884281/samsung-galaxy-s26-plus-ultra-vs-s25-specs-features",
          "published_at": "2026-02-25T15:09:14-05:00",
          "title": "Here’s how the new Samsung Galaxy S26 compares with last year’s S25",
          "standfirst": "Samsung unveiled its Galaxy S26 lineup at its recent Unpacked event in San Francisco. As expected, the new series consists of the baseline S26, which starts at $899.99, and the bigger S26 Plus, which starts at $1,099.99. At the high end, there's also the $1,299.99 S26 Ultra, which is the largest in the lineup and [&#8230;]",
          "content": "Samsung unveiled its Galaxy S26 lineup at its recent Unpacked event in San Francisco. As expected, the new series consists of the baseline S26, which starts at $899.99, and the bigger S26 Plus, which starts at $1,099.99. At the high end, there's also the $1,299.99 S26 Ultra, which is the largest in the lineup and comes with a bigger battery, better cameras, S Pen support, and expanded options for both storage and RAM. The price difference between Samsung's cheapest and most expensive S26 phones is $400 (last year, it was $500). While some of its updated Galaxy AI software features are new, it's another year of minor hardware updates for Sam … Read the full story at The Verge.",
          "feed_position": 5
        },
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/gadgets/883829/samsung-galaxy-s26-plus-ultra-how-to-buy-preorder-price-release-date",
          "published_at": "2026-02-25T14:09:29-05:00",
          "title": "Preorders for Samsung’s S26 phones come with up to $200 in gift cards",
          "standfirst": "As expected, Samsung has taken the wraps off its flagship lineup for 2026. Introduced during the company's recent Unpacked event, the new Galaxy devices - which include the standard S26, the larger S26 Plus, and the high-end S26 Ultra - will be available on March 11th. Preorders are now open ahead of launch, with pricing [&#8230;]",
          "content": "As expected, Samsung has taken the wraps off its flagship lineup for 2026. Introduced during the company's recent Unpacked event, the new Galaxy devices - which include the standard S26, the larger S26 Plus, and the high-end S26 Ultra - will be available on March 11th. Preorders are now open ahead of launch, with pricing starting at $899.99 for the base-model S26, $1,099.99 for the Plus, and $1,299.99 for the Ultra. Overall, the forthcoming S26 lineup looks largely similar to last year's S25 series, only with a handful of notable upgrades. The biggest changes this year are on the software side, with Samsung introducing a privacy display in … Read the full story at The Verge.",
          "feed_position": 7
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/samsung-galaxy-s26-series-galaxy-unpacked/",
          "published_at": "Wed, 25 Feb 2026 18:00:00 +0000",
          "title": "Samsung Galaxy S26, S26+, and S26 Ultra: Specs, Features, Price, Release Date",
          "standfirst": "Samsung’s new phones all get AI enhancements, and the flagship Galaxy S26 Ultra has a Privacy Display that can block the screen from nosy neighbors.",
          "content": "Samsung’s new phones all get AI enhancements, and the flagship Galaxy S26 Ultra has a Privacy Display that can block the screen from nosy neighbors.",
          "feed_position": 7,
          "image_url": "https://media.wired.com/photos/699e769a2630537d81be26ee/master/pass/Samsung%20Galaxy%20S26%20Series%20SOURCE%20Julian%20Chokkattu%20(1).jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/Samsung-Mobile-Galaxy-Unpacked-2026-Galaxy-S26-Series-A-First-Look_dl2-1152x648.jpg",
      "popularity_score": 4014.4097630555557
    },
    {
      "id": "cluster_0",
      "coverage": 2,
      "updated_at": "Thu, 26 Feb 2026 21:30:00 GMT",
      "title": "8 billion tokens a day forced AT&T to rethink AI orchestration — and cut costs by 90%",
      "neutral_headline": "Canadian government demands safety changes from OpenAI",
      "bullet_summary": [
        "“I believe the future of agentic AI is many, many, many small language models (SLMs),” he said",
        "“As the workflow is executed, it&#x27;s AT&T’s data that&#x27;s really driving the decisions,” Markus said",
        "“Things do happen autonomously, but the human on the loop still provides a check and balance of the entire process,” Markus said",
        "“Because in this space, things change every week, if we&#x27;re lucky, sometimes multiple times a week,” he said"
      ],
      "items": [
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/8-billion-tokens-a-day-forced-at-and-t-to-rethink-ai-orchestration-and-cut",
          "published_at": "Thu, 26 Feb 2026 21:30:00 GMT",
          "title": "8 billion tokens a day forced AT&T to rethink AI orchestration — and cut costs by 90%",
          "standfirst": "When your average daily token usage is 8 billion a day, you have a massive scale problem. This was the case at AT&T, and chief data officer Andy Markus and his team recognized that it simply wasn’t feasible (or economical) to push everything through large reasoning models. So, when building out an internal Ask AT&T personal assistant, they reconstructed the orchestration layer. The result: A multi-agent stack built on LangChain where large language model “super agents” direct smaller, underlying “worker” agents performing more concise, purpose-driven work. This flexible orchestration layer has dramatically improved latency, speed and response times, Markus told VentureBeat. Most notably, his team has seen up to 90% cost savings. “I believe the future of agentic AI is many, many, many small language models (SLMs),” he said. “We find small language models to be just about as accurate, if not as accurate, as a large language model on a given domain area.”Most recently, Markus and his team used this re-architected stack along with Microsoft Azure to build and deploy Ask AT&T Workflows, a graphical drag-and-drop agent builder for employees to automate tasks. The agents pull from a suite of proprietary AT&T tools that handle document processing, natural language-to-SQL conversion, and image analysis. “As the workflow is executed, it&#x27;s AT&T’s data that&#x27;s really driving the decisions,” Markus said. Rather than asking general questions, “we&#x27;re asking questions of our data, and we bring our data to bear to make sure it focuses on our information as it makes decisions.” Still, a human always oversees the “chain reaction” of agents. All agent actions are logged, data is isolated throughout the process, and role-based access is enforced when agents pass workloads off to one another. “Things do happen autonomously, but the human on the loop still provides a check and balance of the entire process,” Markus said.Not overbuilding, using ‘interchangeable and selectable’ modelsAT&T doesn’t take a \"build everything from scratch\" mindset, Markus noted; it’s more relying on models that are “interchangeable and selectable” and “never rebuilding a commodity.” As functionality matures across the industry, they’ll deprecate homegrown tools in lieu of off the shelf options, he explained. “Because in this space, things change every week, if we&#x27;re lucky, sometimes multiple times a week,” he said. “We need to be able to pilot, plug in and plug out different components.” They do “really rigorous” evaluations of available options as well as their own; for instance, their Ask Data with Relational Knowledge Graph has topped the Spider 2.0 text to SQL accuracy leaderboard, and other tools have scored highly on the BERT SQL benchmark. In the case of homegrown agentic tools, his team uses LangChain as a core framework, fine-tunes models with standard retrieval-augmented generation (RAG) and other in-house algorithms, and partners closely with Microsoft, using the tech giant’s search functionality for their vector store. Ultimately, though, it’s important not to just fuse agentic AI or other advanced tools into everything for the sake of it, Markus advised. “Sometimes we over complicate things,” he said. “Sometimes I&#x27;ve seen a solution over engineered.” Instead, builders should ask themselves whether a given tool actually needs to be agentic. This could include questions like: What accuracy level could be achieved if it was a simpler, single-turn generative solution? How could they break it down into smaller pieces where each piece could be delivered “way more accurately”?, as Markus put it. Accuracy, cost and tool responsiveness should be core principles. “Even as the solutions have gotten more complicated, those three pretty basic principles still give us a lot of direction,” he said. How 100,000 employees are actually using itAsk AT&T Workflows has been rolled out to 100,000-plus employees. More than half say they use it every day, and active adopters report productivity gains as high as 90%, Markus said. “We&#x27;re looking at, are they using the system repeatedly? Because stickiness is a good indicator of success,” he said. The agent builder offers “two journeys” for employees. One is pro-code, where users can program Python behind the scenes, dictating rules for how agents should work. The other is no-code, featuring a drag-and-drop visual interface for a “pretty light user experience,” Markus said. Interestingly, even proficient users are gravitating toward the latter option. At a recent hackathon geared to a technical audience, participants were given a choice of both, and more than half chose low code. “This was a surprise to us, because these people were all very competent in the programming aspect,” Markus said. Employees are using agents across a variety of functions; for instance, a network engineer may build a series of them to address alerts and reconnect customers when they lose connectivity. In this scenario, one agent can correlate telemetry to identify the network issue and its location, pull change logs and check for known issues. Then, it can open a trouble ticket. Another agent could then come up with ways to solve the issue and even write new code to patch it. Once the problem is resolved, a third agent can then write up a summary with preventative measures for the future. “The [human] engineer would watch over all of it, making sure the agents are performing as expected and taking the right actions,” Markus said. AI-fueled coding is the futureThat same engineering discipline — breaking work into smaller, purpose-built pieces — is now reshaping how AT&T writes code itself, through what Markus calls \"AI-fueled coding.\" He compared the process to RAG; devs use agile coding methods in an integrated development environment (IDE) along with “function-specific” build archetypes that dictates how code should interact. The output is not loose code; the code is “very close to production grade,” and could reach that quality in one turn. “We&#x27;ve all worked with vibe coding, where we have an agentic kind of code editor,” Markus noted. But AI-fueled coding “eliminates a lot of the back and forth iterations that you might see in vibe coding.” He sees this coding technique as “tangibly redefining” the software development cycle, ultimately shortening development timelines and increasing output of production-grade code. Non-technical teams can also get in on the action, using plain language prompts to build software prototypes. His team, for instance, has used the technique to build an internal curated data product in 20 minutes; without AI, building it would have taken six weeks. “We develop software with it, modify software with it, do data science with it, do data analytics with it, do data engineering with it,” Markus said. “So it&#x27;s a game changer.”",
          "content": "When your average daily token usage is 8 billion a day, you have a massive scale problem. This was the case at AT&T, and chief data officer Andy Markus and his team recognized that it simply wasn’t feasible (or economical) to push everything through large reasoning models. So, when building out an internal Ask AT&T personal assistant, they reconstructed the orchestration layer. The result: A multi-agent stack built on LangChain where large language model “super agents” direct smaller, underlying “worker” agents performing more concise, purpose-driven work. This flexible orchestration layer has dramatically improved latency, speed and response times, Markus told VentureBeat. Most notably, his team has seen up to 90% cost savings. “I believe the future of agentic AI is many, many, many small language models (SLMs),” he said. “We find small language models to be just about as accurate, if not as accurate, as a large language model on a given domain area.”Most recently, Markus and his team used this re-architected stack along with Microsoft Azure to build and deploy Ask AT&T Workflows, a graphical drag-and-drop agent builder for employees to automate tasks. The agents pull from a suite of proprietary AT&T tools that handle document processing, natural language-to-SQL conversion, and image analysis. “As the workflow is executed, it&#x27;s AT&T’s data that&#x27;s really driving the decisions,” Markus said. Rather than asking general questions, “we&#x27;re asking questions of our data, and we bring our data to bear to make sure it focuses on our information as it makes decisions.” Still, a human always oversees the “chain reaction” of agents. All agent actions are logged, data is isolated throughout the process, and role-based access is enforced when agents pass workloads off to one another. “Things do happen autonomously, but the human on the loop still provides a check and balance of the entire process,” Markus said.Not overbuilding, using ‘interchangeable and selectable’ modelsAT&T doesn’t take a \"build everything from scratch\" mindset, Markus noted; it’s more relying on models that are “interchangeable and selectable” and “never rebuilding a commodity.” As functionality matures across the industry, they’ll deprecate homegrown tools in lieu of off the shelf options, he explained. “Because in this space, things change every week, if we&#x27;re lucky, sometimes multiple times a week,” he said. “We need to be able to pilot, plug in and plug out different components.” They do “really rigorous” evaluations of available options as well as their own; for instance, their Ask Data with Relational Knowledge Graph has topped the Spider 2.0 text to SQL accuracy leaderboard, and other tools have scored highly on the BERT SQL benchmark. In the case of homegrown agentic tools, his team uses LangChain as a core framework, fine-tunes models with standard retrieval-augmented generation (RAG) and other in-house algorithms, and partners closely with Microsoft, using the tech giant’s search functionality for their vector store. Ultimately, though, it’s important not to just fuse agentic AI or other advanced tools into everything for the sake of it, Markus advised. “Sometimes we over complicate things,” he said. “Sometimes I&#x27;ve seen a solution over engineered.” Instead, builders should ask themselves whether a given tool actually needs to be agentic. This could include questions like: What accuracy level could be achieved if it was a simpler, single-turn generative solution? How could they break it down into smaller pieces where each piece could be delivered “way more accurately”?, as Markus put it. Accuracy, cost and tool responsiveness should be core principles. “Even as the solutions have gotten more complicated, those three pretty basic principles still give us a lot of direction,” he said. How 100,000 employees are actually using itAsk AT&T Workflows has been rolled out to 100,000-plus employees. More than half say they use it every day, and active adopters report productivity gains as high as 90%, Markus said. “We&#x27;re looking at, are they using the system repeatedly? Because stickiness is a good indicator of success,” he said. The agent builder offers “two journeys” for employees. One is pro-code, where users can program Python behind the scenes, dictating rules for how agents should work. The other is no-code, featuring a drag-and-drop visual interface for a “pretty light user experience,” Markus said. Interestingly, even proficient users are gravitating toward the latter option. At a recent hackathon geared to a technical audience, participants were given a choice of both, and more than half chose low code. “This was a surprise to us, because these people were all very competent in the programming aspect,” Markus said. Employees are using agents across a variety of functions; for instance, a network engineer may build a series of them to address alerts and reconnect customers when they lose connectivity. In this scenario, one agent can correlate telemetry to identify the network issue and its location, pull change logs and check for known issues. Then, it can open a trouble ticket. Another agent could then come up with ways to solve the issue and even write new code to patch it. Once the problem is resolved, a third agent can then write up a summary with preventative measures for the future. “The [human] engineer would watch over all of it, making sure the agents are performing as expected and taking the right actions,” Markus said. AI-fueled coding is the futureThat same engineering discipline — breaking work into smaller, purpose-built pieces — is now reshaping how AT&T writes code itself, through what Markus calls \"AI-fueled coding.\" He compared the process to RAG; devs use agile coding methods in an integrated development environment (IDE) along with “function-specific” build archetypes that dictates how code should interact. The output is not loose code; the code is “very close to production grade,” and could reach that quality in one turn. “We&#x27;ve all worked with vibe coding, where we have an agentic kind of code editor,” Markus noted. But AI-fueled coding “eliminates a lot of the back and forth iterations that you might see in vibe coding.” He sees this coding technique as “tangibly redefining” the software development cycle, ultimately shortening development timelines and increasing output of production-grade code. Non-technical teams can also get in on the action, using plain language prompts to build software prototypes. His team, for instance, has used the technique to build an internal curated data product in 20 minutes; without AI, building it would have taken six weeks. “We develop software with it, modify software with it, do data science with it, do data analytics with it, do data engineering with it,” Markus said. “So it&#x27;s a game changer.”",
          "feed_position": 0,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/udBw424PYrASf0rQIqIll/713046aa22da63e2eed56e0d21d385fd/AT_T-SLMs.png?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/technology/alibabas-new-open-source-qwen3-5-medium-models-offer-sonnet-4-5-performance",
          "published_at": "Thu, 26 Feb 2026 03:39:00 GMT",
          "title": "Alibaba's new open source Qwen3.5-Medium models offer Sonnet 4.5 performance on local computers",
          "standfirst": "Alibaba&#x27;s now famed Qwen AI development team has done it again: a little more than a day ago, they released the Qwen3.5 Medium Model series consisting of four new large language models (LLMs) with support for agentic tool calling, three of which are available for commercial usage by enterprises and indie developers under the standard open source Apache 2.0 license:Qwen3.5-35B-A3B Qwen3.5-122B-A10B Qwen3.5-27BDevelopers can download them now on Hugging Face and ModelScope. A fourth model, Qwen3.5-Flash, appears to be proprietary and only available through the Alibaba Cloud Model Studio API, but still offers a strong advantage in cost compared to other models in the West (see pricing comparison table below). But the big twist with the open source models is that they offer comparably high performance on third-party benchmark tests to similarly-sized proprietary models from major U.S. startups like OpenAI or Anthropic, actually beating OpenAI&#x27;s GPT-5-mini and Anthropic&#x27;s Claude Sonnet 4.5 — the latter model which was just released five months ago. And, the Qwen team says it has engineered these models to remain highly accurate even when \"quantized,\" a process that reduces their footprint further by reducing the numbers by which the model&#x27;s settings are stored from many values to far fewer. Crucially, this release brings \"frontier-level\" context windows to the desktop PC. The flagship Qwen3.5-35B-A3B can now exceed a 1 million token context length on consumer-grade GPUs with 32GB of VRAM. While not something everyone has access to, this is far less compute than many other comparably-performant options. This leap is made possible by near-lossless accuracy under 4-bit weight and KV cache quantization, allowing developers to process massive datasets without server-grade infrastructure.Technology: Delta forceAt the heart of Qwen 3.5&#x27;s performance is a sophisticated hybrid architecture. While many models rely solely on standard Transformer blocks, Qwen 3.5 integrates Gated Delta Networks combined with a sparse Mixture-of-Experts (MoE) system.The technical specifications for the Qwen3.5-35B-A3B reveal a highly efficient design:Parameter Efficiency: While the model houses 35 billion parameters in total, it only activates 3 billion for any given token.Expert Diversity: The MoE layer utilizes 256 experts, with 8 routed experts and 1 shared expert helping to maintain performance while slashing inference latency.Near-Lossless Quantization: The series maintains high accuracy even when compressed to 4-bit weights, significantly reducing the memory footprint for local deployment.Base Model Release: In a move to support the research community, Alibaba has open-sourced the Qwen3.5-35B-A3B-Base model alongside the instruct-tuned versions.Product: Intelligence that &#x27;thinks&#x27; firstQwen 3.5 introduces a native \"Thinking Mode\" as its default state. Before providing a final answer, the model generates an internal reasoning chain—delimited by <think> tags—to work through complex logic.The product lineup is tailored for varying hardware environments:Qwen3.5-27B: Optimized for high efficiency, supporting a context length of over 800K tokens.Qwen3.5-Flash: The production-grade hosted version, featuring a default 1 million token context length and built-in official tools.Qwen3.5-122B-A10B: Designed for server-grade GPUs (80GB VRAM), this model supports 1M+ context lengths while narrowing the gap with the world&#x27;s largest frontier models.Benchmark results validate this architectural shift. The 35B-A3B model notably surpasses much larger predecessors, such as Qwen3-235B, as well as the aforementioned proprietary GPT-5 mini and Sonnet 4.5 in categories including knowledge (MMMLU) and visual reasoning (MMMU-Pro).Pricing and API integrationFor those not hosting their own weights, Alibaba Cloud Model Studio provides a competitive API for Qwen3.5-Flash.Input: $0.1 per 1M tokensOutput: $0.4 per 1M tokensCache Creation: $0.125 per 1M tokensCache Read: $0.01 per 1M tokensThe API also features a granular Tool Calling pricing model, with Web Search at $10 per 1,000 calls and Code Interpreter currently offered for a limited time at no cost.This makes Qwen3.5-Flash among the most affordable to run over API among all the major LLMs in the world. See a table comparing them below:ModelInputOutputTotal CostSourceQwen 3 Turbo$0.05$0.20$0.25Alibaba CloudQwen3.5-Flash$0.10$0.40$0.50Alibaba Clouddeepseek-chat (V3.2-Exp)$0.28$0.42$0.70DeepSeekdeepseek-reasoner (V3.2-Exp)$0.28$0.42$0.70DeepSeekGrok 4.1 Fast (reasoning)$0.20$0.50$0.70xAIGrok 4.1 Fast (non-reasoning)$0.20$0.50$0.70xAIMiniMax M2.5$0.15$1.20$1.35MiniMaxMiniMax M2.5-Lightning$0.30$2.40$2.70MiniMaxGemini 3 Flash Preview$0.50$3.00$3.50GoogleKimi-k2.5$0.60$3.00$3.60MoonshotGLM-5$1.00$3.20$4.20Z.aiERNIE 5.0$0.85$3.40$4.25BaiduClaude Haiku 4.5$1.00$5.00$6.00AnthropicQwen3-Max (2026-01-23)$1.20$6.00$7.20Alibaba CloudGemini 3 Pro (≤200K)$2.00$12.00$14.00GoogleGPT-5.2$1.75$14.00$15.75OpenAIClaude Sonnet 4.5$3.00$15.00$18.00AnthropicGemini 3 Pro (>200K)$4.00$18.00$22.00GoogleClaude Opus 4.6$5.00$25.00$30.00AnthropicGPT-5.2 Pro$21.00$168.00$189.00OpenAIWhat it means for enterprise technical leaders and decision-makersWith the launch of the Qwen3.5 Medium Models, the rapid iteration and fine-tuning once reserved for well-funded labs is now accessible for on-premise development at many non-technical firms, effectively decoupling sophisticated AI from massive capital expenditure.Across the organization, this architecture transforms how data is handled and secured. The ability to ingest massive document repositories or hour-scale videos locally allows for deep institutional analysis without the privacy risks of third-party APIs. By running these specialized \"Mixture-of-Experts\" models within a private firewall, organizations can maintain sovereign control over their data while utilizing native \"thinking\" modes and official tool-calling capabilities to build more reliable, autonomous agents. Early adopters on Hugging Face have specifically lauded the model’s ability to \"narrow the gap\" in agentic scenarios where previously only the largest closed models could compete.This shift toward architectural efficiency over raw scale ensures that AI integration remains cost-conscious, secure, and agile enough to keep pace with evolving operational needs.",
          "content": "Alibaba&#x27;s now famed Qwen AI development team has done it again: a little more than a day ago, they released the Qwen3.5 Medium Model series consisting of four new large language models (LLMs) with support for agentic tool calling, three of which are available for commercial usage by enterprises and indie developers under the standard open source Apache 2.0 license:Qwen3.5-35B-A3B Qwen3.5-122B-A10B Qwen3.5-27BDevelopers can download them now on Hugging Face and ModelScope. A fourth model, Qwen3.5-Flash, appears to be proprietary and only available through the Alibaba Cloud Model Studio API, but still offers a strong advantage in cost compared to other models in the West (see pricing comparison table below). But the big twist with the open source models is that they offer comparably high performance on third-party benchmark tests to similarly-sized proprietary models from major U.S. startups like OpenAI or Anthropic, actually beating OpenAI&#x27;s GPT-5-mini and Anthropic&#x27;s Claude Sonnet 4.5 — the latter model which was just released five months ago. And, the Qwen team says it has engineered these models to remain highly accurate even when \"quantized,\" a process that reduces their footprint further by reducing the numbers by which the model&#x27;s settings are stored from many values to far fewer. Crucially, this release brings \"frontier-level\" context windows to the desktop PC. The flagship Qwen3.5-35B-A3B can now exceed a 1 million token context length on consumer-grade GPUs with 32GB of VRAM. While not something everyone has access to, this is far less compute than many other comparably-performant options. This leap is made possible by near-lossless accuracy under 4-bit weight and KV cache quantization, allowing developers to process massive datasets without server-grade infrastructure.Technology: Delta forceAt the heart of Qwen 3.5&#x27;s performance is a sophisticated hybrid architecture. While many models rely solely on standard Transformer blocks, Qwen 3.5 integrates Gated Delta Networks combined with a sparse Mixture-of-Experts (MoE) system.The technical specifications for the Qwen3.5-35B-A3B reveal a highly efficient design:Parameter Efficiency: While the model houses 35 billion parameters in total, it only activates 3 billion for any given token.Expert Diversity: The MoE layer utilizes 256 experts, with 8 routed experts and 1 shared expert helping to maintain performance while slashing inference latency.Near-Lossless Quantization: The series maintains high accuracy even when compressed to 4-bit weights, significantly reducing the memory footprint for local deployment.Base Model Release: In a move to support the research community, Alibaba has open-sourced the Qwen3.5-35B-A3B-Base model alongside the instruct-tuned versions.Product: Intelligence that &#x27;thinks&#x27; firstQwen 3.5 introduces a native \"Thinking Mode\" as its default state. Before providing a final answer, the model generates an internal reasoning chain—delimited by <think> tags—to work through complex logic.The product lineup is tailored for varying hardware environments:Qwen3.5-27B: Optimized for high efficiency, supporting a context length of over 800K tokens.Qwen3.5-Flash: The production-grade hosted version, featuring a default 1 million token context length and built-in official tools.Qwen3.5-122B-A10B: Designed for server-grade GPUs (80GB VRAM), this model supports 1M+ context lengths while narrowing the gap with the world&#x27;s largest frontier models.Benchmark results validate this architectural shift. The 35B-A3B model notably surpasses much larger predecessors, such as Qwen3-235B, as well as the aforementioned proprietary GPT-5 mini and Sonnet 4.5 in categories including knowledge (MMMLU) and visual reasoning (MMMU-Pro).Pricing and API integrationFor those not hosting their own weights, Alibaba Cloud Model Studio provides a competitive API for Qwen3.5-Flash.Input: $0.1 per 1M tokensOutput: $0.4 per 1M tokensCache Creation: $0.125 per 1M tokensCache Read: $0.01 per 1M tokensThe API also features a granular Tool Calling pricing model, with Web Search at $10 per 1,000 calls and Code Interpreter currently offered for a limited time at no cost.This makes Qwen3.5-Flash among the most affordable to run over API among all the major LLMs in the world. See a table comparing them below:ModelInputOutputTotal CostSourceQwen 3 Turbo$0.05$0.20$0.25Alibaba CloudQwen3.5-Flash$0.10$0.40$0.50Alibaba Clouddeepseek-chat (V3.2-Exp)$0.28$0.42$0.70DeepSeekdeepseek-reasoner (V3.2-Exp)$0.28$0.42$0.70DeepSeekGrok 4.1 Fast (reasoning)$0.20$0.50$0.70xAIGrok 4.1 Fast (non-reasoning)$0.20$0.50$0.70xAIMiniMax M2.5$0.15$1.20$1.35MiniMaxMiniMax M2.5-Lightning$0.30$2.40$2.70MiniMaxGemini 3 Flash Preview$0.50$3.00$3.50GoogleKimi-k2.5$0.60$3.00$3.60MoonshotGLM-5$1.00$3.20$4.20Z.aiERNIE 5.0$0.85$3.40$4.25BaiduClaude Haiku 4.5$1.00$5.00$6.00AnthropicQwen3-Max (2026-01-23)$1.20$6.00$7.20Alibaba CloudGemini 3 Pro (≤200K)$2.00$12.00$14.00GoogleGPT-5.2$1.75$14.00$15.75OpenAIClaude Sonnet 4.5$3.00$15.00$18.00AnthropicGemini 3 Pro (>200K)$4.00$18.00$22.00GoogleClaude Opus 4.6$5.00$25.00$30.00AnthropicGPT-5.2 Pro$21.00$168.00$189.00OpenAIWhat it means for enterprise technical leaders and decision-makersWith the launch of the Qwen3.5 Medium Models, the rapid iteration and fine-tuning once reserved for well-funded labs is now accessible for on-premise development at many non-technical firms, effectively decoupling sophisticated AI from massive capital expenditure.Across the organization, this architecture transforms how data is handled and secured. The ability to ingest massive document repositories or hour-scale videos locally allows for deep institutional analysis without the privacy risks of third-party APIs. By running these specialized \"Mixture-of-Experts\" models within a private firewall, organizations can maintain sovereign control over their data while utilizing native \"thinking\" modes and official tool-calling capabilities to build more reliable, autonomous agents. Early adopters on Hugging Face have specifically lauded the model’s ability to \"narrow the gap\" in agentic scenarios where previously only the largest closed models could compete.This shift toward architectural efficiency over raw scale ensures that AI integration remains cost-conscious, secure, and agile enough to keep pace with evolving operational needs.",
          "feed_position": 1,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/1ctDX1Ypc4ajApQBuzdxbA/f59c77208179df91c31908c4d07ab216/Gemini_Generated_Image_s1vvxes1vvxes1vv.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/everything-announced-at-samsung-unpacked-the-galaxy-s26-ultra-galaxy-buds-4-and-more-180000530.html",
          "published_at": "Wed, 25 Feb 2026 21:38:05 +0000",
          "title": "Everything announced at Samsung Unpacked: The Galaxy S26 Ultra, Galaxy Buds 4 and more",
          "standfirst": "Mobile World Congress is right around the corner, but Samsung got out ahead of many rivals that will be showing off new handsets at that event by running the latest edition of Unpacked on Wednesday. At its event in San Francisco’s Palace of Fine Arts, the company revealed the Galaxy S26 lineup, which includes the base S26, the S26+ and the S26 Ultra. We've got some hands-on time with all three handsets as well, and you can read about our in-person experience with the Galaxy S26 Ultra, as well as our S26 and S26+ impressions in those articles.In addition to those, Samsung announced the Galaxy Buds 4 along with (you guessed it) some AI updates. All the devices unveiled today are already available for pre-order, should you already be dying to get your hands on them. Here's a look at everything Samsung announced at the latest Unpacked:Galaxy S26 and S26+ Sam Rutherford for EngadgetNew-ish year, new Samsung phones. Let's deal with the out-and-out bad news first. The S26 and S26+ are each $100 more expensive than their predecessors (the RAM shortage isn't exactly helping to keep prices down). They start at $900 and $1,100, respectively, for variants with 256GB of storage. Samsung has tweaked the design a bit this time by rounding the corners to align them more with the S26 Ultra's look. The base model has a slightly larger display than the S25 at 6.3 inches, though the S26+ still has a 6.7-inch screen (albeit with a higher resolution than the S26 can handle). The S26 has a larger battery capacity than the S25 too at 4,300mAh. In North America, China and Japan, Samsung is sticking with Qualcomm chips rather than using its own Exynos 2600. If you pick up an S26 or S26+ in those markets, it will run on the Snapdragon 8 Elite Gen 5 chipset.The camera modules are the same as last year, but Samsung is aiming to supercharge them with upgrades elsewhere, such as ProScaler image upscaling and an MDNIe chip that's said to greatly improve color precision. There's also a video stabilization feature that tries to keep the horizon level while you're following a moving person or pet, which sounds useful for action shots. The new Object Aware Engine is said to better render skin tones and hair textures to make your selfies look better. Samsung has reworked some AI features too, such as making Now Brief and Auto Eraser compatible with more apps.Pre-orders for the S26 and S26+ are open today, and they'll be available on March 11. The phones will be available in purple, blue, black, white, silver and rose gold, though the latter two are online exclusives. Galaxy S26 UltraThe Galaxy S26 Ultra will be available in the same colorways and on the same date as its smaller siblings. It starts at $1,300, so there’s no price increase from the S25 Ultra. Preorders open today.The S26 Ultra has a 6.9-inch AMOLED display with a QHD+ resolution of 3120 x 1440 and a 120Hz refresh rate. That's all well and good, but the display is hiding (that being the key word) what's perhaps the Galaxy S26 Ultra's most interesting feature.The device has a Privacy Display that’s said to be the first of its kind on a smartphone. The idea here is to prevent people around from seeing what’s on the screen from acute angles. There's a small decrease in brightness when Privacy Display is active, and there are lots of customization options. You can set up Privacy Display to activate when you're asked for a password or PIN, or when you get a notification or open certain apps. So if (for instance) you tend to look at your banking apps when you’re on public transit and don’t want other passengers to see how much moolah you have, Privacy Display seems like a very handy feature.Elsewhere, the S26 Ultra runs on the same chipset as its smaller siblings. It comes with 12 or 16GB of RAM and 256GB, 512GB or 1TB of storage. The battery is larger than the ones in the other S26 models, as the Ultra has a 5,000 mAh capacity. There's support for Super Fast Charging 3.0 as well. Alas, Samsung still hasn't seen fit to offer built-in Qi2 charging magnets in the S26 lineup, which seems like a wild oversight in the year 2026.The selfie camera is the same as on the S26 and S26+. The S26 Ultra has 50MP ultrawide and 200MP wide lenses, along with dual 10MP 3x and 50MP 5x telephoto sensors. The resolutions of those cameras are the same as on the S25 Ultra, but the main 200M and 5x telephoto sensors now have wider apertures to let in more light. The S26 Ultra of course has the camera software features (and other AI features) found in the S26 and S26+.We'll have a review of the devices soon. In the meantime, head on through to our hands-on story for our initial impressions of the S26 Ultra.Galaxy Buds 4 and Buds 4 ProSam Rutherford for EngadgetWhile the S26 phones are more iterative updates this year, Samsung has given its Galaxy Buds a proper refresh. It revamped the design and shape of the Galaxy Buds 4 and Galaxy Buds 4 Pro to do away with the angular look of the stems and remove the lights from them. The earbuds have a \"more refined, computationally designed fit\" too, according to Samsung. The company claims the latest earbuds have smaller earbud heads that allow for a better, more secure fit and a more \"comfortable experience during all-day wear.\" The Galaxy Buds 4 remain in an open-fit format while the Buds Pro 4 have a canal-fit design.The latest earbuds are said to offer improved audio quality and active noise cancellation (ANC), with an ambient sound mode, adaptive EQ and adaptive ANC. On Buds 4 Pro, there's a siren detection feature that enables ambient sound to let you hear things like alarms or emergency vehicle warnings.The Buds 4 Pro have a wide woofer that increases the effective speaker area by nearly 20 percent compared with the previous gen earbuds, Samsung said. They support 24-bit/96kHz audio.If you're using Galaxy Buds 4 or Buds 4 Pro with a Galaxy device, you'll be able to use Bixby, Google Gemini and Perplexity with hands-free voice controls (though the \"hey, Plex\" command for the latter might be a tad confusing for folks who use a certain media server app). The Buds 4 Pro support head gesture controls for managing calls and Bixby interactions as well.As with the S26 phones, pre-orders for the earbuds open today and they'll hit shelves on March 11. The Galaxy Buds 4 cost $180 and Galaxy Buds 4 Pro will run you $250. Both models are available in white and black with a matte finish. There's an online-exclusive pink option for Buds 4 Pro as well.Android AI featuresAhead of Unpacked, Samsung confirmed that it would offer Perplexity as an AI agent option in Galaxy AI on the S26 lineup. As part of that update, it shared that the S26 series would respond to the “Hey Plex” wake phrase, and that Perplexity’s features would also be embedded in the Samsung Browser app. The company also recently updated Bixby to make its own virtual assistant more conversational.On top of that news, Google had announcements of its own to make at Unpacked regarding new Android AI features, which will of course be available on S26 devices. On those handsets and the Pixel 10 lineup, the Gemini app will soon have a feature (in beta) that enables you to offload multi-step tasks, such as booking a ride or putting a grocery order together, to AI. It sure sounds like an attempt to build out agentic AI features on mobile devices.Launching soon as a beta feature in the Gemini app for #Pixel10, Pixel 10 Pro, and Samsung Galaxy S26 series, you can offload multi-step tasks directly to Gemini.Simply long-press the power button and ask Gemini to help book you a ride home or reorder your last meal. Gemini… https://t.co/GjfXTnGg0k pic.twitter.com/YGIvqBkbu3— Google Gemini (@GeminiApp) February 25, 2026 Starting this week on Pixel 10 devices (and soon on S26 phones), Circle to Search will offer the ability to find details about multiple objects at once, such as entire outfits instead of single pieces. Moreover, Gemini-powered, on-device Scam Detection for phone calls will be available for S26 devices in English in the US.Update, February 25 2026, 4:35PM ET: This story has been updated to include more details on the Perplexity AI integration, as well as include mentions in the intro of our hands-on and pre-order articles.This article originally appeared on Engadget at https://www.engadget.com/mobile/everything-announced-at-samsung-unpacked-the-galaxy-s26-ultra-galaxy-buds-4-and-more-180000530.html?src=rss",
          "content": "Mobile World Congress is right around the corner, but Samsung got out ahead of many rivals that will be showing off new handsets at that event by running the latest edition of Unpacked on Wednesday. At its event in San Francisco’s Palace of Fine Arts, the company revealed the Galaxy S26 lineup, which includes the base S26, the S26+ and the S26 Ultra. We've got some hands-on time with all three handsets as well, and you can read about our in-person experience with the Galaxy S26 Ultra, as well as our S26 and S26+ impressions in those articles.In addition to those, Samsung announced the Galaxy Buds 4 along with (you guessed it) some AI updates. All the devices unveiled today are already available for pre-order, should you already be dying to get your hands on them. Here's a look at everything Samsung announced at the latest Unpacked:Galaxy S26 and S26+ Sam Rutherford for EngadgetNew-ish year, new Samsung phones. Let's deal with the out-and-out bad news first. The S26 and S26+ are each $100 more expensive than their predecessors (the RAM shortage isn't exactly helping to keep prices down). They start at $900 and $1,100, respectively, for variants with 256GB of storage. Samsung has tweaked the design a bit this time by rounding the corners to align them more with the S26 Ultra's look. The base model has a slightly larger display than the S25 at 6.3 inches, though the S26+ still has a 6.7-inch screen (albeit with a higher resolution than the S26 can handle). The S26 has a larger battery capacity than the S25 too at 4,300mAh. In North America, China and Japan, Samsung is sticking with Qualcomm chips rather than using its own Exynos 2600. If you pick up an S26 or S26+ in those markets, it will run on the Snapdragon 8 Elite Gen 5 chipset.The camera modules are the same as last year, but Samsung is aiming to supercharge them with upgrades elsewhere, such as ProScaler image upscaling and an MDNIe chip that's said to greatly improve color precision. There's also a video stabilization feature that tries to keep the horizon level while you're following a moving person or pet, which sounds useful for action shots. The new Object Aware Engine is said to better render skin tones and hair textures to make your selfies look better. Samsung has reworked some AI features too, such as making Now Brief and Auto Eraser compatible with more apps.Pre-orders for the S26 and S26+ are open today, and they'll be available on March 11. The phones will be available in purple, blue, black, white, silver and rose gold, though the latter two are online exclusives. Galaxy S26 UltraThe Galaxy S26 Ultra will be available in the same colorways and on the same date as its smaller siblings. It starts at $1,300, so there’s no price increase from the S25 Ultra. Preorders open today.The S26 Ultra has a 6.9-inch AMOLED display with a QHD+ resolution of 3120 x 1440 and a 120Hz refresh rate. That's all well and good, but the display is hiding (that being the key word) what's perhaps the Galaxy S26 Ultra's most interesting feature.The device has a Privacy Display that’s said to be the first of its kind on a smartphone. The idea here is to prevent people around from seeing what’s on the screen from acute angles. There's a small decrease in brightness when Privacy Display is active, and there are lots of customization options. You can set up Privacy Display to activate when you're asked for a password or PIN, or when you get a notification or open certain apps. So if (for instance) you tend to look at your banking apps when you’re on public transit and don’t want other passengers to see how much moolah you have, Privacy Display seems like a very handy feature.Elsewhere, the S26 Ultra runs on the same chipset as its smaller siblings. It comes with 12 or 16GB of RAM and 256GB, 512GB or 1TB of storage. The battery is larger than the ones in the other S26 models, as the Ultra has a 5,000 mAh capacity. There's support for Super Fast Charging 3.0 as well. Alas, Samsung still hasn't seen fit to offer built-in Qi2 charging magnets in the S26 lineup, which seems like a wild oversight in the year 2026.The selfie camera is the same as on the S26 and S26+. The S26 Ultra has 50MP ultrawide and 200MP wide lenses, along with dual 10MP 3x and 50MP 5x telephoto sensors. The resolutions of those cameras are the same as on the S25 Ultra, but the main 200M and 5x telephoto sensors now have wider apertures to let in more light. The S26 Ultra of course has the camera software features (and other AI features) found in the S26 and S26+.We'll have a review of the devices soon. In the meantime, head on through to our hands-on story for our initial impressions of the S26 Ultra.Galaxy Buds 4 and Buds 4 ProSam Rutherford for EngadgetWhile the S26 phones are more iterative updates this year, Samsung has given its Galaxy Buds a proper refresh. It revamped the design and shape of the Galaxy Buds 4 and Galaxy Buds 4 Pro to do away with the angular look of the stems and remove the lights from them. The earbuds have a \"more refined, computationally designed fit\" too, according to Samsung. The company claims the latest earbuds have smaller earbud heads that allow for a better, more secure fit and a more \"comfortable experience during all-day wear.\" The Galaxy Buds 4 remain in an open-fit format while the Buds Pro 4 have a canal-fit design.The latest earbuds are said to offer improved audio quality and active noise cancellation (ANC), with an ambient sound mode, adaptive EQ and adaptive ANC. On Buds 4 Pro, there's a siren detection feature that enables ambient sound to let you hear things like alarms or emergency vehicle warnings.The Buds 4 Pro have a wide woofer that increases the effective speaker area by nearly 20 percent compared with the previous gen earbuds, Samsung said. They support 24-bit/96kHz audio.If you're using Galaxy Buds 4 or Buds 4 Pro with a Galaxy device, you'll be able to use Bixby, Google Gemini and Perplexity with hands-free voice controls (though the \"hey, Plex\" command for the latter might be a tad confusing for folks who use a certain media server app). The Buds 4 Pro support head gesture controls for managing calls and Bixby interactions as well.As with the S26 phones, pre-orders for the earbuds open today and they'll hit shelves on March 11. The Galaxy Buds 4 cost $180 and Galaxy Buds 4 Pro will run you $250. Both models are available in white and black with a matte finish. There's an online-exclusive pink option for Buds 4 Pro as well.Android AI featuresAhead of Unpacked, Samsung confirmed that it would offer Perplexity as an AI agent option in Galaxy AI on the S26 lineup. As part of that update, it shared that the S26 series would respond to the “Hey Plex” wake phrase, and that Perplexity’s features would also be embedded in the Samsung Browser app. The company also recently updated Bixby to make its own virtual assistant more conversational.On top of that news, Google had announcements of its own to make at Unpacked regarding new Android AI features, which will of course be available on S26 devices. On those handsets and the Pixel 10 lineup, the Gemini app will soon have a feature (in beta) that enables you to offload multi-step tasks, such as booking a ride or putting a grocery order together, to AI. It sure sounds like an attempt to build out agentic AI features on mobile devices.Launching soon as a beta feature in the Gemini app for #Pixel10, Pixel 10 Pro, and Samsung Galaxy S26 series, you can offload multi-step tasks directly to Gemini.Simply long-press the power button and ask Gemini to help book you a ride home or reorder your last meal. Gemini… https://t.co/GjfXTnGg0k pic.twitter.com/YGIvqBkbu3— Google Gemini (@GeminiApp) February 25, 2026 Starting this week on Pixel 10 devices (and soon on S26 phones), Circle to Search will offer the ability to find details about multiple objects at once, such as entire outfits instead of single pieces. Moreover, Gemini-powered, on-device Scam Detection for phone calls will be available for S26 devices in English in the US.Update, February 25 2026, 4:35PM ET: This story has been updated to include more details on the Perplexity AI integration, as well as include mentions in the intro of our hands-on and pre-order articles.This article originally appeared on Engadget at https://www.engadget.com/mobile/everything-announced-at-samsung-unpacked-the-galaxy-s26-ultra-galaxy-buds-4-and-more-180000530.html?src=rss",
          "feed_position": 3,
          "image_url": "https://media-mbst-pub-ue1.s3.amazonaws.com/creatr-uploaded-images/2026-02/81ce1f20-1257-11f1-a3ea-2a64242c1da9"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/canadian-government-demands-safety-changes-from-openai-204924604.html",
          "published_at": "Wed, 25 Feb 2026 20:49:24 +0000",
          "title": "Canadian government demands safety changes from OpenAI",
          "standfirst": "Canadian officials summoned leaders from OpenAI to Ottawa this week to address safety concerns about ChatGPT. The crux of the government concerns was that OpenAI did not notify authorities when it banned the account of a user who allegedly committed a mass shooting in British Columbia earlier this month. \"The message that we delivered, in no uncertain terms, was that we have ‌an expectation that there are going to ⁠be changes implemented, and if they're not forthcoming very quickly, the government is going to be making changes,\" Justice Minister Sean Fraser said of the company and its AI chatbot. It's unclear what those government-led changes or rules might be. There have been two previous, unsuccessful attempts to pass an online harms act in Canada.A recent report by The Wall Street Journal claimed that in 2025, some OpenAI employees flagged the account of the alleged shooter, Jesse Van Rootselaar, as containing potential warnings of committing real-world violence and called for leadership to notify law enforcement. Although Van Rootselaar's account was banned for policy violations, a company rep said that the account activity did not meet OpenAI's criteria for engaging the local police. “Those reports were deeply disturbing, reports saying that OpenAI did not contact law enforcement in a timely manner,\" said Canadian Artificial Intelligence Minister Evan Solomon ahead of the discussion with company leaders. \"We will have a sit-down meeting to have an explanation of their safety protocols and when they escalate and their thresholds of escalation to police, so we have a better understanding of what’s happening and what they do.\"OpenAI has been implicated in mulitple wrongful death suits. The company's ChatGPT was accused of encouraging \"paranoid beliefs\" before a man killed his mother and himself in a December 2025 lawsuit. It is also at the center of one of several wrongful death lawsuits against the makers of AI chatbots for helping teenagers plan and commit suicides. This article originally appeared on Engadget at https://www.engadget.com/ai/canadian-government-demands-safety-changes-from-openai-204924604.html?src=rss",
          "content": "Canadian officials summoned leaders from OpenAI to Ottawa this week to address safety concerns about ChatGPT. The crux of the government concerns was that OpenAI did not notify authorities when it banned the account of a user who allegedly committed a mass shooting in British Columbia earlier this month. \"The message that we delivered, in no uncertain terms, was that we have ‌an expectation that there are going to ⁠be changes implemented, and if they're not forthcoming very quickly, the government is going to be making changes,\" Justice Minister Sean Fraser said of the company and its AI chatbot. It's unclear what those government-led changes or rules might be. There have been two previous, unsuccessful attempts to pass an online harms act in Canada.A recent report by The Wall Street Journal claimed that in 2025, some OpenAI employees flagged the account of the alleged shooter, Jesse Van Rootselaar, as containing potential warnings of committing real-world violence and called for leadership to notify law enforcement. Although Van Rootselaar's account was banned for policy violations, a company rep said that the account activity did not meet OpenAI's criteria for engaging the local police. “Those reports were deeply disturbing, reports saying that OpenAI did not contact law enforcement in a timely manner,\" said Canadian Artificial Intelligence Minister Evan Solomon ahead of the discussion with company leaders. \"We will have a sit-down meeting to have an explanation of their safety protocols and when they escalate and their thresholds of escalation to police, so we have a better understanding of what’s happening and what they do.\"OpenAI has been implicated in mulitple wrongful death suits. The company's ChatGPT was accused of encouraging \"paranoid beliefs\" before a man killed his mother and himself in a December 2025 lawsuit. It is also at the center of one of several wrongful death lawsuits against the makers of AI chatbots for helping teenagers plan and commit suicides. This article originally appeared on Engadget at https://www.engadget.com/ai/canadian-government-demands-safety-changes-from-openai-204924604.html?src=rss",
          "feed_position": 5
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/smartphones/tecno-just-unveiled-a-ridiculously-thin-modular-smartphone-concept-design-194741776.html",
          "published_at": "Wed, 25 Feb 2026 19:47:42 +0000",
          "title": "Tecno just unveiled a ridiculously thin modular smartphone concept design",
          "standfirst": "Tecno just unveiled a rather intriguing modular smartphone concept design at MWC 2026. The standout feature here is likely the size. Most modular smartphone concepts start bulky and only get bulkier once attaching accessories. Tecno's base smartphone is just 4.9mm thin, which is significantly thinner than a pencil and the iPhone Air. Of course, the size increases with each attached module. However, snapping on the power bank module makes the thickness comparable to a standard modern smartphone. Another key feature here is how these various modular components stick together. Tecno has developed new interconnection technology that uses both magnets and pin connectors. This should make it easy to both attach and remove components. The company says this phone has been designed to grow with the user through hardware expansion. To that end, Tecno has developed 10 modules. There are various camera lenses and something that looks like a dedicated gaming controller. Tecno While the magnets are for attaching, the pin connectors assist with power delivery. Data transmission between the phone and the modules is handled wirelessly, with the ability to switch between Wi-Fi, Bluetooth and mmWave depending on where the user is located. There are two colorways for both the phone and the ecosystem of accessories. There's a silver-aluminum edition and a nifty-looking grey version. This doesn't matter to actual consumers because, well, it's just a concept design. It does look like the company's magnetic attachment technology could make it to some actual products down the line. Tecno has always been a company that marched to the beat of its own drummer. It has developed a surprisingly affordable foldable phone, a model with a pop-out portrait lens and a foldable with a novel circular display on the exterior. The industry hasn't quite embraced modular smartphones just yet, even though there have been some nifty concept designs. Google's Project Ara prototype goes back more than a decade, and the same can be said of other concept designs that never saw the light of day. There have been some modular phones released to the real world, but they weren't nearly as ambitious as Tecno's concept. LG launched a semi-modular phone called the G5 back in 2016, but it didn't move too many units. Moto has also released a couple of semi-modular smartphones, but they didn't set the world on fire.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/tecno-just-unveiled-a-ridiculously-thin-modular-smartphone-concept-design-194741776.html?src=rss",
          "content": "Tecno just unveiled a rather intriguing modular smartphone concept design at MWC 2026. The standout feature here is likely the size. Most modular smartphone concepts start bulky and only get bulkier once attaching accessories. Tecno's base smartphone is just 4.9mm thin, which is significantly thinner than a pencil and the iPhone Air. Of course, the size increases with each attached module. However, snapping on the power bank module makes the thickness comparable to a standard modern smartphone. Another key feature here is how these various modular components stick together. Tecno has developed new interconnection technology that uses both magnets and pin connectors. This should make it easy to both attach and remove components. The company says this phone has been designed to grow with the user through hardware expansion. To that end, Tecno has developed 10 modules. There are various camera lenses and something that looks like a dedicated gaming controller. Tecno While the magnets are for attaching, the pin connectors assist with power delivery. Data transmission between the phone and the modules is handled wirelessly, with the ability to switch between Wi-Fi, Bluetooth and mmWave depending on where the user is located. There are two colorways for both the phone and the ecosystem of accessories. There's a silver-aluminum edition and a nifty-looking grey version. This doesn't matter to actual consumers because, well, it's just a concept design. It does look like the company's magnetic attachment technology could make it to some actual products down the line. Tecno has always been a company that marched to the beat of its own drummer. It has developed a surprisingly affordable foldable phone, a model with a pop-out portrait lens and a foldable with a novel circular display on the exterior. The industry hasn't quite embraced modular smartphones just yet, even though there have been some nifty concept designs. Google's Project Ara prototype goes back more than a decade, and the same can be said of other concept designs that never saw the light of day. There have been some modular phones released to the real world, but they weren't nearly as ambitious as Tecno's concept. LG launched a semi-modular phone called the G5 back in 2016, but it didn't move too many units. Moto has also released a couple of semi-modular smartphones, but they didn't set the world on fire.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/tecno-just-unveiled-a-ridiculously-thin-modular-smartphone-concept-design-194741776.html?src=rss",
          "feed_position": 7,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2026-02/9f4ae160-127e-11f1-b47f-ea3488490078"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/big-tech/kalshi-fined-a-mrbeast-editor-for-insider-trading-191027814.html",
          "published_at": "Wed, 25 Feb 2026 19:10:27 +0000",
          "title": "Kalshi fined a MrBeast editor for insider trading",
          "standfirst": "Kalshi, one of several online prediction markets that have exploded in popularity in the last few years, has suspended one of YouTube MrBeast's video editors for insider trading, NPR reports. Besides being suspended from the platform for two years, Kalshi says the editor will also be required to pay a financial penalty that's five times his initial trade size.The editor, Artem Kaptur, traded in markets related to YouTube and specifically, MrBeast. Kalshi says his transactions were initially flagged because of his \"near-perfect trading success on markets with low odds, which were statistically anomalous.\" Because trades are public on Kalshi, multiple users also flagged the trades as suspicious. Kalshi learned Kaptur was an employee of MrBeast during its investigation and determined he \"likely had access to material non-public information connected to his trading.\" Perhaps unsurprisingly, trading with insider information violates Kalshi's rules.Kalshi says that it reported the insider trading to the Commodity Futures Trading Commission (CFTC) and plans to donate the over $20,000 Kaptur has been fined to \"a non-profit that provides consumer education on derivatives markets.\" In a statement provided to NPR, Beast Industries, MrBeast's production company, said it has a zero-tolerance policy for insider trading. \"We have a longstanding policy in place against employees using proprietary company information in order to safeguard the highest standards and ethics throughout our organization,\" Beast Industries said. Separately, Kalshi has also suspended and fined a politician who was running to be Governor of California. \"In May, our Surveillance Department saw an online video by a candidate for Governor of California that appeared to show him trading on his own candidacy,\" Kalshi says. \"We immediately froze his account and opened an investigation. The candidate was initially cooperative and acknowledged that this violated the exchange rules. As a candidate in a race, you can (and probably should) follow and use Kalshi’s market forecast, but you should not trade on it.\"Like other prediction markets, Kalshi lets users make trades based on a variety of different subjects and events. For example, you could participate in a market focused on the results of a basketball game, or something more unusual, like who'll win the current season of Survivor. Despite resembling gambling, online predictive markets aren't currently regulated by state gambling laws, and instead classify bets as a type of futures contract, placing them under the purview of the CFTC. That hasn't stopped states from trying to regulate prediction markets anyway. For example, Nevada sued Kalshi for operating a sports gambling market without a permit earlier in February.This article originally appeared on Engadget at https://www.engadget.com/big-tech/kalshi-fined-a-mrbeast-editor-for-insider-trading-191027814.html?src=rss",
          "content": "Kalshi, one of several online prediction markets that have exploded in popularity in the last few years, has suspended one of YouTube MrBeast's video editors for insider trading, NPR reports. Besides being suspended from the platform for two years, Kalshi says the editor will also be required to pay a financial penalty that's five times his initial trade size.The editor, Artem Kaptur, traded in markets related to YouTube and specifically, MrBeast. Kalshi says his transactions were initially flagged because of his \"near-perfect trading success on markets with low odds, which were statistically anomalous.\" Because trades are public on Kalshi, multiple users also flagged the trades as suspicious. Kalshi learned Kaptur was an employee of MrBeast during its investigation and determined he \"likely had access to material non-public information connected to his trading.\" Perhaps unsurprisingly, trading with insider information violates Kalshi's rules.Kalshi says that it reported the insider trading to the Commodity Futures Trading Commission (CFTC) and plans to donate the over $20,000 Kaptur has been fined to \"a non-profit that provides consumer education on derivatives markets.\" In a statement provided to NPR, Beast Industries, MrBeast's production company, said it has a zero-tolerance policy for insider trading. \"We have a longstanding policy in place against employees using proprietary company information in order to safeguard the highest standards and ethics throughout our organization,\" Beast Industries said. Separately, Kalshi has also suspended and fined a politician who was running to be Governor of California. \"In May, our Surveillance Department saw an online video by a candidate for Governor of California that appeared to show him trading on his own candidacy,\" Kalshi says. \"We immediately froze his account and opened an investigation. The candidate was initially cooperative and acknowledged that this violated the exchange rules. As a candidate in a race, you can (and probably should) follow and use Kalshi’s market forecast, but you should not trade on it.\"Like other prediction markets, Kalshi lets users make trades based on a variety of different subjects and events. For example, you could participate in a market focused on the results of a basketball game, or something more unusual, like who'll win the current season of Survivor. Despite resembling gambling, online predictive markets aren't currently regulated by state gambling laws, and instead classify bets as a type of futures contract, placing them under the purview of the CFTC. That hasn't stopped states from trying to regulate prediction markets anyway. For example, Nevada sued Kalshi for operating a sports gambling market without a permit earlier in February.This article originally appeared on Engadget at https://www.engadget.com/big-tech/kalshi-fined-a-mrbeast-editor-for-insider-trading-191027814.html?src=rss",
          "feed_position": 9
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/anthropic-weakens-its-safety-pledge-in-the-wake-of-the-pentagons-pressure-campaign-183436413.html",
          "published_at": "Wed, 25 Feb 2026 18:34:36 +0000",
          "title": "Anthropic weakens its safety pledge in the wake of the Pentagon's pressure campaign",
          "standfirst": "Two stories about the Claude maker Anthropic broke on Tuesday that, when combined, arguably paint a chilling picture. First, US Defense Secretary Pete Hegseth is reportedly pressuring Anthropic to yield its AI safeguards and give the military unrestrained access to its Claude AI chatbot. The company then chose the same day that the Hegseth news broke to drop its centerpiece safety pledge.On Tuesday, Anthropic said it was modifying its Responsible Scaling Policy (RSP) to lower safety guardrails. Up until now, the company's core pledge has been to stop training new AI models unless specific safety guidelines can be guaranteed in advance. This policy, which set hard tripwires to halt development, was a big part of Anthropic's pitch to businesses and consumers.“Two and a half years later, our honest assessment is that some parts of this theory of change have played out as we hoped, but others have not,” Anthropic wrote. Now, its updated policy approaches safety relatively, rather than with strict red lines.Anthropic's quotes in an interview with Time sound reasonable enough in a vacuum. \"We felt that it wouldn't actually help anyone for us to stop training AI models,\" Jared Kaplan, Anthropic's chief science officer, told Time. \"We didn't really feel, with the rapid advance of AI, that it made sense for us to make unilateral commitments… if competitors are blazing ahead.\"Anthropic CEO Dario Amodei (Photo by David Dee Delgado/Getty Images for The New York Times)David Dee Delgado via Getty ImagesBut you could also read those quotes as the latest example of a hot startup’s ethics becoming grayer as its valuation rises. (Remember Google’s old “Don’t be evil” mantra that it later removed from its code of conduct?) The latest versions of Claude have drawn widespread praise, especially in coding. In February, Anthropic raised $30 billion in new investments. It now has a valuation of $380 billion. (Speaking of the competition Kaplan referred to, rival OpenAI is currently valued at over $850 billion.)In place of Anthropic's previous tripwires, it will implement new \"Risk Reports\" and \"Frontier Safety Roadmaps.\" These disclosure models are designed to provide transparency to the public in place of those hard lines in the sand.Anthropic says the change was motivated by a \"collective action problem\" stemming from the competitive AI landscape and the US's anti-regulatory approach. \"If one AI developer paused development to implement safety measures while others moved forward training and deploying AI systems without strong mitigations, that could result in a world that is less safe,\" the new RSP reads. \"The developers with the weakest protections would set the pace, and responsible developers would lose their ability to do safety research and advance the public beneﬁt.\"Defense Secretary Pete Hegseth (Photo by AAron Ontiveroz/The Denver Post)AAron Ontiveroz via Getty ImagesNeither Anthropic's announcement nor the Time exclusive mentions the elephant in the room: the Pentagon's pressure campaign. On Tuesday, Axios reported that Hegseth told Anthropic CEO Dario Amodei that the company has until Friday to give the military unfettered access to its AI model or face penalties. The company has reportedly offered to adopt its usage policies for the Pentagon. However, it wouldn't allow its model to be used for the mass surveillance of Americans or weapons that fire without human involvement.If Anthropic doesn't relent, experts say its best bet would be legal action. But will the Pentagon's proposed penalties be enough to scare a profit-driven startup into compliance? Hegseths' threats reportedly include invoking the Defense Production Act, which gives the president authority to direct private companies prioritize certain contracts in the name of national defense. The military could also sever its contract with Anthropic and designate it as a supply chain risk. That would force other companies working with the Pentagon to certify that Claude isn't included in their workflows.Claude is the only AI model currently used for the military's most sensitive work. \"The only reason we're still talking to these people is we need them and we need them now,” a defense official told Axios. “The problem for these guys is they are that good.\" Claude was reportedly used in the Maduro raid in Venezuela, a topic Amodei is said to have raised with its partner Palantir.Time's story about the new RSP included reactions from a nonprofit director focused on AI risks. Chris Painter, director of METR, described the changes as both understandable and perhaps an ill omen. \"I like the emphasis on transparent risk reporting and publicly verifiable safety roadmaps,\" he said. However, he also raised concerns that the more flexible RSP could lead to a \"frog-boiling\" effect. In other words, when safety becomes a gray area, a seemingly never-ending series of rationalizations could take the company down the very dark path it once condemned.Painter said the new RSP shows that Anthropic \"believes it needs to shift into triage mode with its safety plans, because methods to assess and mitigate risk are not keeping up with the pace of capabilities. This is more evidence that society is not prepared for the potential catastrophic risks posed by AI.\"This article originally appeared on Engadget at https://www.engadget.com/ai/anthropic-weakens-its-safety-pledge-in-the-wake-of-the-pentagons-pressure-campaign-183436413.html?src=rss",
          "content": "Two stories about the Claude maker Anthropic broke on Tuesday that, when combined, arguably paint a chilling picture. First, US Defense Secretary Pete Hegseth is reportedly pressuring Anthropic to yield its AI safeguards and give the military unrestrained access to its Claude AI chatbot. The company then chose the same day that the Hegseth news broke to drop its centerpiece safety pledge.On Tuesday, Anthropic said it was modifying its Responsible Scaling Policy (RSP) to lower safety guardrails. Up until now, the company's core pledge has been to stop training new AI models unless specific safety guidelines can be guaranteed in advance. This policy, which set hard tripwires to halt development, was a big part of Anthropic's pitch to businesses and consumers.“Two and a half years later, our honest assessment is that some parts of this theory of change have played out as we hoped, but others have not,” Anthropic wrote. Now, its updated policy approaches safety relatively, rather than with strict red lines.Anthropic's quotes in an interview with Time sound reasonable enough in a vacuum. \"We felt that it wouldn't actually help anyone for us to stop training AI models,\" Jared Kaplan, Anthropic's chief science officer, told Time. \"We didn't really feel, with the rapid advance of AI, that it made sense for us to make unilateral commitments… if competitors are blazing ahead.\"Anthropic CEO Dario Amodei (Photo by David Dee Delgado/Getty Images for The New York Times)David Dee Delgado via Getty ImagesBut you could also read those quotes as the latest example of a hot startup’s ethics becoming grayer as its valuation rises. (Remember Google’s old “Don’t be evil” mantra that it later removed from its code of conduct?) The latest versions of Claude have drawn widespread praise, especially in coding. In February, Anthropic raised $30 billion in new investments. It now has a valuation of $380 billion. (Speaking of the competition Kaplan referred to, rival OpenAI is currently valued at over $850 billion.)In place of Anthropic's previous tripwires, it will implement new \"Risk Reports\" and \"Frontier Safety Roadmaps.\" These disclosure models are designed to provide transparency to the public in place of those hard lines in the sand.Anthropic says the change was motivated by a \"collective action problem\" stemming from the competitive AI landscape and the US's anti-regulatory approach. \"If one AI developer paused development to implement safety measures while others moved forward training and deploying AI systems without strong mitigations, that could result in a world that is less safe,\" the new RSP reads. \"The developers with the weakest protections would set the pace, and responsible developers would lose their ability to do safety research and advance the public beneﬁt.\"Defense Secretary Pete Hegseth (Photo by AAron Ontiveroz/The Denver Post)AAron Ontiveroz via Getty ImagesNeither Anthropic's announcement nor the Time exclusive mentions the elephant in the room: the Pentagon's pressure campaign. On Tuesday, Axios reported that Hegseth told Anthropic CEO Dario Amodei that the company has until Friday to give the military unfettered access to its AI model or face penalties. The company has reportedly offered to adopt its usage policies for the Pentagon. However, it wouldn't allow its model to be used for the mass surveillance of Americans or weapons that fire without human involvement.If Anthropic doesn't relent, experts say its best bet would be legal action. But will the Pentagon's proposed penalties be enough to scare a profit-driven startup into compliance? Hegseths' threats reportedly include invoking the Defense Production Act, which gives the president authority to direct private companies prioritize certain contracts in the name of national defense. The military could also sever its contract with Anthropic and designate it as a supply chain risk. That would force other companies working with the Pentagon to certify that Claude isn't included in their workflows.Claude is the only AI model currently used for the military's most sensitive work. \"The only reason we're still talking to these people is we need them and we need them now,” a defense official told Axios. “The problem for these guys is they are that good.\" Claude was reportedly used in the Maduro raid in Venezuela, a topic Amodei is said to have raised with its partner Palantir.Time's story about the new RSP included reactions from a nonprofit director focused on AI risks. Chris Painter, director of METR, described the changes as both understandable and perhaps an ill omen. \"I like the emphasis on transparent risk reporting and publicly verifiable safety roadmaps,\" he said. However, he also raised concerns that the more flexible RSP could lead to a \"frog-boiling\" effect. In other words, when safety becomes a gray area, a seemingly never-ending series of rationalizations could take the company down the very dark path it once condemned.Painter said the new RSP shows that Anthropic \"believes it needs to shift into triage mode with its safety plans, because methods to assess and mitigate risk are not keeping up with the pace of capabilities. This is more evidence that society is not prepared for the potential catastrophic risks posed by AI.\"This article originally appeared on Engadget at https://www.engadget.com/ai/anthropic-weakens-its-safety-pledge-in-the-wake-of-the-pentagons-pressure-campaign-183436413.html?src=rss",
          "feed_position": 10,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/2026-02/575fb8b7-e5f0-4216-a05a-146e0292b32c"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/smartphones/samsung-galaxy-s26-vs-galaxy-s25-whats-changed-and-which-one-should-you-buy-181515367.html",
          "published_at": "Wed, 25 Feb 2026 18:15:15 +0000",
          "title": "Samsung Galaxy S26 vs. Galaxy S25: What’s changed and which one should you buy?",
          "standfirst": "Following Samsung’s Unpacked event, the Samsung Galaxy S26 is available for pre-order, and it looks very familiar. That is not necessarily a bad thing. Like recent updates in the Galaxy S line, Samsung is refining its flagship rather than dramatically reinventing it. Both phones share a lot of core DNA, including compact designs, high-refresh AMOLED displays and similar camera hardware. The S26 does introduce a handful of meaningful updates, however, including a slightly larger battery and newer software out of the box. Those changes also come with a higher starting price: the Galaxy S26 begins at $899.99 compared to the S25’s $799.99 launch price. The entry model now includes 256GB of storage instead of the S25’s base 128GB. Here's how the Galaxy S26 compares with last year’s Galaxy S25 on paper and whether the newer model is worth your attention. Galaxy S26 vs. Galaxy S25: Design, display and performance Physically, the Galaxy S26 stays very close to the design Samsung established with the S25. You still get a compact handset with flat edges, an aluminum frame and IP68 water and dust resistance. The overall look and feel should be immediately familiar to anyone who used last year’s phone. The display story is similarly steady. Both phones use Samsung’s Dynamic AMOLED 2X panels with adaptive refresh rates up to 120Hz, and the S25 is rated for peak brightness of up to 2,600 nits. In everyday use, whether you are scrolling, gaming or watching video, the viewing experience should feel broadly similar between the two devices. Under the hood, the Galaxy S25 is powered globally by Qualcomm’s Snapdragon 8 Elite for Galaxy chipset paired with 12GB of RAM. The Galaxy S26 continues to target flagship-class performance. While Samsung has made internal refinements, overall speed should remain firmly in high-end territory for routine tasks, multitasking and mobile gaming. On the software front, the S25 launched with Android 15 and One UI 7, while the Galaxy S26 ships with a newer version of Samsung’s software out of the box. As usual, the older model is expected to receive updates over time, which may narrow the long-term software gap. Galaxy S26 vs. Galaxy S25: Cameras Samsung has not dramatically reshuffled the base Galaxy camera hardware. The Galaxy S25 features a triple-camera setup built around a 50-megapixel main sensor, a 12MP ultrawide and a 10MP telephoto with 3x optical zoom, along with a 12MP front camera. The Galaxy S26 largely sticks with the same proven approach, which suggests image quality should remain broadly consistent in good lighting. As is often the case with Samsung’s year-to-year updates, any meaningful gains are likely to come from image processing improvements rather than brand-new sensors. For most people, that means the S26 should deliver the punchy, reliable photos Samsung flagships are known for, but Galaxy S25 owners should not expect a dramatic leap in camera hardware. Galaxy S26 vs. Galaxy S25: Battery life and charging Battery capacity is one area where the Galaxy S26 makes a measurable change. The Galaxy S25 uses a 4,000mAh battery, while the Galaxy S26 increases that to 4,300mAh. That modest bump should translate into slightly longer endurance in day-to-day use, though real-world gains will depend on efficiency improvements and individual usage patterns. Charging speeds remain largely unchanged. The Galaxy S25 supports up to 25W wired charging, up to 15W wireless charging and 4.5W reverse wireless charging, and the Galaxy S26 stays in the same general range. Galaxy S26 vs. Galaxy S25: Software and AI This year, Samsung is putting more emphasis on Galaxy AI, even on the base Galaxy S26. While many of the headline features are aimed at the Ultra and Plus models, the standard S26 still picks up several practical upgrades. One of the more useful additions is Document Scan, which uses AI to clean up scans by automatically removing distortions, fingers and creases. It can also bundle multiple images into a single PDF, making it easier to digitize receipts, notes or forms without extra editing. Samsung is also expanding its proactive assistant features. Now Brief becomes more personalized on the S26, surfacing reminders and updates based on your activity throughout the day, while the new Now Nudge system can suggest relevant content at the right moment. For example, if someone asks for photos from a recent trip, the phone can proactively surface matching images from your gallery instead of making you search manually. Search is getting smarter as well. Circle to Search with Google now supports enhanced multi-object recognition, allowing you to identify several items in an image at once. Samsung is also upgrading Bixby into a more conversational assistant, and the S26 supports third-party agents such as Gemini and Perplexity for handling more complex, multi-step tasks through voice commands. Security and privacy features are expanding in the background too. The Galaxy S26 introduces AI-powered Call Screening to summarize unknown callers, along with new Privacy Alerts that warn when apps request sensitive permissions. Samsung is also extending its post-quantum cryptography protections deeper into the system, backed by the company’s Knox security platform and seven years of promised security updates. Galaxy S26 vs. Galaxy S25: How to choose If you already own a Galaxy S25, the Galaxy S26 looks like a fairly iterative update. The core experience, including performance, display quality and camera hardware, remains very similar. The main tangible upgrade is the slightly larger battery, along with newer software out of the box. For most S25 owners, that alone probably is not a compelling reason to upgrade. However, if you are coming from an older Galaxy phone or buying fresh, the Galaxy S26 is the more future-proof pick simply because it starts one generation ahead in Samsung’s update cycle and packs the larger battery. As usual with Samsung’s yearly refreshes, the real decision may come down to pricing and discounts. If the Galaxy S25 sees significant price cuts, it could remain the better value. But at similar prices, the Galaxy S26 is the safer long-term buy. Galaxy S26 vs. Galaxy S25: Specs at a glance Specs Samsung Galaxy S26 Samsung Galaxy S25 Price (MSRP) $899.99 $799.99 (128GB), $859.99 (256GB) Dimensions 5.88 x 2.82 x 0.28 inches 5.78 x 2.78 x 0.28 inches Weight 5.9 ounces 5.7 ounces Screen size 6.3 inches (FHD+) 6.2 inches (FHD+) Screen resolution 2,340 x 1,080 2,340 x 1,080 Screen type Dynamic AMOLED 2X, 120Hz adaptive refresh (1–120Hz), Up to 2,600 nits peak brightness, Corning Gorilla Glass Victus 3 Dynamic AMOLED 2X, 120Hz adaptive refresh (1–120Hz), Up to 2,600 nits peak brightness, Corning Gorilla Glass Victus 2 SoC Snapdragon 8 Elite Gen 5 for Galaxy Snapdragon 8 Elite for Galaxy RAM 12GB 12GB Battery 4,300mAh 4,000mAh Charging Up to 25W (wired), 15W (wireless) Up to 25W (wired), 15W (wireless) Storage 256GB, 512GB 128GB, 256GB Rear camera 50MP main, 12MP ultrawide, 10MP 3x telephoto 50MP main, 12MP ultrawide, 10MP 3x telephoto Front camera 12MP 12MP Video capture Up to 4K 60fps, 8K 30fps Up to 4K 60fps, 8K 30fps Water and dust resistance rating IP68 IP68 Wi-Fi Wi-Fi 7 Wi-Fi 7 Bluetooth Bluetooth 6.0 Bluetooth 5.4 OS Android 16 with One UI 8.5 Android 15 with One UI 7 Colors and finish Cobalt Violet, White, Black, Sky Blue, Pink Gold*, Silver Shadow* (*Samsung.com exclusive) Navy, Icyblue, Mint, Silver Shadow, Blueblack*, Coralred*, Pinkgold* (*Samsung.com exclusive) This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/samsung-galaxy-s26-vs-galaxy-s25-whats-changed-and-which-one-should-you-buy-181515367.html?src=rss",
          "content": "Following Samsung’s Unpacked event, the Samsung Galaxy S26 is available for pre-order, and it looks very familiar. That is not necessarily a bad thing. Like recent updates in the Galaxy S line, Samsung is refining its flagship rather than dramatically reinventing it. Both phones share a lot of core DNA, including compact designs, high-refresh AMOLED displays and similar camera hardware. The S26 does introduce a handful of meaningful updates, however, including a slightly larger battery and newer software out of the box. Those changes also come with a higher starting price: the Galaxy S26 begins at $899.99 compared to the S25’s $799.99 launch price. The entry model now includes 256GB of storage instead of the S25’s base 128GB. Here's how the Galaxy S26 compares with last year’s Galaxy S25 on paper and whether the newer model is worth your attention. Galaxy S26 vs. Galaxy S25: Design, display and performance Physically, the Galaxy S26 stays very close to the design Samsung established with the S25. You still get a compact handset with flat edges, an aluminum frame and IP68 water and dust resistance. The overall look and feel should be immediately familiar to anyone who used last year’s phone. The display story is similarly steady. Both phones use Samsung’s Dynamic AMOLED 2X panels with adaptive refresh rates up to 120Hz, and the S25 is rated for peak brightness of up to 2,600 nits. In everyday use, whether you are scrolling, gaming or watching video, the viewing experience should feel broadly similar between the two devices. Under the hood, the Galaxy S25 is powered globally by Qualcomm’s Snapdragon 8 Elite for Galaxy chipset paired with 12GB of RAM. The Galaxy S26 continues to target flagship-class performance. While Samsung has made internal refinements, overall speed should remain firmly in high-end territory for routine tasks, multitasking and mobile gaming. On the software front, the S25 launched with Android 15 and One UI 7, while the Galaxy S26 ships with a newer version of Samsung’s software out of the box. As usual, the older model is expected to receive updates over time, which may narrow the long-term software gap. Galaxy S26 vs. Galaxy S25: Cameras Samsung has not dramatically reshuffled the base Galaxy camera hardware. The Galaxy S25 features a triple-camera setup built around a 50-megapixel main sensor, a 12MP ultrawide and a 10MP telephoto with 3x optical zoom, along with a 12MP front camera. The Galaxy S26 largely sticks with the same proven approach, which suggests image quality should remain broadly consistent in good lighting. As is often the case with Samsung’s year-to-year updates, any meaningful gains are likely to come from image processing improvements rather than brand-new sensors. For most people, that means the S26 should deliver the punchy, reliable photos Samsung flagships are known for, but Galaxy S25 owners should not expect a dramatic leap in camera hardware. Galaxy S26 vs. Galaxy S25: Battery life and charging Battery capacity is one area where the Galaxy S26 makes a measurable change. The Galaxy S25 uses a 4,000mAh battery, while the Galaxy S26 increases that to 4,300mAh. That modest bump should translate into slightly longer endurance in day-to-day use, though real-world gains will depend on efficiency improvements and individual usage patterns. Charging speeds remain largely unchanged. The Galaxy S25 supports up to 25W wired charging, up to 15W wireless charging and 4.5W reverse wireless charging, and the Galaxy S26 stays in the same general range. Galaxy S26 vs. Galaxy S25: Software and AI This year, Samsung is putting more emphasis on Galaxy AI, even on the base Galaxy S26. While many of the headline features are aimed at the Ultra and Plus models, the standard S26 still picks up several practical upgrades. One of the more useful additions is Document Scan, which uses AI to clean up scans by automatically removing distortions, fingers and creases. It can also bundle multiple images into a single PDF, making it easier to digitize receipts, notes or forms without extra editing. Samsung is also expanding its proactive assistant features. Now Brief becomes more personalized on the S26, surfacing reminders and updates based on your activity throughout the day, while the new Now Nudge system can suggest relevant content at the right moment. For example, if someone asks for photos from a recent trip, the phone can proactively surface matching images from your gallery instead of making you search manually. Search is getting smarter as well. Circle to Search with Google now supports enhanced multi-object recognition, allowing you to identify several items in an image at once. Samsung is also upgrading Bixby into a more conversational assistant, and the S26 supports third-party agents such as Gemini and Perplexity for handling more complex, multi-step tasks through voice commands. Security and privacy features are expanding in the background too. The Galaxy S26 introduces AI-powered Call Screening to summarize unknown callers, along with new Privacy Alerts that warn when apps request sensitive permissions. Samsung is also extending its post-quantum cryptography protections deeper into the system, backed by the company’s Knox security platform and seven years of promised security updates. Galaxy S26 vs. Galaxy S25: How to choose If you already own a Galaxy S25, the Galaxy S26 looks like a fairly iterative update. The core experience, including performance, display quality and camera hardware, remains very similar. The main tangible upgrade is the slightly larger battery, along with newer software out of the box. For most S25 owners, that alone probably is not a compelling reason to upgrade. However, if you are coming from an older Galaxy phone or buying fresh, the Galaxy S26 is the more future-proof pick simply because it starts one generation ahead in Samsung’s update cycle and packs the larger battery. As usual with Samsung’s yearly refreshes, the real decision may come down to pricing and discounts. If the Galaxy S25 sees significant price cuts, it could remain the better value. But at similar prices, the Galaxy S26 is the safer long-term buy. Galaxy S26 vs. Galaxy S25: Specs at a glance Specs Samsung Galaxy S26 Samsung Galaxy S25 Price (MSRP) $899.99 $799.99 (128GB), $859.99 (256GB) Dimensions 5.88 x 2.82 x 0.28 inches 5.78 x 2.78 x 0.28 inches Weight 5.9 ounces 5.7 ounces Screen size 6.3 inches (FHD+) 6.2 inches (FHD+) Screen resolution 2,340 x 1,080 2,340 x 1,080 Screen type Dynamic AMOLED 2X, 120Hz adaptive refresh (1–120Hz), Up to 2,600 nits peak brightness, Corning Gorilla Glass Victus 3 Dynamic AMOLED 2X, 120Hz adaptive refresh (1–120Hz), Up to 2,600 nits peak brightness, Corning Gorilla Glass Victus 2 SoC Snapdragon 8 Elite Gen 5 for Galaxy Snapdragon 8 Elite for Galaxy RAM 12GB 12GB Battery 4,300mAh 4,000mAh Charging Up to 25W (wired), 15W (wireless) Up to 25W (wired), 15W (wireless) Storage 256GB, 512GB 128GB, 256GB Rear camera 50MP main, 12MP ultrawide, 10MP 3x telephoto 50MP main, 12MP ultrawide, 10MP 3x telephoto Front camera 12MP 12MP Video capture Up to 4K 60fps, 8K 30fps Up to 4K 60fps, 8K 30fps Water and dust resistance rating IP68 IP68 Wi-Fi Wi-Fi 7 Wi-Fi 7 Bluetooth Bluetooth 6.0 Bluetooth 5.4 OS Android 16 with One UI 8.5 Android 15 with One UI 7 Colors and finish Cobalt Violet, White, Black, Sky Blue, Pink Gold*, Silver Shadow* (*Samsung.com exclusive) Navy, Icyblue, Mint, Silver Shadow, Blueblack*, Coralred*, Pinkgold* (*Samsung.com exclusive) This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/samsung-galaxy-s26-vs-galaxy-s25-whats-changed-and-which-one-should-you-buy-181515367.html?src=rss",
          "feed_position": 12
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/smartphones/samsung-galaxy-s26-vs-s26-vs-s26-ultra-comparing-the-three-new-phones-181047172.html",
          "published_at": "Wed, 25 Feb 2026 18:10:47 +0000",
          "title": "Samsung Galaxy S26 vs. S26+ vs. S26 Ultra: Comparing the three new phones",
          "standfirst": "Samsung has officially unveiled the Galaxy S26, Galaxy S26+ and Galaxy S26 Ultra, and the company is once again leaning heavily on AI, camera upgrades and refined hardware to move the lineup forward. While the overall design remains familiar, there are some meaningful differences between the three models, particularly when it comes to display tech, charging speeds and camera hardware. Across the board, the S26 family is powered by Qualcomm’s Snapdragon 8 Elite Gen 5 for Galaxy chip and runs Android 16 with One UI 8.5. Samsung is also doubling down on Galaxy AI features like Now Brief, Now Nudge and upgraded Circle to Search, positioning the new phones as more proactive assistants than before. As usual, though, the Ultra model is where Samsung is pushing the envelope the furthest. It gains the most advanced camera system, faster wired and wireless charging and the company’s new built-in Privacy Display tech. Pre-orders are available now, with official sales starting on March 11. If you’re trying to decide which model makes the most sense for your needs (and budget), here’s how the three devices stack up on paper. Samsung Galaxy S26 vs. S26+ vs. S26 Ultra: Specs compared Specs Samsung Galaxy S26 Samsung Galaxy S26+ Samsung Galaxy S26 Ultra Price (MSRP) $899.99 $1,099.99 $1,299.99 Dimensions 71.7 x 149.6 x 7.2 mm 71.7 x 149.6 x 7.2 mm 78.1 x 163.6 x 7.9 mm Weight 167g 190g 214g Screen size 6.3 inches (FHD+) 6.7 inches (QHD+) 6.9 inches (QHD+) Screen resolution 2340 x 1080 3120 x 1440 3120 x 1440 Screen type Dynamic AMOLED 2X, 120Hz adaptive refresh (1–120Hz), Up to 2,600 nits peak brightness Dynamic AMOLED 2X, 120Hz adaptive refresh (1–120Hz), Up to 2,600 nits peak brightness Dynamic AMOLED 2X, 120Hz adaptive refresh (1–120Hz), Up to 2,600 nits peak brightness SoC Snapdragon 8 Elite Gen 5 for Galaxy Snapdragon 8 Elite Gen 5 for Galaxy Snapdragon 8 Elite Gen 5 for Galaxy RAM 12GB 12GB 12GB or 16GB Battery 4,300 mAh 4,300 mAh 5,000 mAh Charging 25W (wired), 15W (wireless) 45W (wired), 20W (wireless) 60W (wired), 25W (wireless) Storage 256/512GB 256/512GB 256/512GB, 1TB Rear camera 50MP main, 12MP ultrawide, 10MP 3x telephoto 50MP main, 12MP ultrawide, 10MP 3x telephoto 200MP main, 50MP ultrawide, 10MP 3x telephoto, 50MP 5x periscope telephoto Front camera 12MP 12MP 12MP Video capture Up to 4K 60fps, 8K 30fps Up to 4K 60fps, 8K 30fps Up to 4K 120fps, 8K 30fps Water and dust resistance rating IP68 IP68 IP68 Wi-Fi Wi-Fi 7 Wi-Fi 7 Wi-Fi 7 Bluetooth Bluetooth 6.0 Bluetooth 6.0 Bluetooth 6.0 OS Android 16 with One UI 8.5 Android 16 with One UI 8.5 Android 16 with One UI 8.5 Colors and finish Cobalt Violet, White, Black, and Sky Blue / Pink Gold and Silver Shadow (Samsung exclusive) Cobalt Violet, White, Black, and Sky Blue / Pink Gold and Silver Shadow (Samsung exclusive) Cobalt Violet, White, Black, and Sky Blue / Pink Gold and Silver Shadow (Samsung exclusive) This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/samsung-galaxy-s26-vs-s26-vs-s26-ultra-comparing-the-three-new-phones-181047172.html?src=rss",
          "content": "Samsung has officially unveiled the Galaxy S26, Galaxy S26+ and Galaxy S26 Ultra, and the company is once again leaning heavily on AI, camera upgrades and refined hardware to move the lineup forward. While the overall design remains familiar, there are some meaningful differences between the three models, particularly when it comes to display tech, charging speeds and camera hardware. Across the board, the S26 family is powered by Qualcomm’s Snapdragon 8 Elite Gen 5 for Galaxy chip and runs Android 16 with One UI 8.5. Samsung is also doubling down on Galaxy AI features like Now Brief, Now Nudge and upgraded Circle to Search, positioning the new phones as more proactive assistants than before. As usual, though, the Ultra model is where Samsung is pushing the envelope the furthest. It gains the most advanced camera system, faster wired and wireless charging and the company’s new built-in Privacy Display tech. Pre-orders are available now, with official sales starting on March 11. If you’re trying to decide which model makes the most sense for your needs (and budget), here’s how the three devices stack up on paper. Samsung Galaxy S26 vs. S26+ vs. S26 Ultra: Specs compared Specs Samsung Galaxy S26 Samsung Galaxy S26+ Samsung Galaxy S26 Ultra Price (MSRP) $899.99 $1,099.99 $1,299.99 Dimensions 71.7 x 149.6 x 7.2 mm 71.7 x 149.6 x 7.2 mm 78.1 x 163.6 x 7.9 mm Weight 167g 190g 214g Screen size 6.3 inches (FHD+) 6.7 inches (QHD+) 6.9 inches (QHD+) Screen resolution 2340 x 1080 3120 x 1440 3120 x 1440 Screen type Dynamic AMOLED 2X, 120Hz adaptive refresh (1–120Hz), Up to 2,600 nits peak brightness Dynamic AMOLED 2X, 120Hz adaptive refresh (1–120Hz), Up to 2,600 nits peak brightness Dynamic AMOLED 2X, 120Hz adaptive refresh (1–120Hz), Up to 2,600 nits peak brightness SoC Snapdragon 8 Elite Gen 5 for Galaxy Snapdragon 8 Elite Gen 5 for Galaxy Snapdragon 8 Elite Gen 5 for Galaxy RAM 12GB 12GB 12GB or 16GB Battery 4,300 mAh 4,300 mAh 5,000 mAh Charging 25W (wired), 15W (wireless) 45W (wired), 20W (wireless) 60W (wired), 25W (wireless) Storage 256/512GB 256/512GB 256/512GB, 1TB Rear camera 50MP main, 12MP ultrawide, 10MP 3x telephoto 50MP main, 12MP ultrawide, 10MP 3x telephoto 200MP main, 50MP ultrawide, 10MP 3x telephoto, 50MP 5x periscope telephoto Front camera 12MP 12MP 12MP Video capture Up to 4K 60fps, 8K 30fps Up to 4K 60fps, 8K 30fps Up to 4K 120fps, 8K 30fps Water and dust resistance rating IP68 IP68 IP68 Wi-Fi Wi-Fi 7 Wi-Fi 7 Wi-Fi 7 Bluetooth Bluetooth 6.0 Bluetooth 6.0 Bluetooth 6.0 OS Android 16 with One UI 8.5 Android 16 with One UI 8.5 Android 16 with One UI 8.5 Colors and finish Cobalt Violet, White, Black, and Sky Blue / Pink Gold and Silver Shadow (Samsung exclusive) Cobalt Violet, White, Black, and Sky Blue / Pink Gold and Silver Shadow (Samsung exclusive) Cobalt Violet, White, Black, and Sky Blue / Pink Gold and Silver Shadow (Samsung exclusive) This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/samsung-galaxy-s26-vs-s26-vs-s26-ultra-comparing-the-three-new-phones-181047172.html?src=rss",
          "feed_position": 13
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/google-announces-new-android-ai-features-coming-to-the-galaxy-s26-and-pixel-10-series-180039674.html",
          "published_at": "Wed, 25 Feb 2026 18:00:39 +0000",
          "title": "Google announces new Android AI features coming to the Galaxy S26 and Pixel 10 series",
          "standfirst": "Google unveiled a new batch of Android updates, including more Gemini-powered tools and improved scam detection features at Samsung’s Galaxy S26 launch on Wednesday. A new feature in the Gemini app will let users hand off multi-step tasks, like ordering a rideshare or building a grocery cart. The feature, which will first arrive in beta, runs in the background while users perform other tasks. Gemini's progress can be monitored live via notifications, so users can see what it's doing and jump in at any time. Google Google says this feature will initially be limited to certain food, grocery or rideshare apps. It will be available first on select devices, including the Galaxy S26 and Pixel 10, in the US and Korea. Android is also getting an upgrade for Circle to Search, enabling it to search for multiple objects seen on screen at once. One implementation of this is full-outfit searches using \"find the look.\" Once the app has found all the individual pieces of the circled outfit, users can try them on virtually. This will be available on Galaxy S26 and Pixel 10 devices. The beefed-up feature can also be used to gain insights into multiple objects in an image. Google The company is also using Gemini to bring on-device Scam Detection for calls to Samsung’s Phone app. The tool alerts users if someone on their call is using speech patterns commonly heard from scammers. Google says the feature is never used while on a call with someone in your contacts and is off by default. Google The same technology and approach will also be used to detect scams in Google Messages. For now, scam detection on phone calls is only available on the Galaxy S26 in English in the US, while detection in messages is supported across various markets. All of these new features are available now on the Pixel 10 and Galaxy S26 lineups, with availability in select markets varying by feature.This article originally appeared on Engadget at https://www.engadget.com/ai/google-announces-new-android-ai-features-coming-to-the-galaxy-s26-and-pixel-10-series-180039674.html?src=rss",
          "content": "Google unveiled a new batch of Android updates, including more Gemini-powered tools and improved scam detection features at Samsung’s Galaxy S26 launch on Wednesday. A new feature in the Gemini app will let users hand off multi-step tasks, like ordering a rideshare or building a grocery cart. The feature, which will first arrive in beta, runs in the background while users perform other tasks. Gemini's progress can be monitored live via notifications, so users can see what it's doing and jump in at any time. Google Google says this feature will initially be limited to certain food, grocery or rideshare apps. It will be available first on select devices, including the Galaxy S26 and Pixel 10, in the US and Korea. Android is also getting an upgrade for Circle to Search, enabling it to search for multiple objects seen on screen at once. One implementation of this is full-outfit searches using \"find the look.\" Once the app has found all the individual pieces of the circled outfit, users can try them on virtually. This will be available on Galaxy S26 and Pixel 10 devices. The beefed-up feature can also be used to gain insights into multiple objects in an image. Google The company is also using Gemini to bring on-device Scam Detection for calls to Samsung’s Phone app. The tool alerts users if someone on their call is using speech patterns commonly heard from scammers. Google says the feature is never used while on a call with someone in your contacts and is off by default. Google The same technology and approach will also be used to detect scams in Google Messages. For now, scam detection on phone calls is only available on the Galaxy S26 in English in the US, while detection in messages is supported across various markets. All of these new features are available now on the Pixel 10 and Galaxy S26 lineups, with availability in select markets varying by feature.This article originally appeared on Engadget at https://www.engadget.com/ai/google-announces-new-android-ai-features-coming-to-the-galaxy-s26-and-pixel-10-series-180039674.html?src=rss",
          "feed_position": 15,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2026-02/8364e260-1270-11f1-bb73-540b7150e7a1"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/smartphones/samsung-galaxy-s26-hands-on-launch-date-price-180005654.html",
          "published_at": "Wed, 25 Feb 2026 18:00:05 +0000",
          "title": "Samsung Galaxy S26 hands-on: A lot more of the same for a little more money",
          "standfirst": "As we prepare to leave the winter months, Samsung announced another family of Galaxy S flagships for those looking to upgrade. As usual, the company put its best components and features into the Galaxy S26 Ultra, but it also added more to the base S26 and S26+. The company has hit its groove with its smaller (and cheaper) flagships, delivering solid devices with increasingly better cameras, occasionally even offering feature parity with its most expensive smartphone. In 2026, that’s what we’re getting, with the 6.3-inch S26 ($899) and 6.7-inch S26+ ($1,099). Both phones are more expensive than last year, and it’s often a game of spot-the-difference when it comes to showing what’s new. Fortunately, the best parts have been retained, too. Samsung has unified the design style across the entire S26 series, with the same corner ratios, curved edges and other design touches. While I tested both phones, I’ll focus on the S26. Barring screen differences and battery size, they’re identically specced. This year’s S26 color selection has a premium Samsung ‘mood’ to it that I can’t quite explain. Does purple mean Samsung to my brain? Maybe. Cobalt Violet is the particular shade I’m talking about, but there are also blue, black and white colors. Additional silver and pink-gold options will be available as online exclusives. There’s not much else to say about the design: it’s another Galaxy S flagship, and if it ain’t broke… Mat Smith for Engadget Samsung has increased the battery capacity to 4,300 mAh on the S26, while somehow maintaining the same thickness as last year’s S25. However, the S26+ has the same 4,900mAH battery as its predecessor. All S26 devices will launch with 256GB of storage and 12GB of RAM, with bigger storage options available. With the S26, Samsung has slightly increased the screen size to 6.3 inches, up from last year's 6.2-inch S25. The S26 comes with a familiar camera trio: a 50-megapixel main sensor, 12MP ultrawide, and 10MP telephoto with up to 3x optical zoom. On paper, that’s identical to last year’s base S25. However, Samsung has improved performance with its ProScaler technology for upscaling images and an MDNIe chip, which the company says provides four times the color precision compared to previous devices. There are software improvements too, with video features being the most tangible upgrade, among more AI-assisted photo editing tools. Super Steady video has been upgraded to a 360-degree horizontal lock. This camera mode uses the S26’s gyroscopes to maintain a consistent horizon even as you rush to chase a pet or family member while recording, or to capture snowboarding buddies. (There’s always a snowboarding example when a company mentions horizontal lock.) It’s nice to see a feature we’re used to finding on gimbals and action cams built into an unashamedly mainstream phone like the S26. Auto Framing is another new feature coming to both 4K and 8K video capture. It uses AI to lock onto subjects and automatically tighten framing to what you want to capture. Even during brief testing, I was intrigued and liked the dramatic punch-in effect as I recorded nearby people. It creates a faux-panning effect as it tracks moving subjects, something you might have experienced with Center Stage on Apple devices. Samsung has also upgraded image processing on its front-facing cameras with a new Object Aware Engine for improved portrait mode shots, hair textures and more accurate skin tones. Based on my early testing, images seemed sharper than on my older Samsung devices, even though this is (again) largely the same 12MP camera as last year. With processors, it's getting a little more complicated. In the US, Samsung's entire S26 series will use the Snapdragon 8 Elite Gen 5 for Galaxy, but in Europe, both the S26 and S26+ will be powered by the company’s own Exynos 2600, apparently the world’s first 2nm chipset. Comparing it to Snapdragon’s top mobile processor, however, will have to wait until review time. With more power for AI functions, Samsung has continued to evolve and expand its AI software, although it seems less of a priority this year. Only one AI feature stood out during my briefing: Audio Eraser. While this launched on the S25, it only worked on audio and video you captured yourself. Now, Samsung expanded it to most major video platforms, including Netflix, Instagram and YouTube, adding the ability to strip out noise and distractions and amplify the volume of voices. It was especially effective with a rowdy replay of an Arsenal football soccer match, and sounded like I was listening to a dedicated commentary channel. Interestingly, unlike many sound editing apps and features, it will work on downloaded videos on those platforms without an internet connection. Elsewhere, Now Nudge will attempt to suggest actions based on what’s happening onscreen, such as sharing contact numbers with someone or suggesting calendar times while dealing with work emails. Samsung’s Now Brief can pull information and notifications from a wider array of apps and sources to deliver in its daily briefings. However, again, that’s hard to assess at this early stage. There are several more quality–of-life software updates, too, like the ability to sift through all those screenshots after they’ve been automatically categorized into sections like barcodes, events and more. If you can’t get enough AI image generation, you can now use Photo Assist to edit your photos using descriptive prompts. Elsewhere, Circle-to-Search now supports multiple, well, circles, if you’re looking to tag and search for multiple objects at once. Mat Smith for Engadget It’s not the most exciting year for Samsung’s smaller flagship phones. While the S26 Ultra can boast a new Privacy Display that’s the first of its kind, the rest of the S26 family have a little too much in common with their predecessors. The new video features seem useful and intuitive, so there’s more to explore there. We’ll have more to say in our full reviews soon. Both the Galaxy S26 and S26+ launch on March 11th and are available to preorder now.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/samsung-galaxy-s26-hands-on-launch-date-price-180005654.html?src=rss",
          "content": "As we prepare to leave the winter months, Samsung announced another family of Galaxy S flagships for those looking to upgrade. As usual, the company put its best components and features into the Galaxy S26 Ultra, but it also added more to the base S26 and S26+. The company has hit its groove with its smaller (and cheaper) flagships, delivering solid devices with increasingly better cameras, occasionally even offering feature parity with its most expensive smartphone. In 2026, that’s what we’re getting, with the 6.3-inch S26 ($899) and 6.7-inch S26+ ($1,099). Both phones are more expensive than last year, and it’s often a game of spot-the-difference when it comes to showing what’s new. Fortunately, the best parts have been retained, too. Samsung has unified the design style across the entire S26 series, with the same corner ratios, curved edges and other design touches. While I tested both phones, I’ll focus on the S26. Barring screen differences and battery size, they’re identically specced. This year’s S26 color selection has a premium Samsung ‘mood’ to it that I can’t quite explain. Does purple mean Samsung to my brain? Maybe. Cobalt Violet is the particular shade I’m talking about, but there are also blue, black and white colors. Additional silver and pink-gold options will be available as online exclusives. There’s not much else to say about the design: it’s another Galaxy S flagship, and if it ain’t broke… Mat Smith for Engadget Samsung has increased the battery capacity to 4,300 mAh on the S26, while somehow maintaining the same thickness as last year’s S25. However, the S26+ has the same 4,900mAH battery as its predecessor. All S26 devices will launch with 256GB of storage and 12GB of RAM, with bigger storage options available. With the S26, Samsung has slightly increased the screen size to 6.3 inches, up from last year's 6.2-inch S25. The S26 comes with a familiar camera trio: a 50-megapixel main sensor, 12MP ultrawide, and 10MP telephoto with up to 3x optical zoom. On paper, that’s identical to last year’s base S25. However, Samsung has improved performance with its ProScaler technology for upscaling images and an MDNIe chip, which the company says provides four times the color precision compared to previous devices. There are software improvements too, with video features being the most tangible upgrade, among more AI-assisted photo editing tools. Super Steady video has been upgraded to a 360-degree horizontal lock. This camera mode uses the S26’s gyroscopes to maintain a consistent horizon even as you rush to chase a pet or family member while recording, or to capture snowboarding buddies. (There’s always a snowboarding example when a company mentions horizontal lock.) It’s nice to see a feature we’re used to finding on gimbals and action cams built into an unashamedly mainstream phone like the S26. Auto Framing is another new feature coming to both 4K and 8K video capture. It uses AI to lock onto subjects and automatically tighten framing to what you want to capture. Even during brief testing, I was intrigued and liked the dramatic punch-in effect as I recorded nearby people. It creates a faux-panning effect as it tracks moving subjects, something you might have experienced with Center Stage on Apple devices. Samsung has also upgraded image processing on its front-facing cameras with a new Object Aware Engine for improved portrait mode shots, hair textures and more accurate skin tones. Based on my early testing, images seemed sharper than on my older Samsung devices, even though this is (again) largely the same 12MP camera as last year. With processors, it's getting a little more complicated. In the US, Samsung's entire S26 series will use the Snapdragon 8 Elite Gen 5 for Galaxy, but in Europe, both the S26 and S26+ will be powered by the company’s own Exynos 2600, apparently the world’s first 2nm chipset. Comparing it to Snapdragon’s top mobile processor, however, will have to wait until review time. With more power for AI functions, Samsung has continued to evolve and expand its AI software, although it seems less of a priority this year. Only one AI feature stood out during my briefing: Audio Eraser. While this launched on the S25, it only worked on audio and video you captured yourself. Now, Samsung expanded it to most major video platforms, including Netflix, Instagram and YouTube, adding the ability to strip out noise and distractions and amplify the volume of voices. It was especially effective with a rowdy replay of an Arsenal football soccer match, and sounded like I was listening to a dedicated commentary channel. Interestingly, unlike many sound editing apps and features, it will work on downloaded videos on those platforms without an internet connection. Elsewhere, Now Nudge will attempt to suggest actions based on what’s happening onscreen, such as sharing contact numbers with someone or suggesting calendar times while dealing with work emails. Samsung’s Now Brief can pull information and notifications from a wider array of apps and sources to deliver in its daily briefings. However, again, that’s hard to assess at this early stage. There are several more quality–of-life software updates, too, like the ability to sift through all those screenshots after they’ve been automatically categorized into sections like barcodes, events and more. If you can’t get enough AI image generation, you can now use Photo Assist to edit your photos using descriptive prompts. Elsewhere, Circle-to-Search now supports multiple, well, circles, if you’re looking to tag and search for multiple objects at once. Mat Smith for Engadget It’s not the most exciting year for Samsung’s smaller flagship phones. While the S26 Ultra can boast a new Privacy Display that’s the first of its kind, the rest of the S26 family have a little too much in common with their predecessors. The new video features seem useful and intuitive, so there’s more to explore there. We’ll have more to say in our full reviews soon. Both the Galaxy S26 and S26+ launch on March 11th and are available to preorder now.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/samsung-galaxy-s26-hands-on-launch-date-price-180005654.html?src=rss",
          "feed_position": 16,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2026-02/41198390-10a7-11f1-9ffe-5ea02fda5b50"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/audio/headphones/samsungs-redesigned-galaxy-buds-4-lineup-has-retooled-sound-improved-anc-and-new-features-180000718.html",
          "published_at": "Wed, 25 Feb 2026 18:00:00 +0000",
          "title": "Samsung's redesigned Galaxy Buds 4 lineup has retooled sound, improved ANC and new features",
          "standfirst": "Samsung isn’t waiting a full year to reveal its latest Galaxy Buds. The company debuted the Galaxy Buds 4 and Galaxy Buds 4 Pro at its Galaxy S26 Unpacked event where the hot topic was three new phones. When it comes to Samsung’s earbuds, the company has overhauled the shape and design while improving sound quality, active noise cancellation (ANC) and adding new features. As always, the best of what the Galaxy Buds 4 lineup has to offer will be reserved for people with a recent Samsung phone. While the company is keeping its AirPods-esque “blade” design, it retooled that element to ditch the angular shape and the gimmicky lights. It’s now a flat, metal panel and the area that allows for pinch controls has been engraved so that your fingers find it easily. In terms of shape, Samsung says it analyzed data from hundreds of millions of ear data points and ran over 10,000 simulations to improve overall fit with smaller earbuds. The Galaxy Buds 4 remain an open-fit design while the Pro version has a tip that seals off your ears. Like before, the company kept the transparent lids for the charging cases, although this time the earbuds lay flat in those rather than standing up. Inside of the Galaxy Buds 4 Pro, Samsung is using a wider woofer as part of its two-way driver setup for cleaner bass. That configuration’s dedicated tweeter should also deliver natural, rich treble, according to the company. Both Galaxy Buds 4 models support high quality audio up to 24bit/96kHz (from a recent Samsung device) and direct multi-channel 360 audio is available as well. Samsung Galaxy Buds 4 and Galaxy Buds 4 Pro Sam Rutherford for Engadget Although the Galaxy Buds Pro 4 got the bulk of the ANC upgrades, Samsung says it improved noise-canceling performance for both models. The company promises effective noise blocking for transit sounds — engine noise from buses, trains or planes — in addition to “everyday background noise.” What’s more, both of the Galaxy Buds 4 devices feature ambient sound mode, adaptive EQ and adaptive ANC, with the latter two applying adjustments automatically as needed. The Pro model can also detect the user’s voice and increase ambient sound for conversations — a feature that’s held over from the Galaxy Buds 3 Pro. When you stop talking, the earbuds will automatically resume ANC. The Galaxy Buds 4 Pro also has a Siren Detect feature that activates ambient sound so that you can hear safety alerts like alarms or emergency vehicles. The new item that pushes the Galaxy Buds 4 Pro closer to the AirPods Pro 3 is head gestures. Samsung will now let users manage calls and interact with Bixby by nodding or shaking their head side to side. As before, the Galaxy Buds remain a conduit to Bixby, but they’re also a gateway to Gemini and Perplexity — all of which can be accessed hands-free via voice controls. The Galaxy Buds 4 ($180) and Galaxy Buds 4 Pro ($250) are available for pre-order today before hitting shelves on March 11. Both models will be available in black and white, and there’s a pink gold option on the Pro, although that third color is a Samsung online exclusive. This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/samsungs-redesigned-galaxy-buds-4-lineup-has-retooled-sound-improved-anc-and-new-features-180000718.html?src=rss",
          "content": "Samsung isn’t waiting a full year to reveal its latest Galaxy Buds. The company debuted the Galaxy Buds 4 and Galaxy Buds 4 Pro at its Galaxy S26 Unpacked event where the hot topic was three new phones. When it comes to Samsung’s earbuds, the company has overhauled the shape and design while improving sound quality, active noise cancellation (ANC) and adding new features. As always, the best of what the Galaxy Buds 4 lineup has to offer will be reserved for people with a recent Samsung phone. While the company is keeping its AirPods-esque “blade” design, it retooled that element to ditch the angular shape and the gimmicky lights. It’s now a flat, metal panel and the area that allows for pinch controls has been engraved so that your fingers find it easily. In terms of shape, Samsung says it analyzed data from hundreds of millions of ear data points and ran over 10,000 simulations to improve overall fit with smaller earbuds. The Galaxy Buds 4 remain an open-fit design while the Pro version has a tip that seals off your ears. Like before, the company kept the transparent lids for the charging cases, although this time the earbuds lay flat in those rather than standing up. Inside of the Galaxy Buds 4 Pro, Samsung is using a wider woofer as part of its two-way driver setup for cleaner bass. That configuration’s dedicated tweeter should also deliver natural, rich treble, according to the company. Both Galaxy Buds 4 models support high quality audio up to 24bit/96kHz (from a recent Samsung device) and direct multi-channel 360 audio is available as well. Samsung Galaxy Buds 4 and Galaxy Buds 4 Pro Sam Rutherford for Engadget Although the Galaxy Buds Pro 4 got the bulk of the ANC upgrades, Samsung says it improved noise-canceling performance for both models. The company promises effective noise blocking for transit sounds — engine noise from buses, trains or planes — in addition to “everyday background noise.” What’s more, both of the Galaxy Buds 4 devices feature ambient sound mode, adaptive EQ and adaptive ANC, with the latter two applying adjustments automatically as needed. The Pro model can also detect the user’s voice and increase ambient sound for conversations — a feature that’s held over from the Galaxy Buds 3 Pro. When you stop talking, the earbuds will automatically resume ANC. The Galaxy Buds 4 Pro also has a Siren Detect feature that activates ambient sound so that you can hear safety alerts like alarms or emergency vehicles. The new item that pushes the Galaxy Buds 4 Pro closer to the AirPods Pro 3 is head gestures. Samsung will now let users manage calls and interact with Bixby by nodding or shaking their head side to side. As before, the Galaxy Buds remain a conduit to Bixby, but they’re also a gateway to Gemini and Perplexity — all of which can be accessed hands-free via voice controls. The Galaxy Buds 4 ($180) and Galaxy Buds 4 Pro ($250) are available for pre-order today before hitting shelves on March 11. Both models will be available in black and white, and there’s a pink gold option on the Pro, although that third color is a Samsung online exclusive. This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/samsungs-redesigned-galaxy-buds-4-lineup-has-retooled-sound-improved-anc-and-new-features-180000718.html?src=rss",
          "feed_position": 17,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/buds-1.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/smartphones/samsungs-galaxy-s26-ultra-offers-a-subtle-set-of-hardware-improvements-180000725.html",
          "published_at": "Wed, 25 Feb 2026 18:00:00 +0000",
          "title": "Samsung's Galaxy S26 Ultra offers a subtle set of hardware improvements",
          "standfirst": "Samsung has announced the latest version of its flagship smartphone, the Samsung Galaxy S26 Ultra, and just like last year, the high-end phone is where the company is making some of its biggest changes. The S26 Ultra includes a new processor, a new privacy-focused display technology, an improved camera system and like Samsung's other phones, a crop of new AI-powered software features.On first blush, the Galaxy S26 Ultra isn't all that different from the Galaxy S25 Ultra. Samsung is still using a 6.9-inch QHD+ AMOLED screen, with an 120Hz refresh rate and support for an S Pen stylus. The S26 Ultra also features the same flat sides, utter lack of Qi2-compatible magnets and pronounced camera bump. Despite those similarities, the new flagship does have some differences: for one, it's ever so slightly thinner at 0.31-inches than the S25 Ultra was at 0.32-inches. It also comes with an aluminum frame rather than the titanium frame of the previous generation. For stylus fans, the new S Pen has a curved top that lets it better match the curves of the S26 Ultra. Biggest of all, Samsung's new phone includes \"Privacy Display,\" a new technology that lets the phone limit how much of its screen is visible when you're not looking directly at it.Sam Rutherford for EngadgetInside, the Galaxy S26 Ultra uses Qualcomm's new Snapdragon 8 Elite Gen 5 for Galaxy chip, a modified version of the flagship mobile chip it debuted last year, and either 12 or 16GB of RAM. In terms of storage, the Galaxy S26 Ultra can come with either 256GB, 512GB or 1TB of memory. Regardless of which version you pick, you'll get a 5,000mAh battery with support for Samsung's wired and wireless fast charging, and Wireless PowerShare for topping up accessories like wireless earbuds.The Galaxy S26 Ultra, just like the S25 Ultra before it, includes an array of four cameras on the back and one selfie camera on the front. The phone features a 200MP f/1.4 wide, 50MP f/1.9 ultra-wide, 10MP f/2.4 3x telephoto, 50MP f/2.9 periscope telephoto and 12MP f/2.2 selfie camera. If you were to just look at just the megapixel counts of the phone, they're identical to last year's model. Samsung's major tweaks are to the aperture of both the wide and periscope cameras, which should let them capture more light.Sam Rutherford for EngadgetOf course, plenty of the flashiest parts of Samsung's new smartphone are software features. The improved photo and video performances of the Galaxy S26 Ultra's cameras is partially driven by software tweaks. Samsung is also adopting Perplexity as a second, system-level AI assistant. The AI can be called with a button press or \"Hey Plex,\" powers improvements to Bixby and can act inside Samsung apps. That doesn't mean Gemini isn't still available, though. Google's AI will gain the ability to handle things like booking a rideshare or filling an online grocery cart in the background on the Galaxy S26 Ultra.The Galaxy S26 Ultra starts at $1,300 and is available to pre-order today in a purple-ish \"Cobalt Violet,\" light blue \"Sky Blue,\" black, white and exclusively through Samsung's online store, \"Silver Shadow\" and \"Pink Gold.\" The phone will become generally available on March 11.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/samsungs-galaxy-s26-ultra-offers-a-subtle-set-of-hardware-improvements-180000725.html?src=rss",
          "content": "Samsung has announced the latest version of its flagship smartphone, the Samsung Galaxy S26 Ultra, and just like last year, the high-end phone is where the company is making some of its biggest changes. The S26 Ultra includes a new processor, a new privacy-focused display technology, an improved camera system and like Samsung's other phones, a crop of new AI-powered software features.On first blush, the Galaxy S26 Ultra isn't all that different from the Galaxy S25 Ultra. Samsung is still using a 6.9-inch QHD+ AMOLED screen, with an 120Hz refresh rate and support for an S Pen stylus. The S26 Ultra also features the same flat sides, utter lack of Qi2-compatible magnets and pronounced camera bump. Despite those similarities, the new flagship does have some differences: for one, it's ever so slightly thinner at 0.31-inches than the S25 Ultra was at 0.32-inches. It also comes with an aluminum frame rather than the titanium frame of the previous generation. For stylus fans, the new S Pen has a curved top that lets it better match the curves of the S26 Ultra. Biggest of all, Samsung's new phone includes \"Privacy Display,\" a new technology that lets the phone limit how much of its screen is visible when you're not looking directly at it.Sam Rutherford for EngadgetInside, the Galaxy S26 Ultra uses Qualcomm's new Snapdragon 8 Elite Gen 5 for Galaxy chip, a modified version of the flagship mobile chip it debuted last year, and either 12 or 16GB of RAM. In terms of storage, the Galaxy S26 Ultra can come with either 256GB, 512GB or 1TB of memory. Regardless of which version you pick, you'll get a 5,000mAh battery with support for Samsung's wired and wireless fast charging, and Wireless PowerShare for topping up accessories like wireless earbuds.The Galaxy S26 Ultra, just like the S25 Ultra before it, includes an array of four cameras on the back and one selfie camera on the front. The phone features a 200MP f/1.4 wide, 50MP f/1.9 ultra-wide, 10MP f/2.4 3x telephoto, 50MP f/2.9 periscope telephoto and 12MP f/2.2 selfie camera. If you were to just look at just the megapixel counts of the phone, they're identical to last year's model. Samsung's major tweaks are to the aperture of both the wide and periscope cameras, which should let them capture more light.Sam Rutherford for EngadgetOf course, plenty of the flashiest parts of Samsung's new smartphone are software features. The improved photo and video performances of the Galaxy S26 Ultra's cameras is partially driven by software tweaks. Samsung is also adopting Perplexity as a second, system-level AI assistant. The AI can be called with a button press or \"Hey Plex,\" powers improvements to Bixby and can act inside Samsung apps. That doesn't mean Gemini isn't still available, though. Google's AI will gain the ability to handle things like booking a rideshare or filling an online grocery cart in the background on the Galaxy S26 Ultra.The Galaxy S26 Ultra starts at $1,300 and is available to pre-order today in a purple-ish \"Cobalt Violet,\" light blue \"Sky Blue,\" black, white and exclusively through Samsung's online store, \"Silver Shadow\" and \"Pink Gold.\" The phone will become generally available on March 11.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/samsungs-galaxy-s26-ultra-offers-a-subtle-set-of-hardware-improvements-180000725.html?src=rss",
          "feed_position": 18,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/ultra-3.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/smartphones/googles-circle-to-search-can-now-identify-multiple-objects-in-an-image-180000385.html",
          "published_at": "Wed, 25 Feb 2026 18:00:00 +0000",
          "title": "Google's Circle to Search can now identify multiple objects in an image",
          "standfirst": "To coincide with the release of Samsung's new Galaxy S26 family of phones, Google is pushing out a small but meaningful update to Circle to Search. As a reminder, Circle to Search allows you to carry out a Google Search from almost anywhere on your phone. Just tap and hold your device's home button, and then circle the passage or image you want to know more about. With previous iterations of Circle to Search, the tool's underlying AI system was limited to searching against a single object in an image. Now, thanks to Gemini 3, it can scan and identify multiple objects at the same time. Naturally, Google is quick to point out the boon this represents for shopaholics. If you see a fit you like on Instagram, you can circle an entire person and the tool will attempt to find a match for each item they're wearing, including any shoes and accessories. At the same time, Google has made it easier to see how those clothes might look on you by bringing its virtual try on feature directly inside of Circle to Search. The benefits of the new model aren't only limited to shopping queries. Building on a search technique Google debuted with AI Mode, Circle to Search can now also reason through the relationship between different objects in an image. So say you see a photo of a coral reef and want to know how all the different pictured fish live together, Circle to Search will not only be able to identify the different species shown but also explain how they coexist with one another. Google is bringing the new and improved Circle to Search to Galaxy S26 and Pixel 10 phones first before rolling it out to more Android devices soon. This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/googles-circle-to-search-can-now-identify-multiple-objects-in-an-image-180000385.html?src=rss",
          "content": "To coincide with the release of Samsung's new Galaxy S26 family of phones, Google is pushing out a small but meaningful update to Circle to Search. As a reminder, Circle to Search allows you to carry out a Google Search from almost anywhere on your phone. Just tap and hold your device's home button, and then circle the passage or image you want to know more about. With previous iterations of Circle to Search, the tool's underlying AI system was limited to searching against a single object in an image. Now, thanks to Gemini 3, it can scan and identify multiple objects at the same time. Naturally, Google is quick to point out the boon this represents for shopaholics. If you see a fit you like on Instagram, you can circle an entire person and the tool will attempt to find a match for each item they're wearing, including any shoes and accessories. At the same time, Google has made it easier to see how those clothes might look on you by bringing its virtual try on feature directly inside of Circle to Search. The benefits of the new model aren't only limited to shopping queries. Building on a search technique Google debuted with AI Mode, Circle to Search can now also reason through the relationship between different objects in an image. So say you see a photo of a coral reef and want to know how all the different pictured fish live together, Circle to Search will not only be able to identify the different species shown but also explain how they coexist with one another. Google is bringing the new and improved Circle to Search to Galaxy S26 and Pixel 10 phones first before rolling it out to more Android devices soon. This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/googles-circle-to-search-can-now-identify-multiple-objects-in-an-image-180000385.html?src=rss",
          "feed_position": 19
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/smartphones/samsung-galaxy-s26-ultra-hands-on-meaningful-tweaks-plus-a-slick-new-privacy-display-180000057.html",
          "published_at": "Wed, 25 Feb 2026 18:00:00 +0000",
          "title": "Samsung Galaxy S26 Ultra hands-on: Meaningful tweaks plus a slick new Privacy Display",
          "standfirst": "Last year, it felt like Samsung relied a bit too much on AI when trying to convince people to upgrade to its flagship phone. And while there’s no shortage of features that utilize machine learning on the new Galaxy S26 Ultra, it feels like Samsung has done a much better job of filling out the rest of the phone’s kit with fresh hardware, faster charging and a more cohesive design. It’s still rather expensive, but its price has stayed flat year-over-year at $1,300, which when combined with everything else makes it a much more attractive package than its predecessor. Design and displaySamsung’s Ultra phones are always going to be somewhat boxy and that’s OK. However, for the Galaxy S26 Ultra, the company’s top-of-the-line handset is getting a slightly curvier appearance thanks to rounder corners. There’s also a very (and I do mean very) small reduction in size that technically makes this version the thinnest and lightest Ultra to date (214 grams and 7.9mm thick). That said, considering the previous model weighed 218 grams and measured 8.2mm, it’s incredibly hard to feel a difference even when you know what you’re looking for. The two biggest changes to the S26 Ultra's exterior design are more rounded corners and an aluminum chassis instead of titanium like we got on the S25U. Sam Rutherford for EngadgetIn reality, the biggest exterior change is that Samsung has ditched the titanium frame from last year’s phone in favor of an Armor Aluminum chassis with Corning Gorilla Armor 2 panels in front and back. Samsung says this new design is meant to make the Ultra fit in better with its less expensive siblings while also making it easier to do things like color match the phone’s body to the rest of the device. Also, for anyone who keeps track of Samsung’s palette, the hero color for the S26 Ultra is a rather fetching shade of purple called cobalt violet, with sky blue, white and black available as well (plus silver shadow and pink gold being Samsung’s online exclusive hues).If you look closely at the top of the phone, you can see where a notification has been blacked out by the S26 Ultra's Privacy Display. Sam Rutherford for EngadgetHowever, my favorite new thing on the S26 Ultra is its Privacy Display. When activated, it functions a lot like HP’s Sure View tech, which prevents people from peeking at your screen from acute angles. It works both when viewed from the side or up and down and has a surprising amount of customization. Not only can you set it to turn on automatically when the phone asks you for a password or PIN, it can also be triggered by specific apps or whenever you receive a notification. But perhaps the most impressive thing is that there’s almost no impact on image quality. When Privacy Display is active, there is a minor reduction in overall brightness, but aside from that, it’s really hard to tell when it’s on (at least from the front). Furthermore, the S26 Ultra’s 6.9-inch AMOLED screen has the same underlying specs as last year, including its 120Hz variable refresh rate and 2,600 nit peak brightness, so there are pretty much no trade-offs for the added functionality. Performance and chargingThe S26 Ultra still comes with an included S-Pen and a built-in storage slot, but it still doesn't have Bluetooth connectivity like on some of Samsung's older models. Sam Rutherford for EngadgetInside, the S26 Ultra features a Qualcomm Snapdragon 8 Elite Gen 5 for Galaxy chip along with either 12GB or 16GB of RAM and up to 1TB of storage. Compared to its predecessor, Samsung claims the NPU’s performance has made the biggest leap with it being 39 percent more powerful year-over-year with respectable increases for its CPU (19 percent faster) and GPU (24 percent faster) as well.As for charging, both wired and wireless speeds have gotten a big boost with the former now rated at up to 60 watts (up from 45 watts) or 25 watts (up from 15) for the latter when using compatible Qi2 pads. Samsung says buyers will even get a three amp cable in the box, so all you need to do to get those peak wired speeds is to hook it up to the right adapter.A small quirk with the S26 Ultra's S-Pen is that because the end of the stylus is curved to match the corner of the phone, if you put it in \"wrong,\" it'll stick out a bit. Sam Rutherford for EngadgetUnfortunately, we’re still not getting a magnetic ring inside the phone, which means if you want to use the S26 Ultra with magnetic accessories, you’ll need to pair the phone with a case that supports that functionality. This is super frustrating because Samsung says this decision was made in part to keep the handset as thin as possible, but when you consider the difference between the S26 Ultra and the S25 Ultra is 0.3mm, that choice feels rather misguided. CamerasOne of my biggest complaints about last year’s S25 Ultra is that the only new hardware was an updated 50MP sensor for its ultra-wide lens, which is the camera I (and probably most people) use the least. Thankfully, it seems Samsung took note of that because while the resolution of its 200MP main cam, 10MP 3x telephoto and 50MP 5X telephoto are the same as before, the S26 Ultra’s main and 5x zoom lenses now have significantly wider apertures (from f/1.7 to f/1.4 and f/3.4 to f/2.9, respectively). This results in as much as 47 percent more light reaching the phone’s primary sensor (or 37 percent for the 5x telephoto), which should result in some major gains in photo quality and low light sensitivity. That said, I wasn’t able to properly test this during my hands-on session, so I’m going to reserve final judgement for a proper review. The S26 Ultra's 200MP main and 50MP 5x zoon lenses feature significantly larger apertures, which should deliver much improved image quality in low light conditions. Sam Rutherford for EngadgetMeanwhile, for video capture, Samsung is adding support for the APV codec at up to 8K/30 fps to the S26 Ultra along with a new horizon lock feature that will keep your footage level no matter how much you rotate the phone. Now I will admit that the latter didn’t impress me much when I first heard about it, but after testing it out and spinning the phone a full 360-degrees while recording a clip, I was shocked when the resulting video showed no hint of being whirled around. Samsung also says the handset’s improved Nightography processing uses AI to recognize noise patterns in low light to improve image quality. But similar to the wider apertures bringing in more light, I’ll believe it when I see it. Finally, there’s a new AI-powered Photo Assist tool that lets you edit or adjust images using natural language prompts. From what I experienced, it’s effective and works as you’d expect. However, with the proliferation of services and devices offering similar functionality over the past year, this feature feels more like Samsung’s attempt to keep up with the Joneses. AI featuresWhen it comes to AI, the S26 Ultra is getting the same batch of new and improved features as the rest of the S26 family. So if you’re big into machine learning, there’s no need to pay extra for this model. Furthermore, many of the updates for 2026 are tweaks or refinements of existing things like the Gallery app, which now uses AI to automatically sort screenshots into eight different categories so they’re easier to find later. There’s also what Samsung is calling Now Nudge, which functions a lot like Google’s Magic Cue. It’s built into the Samsung keyboard and it can do things like suggest relevant photos based on your conversations. One of the S26's most powerful new AI features is Automated App Actions, which allows the phone to do things like book a car ride via Uber while you continue to use other apps in the foreground. Sam Rutherford for EngadgetTo me, the most impressive of the bunch is the S26’s Automated App Actions, which allow you to ask the phone to do slightly more complicated tasks like ordering an Uber to a specific location. After your initial prompt, Gemini can even complete the task in the background while you go back to doomscrolling or watching videos. When it’s done, you’ll get a notification so you can manually review and confirm the command. Unfortunately, Uber will be the only supported app at launch, though Samsung says it’s working on expanding the feature to others like Instacart. Early thoughtsThe Galaxy S26 Ultra will be available in four main colors: sky blue, black, cobalt violet and white, along with two more online exclusive hues in silver shadow and pink gold. Sam Rutherford for EngadgetLook, there’s no getting around it: $1,300 is a lot to spend on a phone. That said, considering the RAM shortage that’s going on right now, keeping the S26 Ultra’s price the same as last year’s phone feels like a small blessing. And when you get that on a handset with a more refined design, a beefier chip, a fancy Privacy Display, faster charging and an updated generation of AI-powered tools, Samsung’s latest flagship feels like a much better deal than its predecessor. Really, the only thing that hasn’t been improved is the Ultra’s S-Pen, which as time goes on, is starting to feel more and more like a consolation prize for people who are still nostalgic about the Note line than a true tentpole feature. Now this doesn’t mean that people with an S25 Ultra or even an S24 Ultra should run out and upgrade. But for anyone with something older than that who’s in the market for a true do-everything phone, the S26 Ultra has quite a bit to offer. Pre-orders for the Galaxy S26 Ultra are live now, with official sales slated for March 11. This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/samsung-galaxy-s26-ultra-hands-on-meaningful-tweaks-plus-a-slick-new-privacy-display-180000057.html?src=rss",
          "content": "Last year, it felt like Samsung relied a bit too much on AI when trying to convince people to upgrade to its flagship phone. And while there’s no shortage of features that utilize machine learning on the new Galaxy S26 Ultra, it feels like Samsung has done a much better job of filling out the rest of the phone’s kit with fresh hardware, faster charging and a more cohesive design. It’s still rather expensive, but its price has stayed flat year-over-year at $1,300, which when combined with everything else makes it a much more attractive package than its predecessor. Design and displaySamsung’s Ultra phones are always going to be somewhat boxy and that’s OK. However, for the Galaxy S26 Ultra, the company’s top-of-the-line handset is getting a slightly curvier appearance thanks to rounder corners. There’s also a very (and I do mean very) small reduction in size that technically makes this version the thinnest and lightest Ultra to date (214 grams and 7.9mm thick). That said, considering the previous model weighed 218 grams and measured 8.2mm, it’s incredibly hard to feel a difference even when you know what you’re looking for. The two biggest changes to the S26 Ultra's exterior design are more rounded corners and an aluminum chassis instead of titanium like we got on the S25U. Sam Rutherford for EngadgetIn reality, the biggest exterior change is that Samsung has ditched the titanium frame from last year’s phone in favor of an Armor Aluminum chassis with Corning Gorilla Armor 2 panels in front and back. Samsung says this new design is meant to make the Ultra fit in better with its less expensive siblings while also making it easier to do things like color match the phone’s body to the rest of the device. Also, for anyone who keeps track of Samsung’s palette, the hero color for the S26 Ultra is a rather fetching shade of purple called cobalt violet, with sky blue, white and black available as well (plus silver shadow and pink gold being Samsung’s online exclusive hues).If you look closely at the top of the phone, you can see where a notification has been blacked out by the S26 Ultra's Privacy Display. Sam Rutherford for EngadgetHowever, my favorite new thing on the S26 Ultra is its Privacy Display. When activated, it functions a lot like HP’s Sure View tech, which prevents people from peeking at your screen from acute angles. It works both when viewed from the side or up and down and has a surprising amount of customization. Not only can you set it to turn on automatically when the phone asks you for a password or PIN, it can also be triggered by specific apps or whenever you receive a notification. But perhaps the most impressive thing is that there’s almost no impact on image quality. When Privacy Display is active, there is a minor reduction in overall brightness, but aside from that, it’s really hard to tell when it’s on (at least from the front). Furthermore, the S26 Ultra’s 6.9-inch AMOLED screen has the same underlying specs as last year, including its 120Hz variable refresh rate and 2,600 nit peak brightness, so there are pretty much no trade-offs for the added functionality. Performance and chargingThe S26 Ultra still comes with an included S-Pen and a built-in storage slot, but it still doesn't have Bluetooth connectivity like on some of Samsung's older models. Sam Rutherford for EngadgetInside, the S26 Ultra features a Qualcomm Snapdragon 8 Elite Gen 5 for Galaxy chip along with either 12GB or 16GB of RAM and up to 1TB of storage. Compared to its predecessor, Samsung claims the NPU’s performance has made the biggest leap with it being 39 percent more powerful year-over-year with respectable increases for its CPU (19 percent faster) and GPU (24 percent faster) as well.As for charging, both wired and wireless speeds have gotten a big boost with the former now rated at up to 60 watts (up from 45 watts) or 25 watts (up from 15) for the latter when using compatible Qi2 pads. Samsung says buyers will even get a three amp cable in the box, so all you need to do to get those peak wired speeds is to hook it up to the right adapter.A small quirk with the S26 Ultra's S-Pen is that because the end of the stylus is curved to match the corner of the phone, if you put it in \"wrong,\" it'll stick out a bit. Sam Rutherford for EngadgetUnfortunately, we’re still not getting a magnetic ring inside the phone, which means if you want to use the S26 Ultra with magnetic accessories, you’ll need to pair the phone with a case that supports that functionality. This is super frustrating because Samsung says this decision was made in part to keep the handset as thin as possible, but when you consider the difference between the S26 Ultra and the S25 Ultra is 0.3mm, that choice feels rather misguided. CamerasOne of my biggest complaints about last year’s S25 Ultra is that the only new hardware was an updated 50MP sensor for its ultra-wide lens, which is the camera I (and probably most people) use the least. Thankfully, it seems Samsung took note of that because while the resolution of its 200MP main cam, 10MP 3x telephoto and 50MP 5X telephoto are the same as before, the S26 Ultra’s main and 5x zoom lenses now have significantly wider apertures (from f/1.7 to f/1.4 and f/3.4 to f/2.9, respectively). This results in as much as 47 percent more light reaching the phone’s primary sensor (or 37 percent for the 5x telephoto), which should result in some major gains in photo quality and low light sensitivity. That said, I wasn’t able to properly test this during my hands-on session, so I’m going to reserve final judgement for a proper review. The S26 Ultra's 200MP main and 50MP 5x zoon lenses feature significantly larger apertures, which should deliver much improved image quality in low light conditions. Sam Rutherford for EngadgetMeanwhile, for video capture, Samsung is adding support for the APV codec at up to 8K/30 fps to the S26 Ultra along with a new horizon lock feature that will keep your footage level no matter how much you rotate the phone. Now I will admit that the latter didn’t impress me much when I first heard about it, but after testing it out and spinning the phone a full 360-degrees while recording a clip, I was shocked when the resulting video showed no hint of being whirled around. Samsung also says the handset’s improved Nightography processing uses AI to recognize noise patterns in low light to improve image quality. But similar to the wider apertures bringing in more light, I’ll believe it when I see it. Finally, there’s a new AI-powered Photo Assist tool that lets you edit or adjust images using natural language prompts. From what I experienced, it’s effective and works as you’d expect. However, with the proliferation of services and devices offering similar functionality over the past year, this feature feels more like Samsung’s attempt to keep up with the Joneses. AI featuresWhen it comes to AI, the S26 Ultra is getting the same batch of new and improved features as the rest of the S26 family. So if you’re big into machine learning, there’s no need to pay extra for this model. Furthermore, many of the updates for 2026 are tweaks or refinements of existing things like the Gallery app, which now uses AI to automatically sort screenshots into eight different categories so they’re easier to find later. There’s also what Samsung is calling Now Nudge, which functions a lot like Google’s Magic Cue. It’s built into the Samsung keyboard and it can do things like suggest relevant photos based on your conversations. One of the S26's most powerful new AI features is Automated App Actions, which allows the phone to do things like book a car ride via Uber while you continue to use other apps in the foreground. Sam Rutherford for EngadgetTo me, the most impressive of the bunch is the S26’s Automated App Actions, which allow you to ask the phone to do slightly more complicated tasks like ordering an Uber to a specific location. After your initial prompt, Gemini can even complete the task in the background while you go back to doomscrolling or watching videos. When it’s done, you’ll get a notification so you can manually review and confirm the command. Unfortunately, Uber will be the only supported app at launch, though Samsung says it’s working on expanding the feature to others like Instacart. Early thoughtsThe Galaxy S26 Ultra will be available in four main colors: sky blue, black, cobalt violet and white, along with two more online exclusive hues in silver shadow and pink gold. Sam Rutherford for EngadgetLook, there’s no getting around it: $1,300 is a lot to spend on a phone. That said, considering the RAM shortage that’s going on right now, keeping the S26 Ultra’s price the same as last year’s phone feels like a small blessing. And when you get that on a handset with a more refined design, a beefier chip, a fancy Privacy Display, faster charging and an updated generation of AI-powered tools, Samsung’s latest flagship feels like a much better deal than its predecessor. Really, the only thing that hasn’t been improved is the Ultra’s S-Pen, which as time goes on, is starting to feel more and more like a consolation prize for people who are still nostalgic about the Note line than a true tentpole feature. Now this doesn’t mean that people with an S25 Ultra or even an S24 Ultra should run out and upgrade. But for anyone with something older than that who’s in the market for a true do-everything phone, the S26 Ultra has quite a bit to offer. Pre-orders for the Galaxy S26 Ultra are live now, with official sales slated for March 11. This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/samsung-galaxy-s26-ultra-hands-on-meaningful-tweaks-plus-a-slick-new-privacy-display-180000057.html?src=rss",
          "feed_position": 20,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/s26-ultra-front-and-back-2.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/smartphones/samsungs-s26-and-s26-offer-familiar-designs-snapdragon-8-gen-5-chips-and-new-software-features-180000224.html",
          "published_at": "Wed, 25 Feb 2026 18:00:00 +0000",
          "title": "Samsung's S26 and S26+ offer familiar designs, Snapdragon 8 Gen 5 chips and new software features",
          "standfirst": "The wait is over. At its Unpacked event today, Samsung took the wraps off its new S26 family of phones. Unlike the S26 Ultra, the S26 and S26+ represent mostly iterative updates. Samsung has tweaked the design of the two devices, making it so they share the same rounded corners of their more expensive sibling. Additionally, the S26 has a slightly larger 6.3-inch AMOLED display and a higher capacity 4,300mAh battery inside. As for the S26+, it still has a 6.7-inch screen and 4,900mAh battery. Like in years past, Samsung is depending on new and expanded software capabilities rather than updated hardware to give the S26 and S26+'s cameras an edge over the competition. As before, both phones feature a 50-megapixel main camera, a 12MP ultra-wide and a 10MP telephoto with 3x optical zoom. For selfies, they’re equipped a 12MP front-facing camera. The company says its new Object Aware Engine will allow the front-facing cameras to deliver more pleasing portrait mode shots, with better rendering of skin tones and hair textures. For videos, Samsung has updated its Super Steady tech, making it capable of maintaining a 360-degree horizontal lock. The upgraded feature should make it easier to maintain a consistent level horizon while trying to record a video of a moving child or pet. A new feature named Auto Framing uses a machine learning algorithm to automatically tighten the frame while filming 4K and 8K clips. The S26 will be available in six different colorways, with the four pictured here available in store. Sam Rutherford for EngadgetAnd if you're a Snapdragon fan, you can rest easy. While some pre-release reports suggested Samsung was planning to use its new flagship Exynos chipset across the entire S26 line, North American and Japanese variants of the S26 and S26+ will once again ship with Qualcomm silicon instead. Specifically, the two phones come specced with the speedy Snapdragon 8 Elite Gen 5, which debuted alongside the OnePlus 15 in November 2025. It will be interesting to see how the new Exynos 2600 compares with its Snapdragon counterpart; the former is the world's first 2nm chipset. Over on the software front, Samsung has upgraded its suite of AI features. For instance, the company has made Now Brief capable of pulling from a wider variety of apps to generate more comprehensive daily summaries. Similarly, the company's handy Auto Eraser feature now works across streaming services like Netflix, allowing you to make it easier to hear dialogue in a greater variety of videos. The two phones will retail for $899 and $1,099, making them both $100 more expensive than their predecessors. They come standard with 12GB of RAM and 256GB of storage. Samsung will also offer 512GB variants, alongside six different colorways of each phone. In-store, you'll find the S26 and S26+ in purple, blue, black and white, with silver and rose gold being online exclusives. Pre-orders open today, with general availability to follow on March 11. This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/samsungs-s26-and-s26-offer-familiar-designs-snapdragon-8-gen-5-chips-and-new-software-features-180000224.html?src=rss",
          "content": "The wait is over. At its Unpacked event today, Samsung took the wraps off its new S26 family of phones. Unlike the S26 Ultra, the S26 and S26+ represent mostly iterative updates. Samsung has tweaked the design of the two devices, making it so they share the same rounded corners of their more expensive sibling. Additionally, the S26 has a slightly larger 6.3-inch AMOLED display and a higher capacity 4,300mAh battery inside. As for the S26+, it still has a 6.7-inch screen and 4,900mAh battery. Like in years past, Samsung is depending on new and expanded software capabilities rather than updated hardware to give the S26 and S26+'s cameras an edge over the competition. As before, both phones feature a 50-megapixel main camera, a 12MP ultra-wide and a 10MP telephoto with 3x optical zoom. For selfies, they’re equipped a 12MP front-facing camera. The company says its new Object Aware Engine will allow the front-facing cameras to deliver more pleasing portrait mode shots, with better rendering of skin tones and hair textures. For videos, Samsung has updated its Super Steady tech, making it capable of maintaining a 360-degree horizontal lock. The upgraded feature should make it easier to maintain a consistent level horizon while trying to record a video of a moving child or pet. A new feature named Auto Framing uses a machine learning algorithm to automatically tighten the frame while filming 4K and 8K clips. The S26 will be available in six different colorways, with the four pictured here available in store. Sam Rutherford for EngadgetAnd if you're a Snapdragon fan, you can rest easy. While some pre-release reports suggested Samsung was planning to use its new flagship Exynos chipset across the entire S26 line, North American and Japanese variants of the S26 and S26+ will once again ship with Qualcomm silicon instead. Specifically, the two phones come specced with the speedy Snapdragon 8 Elite Gen 5, which debuted alongside the OnePlus 15 in November 2025. It will be interesting to see how the new Exynos 2600 compares with its Snapdragon counterpart; the former is the world's first 2nm chipset. Over on the software front, Samsung has upgraded its suite of AI features. For instance, the company has made Now Brief capable of pulling from a wider variety of apps to generate more comprehensive daily summaries. Similarly, the company's handy Auto Eraser feature now works across streaming services like Netflix, allowing you to make it easier to hear dialogue in a greater variety of videos. The two phones will retail for $899 and $1,099, making them both $100 more expensive than their predecessors. They come standard with 12GB of RAM and 256GB of storage. Samsung will also offer 512GB variants, alongside six different colorways of each phone. In-store, you'll find the S26 and S26+ in purple, blue, black and white, with silver and rose gold being online exclusives. Pre-orders open today, with general availability to follow on March 11. This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/samsungs-s26-and-s26-offer-familiar-designs-snapdragon-8-gen-5-chips-and-new-software-features-180000224.html?src=rss",
          "feed_position": 21,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/s26-1.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/hacker-used-anthropics-claude-chatbot-to-attack-multiple-government-agencies-in-mexico-171237255.html",
          "published_at": "Wed, 25 Feb 2026 17:12:37 +0000",
          "title": "Hacker used Anthropic's Claude chatbot to attack multiple government agencies in Mexico",
          "standfirst": "Here's yet another troubling story about this \"golden\" era of AI. A hacker has exploited Anthropic's Claude chatbot to carry out attacks against Mexican government agencies, according to a report by Bloomberg. This resulted in the theft of 150GB of official government data, including taxpayer records, employee credentials and more. The hacker used Claude to find vulnerabilities in government networks and to write scripts to exploit them. It also tasked the chatbot with finding ways to automate data theft, as indicated by cybersecurity company Gambit Security. This started in December and continued for around a month. It looks like the hacker was able to essentially jailbreak Claude with prompts, finally bypassing the chatbot's guardrails. Claude originally refused the nefarious demands until eventually relenting. Hackers Used Anthropic’s Claude to Steal 150 GB of Mexican Government Data> Tell Claude you’re doing a bug bounty > Claude initially refused: > “That violates AI safety guidelines” > Hacker just kept asking > Claude: “OK, I’ll help” > Hacked the entire Mexican… pic.twitter.com/Qaux239K8t— Nawaz Haider (@nawaz0x1) February 25, 2026 \"In total, it produced thousands of detailed reports that included ready-to-execute plans, telling the human operator exactly which internal targets to attack next and what credentials to use,\" said Curtis Simpson, Gambit Security’s chief strategy officer. Anthropic has investigated the claims, disrupted the activity and banned all of the accounts involved, according to a company representative. The spokesperson also said that its latest model, Claude Opus 4.6, includes tools to disrupt this kind of misuse. It's also been reported that this hacker used ChatGPT to supplement the attacks, using OpenAI's chatbot to gather information on how to move through computer networks, determine which credentials were needed to access systems and how to avoid detection. OpenAI says it has identified attempts by the hacker to violate its usage policies and that the tools refused to comply. The hacker remains unidentified. The attacks haven't been attributed to a specific group, but Gambit Security did suggest they could be tied to a foreign government. It's also unclear what the hacker wants to do with all of that data. Mexico's national digital agency hasn't commented on the breach, but did note that cybersecurity is a priority. The state government of Jalisco denies that it was breached, saying only federal networks were impacted. However, Mexico's national electoral institute also denied any breaches or unauthorized access in recent months. It's worth noting that Gambit found at least 20 security vulnerabilities during its research that the country is likely not keen on highlighting. Anthropic just dropped the core commitment of its safety policy: the promise to not train models it couldn't prove were safe first.The new version commits to matching competitors on safety and publishing more transparency reports. But the actual constraint, \"we stop if we can't… pic.twitter.com/k5Zi6dHUMN— Raphael Pfeiffer (@raphpfei) February 25, 2026 This isn't the first time Claude has been used for a major cyberattack. Last year, hackers in China manipulated the tool into attempting to infiltrate dozens of global targets, several of which were successful. Anthropic just nixed its long-standing safety pledge, which committed to never train an AI system unless it could guarantee in advance that safety measures were adequate. So who knows what fresh hell the future will bring as the company's tools become more advanced.This article originally appeared on Engadget at https://www.engadget.com/ai/hacker-used-anthropics-claude-chatbot-to-attack-multiple-government-agencies-in-mexico-171237255.html?src=rss",
          "content": "Here's yet another troubling story about this \"golden\" era of AI. A hacker has exploited Anthropic's Claude chatbot to carry out attacks against Mexican government agencies, according to a report by Bloomberg. This resulted in the theft of 150GB of official government data, including taxpayer records, employee credentials and more. The hacker used Claude to find vulnerabilities in government networks and to write scripts to exploit them. It also tasked the chatbot with finding ways to automate data theft, as indicated by cybersecurity company Gambit Security. This started in December and continued for around a month. It looks like the hacker was able to essentially jailbreak Claude with prompts, finally bypassing the chatbot's guardrails. Claude originally refused the nefarious demands until eventually relenting. Hackers Used Anthropic’s Claude to Steal 150 GB of Mexican Government Data> Tell Claude you’re doing a bug bounty > Claude initially refused: > “That violates AI safety guidelines” > Hacker just kept asking > Claude: “OK, I’ll help” > Hacked the entire Mexican… pic.twitter.com/Qaux239K8t— Nawaz Haider (@nawaz0x1) February 25, 2026 \"In total, it produced thousands of detailed reports that included ready-to-execute plans, telling the human operator exactly which internal targets to attack next and what credentials to use,\" said Curtis Simpson, Gambit Security’s chief strategy officer. Anthropic has investigated the claims, disrupted the activity and banned all of the accounts involved, according to a company representative. The spokesperson also said that its latest model, Claude Opus 4.6, includes tools to disrupt this kind of misuse. It's also been reported that this hacker used ChatGPT to supplement the attacks, using OpenAI's chatbot to gather information on how to move through computer networks, determine which credentials were needed to access systems and how to avoid detection. OpenAI says it has identified attempts by the hacker to violate its usage policies and that the tools refused to comply. The hacker remains unidentified. The attacks haven't been attributed to a specific group, but Gambit Security did suggest they could be tied to a foreign government. It's also unclear what the hacker wants to do with all of that data. Mexico's national digital agency hasn't commented on the breach, but did note that cybersecurity is a priority. The state government of Jalisco denies that it was breached, saying only federal networks were impacted. However, Mexico's national electoral institute also denied any breaches or unauthorized access in recent months. It's worth noting that Gambit found at least 20 security vulnerabilities during its research that the country is likely not keen on highlighting. Anthropic just dropped the core commitment of its safety policy: the promise to not train models it couldn't prove were safe first.The new version commits to matching competitors on safety and publishing more transparency reports. But the actual constraint, \"we stop if we can't… pic.twitter.com/k5Zi6dHUMN— Raphael Pfeiffer (@raphpfei) February 25, 2026 This isn't the first time Claude has been used for a major cyberattack. Last year, hackers in China manipulated the tool into attempting to infiltrate dozens of global targets, several of which were successful. Anthropic just nixed its long-standing safety pledge, which committed to never train an AI system unless it could guarantee in advance that safety measures were adequate. So who knows what fresh hell the future will bring as the company's tools become more advanced.This article originally appeared on Engadget at https://www.engadget.com/ai/hacker-used-anthropics-claude-chatbot-to-attack-multiple-government-agencies-in-mexico-171237255.html?src=rss",
          "feed_position": 22
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/laptops/asus-proart-gopro-edition-px13-review-an-incredible-if-pricy-windows-creator-laptop-170016800.html",
          "published_at": "Wed, 25 Feb 2026 17:00:16 +0000",
          "title": "ASUS ProArt GoPro Edition PX13 review: An incredible if pricy Windows creator laptop",
          "standfirst": "With its ProArt lineup, ASUS has commendably addressed a glaring hole in the PC market by targeting video editors and other creative pros. Its latest model even uses a popular camera marque in its name: the ProArt GoPro Edition PX13. It’s a true co-branding exercise, with GoPro-like styling, a dedicated GoPro hotkey, mil-spec durability for extreme outdoor users and 12 months of GoPro’s Cloud Plus Premium. It has a lot going for it on the inside, too. The AMD Ryzen AI Max+ 395 processor offers 16 Zen 5 cores with integrated Radeon 8060S Graphics (40 cores) and AMD Ryzen AI with up to 50 NPU TOPS. It packs a relatively small but pixel-dense 13-inch 2,880 x 1,800 OLED convertible 360 touch display, 1TB of storage and an impressive 128GB of unified memory. The rub, as you might expect with all that RAM, is the price. The ProArt GoPro Edition PX13 costs $3,000, while a version with the same processor but half the memory is $2,800. That’s high-end MacBook Pro money, and while the ProArt is a good PC creator machine, it falls short of its Apple counterpart in terms of performance and usability. Design In place of the ProArt P13’s smooth lines, the ProArt GoPro Edition comes with a ribbed metal back that’s designed to look like the front of a GoPro Hero 13. It also has GoPro-like ridges on the hinge and plastic above the keyboard, along with GoPro and ProArt branding. The rugged design may appeal to the extreme sports crowd, but I’d prefer something a bit sleeker. The laptop is relatively light at 3.06 pounds, but the dedicated 200W power brick adds an extra pound of weight. Despite the small size, it offers MIL-STD 810H military-grade durability, so it can handle hot and humid conditions while surviving 500Hz vibrations and multiple four-inch drops while running. To help keep the laptop safe outside, ASUS includes a protective padded sleeve with a braided pouch to tuck a selfie stick or another accessory. Steve Dent for Engadget The 2,880 x 1,800 OLED touchscreen is nice but not super bright, with up to 400 nits of brightness or 500 nits in HDR mode. That’s the usual tradeoff for OLED compared to super bright MiniLED displays. However, it has deep blacks and very high color accuracy of Delta < 1 with 100 percent DCI-P3 coverage, along with Dolby Vision support, so it’s great for photo and video work or entertainment. The ProArt is a 360-degree convertible model and ships with an ASUS Pen and Pen charger. That makes it a good option for graphic artists who want to tent the screen or fold it around to use in tablet mode for sketching or painting. The ASUS Pen works well, and though it’s not as accurate as Wacom or other dedicated pen devices, it has nice haptic feedback when you perform actions in the app. The ProArt GoPro Edition’s keyboard is excellent, with a nice amount of travel for typing or gaming. The touchpad is also one of the better ones I’ve used on a PC thanks to the quality tactile feel. The top left of the touchpad contains ASUS’s control dial designed for jogging video footage or adjusting colors, but it’s a bit fussy and gimmicky. For ports, you get HDMI, 3.5mm audio, USB-A 3.2 and two USB-C 4.0 with power delivery that allow up to 130 watts of charging. The laptop weirdly comes with a microSD slot to load GoPro footage straight from the camera, but it would be better to have a regular SD port and microSD adapter. As for wireless and audio, it offers Wi-Fi 7, Bluetooth 5.4 and Dolby Atmos support. Performance Steve Dent for Engadget Built on TSMC’s 4nm line, the Ryzen AI Max+ 395 is AMD’s most powerful APU designed to blend performance and low power consumption. It’s married to a Radeon 8060S GPU with 40 compute units (equivalent to an NVIDIA RTX 4060, AMD says) that makes it ideal for creative chores, AI processing and gaming. This unit also comes with 128GB of unified LPDDR5X RAM that’s soldered directly to the motherboard, shared between the CPU and GPU. Given today’s RAM prices, that amount of memory no doubt contributes to the ProArt GoPro Edition’s high price. AMD finally got its act together for video encoding and decoding. The Ryzen AI Max+’s GPU supports most 8- and 10-bit MP4 codecs, including H.264, H.265, VP9 and AV1. That means you can play back nearly all MP4 or Quicktime camera video files in real time, including the 8K H.265 files recorded by a GoPro Hero 13. At the same time, the large number of cores and threads (16 and 32) helps the ProArt GoPro Edition render certain VFX and do color adjustments quickly. The 1TB of NVMe SSD storage is limited to PCIe 4.0, but it’s relatively speedy with 6.55 GB/s read and 5.86 GB/s write speeds — easily fast enough for 8K video playback. All of that made video work a breeze in DaVinci Resolve 20, Adobe Premiere Pro or GoPro’s Player that can be activated by a special hotkey on the ASUS laptop. Actions like color correction work in real time as well, and 4K H.264 exports can also be performed quickly. That said, some functions like OpenFX and stabilization would work better with a more powerful discrete GPU. Also, unlike my MacBook Pro, the ProArt GoPro Edition’s fans need to engage frequently under intense workloads, creating a lot of noise and killing the battery quickly if the unit isn’t plugged in. Steve Dent for Engadget For other apps, including Photoshop, Illustrator and Lightroom Classic, the ASUS ProArt is ideal. It’s very responsive and the touch display and pen support fine masking or drawing work, something you can’t do on a MacBook Pro. The ProArt also handles synthetic benchmarks well for a PC with an integrated GPU. The single/multi Geekbench 6 CPU score of 2,219/19,088 shows the benefit of 16 processor cores. The 93,108 Geekbench 6 GPU mark isn’t that far behind Acer’s NVIDIA RTX 5070-equipped Predator Titan 14 AI. Geekbench AI scores were also up there with the best laptops. However, Handbrake video encoding was slower than several MacBook M4 laptops I’ve tested. For gaming, it had some of the higher laptop scores I’ve seen on several 3DMark tests (Wildlife Extreme and Port Royal Ray Tracing). It also did pretty darn well on Cyberpunk 2077, hitting 82 fps at 1080p and 60 fps at 1440p in Ultra mode. Considering the machine’s small size, those framerates are really good. However, the laptop is held back gaming-wise by the OLED display that tops out at 500 nits and just 60Hz. A big benefit of the 128GB of fast unified memory is that you can run AI models locally for improved privacy. While the ProArt GoPro Edition normally allocates 64GB of memory to the CPU and splits the rest between the CPU and iGPU, you can dedicate up to 96GB of memory to the GPU for extra large AI applications via the MyASUS app. Another plus of this APU is the battery life. The ProArt GoPro Edition lasted a solid 11:31 hours on the PCMark 10 Modern Office battery rundown test, besting all rivals with similar performance. That tells me that AMD is narrowing the performance-per-watt gap with Apple’s silicon to improve gaming and content creation for PCs on battery power alone. Wrap-up Steve Dent for Engadget ASUS is one of the few PC manufacturers trying to compete with Apple in the creator market, and with the ProArt GoPro Edition laptop, it has largely succeeded. This model offers excellent performance and battery life, a huge amount of memory, a very nice OLED HDR display, a nice range of ports and an excellent keyboard and trackpad. It easily handled my typical video and photo editing chores, even on battery power alone, and the included GoPro features like the Storyblocks cloud storage are a nice option for action cam users. The convertible configuration and touchscreen with pen option are also useful to artists and photo editors. However, this laptop is not cheap at $3,000, which is the same price as a high-end 16-inch MacBook Pro M4 Pro. The latter offers superior battery life, better overall performance on apps like DaVinci Resolve and a far better macOS user experience than the hot mess that is currently Windows 11. However, if you want a Windows PC with a touchscreen, I think the ASUS ProArt GoPro Edition laptop is the best creator model you can get right now.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/asus-proart-gopro-edition-px13-review-an-incredible-if-pricy-windows-creator-laptop-170016800.html?src=rss",
          "content": "With its ProArt lineup, ASUS has commendably addressed a glaring hole in the PC market by targeting video editors and other creative pros. Its latest model even uses a popular camera marque in its name: the ProArt GoPro Edition PX13. It’s a true co-branding exercise, with GoPro-like styling, a dedicated GoPro hotkey, mil-spec durability for extreme outdoor users and 12 months of GoPro’s Cloud Plus Premium. It has a lot going for it on the inside, too. The AMD Ryzen AI Max+ 395 processor offers 16 Zen 5 cores with integrated Radeon 8060S Graphics (40 cores) and AMD Ryzen AI with up to 50 NPU TOPS. It packs a relatively small but pixel-dense 13-inch 2,880 x 1,800 OLED convertible 360 touch display, 1TB of storage and an impressive 128GB of unified memory. The rub, as you might expect with all that RAM, is the price. The ProArt GoPro Edition PX13 costs $3,000, while a version with the same processor but half the memory is $2,800. That’s high-end MacBook Pro money, and while the ProArt is a good PC creator machine, it falls short of its Apple counterpart in terms of performance and usability. Design In place of the ProArt P13’s smooth lines, the ProArt GoPro Edition comes with a ribbed metal back that’s designed to look like the front of a GoPro Hero 13. It also has GoPro-like ridges on the hinge and plastic above the keyboard, along with GoPro and ProArt branding. The rugged design may appeal to the extreme sports crowd, but I’d prefer something a bit sleeker. The laptop is relatively light at 3.06 pounds, but the dedicated 200W power brick adds an extra pound of weight. Despite the small size, it offers MIL-STD 810H military-grade durability, so it can handle hot and humid conditions while surviving 500Hz vibrations and multiple four-inch drops while running. To help keep the laptop safe outside, ASUS includes a protective padded sleeve with a braided pouch to tuck a selfie stick or another accessory. Steve Dent for Engadget The 2,880 x 1,800 OLED touchscreen is nice but not super bright, with up to 400 nits of brightness or 500 nits in HDR mode. That’s the usual tradeoff for OLED compared to super bright MiniLED displays. However, it has deep blacks and very high color accuracy of Delta < 1 with 100 percent DCI-P3 coverage, along with Dolby Vision support, so it’s great for photo and video work or entertainment. The ProArt is a 360-degree convertible model and ships with an ASUS Pen and Pen charger. That makes it a good option for graphic artists who want to tent the screen or fold it around to use in tablet mode for sketching or painting. The ASUS Pen works well, and though it’s not as accurate as Wacom or other dedicated pen devices, it has nice haptic feedback when you perform actions in the app. The ProArt GoPro Edition’s keyboard is excellent, with a nice amount of travel for typing or gaming. The touchpad is also one of the better ones I’ve used on a PC thanks to the quality tactile feel. The top left of the touchpad contains ASUS’s control dial designed for jogging video footage or adjusting colors, but it’s a bit fussy and gimmicky. For ports, you get HDMI, 3.5mm audio, USB-A 3.2 and two USB-C 4.0 with power delivery that allow up to 130 watts of charging. The laptop weirdly comes with a microSD slot to load GoPro footage straight from the camera, but it would be better to have a regular SD port and microSD adapter. As for wireless and audio, it offers Wi-Fi 7, Bluetooth 5.4 and Dolby Atmos support. Performance Steve Dent for Engadget Built on TSMC’s 4nm line, the Ryzen AI Max+ 395 is AMD’s most powerful APU designed to blend performance and low power consumption. It’s married to a Radeon 8060S GPU with 40 compute units (equivalent to an NVIDIA RTX 4060, AMD says) that makes it ideal for creative chores, AI processing and gaming. This unit also comes with 128GB of unified LPDDR5X RAM that’s soldered directly to the motherboard, shared between the CPU and GPU. Given today’s RAM prices, that amount of memory no doubt contributes to the ProArt GoPro Edition’s high price. AMD finally got its act together for video encoding and decoding. The Ryzen AI Max+’s GPU supports most 8- and 10-bit MP4 codecs, including H.264, H.265, VP9 and AV1. That means you can play back nearly all MP4 or Quicktime camera video files in real time, including the 8K H.265 files recorded by a GoPro Hero 13. At the same time, the large number of cores and threads (16 and 32) helps the ProArt GoPro Edition render certain VFX and do color adjustments quickly. The 1TB of NVMe SSD storage is limited to PCIe 4.0, but it’s relatively speedy with 6.55 GB/s read and 5.86 GB/s write speeds — easily fast enough for 8K video playback. All of that made video work a breeze in DaVinci Resolve 20, Adobe Premiere Pro or GoPro’s Player that can be activated by a special hotkey on the ASUS laptop. Actions like color correction work in real time as well, and 4K H.264 exports can also be performed quickly. That said, some functions like OpenFX and stabilization would work better with a more powerful discrete GPU. Also, unlike my MacBook Pro, the ProArt GoPro Edition’s fans need to engage frequently under intense workloads, creating a lot of noise and killing the battery quickly if the unit isn’t plugged in. Steve Dent for Engadget For other apps, including Photoshop, Illustrator and Lightroom Classic, the ASUS ProArt is ideal. It’s very responsive and the touch display and pen support fine masking or drawing work, something you can’t do on a MacBook Pro. The ProArt also handles synthetic benchmarks well for a PC with an integrated GPU. The single/multi Geekbench 6 CPU score of 2,219/19,088 shows the benefit of 16 processor cores. The 93,108 Geekbench 6 GPU mark isn’t that far behind Acer’s NVIDIA RTX 5070-equipped Predator Titan 14 AI. Geekbench AI scores were also up there with the best laptops. However, Handbrake video encoding was slower than several MacBook M4 laptops I’ve tested. For gaming, it had some of the higher laptop scores I’ve seen on several 3DMark tests (Wildlife Extreme and Port Royal Ray Tracing). It also did pretty darn well on Cyberpunk 2077, hitting 82 fps at 1080p and 60 fps at 1440p in Ultra mode. Considering the machine’s small size, those framerates are really good. However, the laptop is held back gaming-wise by the OLED display that tops out at 500 nits and just 60Hz. A big benefit of the 128GB of fast unified memory is that you can run AI models locally for improved privacy. While the ProArt GoPro Edition normally allocates 64GB of memory to the CPU and splits the rest between the CPU and iGPU, you can dedicate up to 96GB of memory to the GPU for extra large AI applications via the MyASUS app. Another plus of this APU is the battery life. The ProArt GoPro Edition lasted a solid 11:31 hours on the PCMark 10 Modern Office battery rundown test, besting all rivals with similar performance. That tells me that AMD is narrowing the performance-per-watt gap with Apple’s silicon to improve gaming and content creation for PCs on battery power alone. Wrap-up Steve Dent for Engadget ASUS is one of the few PC manufacturers trying to compete with Apple in the creator market, and with the ProArt GoPro Edition laptop, it has largely succeeded. This model offers excellent performance and battery life, a huge amount of memory, a very nice OLED HDR display, a nice range of ports and an excellent keyboard and trackpad. It easily handled my typical video and photo editing chores, even on battery power alone, and the included GoPro features like the Storyblocks cloud storage are a nice option for action cam users. The convertible configuration and touchscreen with pen option are also useful to artists and photo editors. However, this laptop is not cheap at $3,000, which is the same price as a high-end 16-inch MacBook Pro M4 Pro. The latter offers superior battery life, better overall performance on apps like DaVinci Resolve and a far better macOS user experience than the hot mess that is currently Windows 11. However, if you want a Windows PC with a touchscreen, I think the ASUS ProArt GoPro Edition laptop is the best creator model you can get right now.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/asus-proart-gopro-edition-px13-review-an-incredible-if-pricy-windows-creator-laptop-170016800.html?src=rss",
          "feed_position": 24,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2026-02/d21435b0-11a2-11f1-af6f-89080f78ba90"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/visual-imitation-learning-guidde-trains-ai-agents-on-human-expert-video",
          "published_at": "Wed, 25 Feb 2026 15:26:00 GMT",
          "title": "Visual imitation learning: Guidde trains AI agents on human 'expert video' instead of documentation",
          "standfirst": "For years, the \"last mile\" of digital transformation has been littered with forgotten PDFs and ignored training manuals. Organizations spend millions on sophisticated software like SAP or Salesforce, only for employees to struggle with basic navigation. Now, as the era of agentic AI arrives, companies face a double-edged sword: they must teach human employees to collaborate with AI, while simultaneously teaching AI agents to navigate the labyrinthine interfaces of the modern enterprise. One idea that seems to be gaining momentum among AI-forward businesses: using screen recordings and tutorials/walkthroughs of someone performing an enterprise task — be it creating a new ticket or processing an invoice — and training AI to replicate the flow based on the screen capture. Just this week, a startup called Standard Intelligence went viral on X showing an early demo of open-ended version of this for the physical and digital world.But the truth is, there are already players tackling this problem for the enterprise itself square-on: case-in-point, Guidde, an Israel startup born during the video-centric years of the COVID-19 pandemic, today announced an oversubscribed $50 million Series B funding round led by PSG Equity to address this exact knowledge infrastructure crisis. Instead of feeding an agent a static PDF manual, Guidde provides high-fidelity \"Video Ground Truth\"—a rich stream of data captured from real human experts as they navigate complex software.The investment signals a shift in how the tech industry views documentation—not as a static byproduct of work, but as the critical telemetry needed to train the next generation of autonomous digital agents.Technology: from video capture to world modelsAt its core, Guidde is an AI Digital Adoption Platform (ADAP). However, its technological breakthrough lies in what happens behind the scenes during a recording. Guidde isn&#x27;t just recording pixels; it is capturing every click, scroll, and latent interaction with the HTML page—the subtle pauses, the specific scroll depths, and the corrections a human makes when a system lags. This telemetry transforms raw video into a Vision-Language-Action (VLA) training set. Meanwhile, the platform&#x27;s Magic Redaction automatically obscures sensitive data like passwords or credit card numbers during capture, ensuring materials remain secure and HIPAA-aligned. \"Every time you click a button, you drag-and-drop, you scroll, you type, we gather the interaction... all of it, we do cleanse it—there&#x27;s no private information,\" explained Guidde co-founder and CEO Yoav Einav in an exclusive interview with VentureBeat.Under the hood, the platform captures the underlying metadata and DOM (Document Object Model) changes synchronized with the video frames. The differentiator is the telemetry hidden beneath the surface.This rich metadata creates a \"digital world model\" of enterprise software. And because each enterprise uses its own unique mix of apps and processes, Guidde is creating a data moat that allows enterprise agents to reason through legacy UIs with the same spatial awareness as a human, ensuring that automation actually works in a production environment rather than just a lab demo. For a human, it’s a tutorial. For an AI agent, it is a high-fidelity map of the interface. This allows agents to \"see\" and reason through complex UIs the way humans do, solving the \"last mile\" of automation where agents previously failed due to lack of specific enterprise and in-situ usage context.In a sense, Guidde is building a \"self-driving car\" like a Waymo for computer usage. Product: three pillars of Guidd-anceThe platform has evolved into three distinct products designed to scale with an organization&#x27;s maturity:Guidde Create: The engine for subject matter experts to turn workflows into documentation in minutes.Guidde Broadcast: A personalized recommendation engine—often compared to Netflix—that delivers answers inside the tools people actually use. It knows who the user is and what department they are in to surface relevant content exactly when needed.Guidde Discover: The newly launched \"agentic\" pillar. Like Waze mapping roads by observing drivers, Discover maps software routes by tracking how employees work. It understands the workflow, creates the content, and updates it automatically when the UI changes.Training humans how to use AI — and AI using humansThe most non-obvious aspect of Guidde’s growth is its dual-purpose mission. \"We&#x27;re the only platform that trains both humans and agents,\" Einav stated.As companies roll out AI tools like Microsoft 365 Copilot or ServiceNow agents, they hit a proficiency gap. One of Guidde’s largest customers revealed they were paying over $1 million a year for a sophisticated AI tool, yet \"nobody knows how to use them because they did like a 30-minute training session, and then that’s it.\" Guidde closes this gap by providing \"bite-sized\" video tutorials in the flow of work.Simultaneously, these videos train the AI agents themselves. Foundation models like Gemini or GPT-4 often hallucinate when tasked with specific enterprise workflows because they weren&#x27;t trained on the highly specific, internal \"vanilla workflows\" found in private enterprise systems. Guidde provides the \"starting point,\" the \"metadata,\" and the \"x, y coordinates of the button\" that an agent needs to complete an action without getting stuck.The multimodal advantageTo maintain this level of accuracy, Guidde employs a multimodal infrastructure. The system doesn&#x27;t rely on a single model; instead, it uses a \"fleet\" of models that evaluate one another.Google Gemini: Generally used for visual tasks like analyzing PDFs or PowerPoints.Anthropic Claude: Leveraged for writing the storyline and narrative scripts.Feedback Loops: When a user edits a video, that data is fed back into the model to prevent the same mistakes from occurring in future captures.This approach allows Guidde to replace a legacy stack of six or seven disconnected tools—Loom for capture, Adobe Premiere for editing, 11Labs for text-to-speech, and Synthesia for avatars—with a single, AI-native platform. \"We basically pack everything for you,\" Einav says, \"and automate the entire process based on your brand guidelines.\"Video-first origin storyThe genesis of Guidde lies in a frustration familiar to any product leader. Before founding the company, Einav and co-founder Dan Sahar spent years mastering video traffic at Qwilt, a company they started in 2010 to analyze how people watched Netflix and Disney+. When COVID-19 hit, they saw a massive opportunity to apply that video expertise to the workplace. They observed that short video explainers could increase free-to-paid account conversions by 30%, but the friction of creating them was unsustainable.In an interview, Einav recalled the \"tedious work\" of the old world: \"My team in Israel were creating the content, someone in the US with a US accent was doing the narration, someone in the marketing team would write the script... and someone in the enablement team would do the edit.\" This fragmented workflow meant a single video took two to three weeks to produce. \"And then two weeks later, the product changes, and you need to redo it from scratch,\" Einav added.Guidde was built to collapse this cycle into seconds. By automating the \"Magic Capture\" of a workflow, the platform generates a structured narrative script and professional AI voiceover instantly. This removes the editing bottleneck, transforming subject matter experts into \"training powerhouses.\"Licensing and market impactGuidde’s pricing structure reflects its transition from a utility to a core piece of enterprise infrastructure:Free: $0 (Up to 25 videos, web-app support).Pro: $18/creator/month (Unlimited videos, brand kits).Business: $39/creator/month (Unlimited text-to-voice, analytics).Enterprise: Custom pricing (Multi-language translation, SSO, Magic Redaction).The platform&#x27;s impact is already visible in the numbers: a 41% reduction in video creation time and 34% fewer inbound support tickets. For customers like Emerson, this translates to 40–60% quicker guide creation. Support teams, in particular, are finding they can offload 80% of their ticket volume with agents—but only if those agents have the content to be useful. \"The agent without the content is useless,\" Einav warns, noting that most enterprise documentation is either years out of date or entirely undocumented.Community and industry early receptionGuidde already claims 4,500 enterprise customers and seeks to expand this number with its new round of funding. Support and operations leaders have been vocal about the platform&#x27;s ease of use. Christopher Cummings, VP of Client Experience at DocNetwork, highlighted its ability to provide \"quick, personalized video responses to customer questions.\" Meanwhile, Wren Cotrone, a Director of Customer Support, noted that \"Once you set the branding the way you want, you can really zoom through this stuff.\"Ronen Nir, Managing Director at PSG, summarized the investment thesis: \"Guidde is solving one of the biggest blockers to successful AI adoption: the knowledge infrastructure.\"Why this matters nowThe paradigm shift from text-only LLMs to agentic video intelligence is the defining trend of 2026. Guidde’s Series B signals that the \"ground truth\" for enterprise agents will come from raw video observation, not static documentation.By capturing how work gets done across 10s of millions of workflows, Guidde is building a dataset that few others possess. As Einav put it: \"It starts with humans in the loop, and over time moves toward full autonomy.\" For the modern enterprise, the map is no longer a static document—it’s a living, breathing video intelligence layer that guides both the workforce and the agents that support them.",
          "content": "For years, the \"last mile\" of digital transformation has been littered with forgotten PDFs and ignored training manuals. Organizations spend millions on sophisticated software like SAP or Salesforce, only for employees to struggle with basic navigation. Now, as the era of agentic AI arrives, companies face a double-edged sword: they must teach human employees to collaborate with AI, while simultaneously teaching AI agents to navigate the labyrinthine interfaces of the modern enterprise. One idea that seems to be gaining momentum among AI-forward businesses: using screen recordings and tutorials/walkthroughs of someone performing an enterprise task — be it creating a new ticket or processing an invoice — and training AI to replicate the flow based on the screen capture. Just this week, a startup called Standard Intelligence went viral on X showing an early demo of open-ended version of this for the physical and digital world.But the truth is, there are already players tackling this problem for the enterprise itself square-on: case-in-point, Guidde, an Israel startup born during the video-centric years of the COVID-19 pandemic, today announced an oversubscribed $50 million Series B funding round led by PSG Equity to address this exact knowledge infrastructure crisis. Instead of feeding an agent a static PDF manual, Guidde provides high-fidelity \"Video Ground Truth\"—a rich stream of data captured from real human experts as they navigate complex software.The investment signals a shift in how the tech industry views documentation—not as a static byproduct of work, but as the critical telemetry needed to train the next generation of autonomous digital agents.Technology: from video capture to world modelsAt its core, Guidde is an AI Digital Adoption Platform (ADAP). However, its technological breakthrough lies in what happens behind the scenes during a recording. Guidde isn&#x27;t just recording pixels; it is capturing every click, scroll, and latent interaction with the HTML page—the subtle pauses, the specific scroll depths, and the corrections a human makes when a system lags. This telemetry transforms raw video into a Vision-Language-Action (VLA) training set. Meanwhile, the platform&#x27;s Magic Redaction automatically obscures sensitive data like passwords or credit card numbers during capture, ensuring materials remain secure and HIPAA-aligned. \"Every time you click a button, you drag-and-drop, you scroll, you type, we gather the interaction... all of it, we do cleanse it—there&#x27;s no private information,\" explained Guidde co-founder and CEO Yoav Einav in an exclusive interview with VentureBeat.Under the hood, the platform captures the underlying metadata and DOM (Document Object Model) changes synchronized with the video frames. The differentiator is the telemetry hidden beneath the surface.This rich metadata creates a \"digital world model\" of enterprise software. And because each enterprise uses its own unique mix of apps and processes, Guidde is creating a data moat that allows enterprise agents to reason through legacy UIs with the same spatial awareness as a human, ensuring that automation actually works in a production environment rather than just a lab demo. For a human, it’s a tutorial. For an AI agent, it is a high-fidelity map of the interface. This allows agents to \"see\" and reason through complex UIs the way humans do, solving the \"last mile\" of automation where agents previously failed due to lack of specific enterprise and in-situ usage context.In a sense, Guidde is building a \"self-driving car\" like a Waymo for computer usage. Product: three pillars of Guidd-anceThe platform has evolved into three distinct products designed to scale with an organization&#x27;s maturity:Guidde Create: The engine for subject matter experts to turn workflows into documentation in minutes.Guidde Broadcast: A personalized recommendation engine—often compared to Netflix—that delivers answers inside the tools people actually use. It knows who the user is and what department they are in to surface relevant content exactly when needed.Guidde Discover: The newly launched \"agentic\" pillar. Like Waze mapping roads by observing drivers, Discover maps software routes by tracking how employees work. It understands the workflow, creates the content, and updates it automatically when the UI changes.Training humans how to use AI — and AI using humansThe most non-obvious aspect of Guidde’s growth is its dual-purpose mission. \"We&#x27;re the only platform that trains both humans and agents,\" Einav stated.As companies roll out AI tools like Microsoft 365 Copilot or ServiceNow agents, they hit a proficiency gap. One of Guidde’s largest customers revealed they were paying over $1 million a year for a sophisticated AI tool, yet \"nobody knows how to use them because they did like a 30-minute training session, and then that’s it.\" Guidde closes this gap by providing \"bite-sized\" video tutorials in the flow of work.Simultaneously, these videos train the AI agents themselves. Foundation models like Gemini or GPT-4 often hallucinate when tasked with specific enterprise workflows because they weren&#x27;t trained on the highly specific, internal \"vanilla workflows\" found in private enterprise systems. Guidde provides the \"starting point,\" the \"metadata,\" and the \"x, y coordinates of the button\" that an agent needs to complete an action without getting stuck.The multimodal advantageTo maintain this level of accuracy, Guidde employs a multimodal infrastructure. The system doesn&#x27;t rely on a single model; instead, it uses a \"fleet\" of models that evaluate one another.Google Gemini: Generally used for visual tasks like analyzing PDFs or PowerPoints.Anthropic Claude: Leveraged for writing the storyline and narrative scripts.Feedback Loops: When a user edits a video, that data is fed back into the model to prevent the same mistakes from occurring in future captures.This approach allows Guidde to replace a legacy stack of six or seven disconnected tools—Loom for capture, Adobe Premiere for editing, 11Labs for text-to-speech, and Synthesia for avatars—with a single, AI-native platform. \"We basically pack everything for you,\" Einav says, \"and automate the entire process based on your brand guidelines.\"Video-first origin storyThe genesis of Guidde lies in a frustration familiar to any product leader. Before founding the company, Einav and co-founder Dan Sahar spent years mastering video traffic at Qwilt, a company they started in 2010 to analyze how people watched Netflix and Disney+. When COVID-19 hit, they saw a massive opportunity to apply that video expertise to the workplace. They observed that short video explainers could increase free-to-paid account conversions by 30%, but the friction of creating them was unsustainable.In an interview, Einav recalled the \"tedious work\" of the old world: \"My team in Israel were creating the content, someone in the US with a US accent was doing the narration, someone in the marketing team would write the script... and someone in the enablement team would do the edit.\" This fragmented workflow meant a single video took two to three weeks to produce. \"And then two weeks later, the product changes, and you need to redo it from scratch,\" Einav added.Guidde was built to collapse this cycle into seconds. By automating the \"Magic Capture\" of a workflow, the platform generates a structured narrative script and professional AI voiceover instantly. This removes the editing bottleneck, transforming subject matter experts into \"training powerhouses.\"Licensing and market impactGuidde’s pricing structure reflects its transition from a utility to a core piece of enterprise infrastructure:Free: $0 (Up to 25 videos, web-app support).Pro: $18/creator/month (Unlimited videos, brand kits).Business: $39/creator/month (Unlimited text-to-voice, analytics).Enterprise: Custom pricing (Multi-language translation, SSO, Magic Redaction).The platform&#x27;s impact is already visible in the numbers: a 41% reduction in video creation time and 34% fewer inbound support tickets. For customers like Emerson, this translates to 40–60% quicker guide creation. Support teams, in particular, are finding they can offload 80% of their ticket volume with agents—but only if those agents have the content to be useful. \"The agent without the content is useless,\" Einav warns, noting that most enterprise documentation is either years out of date or entirely undocumented.Community and industry early receptionGuidde already claims 4,500 enterprise customers and seeks to expand this number with its new round of funding. Support and operations leaders have been vocal about the platform&#x27;s ease of use. Christopher Cummings, VP of Client Experience at DocNetwork, highlighted its ability to provide \"quick, personalized video responses to customer questions.\" Meanwhile, Wren Cotrone, a Director of Customer Support, noted that \"Once you set the branding the way you want, you can really zoom through this stuff.\"Ronen Nir, Managing Director at PSG, summarized the investment thesis: \"Guidde is solving one of the biggest blockers to successful AI adoption: the knowledge infrastructure.\"Why this matters nowThe paradigm shift from text-only LLMs to agentic video intelligence is the defining trend of 2026. Guidde’s Series B signals that the \"ground truth\" for enterprise agents will come from raw video observation, not static documentation.By capturing how work gets done across 10s of millions of workflows, Guidde is building a dataset that few others possess. As Einav put it: \"It starts with humans in the loop, and over time moves toward full autonomy.\" For the modern enterprise, the map is no longer a static document—it’s a living, breathing video intelligence layer that guides both the workforce and the agents that support them.",
          "feed_position": 2,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/7aRuhvTOYDPSfw1YxZsPww/95806d3437bcc72e4a9738d274f55853/cVNbB5uAbGAiRkyBBomOn_QZucEvrO.jpg?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/technology/gong-launches-mission-andromeda-with-ai-sales-coaching-chatbot-and-open-mcp",
          "published_at": "Wed, 25 Feb 2026 10:30:00 GMT",
          "title": "Gong launches ‘Mission Andromeda’ with AI sales coaching, chatbot and open MCP connections to rivals",
          "standfirst": "Gong, the revenue intelligence company that has spent a decade turning recorded sales calls into data, today launched what it calls Mission Andromeda — its most ambitious platform release to date, bundling a new AI-powered coaching product, a sales-focused chatbot, unified account management tools, and open interoperability with rival AI systems through the Model Context Protocol.The release arrives at a pivotal moment. The revenue technology market is consolidating at a pace that would have been unthinkable two years ago, and Gong — still a private company with roughly $300 million in annual recurring revenue — finds itself at the center of a category that Gartner only formally defined three months ago. Mission Andromeda is Gong&#x27;s answer to a basic question facing every enterprise AI vendor in 2026: Can you move beyond surfacing insights and actually change how people work?\"The whole show, Andromeda, is basically a collection of very significant capabilities that take us a huge step forward,\" Eilon Reshef, Gong&#x27;s co-founder and chief product officer, told VentureBeat in an interview ahead of the launch. He described it as an effort to make revenue teams \"more productive as individuals\" and to give leaders \"better decisions\" — positioning the release not as a feature dump, but as an operating system upgrade.The new products target every layer of the sales workflow, from coaching to account managementMission Andromeda contains four main components, each targeting a different layer of the sales workflow.The headliner is Gong Enable, a brand-new product with its own pricing tier — Reshef described it as \"in the tens of dollars per seat per month\" — that attacks what the company sees as a gaping hole in most sales organizations: the disconnect between training and performance. Highspot and Seismic announced their intent to merge in February 2026, creating a combined enablement giant, and Gong is now moving directly onto their turf.Gong Enable has three pieces. The first, AI Call Reviewer, analyzes completed customer calls and grades reps based on their organization&#x27;s own methodology. When asked whether this operates in real time, Reshef was direct: \"For that particular agent, it&#x27;s post-call, because obviously you want to grade the whole call as a whole — maybe you didn&#x27;t do anything in minute one, minute 30.\" The second piece, AI Trainer, lets reps practice high-stakes conversations — pricing objections, renewal risk scenarios — against AI-generated simulations built from the company&#x27;s own winning call patterns. The third, Initiative Tracking, links coaching programs to revenue metrics so leaders can see whether new behaviors actually show up in live deals.Beyond Enable, the launch includes Gong Assistant, a conversational AI chatbot purpose-built for revenue teams that lets users ask questions about customer calls inside the platform. The release also introduces Account Console and Account Boards, which unify customer activity, risk signals, and next steps into a single view for sales and post-sales teams. And rounding out the package is built-in support for the Model Context Protocol, the open standard originally developed by Anthropic, enabling Gong to exchange data with AI systems from Microsoft, Salesforce, HubSpot, and others.Gong uses four different LLM providers and says the real moat is the data, not the modelsIn a market where every company wants to claim proprietary AI supremacy, Reshef described a notably pragmatic approach to the models powering the new features. Gong uses both internal models and foundation models from external providers, he said, noting that \"four out of the five leading AI companies, LLM, are basically Gong customers.\"The company picks models task by task. \"Based on the product or task at hand, we pick the right model,\" he said. \"We would sometimes swap in and out a model if we feel it&#x27;s best for our customers and they get more and more power.\" Reshef drew a clear line between what needs a large language model and what does not: \"Our revenue prediction models are not using LLMs, but kind of the core interaction chatbots — of course, you&#x27;re going to use the foundation model.\"This approach contrasts with competitors that have hitched their wagon to a single AI provider. It also reflects a philosophical choice: Gong&#x27;s real moat, Reshef suggested, is not the models themselves but the data underneath — what the company calls the Revenue Graph, its proprietary layer that captures phone calls, Zoom meetings, emails, text messages, WhatsApp conversations, and more, stitching them together into a connected intelligence layer.Recording every sales conversation raises obvious privacy questions, and Gong says it has spent a decade answering themStoring and analyzing every customer conversation a sales team has raises obvious questions about privacy and data governance. Reshef was eager to address them head-on.\"We&#x27;ve been around the block for a long while — a little bit over a decade — with AI first,\" he said. \"Over the years, we&#x27;ve developed exactly those capabilities that are the most boring pieces of AI, which is: how do you collect the right data? How do you manage it? How do you manage permissions about it, retention policies, right to be forgotten?\"On the sensitive question of whether Gong trains its AI on customer data across accounts, Reshef drew a firm boundary. Training, he explained, happens per customer: \"The majority of the training happens based on each customer&#x27;s data.\" He pointed to large accounts like Cisco, which he said has 20,000 Gong users — enough data to train the AI Trainer from within their own environment. \"AI Trainer can go mine what&#x27;s working in their environment. It might not work in their competitor&#x27;s environment — maybe their benefits are different, their objections are different.\"Cross-customer training, he said, happens \"only in very, very rare cases, very safe based — like transcription. But we don&#x27;t do it for business-specific processes.\"MCP gives Gong an open door to rival platforms, but security remains an unsolved problem across the industryGong&#x27;s support for Model Context Protocol is perhaps the most strategically significant piece of the launch. The company now offers built-in client and server support for MCP, enabling organizations to connect Gong with other AI systems while maintaining clear controls over data access, usage, and provenance. Gong first announced MCP support in October 2025 at its Celebrate conference, where it revealed initial integrations with Microsoft Dynamics 365, Microsoft 365 Copilot, Salesforce Agentforce, and HubSpot CRM. Today&#x27;s launch builds on that foundation.But Reshef did not sugarcoat MCP&#x27;s limitations. \"MCP is very immature when it comes to security,\" he told VentureBeat. The protocol lets enterprise AI systems share data and context, but trust remains the enterprise&#x27;s responsibility. He explained a two-sided model: Gong can pull data from partners like Zendesk through certified integrations, and simultaneously makes its own MCP server available so that tools like Microsoft Copilot can query Gong&#x27;s data. \"It&#x27;s up to the company which connections they actually feel are secure enough,\" he said. \"The safest ones are the ones that we&#x27;ve kind of like certified in a way. But MCP is an open protocol. They can connect it to their own systems. We have no control over this.\"That candor matters. As MCP adoption accelerates across the enterprise software stack, security teams are scrambling to understand what happens when agentic AI systems start talking to each other without humans in the loop. Gong appears to be betting that transparency about the protocol&#x27;s immaturity will build more trust than marketing bravado.Early customers report faster ramp times and higher win rates, but the newest features are still days oldWhen asked for hard numbers, Reshef offered a mix of platform-wide results and measured candor about the newest features. Existing Gong customers report roughly a 50 percent reduction in sales rep ramp time and 10 to 15 percent improvements in win rates, he said.But on Gong Enable specifically, he acknowledged the product is still brand new. \"The trainer has been in the market for literally, you know, days, a week,\" he said. \"I would probably lie to you if I said, &#x27;Hey, we&#x27;re already seeing people crushing it after taking three or four courses.&#x27;\" For the earlier version of Enable that includes the AI Call Reviewer, however, he said customers are \"definitely seeing a very high kind of skill improvement\" and are attributing increases in win rates and quota attainment to those gains — though he conceded that \"it&#x27;s always hard to do 100 percent attribution.\"Morningstar, one of Gong&#x27;s early adopters, offered a pre-launch endorsement. Rae Cheney, Director of Sales Enablement Technology at Morningstar, said in a statement that Gong Enable helped the firm \"spend less time on status updates and more time on the work that actually moves deals.\"Reshef insists AI still needs a human operator, putting Gong at odds with the autonomous agent hypeOne of the more interesting threads in Reshef&#x27;s remarks concerned his view of AI autonomy — or rather, its limits. He pushed back on what he called a \"common misperception about AI\" — that it operates completely autonomously.\"There has to be a person in the middle, which I call operator,\" he said. \"It could be RevOps. It could be enablement. In the case of training, it could be analysts. Sometimes it could be even business leaders.\" Those operators, he argued, are responsible for a \"repeatable process of AI doing something, measuring the AI\" and adjusting over time.This philosophy extends to the AI Call Reviewer&#x27;s feedback. Gong does not dictate what the system trains on — enablement leaders choose. \"We don&#x27;t decide what they want to train on. We let them choose,\" Reshef said. \"You iterate, you optimize, you see how it goes, and there has to be somebody in the organization who&#x27;s responsible for making sure this aligns with the business needs.\"That stance puts Gong at odds with the more aggressive \"autonomous agent\" rhetoric emerging from some competitors, and it may resonate with enterprise buyers who remain cautious about letting AI run unsupervised in revenue-critical workflows.A wave of mega-mergers is reshaping the revenue AI market, and Gong is racing to stay ahead of the combined giantsMission Andromeda does not exist in a vacuum. The revenue AI landscape has been reshaped by a remarkable wave of consolidation over the past six months.In a category-defining move, Clari and Salesloft merged in December 2025 to form what they called a \"Revenue AI powerhouse,\" combining roughly $450 million in ARR under new CEO Steve Cox. Just two weeks ago, Highspot and Seismic signed a definitive agreement to merge, creating a combined entity worth more than $6 billion focused on AI-powered sales enablement — the very same territory Gong is now invading with Enable.Meanwhile, Gong was named a Leader in the inaugural 2025 Gartner Magic Quadrant for Revenue Action Orchestration, published in December. The company placed highest among the 12 vendors evaluated on both the \"Ability to Execute\" and \"Completeness of Vision\" axes and ranked first in all four evaluated use cases in Gartner&#x27;s companion Critical Capabilities report.In his interview, Reshef did not name competitors directly, but he drew a clear contrast. \"We&#x27;ve built a product from the ground up. It&#x27;s all organic,\" he said. \"All of the other players in the field have sort of stitched together tools. And obviously you can&#x27;t just get it to be a coherent product if you just stitch together tools. Some of them even have multiple logins.\" That is a thinly veiled shot at the merged Clari-Salesloft entity, which Forrester has described as presenting a \"bifurcated approach\" — Salesloft serving frontline users while Clari supports management insights.Reshef also pointed to growth as a competitive weapon. \"We&#x27;re growing at the top deck side in terms of SaaS companies,\" he said, adding that Gong hired roughly 200 R&D employees this year and plans to hire another 200. \"It&#x27;s kind of a flywheel where we can invest more in R&D, we make the product better, we get more capabilities, more flexibility, more enterprise customers.\"Gong declines to discuss IPO timing, but its structured launch cadence tells a story of its ownAny discussion of Gong&#x27;s trajectory inevitably raises the question of a public offering. When asked directly, Reshef declined to comment: \"I wouldn&#x27;t comment on IPO at this stage. No.\"The company has been on a clear growth arc. Gong has raised approximately $584 million to date, with its last official funding round valuing it at $7.25 billion — the culmination of a series of rapid jumps from $750 million in 2019 to $2.2 billion in 2020. The company reached an annual sales run rate of approximately $300 million in January 2025, driven largely by the adoption of AI, according to Calcalist.But that valuation has since slipped. As Calcalist reported in November 2025, Gong is conducting a secondary round for company employees and investors at a valuation of roughly $4.5 billion — well below its 2021 peak. The offering is being conducted through Nasdaq&#x27;s private market platform and was in advanced stages at the time of the report. It is not yet clear whether the company has repriced employee options, some of which were issued at significantly higher valuations than the current secondary round. Gong told Calcalist that it \"regularly receives inquiries from potential investors\" but as a private company does not \"engage in speculation.\"The structured quarterly launch cadence that Mission Andromeda inaugurates — complete with galactic naming conventions and coordinated product narratives — certainly resembles the kind of predictable, story-driven approach that public market investors reward. Reshef framed it differently: \"We felt like having quarterly launches with a name, a mission, and a story around it makes it easier to work... It&#x27;s a good way to educate the market on a regular basis.\"Gong&#x27;s 50 percent productivity target reveals where it thinks the future of sales is headingReshef&#x27;s most revealing comment came when he laid out the company&#x27;s long-term thesis: Gong aims to increase productivity for revenue professionals by 50 percent. \"We&#x27;re not there yet,\" he admitted. \"I think we&#x27;re like at 20 to 30 — whatever, hard to measure.\"He broke the productivity gain into two categories. The first is making high-complexity human tasks — like conducting a live Zoom sales call — better, through coaching, training, and review. \"I think there&#x27;s going to be a long while, if ever, that Zoom conversations are going to get replaced by bots,\" he said. The second is automating the manual drudgery: call preparation, post-meeting summaries, follow-up emails, account research briefs.The distinction matters because it frames Gong&#x27;s ambition not as replacing salespeople but as making them dramatically more effective — a message calibrated to appeal to the thousands of revenue leaders who control Gong&#x27;s buying decisions. Whether that thesis holds will depend on whether Gong Enable, the AI Trainer, and the rest of Mission Andromeda can deliver measurable gains in a market that has been burned before by tools that promise insight but struggle to change behavior.Gong currently serves more than 5,000 companies worldwide. The Clari-Salesloft merger has produced a rival with deeper combined resources. The Highspot-Seismic combination is assembling a sales enablement colossus. And a new Gartner category means every enterprise buyer now has a framework for comparison shopping. The next twelve months will test whether Mission Andromeda is the release that cements Gong&#x27;s position at the center of the revenue AI category — or the last big swing before the consolidated giants close in.\"Our mission is to be at the forefront,\" Reshef said. \"If everybody else is doing 20 percent, we&#x27;re going to do 50. If everybody is going to do 50, we&#x27;re going to do 80.\"In the revenue AI wars, that kind of confidence is easy to project. Delivering on it, with brand-new products still days old and a market being remade around you in real time, is something else entirely.",
          "content": "Gong, the revenue intelligence company that has spent a decade turning recorded sales calls into data, today launched what it calls Mission Andromeda — its most ambitious platform release to date, bundling a new AI-powered coaching product, a sales-focused chatbot, unified account management tools, and open interoperability with rival AI systems through the Model Context Protocol.The release arrives at a pivotal moment. The revenue technology market is consolidating at a pace that would have been unthinkable two years ago, and Gong — still a private company with roughly $300 million in annual recurring revenue — finds itself at the center of a category that Gartner only formally defined three months ago. Mission Andromeda is Gong&#x27;s answer to a basic question facing every enterprise AI vendor in 2026: Can you move beyond surfacing insights and actually change how people work?\"The whole show, Andromeda, is basically a collection of very significant capabilities that take us a huge step forward,\" Eilon Reshef, Gong&#x27;s co-founder and chief product officer, told VentureBeat in an interview ahead of the launch. He described it as an effort to make revenue teams \"more productive as individuals\" and to give leaders \"better decisions\" — positioning the release not as a feature dump, but as an operating system upgrade.The new products target every layer of the sales workflow, from coaching to account managementMission Andromeda contains four main components, each targeting a different layer of the sales workflow.The headliner is Gong Enable, a brand-new product with its own pricing tier — Reshef described it as \"in the tens of dollars per seat per month\" — that attacks what the company sees as a gaping hole in most sales organizations: the disconnect between training and performance. Highspot and Seismic announced their intent to merge in February 2026, creating a combined enablement giant, and Gong is now moving directly onto their turf.Gong Enable has three pieces. The first, AI Call Reviewer, analyzes completed customer calls and grades reps based on their organization&#x27;s own methodology. When asked whether this operates in real time, Reshef was direct: \"For that particular agent, it&#x27;s post-call, because obviously you want to grade the whole call as a whole — maybe you didn&#x27;t do anything in minute one, minute 30.\" The second piece, AI Trainer, lets reps practice high-stakes conversations — pricing objections, renewal risk scenarios — against AI-generated simulations built from the company&#x27;s own winning call patterns. The third, Initiative Tracking, links coaching programs to revenue metrics so leaders can see whether new behaviors actually show up in live deals.Beyond Enable, the launch includes Gong Assistant, a conversational AI chatbot purpose-built for revenue teams that lets users ask questions about customer calls inside the platform. The release also introduces Account Console and Account Boards, which unify customer activity, risk signals, and next steps into a single view for sales and post-sales teams. And rounding out the package is built-in support for the Model Context Protocol, the open standard originally developed by Anthropic, enabling Gong to exchange data with AI systems from Microsoft, Salesforce, HubSpot, and others.Gong uses four different LLM providers and says the real moat is the data, not the modelsIn a market where every company wants to claim proprietary AI supremacy, Reshef described a notably pragmatic approach to the models powering the new features. Gong uses both internal models and foundation models from external providers, he said, noting that \"four out of the five leading AI companies, LLM, are basically Gong customers.\"The company picks models task by task. \"Based on the product or task at hand, we pick the right model,\" he said. \"We would sometimes swap in and out a model if we feel it&#x27;s best for our customers and they get more and more power.\" Reshef drew a clear line between what needs a large language model and what does not: \"Our revenue prediction models are not using LLMs, but kind of the core interaction chatbots — of course, you&#x27;re going to use the foundation model.\"This approach contrasts with competitors that have hitched their wagon to a single AI provider. It also reflects a philosophical choice: Gong&#x27;s real moat, Reshef suggested, is not the models themselves but the data underneath — what the company calls the Revenue Graph, its proprietary layer that captures phone calls, Zoom meetings, emails, text messages, WhatsApp conversations, and more, stitching them together into a connected intelligence layer.Recording every sales conversation raises obvious privacy questions, and Gong says it has spent a decade answering themStoring and analyzing every customer conversation a sales team has raises obvious questions about privacy and data governance. Reshef was eager to address them head-on.\"We&#x27;ve been around the block for a long while — a little bit over a decade — with AI first,\" he said. \"Over the years, we&#x27;ve developed exactly those capabilities that are the most boring pieces of AI, which is: how do you collect the right data? How do you manage it? How do you manage permissions about it, retention policies, right to be forgotten?\"On the sensitive question of whether Gong trains its AI on customer data across accounts, Reshef drew a firm boundary. Training, he explained, happens per customer: \"The majority of the training happens based on each customer&#x27;s data.\" He pointed to large accounts like Cisco, which he said has 20,000 Gong users — enough data to train the AI Trainer from within their own environment. \"AI Trainer can go mine what&#x27;s working in their environment. It might not work in their competitor&#x27;s environment — maybe their benefits are different, their objections are different.\"Cross-customer training, he said, happens \"only in very, very rare cases, very safe based — like transcription. But we don&#x27;t do it for business-specific processes.\"MCP gives Gong an open door to rival platforms, but security remains an unsolved problem across the industryGong&#x27;s support for Model Context Protocol is perhaps the most strategically significant piece of the launch. The company now offers built-in client and server support for MCP, enabling organizations to connect Gong with other AI systems while maintaining clear controls over data access, usage, and provenance. Gong first announced MCP support in October 2025 at its Celebrate conference, where it revealed initial integrations with Microsoft Dynamics 365, Microsoft 365 Copilot, Salesforce Agentforce, and HubSpot CRM. Today&#x27;s launch builds on that foundation.But Reshef did not sugarcoat MCP&#x27;s limitations. \"MCP is very immature when it comes to security,\" he told VentureBeat. The protocol lets enterprise AI systems share data and context, but trust remains the enterprise&#x27;s responsibility. He explained a two-sided model: Gong can pull data from partners like Zendesk through certified integrations, and simultaneously makes its own MCP server available so that tools like Microsoft Copilot can query Gong&#x27;s data. \"It&#x27;s up to the company which connections they actually feel are secure enough,\" he said. \"The safest ones are the ones that we&#x27;ve kind of like certified in a way. But MCP is an open protocol. They can connect it to their own systems. We have no control over this.\"That candor matters. As MCP adoption accelerates across the enterprise software stack, security teams are scrambling to understand what happens when agentic AI systems start talking to each other without humans in the loop. Gong appears to be betting that transparency about the protocol&#x27;s immaturity will build more trust than marketing bravado.Early customers report faster ramp times and higher win rates, but the newest features are still days oldWhen asked for hard numbers, Reshef offered a mix of platform-wide results and measured candor about the newest features. Existing Gong customers report roughly a 50 percent reduction in sales rep ramp time and 10 to 15 percent improvements in win rates, he said.But on Gong Enable specifically, he acknowledged the product is still brand new. \"The trainer has been in the market for literally, you know, days, a week,\" he said. \"I would probably lie to you if I said, &#x27;Hey, we&#x27;re already seeing people crushing it after taking three or four courses.&#x27;\" For the earlier version of Enable that includes the AI Call Reviewer, however, he said customers are \"definitely seeing a very high kind of skill improvement\" and are attributing increases in win rates and quota attainment to those gains — though he conceded that \"it&#x27;s always hard to do 100 percent attribution.\"Morningstar, one of Gong&#x27;s early adopters, offered a pre-launch endorsement. Rae Cheney, Director of Sales Enablement Technology at Morningstar, said in a statement that Gong Enable helped the firm \"spend less time on status updates and more time on the work that actually moves deals.\"Reshef insists AI still needs a human operator, putting Gong at odds with the autonomous agent hypeOne of the more interesting threads in Reshef&#x27;s remarks concerned his view of AI autonomy — or rather, its limits. He pushed back on what he called a \"common misperception about AI\" — that it operates completely autonomously.\"There has to be a person in the middle, which I call operator,\" he said. \"It could be RevOps. It could be enablement. In the case of training, it could be analysts. Sometimes it could be even business leaders.\" Those operators, he argued, are responsible for a \"repeatable process of AI doing something, measuring the AI\" and adjusting over time.This philosophy extends to the AI Call Reviewer&#x27;s feedback. Gong does not dictate what the system trains on — enablement leaders choose. \"We don&#x27;t decide what they want to train on. We let them choose,\" Reshef said. \"You iterate, you optimize, you see how it goes, and there has to be somebody in the organization who&#x27;s responsible for making sure this aligns with the business needs.\"That stance puts Gong at odds with the more aggressive \"autonomous agent\" rhetoric emerging from some competitors, and it may resonate with enterprise buyers who remain cautious about letting AI run unsupervised in revenue-critical workflows.A wave of mega-mergers is reshaping the revenue AI market, and Gong is racing to stay ahead of the combined giantsMission Andromeda does not exist in a vacuum. The revenue AI landscape has been reshaped by a remarkable wave of consolidation over the past six months.In a category-defining move, Clari and Salesloft merged in December 2025 to form what they called a \"Revenue AI powerhouse,\" combining roughly $450 million in ARR under new CEO Steve Cox. Just two weeks ago, Highspot and Seismic signed a definitive agreement to merge, creating a combined entity worth more than $6 billion focused on AI-powered sales enablement — the very same territory Gong is now invading with Enable.Meanwhile, Gong was named a Leader in the inaugural 2025 Gartner Magic Quadrant for Revenue Action Orchestration, published in December. The company placed highest among the 12 vendors evaluated on both the \"Ability to Execute\" and \"Completeness of Vision\" axes and ranked first in all four evaluated use cases in Gartner&#x27;s companion Critical Capabilities report.In his interview, Reshef did not name competitors directly, but he drew a clear contrast. \"We&#x27;ve built a product from the ground up. It&#x27;s all organic,\" he said. \"All of the other players in the field have sort of stitched together tools. And obviously you can&#x27;t just get it to be a coherent product if you just stitch together tools. Some of them even have multiple logins.\" That is a thinly veiled shot at the merged Clari-Salesloft entity, which Forrester has described as presenting a \"bifurcated approach\" — Salesloft serving frontline users while Clari supports management insights.Reshef also pointed to growth as a competitive weapon. \"We&#x27;re growing at the top deck side in terms of SaaS companies,\" he said, adding that Gong hired roughly 200 R&D employees this year and plans to hire another 200. \"It&#x27;s kind of a flywheel where we can invest more in R&D, we make the product better, we get more capabilities, more flexibility, more enterprise customers.\"Gong declines to discuss IPO timing, but its structured launch cadence tells a story of its ownAny discussion of Gong&#x27;s trajectory inevitably raises the question of a public offering. When asked directly, Reshef declined to comment: \"I wouldn&#x27;t comment on IPO at this stage. No.\"The company has been on a clear growth arc. Gong has raised approximately $584 million to date, with its last official funding round valuing it at $7.25 billion — the culmination of a series of rapid jumps from $750 million in 2019 to $2.2 billion in 2020. The company reached an annual sales run rate of approximately $300 million in January 2025, driven largely by the adoption of AI, according to Calcalist.But that valuation has since slipped. As Calcalist reported in November 2025, Gong is conducting a secondary round for company employees and investors at a valuation of roughly $4.5 billion — well below its 2021 peak. The offering is being conducted through Nasdaq&#x27;s private market platform and was in advanced stages at the time of the report. It is not yet clear whether the company has repriced employee options, some of which were issued at significantly higher valuations than the current secondary round. Gong told Calcalist that it \"regularly receives inquiries from potential investors\" but as a private company does not \"engage in speculation.\"The structured quarterly launch cadence that Mission Andromeda inaugurates — complete with galactic naming conventions and coordinated product narratives — certainly resembles the kind of predictable, story-driven approach that public market investors reward. Reshef framed it differently: \"We felt like having quarterly launches with a name, a mission, and a story around it makes it easier to work... It&#x27;s a good way to educate the market on a regular basis.\"Gong&#x27;s 50 percent productivity target reveals where it thinks the future of sales is headingReshef&#x27;s most revealing comment came when he laid out the company&#x27;s long-term thesis: Gong aims to increase productivity for revenue professionals by 50 percent. \"We&#x27;re not there yet,\" he admitted. \"I think we&#x27;re like at 20 to 30 — whatever, hard to measure.\"He broke the productivity gain into two categories. The first is making high-complexity human tasks — like conducting a live Zoom sales call — better, through coaching, training, and review. \"I think there&#x27;s going to be a long while, if ever, that Zoom conversations are going to get replaced by bots,\" he said. The second is automating the manual drudgery: call preparation, post-meeting summaries, follow-up emails, account research briefs.The distinction matters because it frames Gong&#x27;s ambition not as replacing salespeople but as making them dramatically more effective — a message calibrated to appeal to the thousands of revenue leaders who control Gong&#x27;s buying decisions. Whether that thesis holds will depend on whether Gong Enable, the AI Trainer, and the rest of Mission Andromeda can deliver measurable gains in a market that has been burned before by tools that promise insight but struggle to change behavior.Gong currently serves more than 5,000 companies worldwide. The Clari-Salesloft merger has produced a rival with deeper combined resources. The Highspot-Seismic combination is assembling a sales enablement colossus. And a new Gartner category means every enterprise buyer now has a framework for comparison shopping. The next twelve months will test whether Mission Andromeda is the release that cements Gong&#x27;s position at the center of the revenue AI category — or the last big swing before the consolidated giants close in.\"Our mission is to be at the forefront,\" Reshef said. \"If everybody else is doing 20 percent, we&#x27;re going to do 50. If everybody is going to do 50, we&#x27;re going to do 80.\"In the revenue AI wars, that kind of confidence is easy to project. Delivering on it, with brand-new products still days old and a market being remade around you in real time, is something else entirely.",
          "feed_position": 3,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/1ijctTADhD7mTtP0VyjbkV/91f51845e4a0e8e2a400ea8f0e9cdbf2/nuneybits_Vector_art_of_gong_atop_mountain_Andromeda_43dbd9d6-d291-40c7-baa9-de9803040738.webp?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/xais-trade-secret-lawsuit-against-openai-has-been-dismissed-101912599.html",
          "published_at": "Wed, 25 Feb 2026 10:19:12 +0000",
          "title": "xAI's trade secret lawsuit against OpenAI has been dismissed",
          "standfirst": "OpenAI has successfully convinced the court to dismiss the lawsuit filed by Elon Musk’s xAI, accusing the company of stealing its trade secrets. In her decision, US District Judge Rita F. Lin wrote that xAI’s complaint “does not point to any misconduct by OpenAI” and instead attributes all listed misconducts to its eight former employees who “ left for OpenAI at around the same time.” Lin said that xAI accused two of its former employees of stealing its source code before leaving at a time when they were already speaking to an OpenAI recruiter. However, the company didn’t say if the recruiter told those former employees to do so. xAI’s lawsuit also accuses two other former employees of keeping their work chats on their devices even after leaving, another of refusing to provide certifications related to confidential information after his departure, and another of unsuccessfully trying to access xAI hiring and datacenter optimization information when he was already working for OpenAI. “Notably absent are allegations about the conduct of OpenAI itself,” the judge noted. xAI didn’t include any information that directly accuses OpenAI of making those employees steal its trade secrets. It also didn’t include allegations that those former employees used any stolen trade secrets after they were already working for OpenAI. To be precise, OpenAI’s motion for dismissal was granted with leave to amend, so the lawsuit may not be completely over just yet. That means xAI can still file an amended complaint addressing what the judge wrote in her decision until March 17, 2026. OpenAI and xAI have a longstanding feud, and this is just one of the several lawsuits between the two companies. In fact, Musk has an ongoing complaint against OpenAI and Microsoft, accusing the former of violating its nonprofit status. Musk, who was an early funder of OpenAI, is now asking the company for $79 billion to $134 billion in damages from “wrongful gains.”This article originally appeared on Engadget at https://www.engadget.com/ai/xais-trade-secret-lawsuit-against-openai-has-been-dismissed-101912599.html?src=rss",
          "content": "OpenAI has successfully convinced the court to dismiss the lawsuit filed by Elon Musk’s xAI, accusing the company of stealing its trade secrets. In her decision, US District Judge Rita F. Lin wrote that xAI’s complaint “does not point to any misconduct by OpenAI” and instead attributes all listed misconducts to its eight former employees who “ left for OpenAI at around the same time.” Lin said that xAI accused two of its former employees of stealing its source code before leaving at a time when they were already speaking to an OpenAI recruiter. However, the company didn’t say if the recruiter told those former employees to do so. xAI’s lawsuit also accuses two other former employees of keeping their work chats on their devices even after leaving, another of refusing to provide certifications related to confidential information after his departure, and another of unsuccessfully trying to access xAI hiring and datacenter optimization information when he was already working for OpenAI. “Notably absent are allegations about the conduct of OpenAI itself,” the judge noted. xAI didn’t include any information that directly accuses OpenAI of making those employees steal its trade secrets. It also didn’t include allegations that those former employees used any stolen trade secrets after they were already working for OpenAI. To be precise, OpenAI’s motion for dismissal was granted with leave to amend, so the lawsuit may not be completely over just yet. That means xAI can still file an amended complaint addressing what the judge wrote in her decision until March 17, 2026. OpenAI and xAI have a longstanding feud, and this is just one of the several lawsuits between the two companies. In fact, Musk has an ongoing complaint against OpenAI and Microsoft, accusing the former of violating its nonprofit status. Musk, who was an early funder of OpenAI, is now asking the company for $79 billion to $134 billion in damages from “wrongful gains.”This article originally appeared on Engadget at https://www.engadget.com/ai/xais-trade-secret-lawsuit-against-openai-has-been-dismissed-101912599.html?src=rss",
          "feed_position": 29
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/apps/apple-introduces-age-verification-for-apps-in-utah-louisiana-and-australia-080855449.html",
          "published_at": "Wed, 25 Feb 2026 08:08:56 +0000",
          "title": "Apple introduces age verification for apps in Utah, Louisiana and Australia",
          "standfirst": "Now that Apple has started blocking users under 18 in certain regions from downloading apps, the company has introduced new age verification tools. Those will help developers \"meet their age assurance obligations under upcoming US and regional laws, including in Brazil, Australia, Singapore, Utah and Louisiana,\" the company said in a news release on its Developer site. As of February 24, 2026, users in Australia, Brazil and Singapore won't be able to download apps rated 18+ unless their age is confirmed through \"reasonable methods.\" Apple noted that any apps distributed in Brazil that are declared to contain loot boxes will be updated to 18+. While the App Store can perform those checks automatically, \"developers may have separate obligations to independently confirm that their users are adults,\" Apple wrote. For that, developers can employ the company's Declared Age Range API (on iOS, iPadOS and macOS) to get \"helpful signals\" about a user's age. In Utah as of May 6, 2026 and Louisiana on July 1, 2026, \"age categories will be shared with the developer's app when requested through the Declared Age Range API.\" That API will also provide \"new signals,\" like whether age-related regulatory requirements apply to the user and if the user must share their age range. \"The API will also let you know if you need to get a parent or guardian's permission for significant app updates for a child,\" Apple says. Under Utah's new law, users must be over 18 to make a new account with an app store, while underage uses will need to link their account to a parent's in order to get permission to use certain apps. Louisiana and Texas also passed similar laws and California plans to enact age-based rules for app stores in 2027. Those rules are designed to protect children from predators, financial harm and other problems. However, critics have described the laws as blunt tools that harm privacy and internet anonymity. \"A poorly designed system might store this personal data, and even correlate it to the online content that we look at,\" the Electronic Frontier Foundation notes. \"In the hands of an adversary, and cross-referenced to other readily available information, this information can expose intimate details about us.\"This article originally appeared on Engadget at https://www.engadget.com/apps/apple-introduces-age-verification-for-apps-in-utah-louisiana-and-australia-080855449.html?src=rss",
          "content": "Now that Apple has started blocking users under 18 in certain regions from downloading apps, the company has introduced new age verification tools. Those will help developers \"meet their age assurance obligations under upcoming US and regional laws, including in Brazil, Australia, Singapore, Utah and Louisiana,\" the company said in a news release on its Developer site. As of February 24, 2026, users in Australia, Brazil and Singapore won't be able to download apps rated 18+ unless their age is confirmed through \"reasonable methods.\" Apple noted that any apps distributed in Brazil that are declared to contain loot boxes will be updated to 18+. While the App Store can perform those checks automatically, \"developers may have separate obligations to independently confirm that their users are adults,\" Apple wrote. For that, developers can employ the company's Declared Age Range API (on iOS, iPadOS and macOS) to get \"helpful signals\" about a user's age. In Utah as of May 6, 2026 and Louisiana on July 1, 2026, \"age categories will be shared with the developer's app when requested through the Declared Age Range API.\" That API will also provide \"new signals,\" like whether age-related regulatory requirements apply to the user and if the user must share their age range. \"The API will also let you know if you need to get a parent or guardian's permission for significant app updates for a child,\" Apple says. Under Utah's new law, users must be over 18 to make a new account with an app store, while underage uses will need to link their account to a parent's in order to get permission to use certain apps. Louisiana and Texas also passed similar laws and California plans to enact age-based rules for app stores in 2027. Those rules are designed to protect children from predators, financial harm and other problems. However, critics have described the laws as blunt tools that harm privacy and internet anonymity. \"A poorly designed system might store this personal data, and even correlate it to the online content that we look at,\" the Electronic Frontier Foundation notes. \"In the hands of an adversary, and cross-referenced to other readily available information, this information can expose intimate details about us.\"This article originally appeared on Engadget at https://www.engadget.com/apps/apple-introduces-age-verification-for-apps-in-utah-louisiana-and-australia-080855449.html?src=rss",
          "feed_position": 31
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/anthropic-just-released-a-mobile-version-of-claude-code-called-remote",
          "published_at": "Wed, 25 Feb 2026 02:37:00 GMT",
          "title": "Anthropic just released a mobile version of Claude Code called Remote Control",
          "standfirst": "Claude Code has become increasingly popular in the first year since its launch, and especially in recent months, as developers and non-technical users alike flock to AI unicorn Anthropic&#x27;s hit coding agent to create full applications and websites in days, on their own, that would&#x27;ve taken months and technical teams without. It&#x27;s not a stretch to say it helped spur the \"vibe coding\" boom — using plain English instead of programming languages to write software.But it&#x27;s all been restricted to the desktop Claude Code apps and Terminal command-line interfaces and integrated development environments (IDEs) — until today. Now, Anthropic has added a new mode, Remote Control, that lets users issue commands to Claude Code from their iPhone and Android smartphones — starting with subscribers to Anthropic&#x27;s Claude Max ($100-$200 USD monthly) subscription tier.Anthropic posted on X saying Remote Control will also make its way to Claude Pro ($20 USD monthly) subscribers in the future.The mobile command centerAnnounced earlier today by Claude Code Product Manager Noah Zweben, Remote Control is a synchronization layer that bridges local CLI environments with the Claude mobile app and web interface. The feature allows developers to initiate a complex task in their terminal and maintain full control of it from a phone or tablet, effectively decoupling the AI agent from the physical workstation.Currently, Remote Control is available as a Research Preview for subscribers on the Claude Max tier. While access for Claude Pro ($20/month) users is expected shortly, the feature remains a high-end tool for power users and is notably absent from Team or Enterprise plans during this initial phase. To access the feature, users must follow this guide and update to Claude version 2.1.52 and execute the command claude remote-control or use the in-session slash command /rc. Once active, the terminal displays a QR code that, when scanned, opens a responsive, synchronized session in the Claude mobile app.Less screen time, more IRL time: philosophy of flowThe messaging behind the release centers on the preservation of a developer&#x27;s \"flow state.\" In his announcement, Zweben framed the update as a lifestyle upgrade rather than just a technical one, encouraging users to \"take a walk, see the sun, walk your dog without losing your flow.\"This \"Remote Control\" is not a cloud-based replacement for local development, but a portal into it. According to official documentation, the core value is that \"Claude keeps running on your machine, and you can control the session from the Claude app.\" This ensures that local context—filesystem access, environment variables, and Model Context Protocol (MCP)servers—remains active and reachable even if the user is miles away from their desk.Architecture, security, and setupClaude Code Remote Control functions as a secure bridge between your local terminal and Anthropic’s cloud interface, which provides the Anthropic AI models, Opus 4.6 and Sonnet 4.6, that power Claude Code.When you run the command, your desktop machine initiates an outbound connection to Anthropic’s API for serving the models — meaning you aren&#x27;t opening any \"inbound\" ports or exposing your computer to the open web. Instead, your local machine polls the API for instructions. When you visit the session URL or use the Claude app, you are essentially using those devices as a \"remote window\" to view and command the process still running on your computer. Your files and MCP servers never leave your machine; only the chat messages and tool results flow through the encrypted bridge.To get started, ensure you are on a Pro or Max plan and have authenticated your CLI using the /login command. Simply navigate to your project directory and run claude remote-control to initialize the session. The terminal will then generate a unique session URL and a QR code (toggleable via the spacebar) for your mobile device. Once you open that link on your phone, tablet, or another browser, the two surfaces stay in perfect sync—allowing you to start a task at your desk and continue it from the couch while maintaining full access to your local filesystem and project configuration.From brittle community hacks to official solutionPrior to this official release, the developer community went to great lengths to \"hack\" mobile access into their terminal-based workflows. Power users frequently relied on a patchwork of third-party tools like Tailscale for secure tunneling, Termius or Termux for mobile SSH access, and Tmux for session persistence.Some developers even built complex custom WebSocket bridges just to get a responsive mobile UI for their local Claude sessions. These unofficial solutions, while functional, were often brittle and prone to timeout issues. Remote Control replaces these workarounds with a native streaming connection that requires no port forwarding or complex VPN configurations. It also includes automatic reconnection logic: if a user’s laptop sleeps or the network drops, the session remains alive in the background and reconnects as soon as the host machine is back online.The $2.5 billion-dollar agentThe launch of Remote Control serves as an \"escalation of force\" in what has become a dominant business for Anthropic. As of February 2026, Claude Code has hit a $2.5 billion annualized run rate — a figure that has more than doubled since the start of the year alone.Claude Code is currently experiencing its \"ChatGPT moment,\" surging to 29 million daily installs within Visual Studio Code. Its efficiency is no longer theoretical; recent analysis suggests that 4% of all public GitHub commits worldwide are now authored by Claude Code. By extending this power to mobile, Anthropic is further entrenching its lead in the \"agentic\" coding space, moving beyond simple autocomplete to a world where the AI acts as an autonomous collaborator.Future outlook: vibe coding everywhereThe move toward mobile terminal control signals a broader shift in the software market. We are entering an era where AI tools are writing roughly 41% of all code. For developers, this translates to a migration from \"line-by-line\" typing to \"strategic oversight.\"This trend is likely to accelerate as mobile-tethered agents become the norm. The barrier between \"idea\" and \"production\" is collapsing, enabling a single developer to manage complex systems that previously required entire DevOps teams. This shift has already rattled the broader tech market; shares of major cybersecurity firms like CrowdStrike and Datadog fell as much as 11% following the launch of Claude Code&#x27;s automated security scanning features.As Claude Code moves from the desk to the pocket, the definition of a \"software engineer\" is being rewritten. In the coming year, the industry may see a surge in \"one-person unicorns\"—startups built and maintained almost entirely via mobile agentic commands—marking the end of the manual coding era as we knew it.",
          "content": "Claude Code has become increasingly popular in the first year since its launch, and especially in recent months, as developers and non-technical users alike flock to AI unicorn Anthropic&#x27;s hit coding agent to create full applications and websites in days, on their own, that would&#x27;ve taken months and technical teams without. It&#x27;s not a stretch to say it helped spur the \"vibe coding\" boom — using plain English instead of programming languages to write software.But it&#x27;s all been restricted to the desktop Claude Code apps and Terminal command-line interfaces and integrated development environments (IDEs) — until today. Now, Anthropic has added a new mode, Remote Control, that lets users issue commands to Claude Code from their iPhone and Android smartphones — starting with subscribers to Anthropic&#x27;s Claude Max ($100-$200 USD monthly) subscription tier.Anthropic posted on X saying Remote Control will also make its way to Claude Pro ($20 USD monthly) subscribers in the future.The mobile command centerAnnounced earlier today by Claude Code Product Manager Noah Zweben, Remote Control is a synchronization layer that bridges local CLI environments with the Claude mobile app and web interface. The feature allows developers to initiate a complex task in their terminal and maintain full control of it from a phone or tablet, effectively decoupling the AI agent from the physical workstation.Currently, Remote Control is available as a Research Preview for subscribers on the Claude Max tier. While access for Claude Pro ($20/month) users is expected shortly, the feature remains a high-end tool for power users and is notably absent from Team or Enterprise plans during this initial phase. To access the feature, users must follow this guide and update to Claude version 2.1.52 and execute the command claude remote-control or use the in-session slash command /rc. Once active, the terminal displays a QR code that, when scanned, opens a responsive, synchronized session in the Claude mobile app.Less screen time, more IRL time: philosophy of flowThe messaging behind the release centers on the preservation of a developer&#x27;s \"flow state.\" In his announcement, Zweben framed the update as a lifestyle upgrade rather than just a technical one, encouraging users to \"take a walk, see the sun, walk your dog without losing your flow.\"This \"Remote Control\" is not a cloud-based replacement for local development, but a portal into it. According to official documentation, the core value is that \"Claude keeps running on your machine, and you can control the session from the Claude app.\" This ensures that local context—filesystem access, environment variables, and Model Context Protocol (MCP)servers—remains active and reachable even if the user is miles away from their desk.Architecture, security, and setupClaude Code Remote Control functions as a secure bridge between your local terminal and Anthropic’s cloud interface, which provides the Anthropic AI models, Opus 4.6 and Sonnet 4.6, that power Claude Code.When you run the command, your desktop machine initiates an outbound connection to Anthropic’s API for serving the models — meaning you aren&#x27;t opening any \"inbound\" ports or exposing your computer to the open web. Instead, your local machine polls the API for instructions. When you visit the session URL or use the Claude app, you are essentially using those devices as a \"remote window\" to view and command the process still running on your computer. Your files and MCP servers never leave your machine; only the chat messages and tool results flow through the encrypted bridge.To get started, ensure you are on a Pro or Max plan and have authenticated your CLI using the /login command. Simply navigate to your project directory and run claude remote-control to initialize the session. The terminal will then generate a unique session URL and a QR code (toggleable via the spacebar) for your mobile device. Once you open that link on your phone, tablet, or another browser, the two surfaces stay in perfect sync—allowing you to start a task at your desk and continue it from the couch while maintaining full access to your local filesystem and project configuration.From brittle community hacks to official solutionPrior to this official release, the developer community went to great lengths to \"hack\" mobile access into their terminal-based workflows. Power users frequently relied on a patchwork of third-party tools like Tailscale for secure tunneling, Termius or Termux for mobile SSH access, and Tmux for session persistence.Some developers even built complex custom WebSocket bridges just to get a responsive mobile UI for their local Claude sessions. These unofficial solutions, while functional, were often brittle and prone to timeout issues. Remote Control replaces these workarounds with a native streaming connection that requires no port forwarding or complex VPN configurations. It also includes automatic reconnection logic: if a user’s laptop sleeps or the network drops, the session remains alive in the background and reconnects as soon as the host machine is back online.The $2.5 billion-dollar agentThe launch of Remote Control serves as an \"escalation of force\" in what has become a dominant business for Anthropic. As of February 2026, Claude Code has hit a $2.5 billion annualized run rate — a figure that has more than doubled since the start of the year alone.Claude Code is currently experiencing its \"ChatGPT moment,\" surging to 29 million daily installs within Visual Studio Code. Its efficiency is no longer theoretical; recent analysis suggests that 4% of all public GitHub commits worldwide are now authored by Claude Code. By extending this power to mobile, Anthropic is further entrenching its lead in the \"agentic\" coding space, moving beyond simple autocomplete to a world where the AI acts as an autonomous collaborator.Future outlook: vibe coding everywhereThe move toward mobile terminal control signals a broader shift in the software market. We are entering an era where AI tools are writing roughly 41% of all code. For developers, this translates to a migration from \"line-by-line\" typing to \"strategic oversight.\"This trend is likely to accelerate as mobile-tethered agents become the norm. The barrier between \"idea\" and \"production\" is collapsing, enabling a single developer to manage complex systems that previously required entire DevOps teams. This shift has already rattled the broader tech market; shares of major cybersecurity firms like CrowdStrike and Datadog fell as much as 11% following the launch of Claude Code&#x27;s automated security scanning features.As Claude Code moves from the desk to the pocket, the definition of a \"software engineer\" is being rewritten. In the coming year, the industry may see a surge in \"one-person unicorns\"—startups built and maintained almost entirely via mobile agentic commands—marking the end of the manual coding era as we knew it.",
          "feed_position": 4,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/6RPhHUoUFspa6koUR32kvV/c51a10eb9600c128e13637793ca370ed/Gemini_Generated_Image_7ldhz77ldhz77ldh.png?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/anthropic-says-claude-code-transformed-programming-now-claude-cowork-is",
          "published_at": "Wed, 25 Feb 2026 00:40:00 GMT",
          "title": "Anthropic says Claude Code transformed programming. Now Claude Cowork is coming for the rest of the enterprise.",
          "standfirst": "Anthropic opened its virtual \"Briefing: Enterprise Agents\" event on Tuesday with a provocation. Kate Jensen, the company&#x27;s head of Americas, told viewers that the hype around enterprise AI agents in 2025 \"turned out to be mostly premature,\" with many pilots failing to reach production. \"It wasn&#x27;t a failure of effort, it was a failure of approach, and it&#x27;s something we heard directly from our customers,\" Jensen said.The implicit promise: Anthropic has figured out the right approach, and it starts with the playbook that made Claude Code one of the most consequential developer tools of the past year. \"In 2025 Claude transformed how developers work, and in 2026 it will do the same for knowledge work,\" Jensen said. \"The magic behind Claude Code is simple. When you can delegate hard challenges, you can focus on the work that actually matters. Cowork brings that same power to knowledge workers.\"That framing is central to understanding what Anthropic announced on Tuesday. The company rolled out a sweeping set of enterprise capabilities for Claude Cowork, the AI productivity platform it first released in research preview in January. Scott White, head of product for Claude Enterprise, described the ambition plainly during the keynote: \"Cowork makes it possible for Claude to deliver polished, near final work. It goes beyond drafts and suggestions — actual completed projects and deliverables.\"The product updates are dense but consequential. Enterprise administrators can now build private plugin marketplaces tailored to their organizations, connecting to private GitHub repositories as plugin sources and controlling which plugins employees can access. Anthropic introduced new prebuilt plugin templates spanning HR, design, engineering, operations, financial analysis, investment banking, equity research, private equity, and wealth management. The company also shipped new MCP connectors for Google Drive, Google Calendar, Gmail, DocuSign, Apollo, Clay, Outreach, SimilarWeb, MSCI, LegalZoom, FactSet, WordPress, and Harvey — dramatically extending Claude&#x27;s reach into the software ecosystem that enterprises already use. And Claude can now pass context seamlessly between Cowork, Excel, and PowerPoint, including across multiple files, without requiring users to restart when switching applications.White emphasized that the system is designed to feel native to each organization rather than generic. \"We&#x27;ve heard loud and clear from enterprises — you want Claude to work the way that your company works, not just Claude for legal, but Cowork for legal at your company,\" he said. \"That&#x27;s exactly what today&#x27;s launches deliver.\"Real-world results from Spotify, Novo Nordisk, and Salesforce hint at what&#x27;s comingTo ground the product announcements in measurable outcomes, Anthropic showcased three enterprise deployments that illustrate both the scale and the variety of impact the company claims Claude can deliver.At Spotify, engineers had long struggled with code migrations — the slow, manual work of updating and modernizing code across thousands of services. Jensen explained that after integrating Claude directly into the system Spotify&#x27;s engineers use daily, \"any engineer can kick off a large-scale migration just by describing what they need in plain English.\" The company reports up to a 90% reduction in engineering time, over 650 AI-generated code changes shipped per month, and roughly half of all Spotify updates now flowing through the system.At Novo Nordisk, the pharmaceutical giant built an AI-powered platform called NovoScribe with Claude as its intelligence layer, targeting the grueling process of producing regulatory documentation for new medicines. Staff writers had previously averaged just over two reports per year. After deploying Claude, Jensen said, \"documentation creation went from 10 plus weeks to 10 minutes. That&#x27;s a 95% reduction in resources for verification checks. Medicines are reaching patients faster.\" Jensen also noted that Novo Nordisk used Claude Code to build the platform itself, enabling contributions from non-engineers — their digitalization strategy director, who holds a PhD in molecular biology rather than engineering, now prototypes features using natural language. \"A team of 11 is operating like a team many times its size,\" Jensen said.Salesforce, meanwhile, uses Claude models to help power AI in Slack, reporting a 96% satisfaction rate for tools like its Slack bot and saving customers an estimated 97 minutes per week through summarization and recap features. The partnership reflects Anthropic&#x27;s broader ecosystem strategy: Jensen described the companies featured at the event as \"Claude partners and domain experts with the data and trusted relationships that make Claude work in the real world.\"Enterprise leaders reveal the messy reality behind AI transformationPerhaps the most illuminating segment of the event was a panel discussion featuring executives from Thomson Reuters, the New York Stock Exchange, and Epic, who provided candid assessments of AI&#x27;s enterprise reality that went well beyond the polished case studies.Sridhar Masam, CTO of the New York Stock Exchange, described his organization as \"rewiring our engineering process\" with Claude Code and building internal AI agents using the Claude Agent SDK that can take instructions from a Jira ticket all the way to a committed piece of code. But he also identified fundamental shifts in how leaders must think. \"The accountability is shifting,\" he said. \"Traditionally, we are so used to building deterministic platforms. You write code requirements and build. And now, with AI being probabilistic, the accountability doesn&#x27;t end when the project goes live, but on a daily basis, monitoring the behavior and outcomes.\" He described a new paradigm beyond \"buy versus build\" — what he called \"assembly,\" the practice of combining multiple models, multiple vendors, platforms, data, and internal capabilities into solutions. And he noted that highly regulated industries must shift \"from risk avoidance to risk calibration,\" because simply avoiding AI is no longer a competitive option.Steve Hasker from Thomson Reuters, whose Co-Counsel product has reached a million users, was frank about the gap between what the technology can do and what organizations are ready for. \"The tools are in many senses ahead of the change management,\" he said. \"A general counsel&#x27;s office, a law firm, a tax and accounting firm, an audit firm, need to rewire the processes to be able to take advantage of the benefits that the tools provide. And I think it&#x27;s 18 months away before that sort of change management catches up with the standard of the tool.\" He also stressed an \"ironclad guarantee\" to Co-Counsel customers that \"their input will not be part of our AI output,\" and urged enterprise leaders to be \"feverish\" about protecting institutional intellectual property.Seth Hain from Epic — the healthcare technology company behind MyChart — offered a finding that may foreshadow where enterprise AI adoption is truly heading. \"Over half of our use of Claude Code is by non-developer roles across the company,\" Hain said, describing how support and implementation staff had adopted the tool in ways the company never anticipated. Hain also described a deliberate trust-building strategy: Epic&#x27;s first AI capability was a medical record summarization that included links to the underlying source material, giving clinicians the ability to verify and build confidence before the company introduced more autonomous agent capabilities.A year of Claude Code and MCP adoption explains why this moment feels differentTuesday&#x27;s announcements cannot be understood in isolation. They are essentially the culmination of a year in which Anthropic transformed itself from a research-focused AI lab into a company with genuine enterprise distribution and developer ecosystem gravity.The trajectory began with Claude Code, which Jensen noted had taken coding use cases \"from assisting on tiny tasks to AI writing 90 or sometimes even 100% of the code, with enterprises shipping in weeks what once took many quarters.\" But the deeper structural shift was the adoption of MCP — the Model Context Protocol — which has become the connective tissue allowing Claude to reach into and act upon data across an organization&#x27;s entire technology stack. Where previous AI tools were constrained to the information users manually fed them, MCP-connected Claude can pull context from Slack threads, Google Drive documents, CRM records, and financial systems simultaneously. This is what makes the plugin architecture announced Tuesday fundamentally different from earlier chatbot-style enterprise AI: it turns Claude into a reasoning layer that sits across an organization&#x27;s existing infrastructure rather than alongside it.The implications for the broader AI industry are profound. Anthropic is effectively building a platform play — private plugin marketplaces, portable file-based plugins, and an expanding library of MCP connectors — that echoes the ecosystem strategies of earlier platform giants like Salesforce and Microsoft. The difference is velocity: Anthropic is compressing into months the kind of ecosystem development that previously took years. The company&#x27;s willingness to ship sector-specific plugin templates for investment banking, equity research, and wealth management alongside general-purpose tools signals that it sees no bright line between platform and application, between enabling partners and competing with them.This strategic ambiguity is precisely what has spooked Wall Street. IBM shares suffered their worst single-day loss since October 2000 — down nearly 13.2% — on Monday after Anthropic published a blog post about using Claude Code to modernize COBOL, the decades-old programming language that runs on IBM&#x27;s mainframe systems. Enterprise software stocks had already been under heavy pressure since the initial Cowork announcement on January 30, with companies like ServiceNow, Salesforce, Snowflake, Intuit, and Thomson Reuters all experiencing steep declines. Cybersecurity companies tumbled after the company unveiled Claude Code Security on February 20.Yet Tuesday&#x27;s event triggered a partial reversal that revealed something important about how markets are processing AI disruption. Companies named as Anthropic partners and integration targets — Salesforce, DocuSign, LegalZoom, Thomson Reuters, FactSet — all rallied, some sharply. Thomson Reuters surged more than 11%. The market appears to be drawing a new distinction: companies integrated into Anthropic&#x27;s ecosystem may benefit, while those standing outside it face existential risk.Anthropic&#x27;s own economist warns that AI&#x27;s impact will be uneven — and fastPeter McCrory, Anthropic&#x27;s head of economics, presented data from the Anthropic Economic Index that offered a sober counterweight to the event&#x27;s product optimism. Using privacy-preserving methods to analyze how people and businesses use Claude, McCrory&#x27;s team has tracked AI&#x27;s diffusion across more than 150 countries and every US state.The headline finding is striking: a year ago, roughly a third of all US jobs had at least a quarter of their associated tasks appearing in Claude usage data. That figure has now risen to approximately one in every two jobs. \"The scope of impact is broadening out throughout the economy as the tools and as the technology becomes more capable,\" McCrory said. He characterized AI as a \"general purpose technology\" in the economic sense — meaning virtually no facet of the economy will be unaffected.McCrory drew a critical distinction between automation, where Claude simply executes a task, and augmentation, where it collaborates with a human on more complex work. When businesses embed Claude through the API, he noted, \"we see overwhelmingly Claude is being embedded in automated ways\" — a pattern consistent with how transformative technologies have historically diffused through the economy.On the question of job displacement, McCrory was measured but direct. He noted that \"roles that typically require more years of schooling have the largest productivity or efficiency gains,\" suggesting a dynamic economists call skill-biased technical change. He expressed concern about \"jobs that are pure implementation\" — citing data entry workers and technical writers as examples where Claude is already being used for tasks central to those occupations. But he emphasized that no evidence of widespread labor displacement has materialized yet, and pointed to forthcoming research that would introduce methodology for monitoring whether highly exposed workers are beginning to experience it.His advice to enterprise leaders cut to the heart of the organizational challenge. \"It might not just be about fundamental capabilities of the model,\" McCrory said. \"Do you have the right sort of data ecosystem, data infrastructure to provide the right information at the right time?\" If the knowledge Claude needs to execute a sophisticated task exists only in a coworker&#x27;s head, he argued, \"that&#x27;s not a technical problem, per se. That&#x27;s an organizational problem.\"The question every enterprise leader is now asking — and why no one has the answer yetJensen described a concept Anthropic calls \"the thinking divide\" — the growing gap between organizations that embed AI across employees, processes, and products simultaneously, and those that treat it as a point solution. The companies on the right side of that divide, she argued, will compound their advantage over time. Those on the wrong side \"will find themselves falling further and further behind.\"Whether Anthropic ultimately functions as the rising tide that lifts the enterprise software ecosystem or the wave that swamps it remains genuinely uncertain. The same event that triggered a rally in shares of Anthropic&#x27;s named partners has also accelerated a broader reckoning for legacy software companies that cannot yet articulate how they fit into an AI-native world. McCrory, the economist, counseled humility. \"Capabilities are moving very, very quickly,\" he said. \"It might represent an innovation in the method of innovation. So it&#x27;s not just making us better at the things that we do — it&#x27;s helping us discover new ways to do things.\"Thomson Reuters&#x27; Hasker perhaps put it most practically. \"As leaders, we all have to get personally involved and personally invested in using the tools,\" he said. \"We&#x27;ve got to move fast. This environment is changing quickly. We cannot afford to get left behind.\"A Fortune 10 CIO recently told Jensen that enterprises would need to fit a decade of innovation into the next few years. The CIO smiled and said: \"We&#x27;re going to do it in one with you.\" Whether that confidence proves prescient or premature, one thing is clear from Tuesday&#x27;s event — the window for figuring it out is closing faster than most boardrooms realize.",
          "content": "Anthropic opened its virtual \"Briefing: Enterprise Agents\" event on Tuesday with a provocation. Kate Jensen, the company&#x27;s head of Americas, told viewers that the hype around enterprise AI agents in 2025 \"turned out to be mostly premature,\" with many pilots failing to reach production. \"It wasn&#x27;t a failure of effort, it was a failure of approach, and it&#x27;s something we heard directly from our customers,\" Jensen said.The implicit promise: Anthropic has figured out the right approach, and it starts with the playbook that made Claude Code one of the most consequential developer tools of the past year. \"In 2025 Claude transformed how developers work, and in 2026 it will do the same for knowledge work,\" Jensen said. \"The magic behind Claude Code is simple. When you can delegate hard challenges, you can focus on the work that actually matters. Cowork brings that same power to knowledge workers.\"That framing is central to understanding what Anthropic announced on Tuesday. The company rolled out a sweeping set of enterprise capabilities for Claude Cowork, the AI productivity platform it first released in research preview in January. Scott White, head of product for Claude Enterprise, described the ambition plainly during the keynote: \"Cowork makes it possible for Claude to deliver polished, near final work. It goes beyond drafts and suggestions — actual completed projects and deliverables.\"The product updates are dense but consequential. Enterprise administrators can now build private plugin marketplaces tailored to their organizations, connecting to private GitHub repositories as plugin sources and controlling which plugins employees can access. Anthropic introduced new prebuilt plugin templates spanning HR, design, engineering, operations, financial analysis, investment banking, equity research, private equity, and wealth management. The company also shipped new MCP connectors for Google Drive, Google Calendar, Gmail, DocuSign, Apollo, Clay, Outreach, SimilarWeb, MSCI, LegalZoom, FactSet, WordPress, and Harvey — dramatically extending Claude&#x27;s reach into the software ecosystem that enterprises already use. And Claude can now pass context seamlessly between Cowork, Excel, and PowerPoint, including across multiple files, without requiring users to restart when switching applications.White emphasized that the system is designed to feel native to each organization rather than generic. \"We&#x27;ve heard loud and clear from enterprises — you want Claude to work the way that your company works, not just Claude for legal, but Cowork for legal at your company,\" he said. \"That&#x27;s exactly what today&#x27;s launches deliver.\"Real-world results from Spotify, Novo Nordisk, and Salesforce hint at what&#x27;s comingTo ground the product announcements in measurable outcomes, Anthropic showcased three enterprise deployments that illustrate both the scale and the variety of impact the company claims Claude can deliver.At Spotify, engineers had long struggled with code migrations — the slow, manual work of updating and modernizing code across thousands of services. Jensen explained that after integrating Claude directly into the system Spotify&#x27;s engineers use daily, \"any engineer can kick off a large-scale migration just by describing what they need in plain English.\" The company reports up to a 90% reduction in engineering time, over 650 AI-generated code changes shipped per month, and roughly half of all Spotify updates now flowing through the system.At Novo Nordisk, the pharmaceutical giant built an AI-powered platform called NovoScribe with Claude as its intelligence layer, targeting the grueling process of producing regulatory documentation for new medicines. Staff writers had previously averaged just over two reports per year. After deploying Claude, Jensen said, \"documentation creation went from 10 plus weeks to 10 minutes. That&#x27;s a 95% reduction in resources for verification checks. Medicines are reaching patients faster.\" Jensen also noted that Novo Nordisk used Claude Code to build the platform itself, enabling contributions from non-engineers — their digitalization strategy director, who holds a PhD in molecular biology rather than engineering, now prototypes features using natural language. \"A team of 11 is operating like a team many times its size,\" Jensen said.Salesforce, meanwhile, uses Claude models to help power AI in Slack, reporting a 96% satisfaction rate for tools like its Slack bot and saving customers an estimated 97 minutes per week through summarization and recap features. The partnership reflects Anthropic&#x27;s broader ecosystem strategy: Jensen described the companies featured at the event as \"Claude partners and domain experts with the data and trusted relationships that make Claude work in the real world.\"Enterprise leaders reveal the messy reality behind AI transformationPerhaps the most illuminating segment of the event was a panel discussion featuring executives from Thomson Reuters, the New York Stock Exchange, and Epic, who provided candid assessments of AI&#x27;s enterprise reality that went well beyond the polished case studies.Sridhar Masam, CTO of the New York Stock Exchange, described his organization as \"rewiring our engineering process\" with Claude Code and building internal AI agents using the Claude Agent SDK that can take instructions from a Jira ticket all the way to a committed piece of code. But he also identified fundamental shifts in how leaders must think. \"The accountability is shifting,\" he said. \"Traditionally, we are so used to building deterministic platforms. You write code requirements and build. And now, with AI being probabilistic, the accountability doesn&#x27;t end when the project goes live, but on a daily basis, monitoring the behavior and outcomes.\" He described a new paradigm beyond \"buy versus build\" — what he called \"assembly,\" the practice of combining multiple models, multiple vendors, platforms, data, and internal capabilities into solutions. And he noted that highly regulated industries must shift \"from risk avoidance to risk calibration,\" because simply avoiding AI is no longer a competitive option.Steve Hasker from Thomson Reuters, whose Co-Counsel product has reached a million users, was frank about the gap between what the technology can do and what organizations are ready for. \"The tools are in many senses ahead of the change management,\" he said. \"A general counsel&#x27;s office, a law firm, a tax and accounting firm, an audit firm, need to rewire the processes to be able to take advantage of the benefits that the tools provide. And I think it&#x27;s 18 months away before that sort of change management catches up with the standard of the tool.\" He also stressed an \"ironclad guarantee\" to Co-Counsel customers that \"their input will not be part of our AI output,\" and urged enterprise leaders to be \"feverish\" about protecting institutional intellectual property.Seth Hain from Epic — the healthcare technology company behind MyChart — offered a finding that may foreshadow where enterprise AI adoption is truly heading. \"Over half of our use of Claude Code is by non-developer roles across the company,\" Hain said, describing how support and implementation staff had adopted the tool in ways the company never anticipated. Hain also described a deliberate trust-building strategy: Epic&#x27;s first AI capability was a medical record summarization that included links to the underlying source material, giving clinicians the ability to verify and build confidence before the company introduced more autonomous agent capabilities.A year of Claude Code and MCP adoption explains why this moment feels differentTuesday&#x27;s announcements cannot be understood in isolation. They are essentially the culmination of a year in which Anthropic transformed itself from a research-focused AI lab into a company with genuine enterprise distribution and developer ecosystem gravity.The trajectory began with Claude Code, which Jensen noted had taken coding use cases \"from assisting on tiny tasks to AI writing 90 or sometimes even 100% of the code, with enterprises shipping in weeks what once took many quarters.\" But the deeper structural shift was the adoption of MCP — the Model Context Protocol — which has become the connective tissue allowing Claude to reach into and act upon data across an organization&#x27;s entire technology stack. Where previous AI tools were constrained to the information users manually fed them, MCP-connected Claude can pull context from Slack threads, Google Drive documents, CRM records, and financial systems simultaneously. This is what makes the plugin architecture announced Tuesday fundamentally different from earlier chatbot-style enterprise AI: it turns Claude into a reasoning layer that sits across an organization&#x27;s existing infrastructure rather than alongside it.The implications for the broader AI industry are profound. Anthropic is effectively building a platform play — private plugin marketplaces, portable file-based plugins, and an expanding library of MCP connectors — that echoes the ecosystem strategies of earlier platform giants like Salesforce and Microsoft. The difference is velocity: Anthropic is compressing into months the kind of ecosystem development that previously took years. The company&#x27;s willingness to ship sector-specific plugin templates for investment banking, equity research, and wealth management alongside general-purpose tools signals that it sees no bright line between platform and application, between enabling partners and competing with them.This strategic ambiguity is precisely what has spooked Wall Street. IBM shares suffered their worst single-day loss since October 2000 — down nearly 13.2% — on Monday after Anthropic published a blog post about using Claude Code to modernize COBOL, the decades-old programming language that runs on IBM&#x27;s mainframe systems. Enterprise software stocks had already been under heavy pressure since the initial Cowork announcement on January 30, with companies like ServiceNow, Salesforce, Snowflake, Intuit, and Thomson Reuters all experiencing steep declines. Cybersecurity companies tumbled after the company unveiled Claude Code Security on February 20.Yet Tuesday&#x27;s event triggered a partial reversal that revealed something important about how markets are processing AI disruption. Companies named as Anthropic partners and integration targets — Salesforce, DocuSign, LegalZoom, Thomson Reuters, FactSet — all rallied, some sharply. Thomson Reuters surged more than 11%. The market appears to be drawing a new distinction: companies integrated into Anthropic&#x27;s ecosystem may benefit, while those standing outside it face existential risk.Anthropic&#x27;s own economist warns that AI&#x27;s impact will be uneven — and fastPeter McCrory, Anthropic&#x27;s head of economics, presented data from the Anthropic Economic Index that offered a sober counterweight to the event&#x27;s product optimism. Using privacy-preserving methods to analyze how people and businesses use Claude, McCrory&#x27;s team has tracked AI&#x27;s diffusion across more than 150 countries and every US state.The headline finding is striking: a year ago, roughly a third of all US jobs had at least a quarter of their associated tasks appearing in Claude usage data. That figure has now risen to approximately one in every two jobs. \"The scope of impact is broadening out throughout the economy as the tools and as the technology becomes more capable,\" McCrory said. He characterized AI as a \"general purpose technology\" in the economic sense — meaning virtually no facet of the economy will be unaffected.McCrory drew a critical distinction between automation, where Claude simply executes a task, and augmentation, where it collaborates with a human on more complex work. When businesses embed Claude through the API, he noted, \"we see overwhelmingly Claude is being embedded in automated ways\" — a pattern consistent with how transformative technologies have historically diffused through the economy.On the question of job displacement, McCrory was measured but direct. He noted that \"roles that typically require more years of schooling have the largest productivity or efficiency gains,\" suggesting a dynamic economists call skill-biased technical change. He expressed concern about \"jobs that are pure implementation\" — citing data entry workers and technical writers as examples where Claude is already being used for tasks central to those occupations. But he emphasized that no evidence of widespread labor displacement has materialized yet, and pointed to forthcoming research that would introduce methodology for monitoring whether highly exposed workers are beginning to experience it.His advice to enterprise leaders cut to the heart of the organizational challenge. \"It might not just be about fundamental capabilities of the model,\" McCrory said. \"Do you have the right sort of data ecosystem, data infrastructure to provide the right information at the right time?\" If the knowledge Claude needs to execute a sophisticated task exists only in a coworker&#x27;s head, he argued, \"that&#x27;s not a technical problem, per se. That&#x27;s an organizational problem.\"The question every enterprise leader is now asking — and why no one has the answer yetJensen described a concept Anthropic calls \"the thinking divide\" — the growing gap between organizations that embed AI across employees, processes, and products simultaneously, and those that treat it as a point solution. The companies on the right side of that divide, she argued, will compound their advantage over time. Those on the wrong side \"will find themselves falling further and further behind.\"Whether Anthropic ultimately functions as the rising tide that lifts the enterprise software ecosystem or the wave that swamps it remains genuinely uncertain. The same event that triggered a rally in shares of Anthropic&#x27;s named partners has also accelerated a broader reckoning for legacy software companies that cannot yet articulate how they fit into an AI-native world. McCrory, the economist, counseled humility. \"Capabilities are moving very, very quickly,\" he said. \"It might represent an innovation in the method of innovation. So it&#x27;s not just making us better at the things that we do — it&#x27;s helping us discover new ways to do things.\"Thomson Reuters&#x27; Hasker perhaps put it most practically. \"As leaders, we all have to get personally involved and personally invested in using the tools,\" he said. \"We&#x27;ve got to move fast. This environment is changing quickly. We cannot afford to get left behind.\"A Fortune 10 CIO recently told Jensen that enterprises would need to fit a decade of innovation into the next few years. The CIO smiled and said: \"We&#x27;re going to do it in one with you.\" Whether that confidence proves prescient or premature, one thing is clear from Tuesday&#x27;s event — the window for figuring it out is closing faster than most boardrooms realize.",
          "feed_position": 5,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/4Go7ccNVAocm7JfJv7mITS/06d5aee9b462e58c0c16348e6762866f/nuneybits_Vector_art_of_a_burnt_orange_tidal_wave_crashing_over_8c717943-4488-4e3e-a47f-c35dbac7fc46.webp?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/laptops/apples-touchscreen-macbook-will-reportedly-have-a-dynamic-interface-231929456.html",
          "published_at": "Tue, 24 Feb 2026 23:19:29 +0000",
          "title": "Apple's touchscreen MacBook will reportedly have a dynamic interface",
          "standfirst": "Apple's plan to add touchscreens to its premium MacBook Pros is coming into focus. Bloomberg reports that when the new laptops launch this fall, they'll feature a Dynamic Island, not unlike Apple's iPhones, and an interface that changes depending on where you touch your Macbook's screen.This \"dynamic interface\" is reportedly designed to make the transition between mouse input and touch input smoother on Apple's new laptops. Bloomberg says that if users touch an onscreen button, the version of macOS running on these new MacBook Pros will be able to pull up a contextual menu \"that provides more relevant options for touch commands.\" Parts of the interface, like macOS' menu bar, will also be able to enlarge to make menu items easier to select with a finger. Those tweaks are on top of the expected features from touchscreen Apple products, like smooth scrolling and the ability to pinch and zoom into and out of images, files and web pages. The only thing missing from these increasingly iPad-like laptops, per Bloomberg, will be a touchscreen keyboard, because they'll already have a more comfortable physical keyboard attached.To make these new laptops extra enticing, both the 14-inch and 16-inch touchscreen MacBook Pros will feature OLED screens for the first time, likely the reason Apple will be able to include a Dynamic Island-style webcam in the first place. Up until now, the company has offered OLED screens on its iPhones, Apple Watches and more recently the iPad Pro, but it hasn't brought the display technology to laptops. That could reportedly change with these new MacBook Pros.Plenty of Windows laptops include touchscreens, and Microsoft and its partners have incorporated dynamic interface elements in the past to make these touchscreens more natural to use with Windows. Apple is late to the party in this respect, but it's also potentially set up to succeed. Much of modern macOS already looks touch-friendly, and Apple's has expended significant effort making it possible to port touch-based iPad apps to macOS and develop applications across platforms. That, paired with the right interface, could make the experience of using a touchscreen MacBook nicer out of the box, even if it doesn't get rid of the awkwardness of reaching over your keyboard to touch a screen.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/apples-touchscreen-macbook-will-reportedly-have-a-dynamic-interface-231929456.html?src=rss",
          "content": "Apple's plan to add touchscreens to its premium MacBook Pros is coming into focus. Bloomberg reports that when the new laptops launch this fall, they'll feature a Dynamic Island, not unlike Apple's iPhones, and an interface that changes depending on where you touch your Macbook's screen.This \"dynamic interface\" is reportedly designed to make the transition between mouse input and touch input smoother on Apple's new laptops. Bloomberg says that if users touch an onscreen button, the version of macOS running on these new MacBook Pros will be able to pull up a contextual menu \"that provides more relevant options for touch commands.\" Parts of the interface, like macOS' menu bar, will also be able to enlarge to make menu items easier to select with a finger. Those tweaks are on top of the expected features from touchscreen Apple products, like smooth scrolling and the ability to pinch and zoom into and out of images, files and web pages. The only thing missing from these increasingly iPad-like laptops, per Bloomberg, will be a touchscreen keyboard, because they'll already have a more comfortable physical keyboard attached.To make these new laptops extra enticing, both the 14-inch and 16-inch touchscreen MacBook Pros will feature OLED screens for the first time, likely the reason Apple will be able to include a Dynamic Island-style webcam in the first place. Up until now, the company has offered OLED screens on its iPhones, Apple Watches and more recently the iPad Pro, but it hasn't brought the display technology to laptops. That could reportedly change with these new MacBook Pros.Plenty of Windows laptops include touchscreens, and Microsoft and its partners have incorporated dynamic interface elements in the past to make these touchscreens more natural to use with Windows. Apple is late to the party in this respect, but it's also potentially set up to succeed. Much of modern macOS already looks touch-friendly, and Apple's has expended significant effort making it possible to port touch-based iPad apps to macOS and develop applications across platforms. That, paired with the right interface, could make the experience of using a touchscreen MacBook nicer out of the box, even if it doesn't get rid of the awkwardness of reaching over your keyboard to touch a screen.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/apples-touchscreen-macbook-will-reportedly-have-a-dynamic-interface-231929456.html?src=rss",
          "feed_position": 33
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/technology/the-era-of-human-web-search-is-over-nimble-launches-agentic-search-platform",
          "published_at": "Tue, 24 Feb 2026 22:47:00 GMT",
          "title": "The era of human web search is over: Nimble launches Agentic Search Platform for enterprises boasting 99% accuracy",
          "standfirst": "Web Search has already been disrupted by AI — just take a look at how readily Google is presenting users with AI Overviews (summaries of search results) at the top of their results pages, how Bing early on integrated OpenAI&#x27;s GPT models, and how Perplexity continues to build on its own AI-driven web search platform and browsers. Nimble announced the launch of its Agentic Search Platform, a system designed to transform the public web into trusted, decision-grade data for AI systems and business workflows. The launch is supported by $47 million in Series B financing led by Norwest, with participation from Databricks Ventures and others, bringing the company&#x27;s total funding to $75 million.The initiative addresses a fundamental bottleneck in the current AI era: while large language models (LLMs) are becoming more sophisticated, they often reason over incomplete or unverifiable external information. Nimble’s platform aims to eliminate this \"guesswork gap\" by providing a governed data layer that searches, navigates, and validates live internet data in real time.In an exclusive interview with VentureBeat, Nimble co-founder and CEO Uri Knorovich reflected on the early skepticism regarding his vision of a machine-centric internet. \"Whenever we started this company, and the first time I went to investors, I told them the web is built for humans, but machines are going to be the first citizens of the web,\" Knorovich recalled. He noted that while initial reactions labeled him as \"too visionary,\" the current reality of AI adoption has validated his thesis.Technology: Coordinated multi-agent architectureThe core of Nimble’s solution is a proprietary distributed architecture that orchestrates specialized agents to perform tasks traditionally handled by human researchers or brittle web scrapers. According to the company&#x27;s infrastructure documentation, the process is broken down into five distinct layers:Headless browser and browsing agents: These layers manage the initial interaction with a target domain, navigating complex site structures as a human would.Parsing agents: These agents interpret the page content, identifying relevant data elements across various formats.Data processing agents: This layer aggregates, filters, and cleans noisy internet data to produce specific, structured answers.Validation agents: The final step involves verifying the results to ensure accuracy and completeness before delivery.Unlike standard search engines designed for consumer link-clicking, this architecture uses multimodal and reasoning capabilities from frontier models—including those from OpenAI, Anthropic, and Meta—to control real browsers. This allows Nimble to navigate dynamic layouts and cross-check results, producing auditable data outputs rather than simple text summaries.A new paradigm: &#x27;The web is built for humans, but machines are the first citizens&#x27;Knorovich points out that the scale of AI interaction with the web is fundamentally different from human behavior. \"We, as humans, search for maybe three or five options before we making decisions... but every day, Nimble perform more than 3.2 million interactions in the web,\" he explained. This sheer volume of billions of monthly searches represents a programmatic shift that requires a new type of infrastructure.The bottleneck for enterprises today, according to Knorovich, isn&#x27;t the intelligence of the models, but the quality of the data they can access. \"Agents are the headlines, and accurate and reliable web search is the bottleneck,\" he stated.Nimble vs. consumer search: Precision over speedKnorovich explicitly differentiates Nimble from general-purpose tools like Google or consumer AI search assistants. While Google has built a search experience for consumers that is optimized for speed and finding a local restaurant, enterprises require high-scale, high-accuracy results to make multi-million dollar decisions.\"General purpose web search tool are great to have a general answers, such as who is the wife Leo missing,\" Knorovich remarked during the interview. \"But enterprises need deep, granular data, and they need to have the ability to control the search filters, to control the regulation, to control what is a trusted source\". Unlike consumer AI modes that may summarize a Reddit post or high-level news, Nimble provides \"street-level\" information that can be stored directly in an enterprise system of record.Product: Bridging the no-code and developer divideThe Agentic Search Platform is delivered through two primary interfaces designed for enterprise scalability:Web search agents: A no-code AI workflow builder that enables business teams to describe the data they need and receive structured data streams without writing a line of code.Web tools SDK: A suite of APIs for builders to search, extract, and crawl the web directly from their code. This includes specialized tools like the /crawl API for mapping entire domains and the /map API for creating domain trees.The platform is built to deliver data with greater than 99% accuracy — meaning fewer than 1% inaccurate or hallucinated data for the total contents of each search result returned — and a latency of 1-2 milliseconds per request. It integrates natively with major data environments, allowing users to stream clean data directly into Databricks, Snowflake, S3, or Microsoft Fabric.During the interview, Knorovich emphasized that Nimble is designed to be model-agnostic, working seamlessly with state-of-the-art models from OpenAI, Anthropic, and Google&#x27;s Gemini. This flexibility allows companies to use Nimble alongside their existing tech stack, whether they are running models in the cloud or on-premise for high-security environments like healthcare or banking.Case studies: Accuracy in actionKnorovich provided several real-world examples of how this \"street-level\" data impacts professional workflows. For instance, a real estate broker looking to expand into a new territory doesn&#x27;t need a high-level summary from a general-purpose AI. \"If you want to know what&#x27;s happening in the commercial real estate in Atlanta... you&#x27;re not looking for search that&#x27;s optimized for the millisecond,\" Knorovich explained. \"You&#x27;re looking for street-level, neighborhood-level information... data that you can actually see on a table or download to Excel\".Another use case involves major financial institutions utilizing Nimble for \"know your customer\" (KYC) processes. By deploying an autonomous search agent, banks can cross-reference multiple public reports, criminal records, and address verifications to build a complete profile of a client before they even enter the building. The goal, Knorovich noted, is to provide the \"external truth\" that exists outside an organization&#x27;s internal firewalls.Enterprise licensing and complianceNimble differentiates itself from legacy scraping tools through a rigorous focus on governance and trust. The platform is \"compliant-by-design,\" holding certifications for SOC2 Type II, GDPR, CCPA, and HIPAA.Pricing is structured to support both experimental startups and high-scale enterprise operations, aligned with the volume and depth of data retrieved. \"Pricing should be aligned with the value that the user is getting... therefore, we are pricing by the amount of searches that you&#x27;re running,\" Knorovich said.Search and answer APIs: Standard search inputs cost $1 per 1,000, while the \"Answer\" function—which provides reasoning based on search results—costs $4 per 1,000.Managed services: For larger organizations, managed tiers start at $2,000 per month (Startup) and scale to $15,000 per month (Professional) for unlimited agents and priority support.Proxy access: A network of over 1 million residential proxies is available starting at $7.50 per GBCommunity and user reactionsThe transition to agentic search has already been operationalized by several Fortune 500 companies and AI-native startups:Julie Averill, former CIO at Lululemon, stated that pricing intelligence which once took weeks to review can now be responded to in minutes by putting control in the hands of an agent.Itamar Fridman, CEO and Co-founder of Qodo, noted that the platform’s scalability was \"crucial in developing more robust and reliable AI systems\" by feeding LLMs with high-quality data.Dennis Irorere, Data Engineer at TripAdvisor, highlighted that the platform simplifies the extraction of structured data from complex sources, which he described as \"transformative\" for his role.Grips Intelligence reported scaling to over 45,000 e-commerce sites using Nimble’s Web API to deliver real-time pricing and product data.Alta utilizes the platform to power millions of AI-driven go-to-market workflows daily, reporting 3–4× deeper context and >99% reliabilitySeries B to accelerate multi-agent web search and data governanceThe $47 million Series B funding announced alongside the platform will be used to accelerate research in multi-agent web search and further develop the governed data layer. The round saw participation from a wide ecosystem of investors, including Target Global, Square Peg, Hetz Ventures, Slow Ventures, R-Squared Ventures, J-Ventures, and InvestInData.Andrew Ferguson, VP of Databricks Ventures, noted that Nimble complements their Data Intelligence Platform by providing a \"real-time web data layer\" that extends workflows beyond internal sources. This strategic investment signals a shift in the industry toward prioritizing \"external truth\" to ground mission-critical AI applications.For Knorovich, the future of the web belongs to programmatic interaction. \"Programmatic web search is where we are building towards,\" he concluded. By moving away from legacy data vendors and brittle scrapers, Nimble aims to provide the real-time structure needed for AI to act with confidence in the real world.",
          "content": "Web Search has already been disrupted by AI — just take a look at how readily Google is presenting users with AI Overviews (summaries of search results) at the top of their results pages, how Bing early on integrated OpenAI&#x27;s GPT models, and how Perplexity continues to build on its own AI-driven web search platform and browsers. Nimble announced the launch of its Agentic Search Platform, a system designed to transform the public web into trusted, decision-grade data for AI systems and business workflows. The launch is supported by $47 million in Series B financing led by Norwest, with participation from Databricks Ventures and others, bringing the company&#x27;s total funding to $75 million.The initiative addresses a fundamental bottleneck in the current AI era: while large language models (LLMs) are becoming more sophisticated, they often reason over incomplete or unverifiable external information. Nimble’s platform aims to eliminate this \"guesswork gap\" by providing a governed data layer that searches, navigates, and validates live internet data in real time.In an exclusive interview with VentureBeat, Nimble co-founder and CEO Uri Knorovich reflected on the early skepticism regarding his vision of a machine-centric internet. \"Whenever we started this company, and the first time I went to investors, I told them the web is built for humans, but machines are going to be the first citizens of the web,\" Knorovich recalled. He noted that while initial reactions labeled him as \"too visionary,\" the current reality of AI adoption has validated his thesis.Technology: Coordinated multi-agent architectureThe core of Nimble’s solution is a proprietary distributed architecture that orchestrates specialized agents to perform tasks traditionally handled by human researchers or brittle web scrapers. According to the company&#x27;s infrastructure documentation, the process is broken down into five distinct layers:Headless browser and browsing agents: These layers manage the initial interaction with a target domain, navigating complex site structures as a human would.Parsing agents: These agents interpret the page content, identifying relevant data elements across various formats.Data processing agents: This layer aggregates, filters, and cleans noisy internet data to produce specific, structured answers.Validation agents: The final step involves verifying the results to ensure accuracy and completeness before delivery.Unlike standard search engines designed for consumer link-clicking, this architecture uses multimodal and reasoning capabilities from frontier models—including those from OpenAI, Anthropic, and Meta—to control real browsers. This allows Nimble to navigate dynamic layouts and cross-check results, producing auditable data outputs rather than simple text summaries.A new paradigm: &#x27;The web is built for humans, but machines are the first citizens&#x27;Knorovich points out that the scale of AI interaction with the web is fundamentally different from human behavior. \"We, as humans, search for maybe three or five options before we making decisions... but every day, Nimble perform more than 3.2 million interactions in the web,\" he explained. This sheer volume of billions of monthly searches represents a programmatic shift that requires a new type of infrastructure.The bottleneck for enterprises today, according to Knorovich, isn&#x27;t the intelligence of the models, but the quality of the data they can access. \"Agents are the headlines, and accurate and reliable web search is the bottleneck,\" he stated.Nimble vs. consumer search: Precision over speedKnorovich explicitly differentiates Nimble from general-purpose tools like Google or consumer AI search assistants. While Google has built a search experience for consumers that is optimized for speed and finding a local restaurant, enterprises require high-scale, high-accuracy results to make multi-million dollar decisions.\"General purpose web search tool are great to have a general answers, such as who is the wife Leo missing,\" Knorovich remarked during the interview. \"But enterprises need deep, granular data, and they need to have the ability to control the search filters, to control the regulation, to control what is a trusted source\". Unlike consumer AI modes that may summarize a Reddit post or high-level news, Nimble provides \"street-level\" information that can be stored directly in an enterprise system of record.Product: Bridging the no-code and developer divideThe Agentic Search Platform is delivered through two primary interfaces designed for enterprise scalability:Web search agents: A no-code AI workflow builder that enables business teams to describe the data they need and receive structured data streams without writing a line of code.Web tools SDK: A suite of APIs for builders to search, extract, and crawl the web directly from their code. This includes specialized tools like the /crawl API for mapping entire domains and the /map API for creating domain trees.The platform is built to deliver data with greater than 99% accuracy — meaning fewer than 1% inaccurate or hallucinated data for the total contents of each search result returned — and a latency of 1-2 milliseconds per request. It integrates natively with major data environments, allowing users to stream clean data directly into Databricks, Snowflake, S3, or Microsoft Fabric.During the interview, Knorovich emphasized that Nimble is designed to be model-agnostic, working seamlessly with state-of-the-art models from OpenAI, Anthropic, and Google&#x27;s Gemini. This flexibility allows companies to use Nimble alongside their existing tech stack, whether they are running models in the cloud or on-premise for high-security environments like healthcare or banking.Case studies: Accuracy in actionKnorovich provided several real-world examples of how this \"street-level\" data impacts professional workflows. For instance, a real estate broker looking to expand into a new territory doesn&#x27;t need a high-level summary from a general-purpose AI. \"If you want to know what&#x27;s happening in the commercial real estate in Atlanta... you&#x27;re not looking for search that&#x27;s optimized for the millisecond,\" Knorovich explained. \"You&#x27;re looking for street-level, neighborhood-level information... data that you can actually see on a table or download to Excel\".Another use case involves major financial institutions utilizing Nimble for \"know your customer\" (KYC) processes. By deploying an autonomous search agent, banks can cross-reference multiple public reports, criminal records, and address verifications to build a complete profile of a client before they even enter the building. The goal, Knorovich noted, is to provide the \"external truth\" that exists outside an organization&#x27;s internal firewalls.Enterprise licensing and complianceNimble differentiates itself from legacy scraping tools through a rigorous focus on governance and trust. The platform is \"compliant-by-design,\" holding certifications for SOC2 Type II, GDPR, CCPA, and HIPAA.Pricing is structured to support both experimental startups and high-scale enterprise operations, aligned with the volume and depth of data retrieved. \"Pricing should be aligned with the value that the user is getting... therefore, we are pricing by the amount of searches that you&#x27;re running,\" Knorovich said.Search and answer APIs: Standard search inputs cost $1 per 1,000, while the \"Answer\" function—which provides reasoning based on search results—costs $4 per 1,000.Managed services: For larger organizations, managed tiers start at $2,000 per month (Startup) and scale to $15,000 per month (Professional) for unlimited agents and priority support.Proxy access: A network of over 1 million residential proxies is available starting at $7.50 per GBCommunity and user reactionsThe transition to agentic search has already been operationalized by several Fortune 500 companies and AI-native startups:Julie Averill, former CIO at Lululemon, stated that pricing intelligence which once took weeks to review can now be responded to in minutes by putting control in the hands of an agent.Itamar Fridman, CEO and Co-founder of Qodo, noted that the platform’s scalability was \"crucial in developing more robust and reliable AI systems\" by feeding LLMs with high-quality data.Dennis Irorere, Data Engineer at TripAdvisor, highlighted that the platform simplifies the extraction of structured data from complex sources, which he described as \"transformative\" for his role.Grips Intelligence reported scaling to over 45,000 e-commerce sites using Nimble’s Web API to deliver real-time pricing and product data.Alta utilizes the platform to power millions of AI-driven go-to-market workflows daily, reporting 3–4× deeper context and >99% reliabilitySeries B to accelerate multi-agent web search and data governanceThe $47 million Series B funding announced alongside the platform will be used to accelerate research in multi-agent web search and further develop the governed data layer. The round saw participation from a wide ecosystem of investors, including Target Global, Square Peg, Hetz Ventures, Slow Ventures, R-Squared Ventures, J-Ventures, and InvestInData.Andrew Ferguson, VP of Databricks Ventures, noted that Nimble complements their Data Intelligence Platform by providing a \"real-time web data layer\" that extends workflows beyond internal sources. This strategic investment signals a shift in the industry toward prioritizing \"external truth\" to ground mission-critical AI applications.For Knorovich, the future of the web belongs to programmatic interaction. \"Programmatic web search is where we are building towards,\" he concluded. By moving away from legacy data vendors and brittle scrapers, Nimble aims to provide the real-time structure needed for AI to act with confidence in the real world.",
          "feed_position": 6,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/3o6l2UtvJR37cFjPT1ym9N/a39fd40138caaa58bc91479e9b4a42e9/QS4VRiXDpntQnkiIa4eHW_Evg9gSvJ.jpg?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/social-media/discord-delays-age-verification-to-address-user-concerns-205500482.html",
          "published_at": "Tue, 24 Feb 2026 20:55:00 +0000",
          "title": "Discord delays age verification to address user concerns",
          "standfirst": "Earlier this month, Discord said it would be enacting an age verification policy. The platform faced some initial concerns from users about turning over their IDs and personal information, particularly given how poorly similar policies have been going elsewhere. Discord announced today it will delay and make some changes to its plans in response to the ongoing backlash.The first change is that Discord is postponing the global rollout of its age verification plans until the second half of 2026. The company noted that it would meet its legal obligations in places where they exist, likely in those countries that have national laws requiring protections for younger users. But it will not begin the global rollout until it makes some amendments to the offerings.Discord will offer more alternatives to how users can confirm their ages, including verification by credit card. That should allow people to access age-gated content without sharing an ID or performing a face scan. \"If you're among the less than 10 percent of users who do need to verify, we'll give you options, designed to tell us only your age and never your identity,\" according to a blog post credited to co-founder and CTO Stanislav Vishnevskiy.The company is also promising more transparency about its vendors for these verification services and their practices. Discord said that it will not work with any partners for face scans unless the tests are performed completely on-device. The blog post noted that Persona, one of the common vendors for facial age estimation services, does not meet that standard and Discord has opted not to work with the brand. Finally, Discord is also building a new spoiler channel option so that servers with select age-restricted channels won't have to require all members to verify their ages. It will also publish a technical explainer on its own automatic age determination systems.We at Engadget have own worries about the wave of age verification laws happening both within the US and globally, but it's somewhat encouraging to see a digital platform at least trying to continue to deliver anonymity while still creating effective protections for teens.This article originally appeared on Engadget at https://www.engadget.com/social-media/discord-delays-age-verification-to-address-user-concerns-205500482.html?src=rss",
          "content": "Earlier this month, Discord said it would be enacting an age verification policy. The platform faced some initial concerns from users about turning over their IDs and personal information, particularly given how poorly similar policies have been going elsewhere. Discord announced today it will delay and make some changes to its plans in response to the ongoing backlash.The first change is that Discord is postponing the global rollout of its age verification plans until the second half of 2026. The company noted that it would meet its legal obligations in places where they exist, likely in those countries that have national laws requiring protections for younger users. But it will not begin the global rollout until it makes some amendments to the offerings.Discord will offer more alternatives to how users can confirm their ages, including verification by credit card. That should allow people to access age-gated content without sharing an ID or performing a face scan. \"If you're among the less than 10 percent of users who do need to verify, we'll give you options, designed to tell us only your age and never your identity,\" according to a blog post credited to co-founder and CTO Stanislav Vishnevskiy.The company is also promising more transparency about its vendors for these verification services and their practices. Discord said that it will not work with any partners for face scans unless the tests are performed completely on-device. The blog post noted that Persona, one of the common vendors for facial age estimation services, does not meet that standard and Discord has opted not to work with the brand. Finally, Discord is also building a new spoiler channel option so that servers with select age-restricted channels won't have to require all members to verify their ages. It will also publish a technical explainer on its own automatic age determination systems.We at Engadget have own worries about the wave of age verification laws happening both within the US and globally, but it's somewhat encouraging to see a digital platform at least trying to continue to deliver anonymity while still creating effective protections for teens.This article originally appeared on Engadget at https://www.engadget.com/social-media/discord-delays-age-verification-to-address-user-concerns-205500482.html?src=rss",
          "feed_position": 35
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/the-pentagon-has-reportedly-given-anthropic-until-friday-to-let-it-use-claude-as-it-sees-fit-203549467.html",
          "published_at": "Tue, 24 Feb 2026 20:35:49 +0000",
          "title": "The Pentagon has reportedly given Anthropic until Friday to let it use Claude as it sees fit",
          "standfirst": "Defense Secretary Pete Hegseth will reportedly give Anthropic until Friday to drop certain guardrails for military use, as reported by Axios. The outlet also reported that CEO Dario Amodei met with Hegseth yesterday as the Pentagon ratcheted up pressure on the AI company to give in to its demands. The makers of Claude have reportedly been offered an ultimatum: Either yield to the government's demands to remove limits for certain military applications, or potentially be forced to tailor its AI model to the government's needs under the Defense Production Act. Anthropic, for its part, has said that while it was willing to adopt certain policies for the Pentagon, it would not allow its model to be used for mass surveillance of Americans or for the development of autonomous weapons. Claude is currently the only AI model employed in some of the government's most sensitive work. \"The only reason we're still talking to these people is we need them and we need them now. The problem for these guys is they are that good,\" a defense official told Axios. The Pentagon is reportedly ramping up conversations with OpenAI and Google about using their models for classified work. ChatGPT and Gemini are already approved for unclassified government use. Elon Musk's xAI also recently signed with the DoD to use Grok in classified systems.This article originally appeared on Engadget at https://www.engadget.com/ai/the-pentagon-has-reportedly-given-anthropic-until-friday-to-let-it-use-claude-as-it-sees-fit-203549467.html?src=rss",
          "content": "Defense Secretary Pete Hegseth will reportedly give Anthropic until Friday to drop certain guardrails for military use, as reported by Axios. The outlet also reported that CEO Dario Amodei met with Hegseth yesterday as the Pentagon ratcheted up pressure on the AI company to give in to its demands. The makers of Claude have reportedly been offered an ultimatum: Either yield to the government's demands to remove limits for certain military applications, or potentially be forced to tailor its AI model to the government's needs under the Defense Production Act. Anthropic, for its part, has said that while it was willing to adopt certain policies for the Pentagon, it would not allow its model to be used for mass surveillance of Americans or for the development of autonomous weapons. Claude is currently the only AI model employed in some of the government's most sensitive work. \"The only reason we're still talking to these people is we need them and we need them now. The problem for these guys is they are that good,\" a defense official told Axios. The Pentagon is reportedly ramping up conversations with OpenAI and Google about using their models for classified work. ChatGPT and Gemini are already approved for unclassified government use. Elon Musk's xAI also recently signed with the DoD to use Grok in classified systems.This article originally appeared on Engadget at https://www.engadget.com/ai/the-pentagon-has-reportedly-given-anthropic-until-friday-to-let-it-use-claude-as-it-sees-fit-203549467.html?src=rss",
          "feed_position": 36
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/smartphones/iphone-fold-rumors-everything-we-know-right-now-including-the-leaked-design-upgrades-price-and-more-130000733.html",
          "published_at": "Tue, 24 Feb 2026 18:16:43 +0000",
          "title": "iPhone Fold rumors: Everything we know right now, including the leaked design, upgrades, price and more",
          "standfirst": "Apple still hasn’t revealed a foldable iPhone, but the steady drip of leaks suggests the project is moving closer to reality. Over the past few months, analysts and supply-chain watchers have continued to fill in key details, with most reports still pointing to a launch sometime in the second half of 2026. While Apple hasn’t confirmed anything publicly, the overall picture is starting to look more consistent.As always, plans for unreleased Apple hardware can change at any time. Features may shift, timelines can slip and some prototypes may never ship. Even so, recent reporting gives us the clearest sense yet of how Apple’s first foldable could take shape and where it might fit in the broader iPhone lineup.Below, we’ve rounded up the most credible rumors so far, and we’ll keep this guide updated as new details emerge.When could the iPhone Fold launch?Rumors of a foldable iPhone date back as far as 2017, but more recent reporting suggests Apple has finally locked onto a realistic window. Most sources now point to fall 2026, likely alongside the iPhone 18 lineup, with some supply-chain hints suggesting mass production could begin in mid-2026 if development stays on track.Mark Gurman has gone back and forth on timing, initially suggesting Apple could launch “as early as 2026,” before later writing that the device would ship at the end of 2026 and sell primarily in 2027. Analyst Ming-Chi Kuo has also repeatedly cited the second half of 2026 as Apple’s target.Some reports still claim the project could slip into 2027 if Apple runs into manufacturing or durability issues, particularly around the hinge or display. Given Apple’s history of delaying products that it feels aren’t ready, that remains a real possibility.What will the iPhone Fold look like?Current consensus suggests Apple has settled on a book-style foldable design, similar to Samsung’s Galaxy Z Fold series, rather than a clamshell flip phone.When unfolded, the iPhone Fold is expected to resemble a small tablet like the iPad mini (8.3 inches). Based on the rumor mill, though, the iPhone Fold may be a touch smaller, with an internal display measuring around 7.7 to 7.8 inches. When closed, it should function like a conventional smartphone, with an outer display in the 5.5-inch range.CAD leaks and alleged case-maker molds suggest the device may be shorter and wider than a standard iPhone when folded, creating a squarer footprint that better matches the aspect ratio of the inner display. Several reports have also pointed to the iPhone Air as a potential preview of Apple’s foldable design work, with its unusually thin chassis widely interpreted as a look at what one half of a future foldable iPhone could resemble.If that theory holds, it could help explain the Fold’s rumored dimensions. Thickness is expected to land around 4.5 to 4.8mm when unfolded, according to analyst Ming-Chi Kuo, putting it in a similar range to the iPhone Air, and roughly 9 to 9.5mm when folded, depending on the final hinge design and internal layering.iPhone 17 Pro, iPhone AirEngadgetDisplay and the crease questionThe display is arguably the biggest challenge for any foldable phone, and it’s an area where Apple appears to have invested years of development.Multiple reports say Apple will rely on Samsung Display as its primary supplier. At CES 2026, Samsung showcased a new crease-less foldable OLED panel, which several sources — including Bloomberg — suggested could be the same technology Apple plans to use.According to these reports, the panel combines a flexible OLED with a laser-drilled metal support plate that disperses stress when folding. The goal is a display with a nearly invisible crease, something Apple reportedly considers essential before entering the foldable market.If Apple does use this panel, it would mark a notable improvement over current foldables, which still show visible creasing under certain lighting conditions.Cameras and biometricsCamera rumors suggest Apple is planning a four-camera setup. That may include:Two rear cameras (main and ultra-wide, both rumored at 48MP)One punch-hole camera on the outer displayOne under-display camera on the inner screenSeveral sources claim Apple will avoid Face ID entirely on the iPhone Fold. Instead, it’s expected to rely on Touch ID built into the power button, similar to recent iPad models. This would allow Apple to keep both displays free of notches or Dynamic Island cutouts.Under-display camera technology has historically produced lower image quality, but a rumored 24MP sensor would be a significant step up compared to existing foldables, which typically use much lower-resolution sensors.iPhone Fold’s hinge and materialsThe hinge is another area where Apple may diverge from competitors. Multiple reports claim Apple will use Liquidmetal, which is a long-standing trade name for a metallic glass alloy the company has previously used in smaller components. While often referred to as “liquid metal” or “Liquid Metal” in reports, Liquidmetal is the branding Apple has historically associated with the material.Liquidmetal is said to be stronger and more resistant to deformation than titanium, while remaining relatively lightweight. If accurate, this could help improve long-term durability and reduce wear on the foldable display.Leaks from Jon Prosser also reference a metal plate beneath the display that works in tandem with the hinge to minimize creasing — a claim that aligns with reporting from Korean and Chinese supply-chain sources.Battery and other components Battery life is another potential differentiator. According to Ming-Chi Kuo and multiple Asian supply-chain reports, Apple is testing high-density battery cells in the 5,000 to 5,800mAh range.That would make it the largest battery ever used in an iPhone, and competitive with (or larger than) batteries in current Android foldables. The device is also expected to use a future A-series chip and Apple’s in-house modem, with some reports pointing specifically to a next-generation C2 modem as part of Apple’s broader push to reduce reliance on Qualcomm.PriceNone of this will come cheap, that’s for certain. Nearly every report agrees that the iPhone Fold will be Apple’s most expensive iPhone ever.Estimates currently place the price between $2,000 and $2,500 in the US. Bloomberg has said the price will be “at least $2,000,” while other analysts have narrowed the likely range to around $2,100 and $2,300. That positions the iPhone Fold well above the iPhone Pro Max and closer to Apple’s high-end Macs and iPads.Despite years of rumors, there’s still plenty that remains unclear. Apple hasn’t confirmed the name “iPhone Fold,” final dimensions, software features or how iOS would adapt to a folding form factor. Durability, repairability and long-term reliability are also open questions. For now, the safest assumption is that Apple is taking its time and that many of these details could still change before launch. This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/iphone-fold-rumors-everything-we-know-right-now-including-the-leaked-design-upgrades-price-and-more-130000733.html?src=rss",
          "content": "Apple still hasn’t revealed a foldable iPhone, but the steady drip of leaks suggests the project is moving closer to reality. Over the past few months, analysts and supply-chain watchers have continued to fill in key details, with most reports still pointing to a launch sometime in the second half of 2026. While Apple hasn’t confirmed anything publicly, the overall picture is starting to look more consistent.As always, plans for unreleased Apple hardware can change at any time. Features may shift, timelines can slip and some prototypes may never ship. Even so, recent reporting gives us the clearest sense yet of how Apple’s first foldable could take shape and where it might fit in the broader iPhone lineup.Below, we’ve rounded up the most credible rumors so far, and we’ll keep this guide updated as new details emerge.When could the iPhone Fold launch?Rumors of a foldable iPhone date back as far as 2017, but more recent reporting suggests Apple has finally locked onto a realistic window. Most sources now point to fall 2026, likely alongside the iPhone 18 lineup, with some supply-chain hints suggesting mass production could begin in mid-2026 if development stays on track.Mark Gurman has gone back and forth on timing, initially suggesting Apple could launch “as early as 2026,” before later writing that the device would ship at the end of 2026 and sell primarily in 2027. Analyst Ming-Chi Kuo has also repeatedly cited the second half of 2026 as Apple’s target.Some reports still claim the project could slip into 2027 if Apple runs into manufacturing or durability issues, particularly around the hinge or display. Given Apple’s history of delaying products that it feels aren’t ready, that remains a real possibility.What will the iPhone Fold look like?Current consensus suggests Apple has settled on a book-style foldable design, similar to Samsung’s Galaxy Z Fold series, rather than a clamshell flip phone.When unfolded, the iPhone Fold is expected to resemble a small tablet like the iPad mini (8.3 inches). Based on the rumor mill, though, the iPhone Fold may be a touch smaller, with an internal display measuring around 7.7 to 7.8 inches. When closed, it should function like a conventional smartphone, with an outer display in the 5.5-inch range.CAD leaks and alleged case-maker molds suggest the device may be shorter and wider than a standard iPhone when folded, creating a squarer footprint that better matches the aspect ratio of the inner display. Several reports have also pointed to the iPhone Air as a potential preview of Apple’s foldable design work, with its unusually thin chassis widely interpreted as a look at what one half of a future foldable iPhone could resemble.If that theory holds, it could help explain the Fold’s rumored dimensions. Thickness is expected to land around 4.5 to 4.8mm when unfolded, according to analyst Ming-Chi Kuo, putting it in a similar range to the iPhone Air, and roughly 9 to 9.5mm when folded, depending on the final hinge design and internal layering.iPhone 17 Pro, iPhone AirEngadgetDisplay and the crease questionThe display is arguably the biggest challenge for any foldable phone, and it’s an area where Apple appears to have invested years of development.Multiple reports say Apple will rely on Samsung Display as its primary supplier. At CES 2026, Samsung showcased a new crease-less foldable OLED panel, which several sources — including Bloomberg — suggested could be the same technology Apple plans to use.According to these reports, the panel combines a flexible OLED with a laser-drilled metal support plate that disperses stress when folding. The goal is a display with a nearly invisible crease, something Apple reportedly considers essential before entering the foldable market.If Apple does use this panel, it would mark a notable improvement over current foldables, which still show visible creasing under certain lighting conditions.Cameras and biometricsCamera rumors suggest Apple is planning a four-camera setup. That may include:Two rear cameras (main and ultra-wide, both rumored at 48MP)One punch-hole camera on the outer displayOne under-display camera on the inner screenSeveral sources claim Apple will avoid Face ID entirely on the iPhone Fold. Instead, it’s expected to rely on Touch ID built into the power button, similar to recent iPad models. This would allow Apple to keep both displays free of notches or Dynamic Island cutouts.Under-display camera technology has historically produced lower image quality, but a rumored 24MP sensor would be a significant step up compared to existing foldables, which typically use much lower-resolution sensors.iPhone Fold’s hinge and materialsThe hinge is another area where Apple may diverge from competitors. Multiple reports claim Apple will use Liquidmetal, which is a long-standing trade name for a metallic glass alloy the company has previously used in smaller components. While often referred to as “liquid metal” or “Liquid Metal” in reports, Liquidmetal is the branding Apple has historically associated with the material.Liquidmetal is said to be stronger and more resistant to deformation than titanium, while remaining relatively lightweight. If accurate, this could help improve long-term durability and reduce wear on the foldable display.Leaks from Jon Prosser also reference a metal plate beneath the display that works in tandem with the hinge to minimize creasing — a claim that aligns with reporting from Korean and Chinese supply-chain sources.Battery and other components Battery life is another potential differentiator. According to Ming-Chi Kuo and multiple Asian supply-chain reports, Apple is testing high-density battery cells in the 5,000 to 5,800mAh range.That would make it the largest battery ever used in an iPhone, and competitive with (or larger than) batteries in current Android foldables. The device is also expected to use a future A-series chip and Apple’s in-house modem, with some reports pointing specifically to a next-generation C2 modem as part of Apple’s broader push to reduce reliance on Qualcomm.PriceNone of this will come cheap, that’s for certain. Nearly every report agrees that the iPhone Fold will be Apple’s most expensive iPhone ever.Estimates currently place the price between $2,000 and $2,500 in the US. Bloomberg has said the price will be “at least $2,000,” while other analysts have narrowed the likely range to around $2,100 and $2,300. That positions the iPhone Fold well above the iPhone Pro Max and closer to Apple’s high-end Macs and iPads.Despite years of rumors, there’s still plenty that remains unclear. Apple hasn’t confirmed the name “iPhone Fold,” final dimensions, software features or how iOS would adapt to a folding form factor. Durability, repairability and long-term reliability are also open questions. For now, the safest assumption is that Apple is taking its time and that many of these details could still change before launch. This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/iphone-fold-rumors-everything-we-know-right-now-including-the-leaked-design-upgrades-price-and-more-130000733.html?src=rss",
          "feed_position": 42,
          "image_url": "https://media-mbst-pub-ue1.s3.amazonaws.com/creatr-uploaded-images/2025-09/a476c2e0-9780-11f0-bd4b-d87caa240702"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/social-media/reddit-fined-196-million-over-age-verification-checks-in-the-uk-173705048.html",
          "published_at": "Tue, 24 Feb 2026 17:37:05 +0000",
          "title": "Reddit fined $19.6 million over age verification checks in the UK",
          "standfirst": "A common theme in online age verification laws is the tension between user privacy and preventing children from accessing harmful or inappropriate content. Now the UK is sending a not-so-subtle message to Reddit on the subject, to the tune of £14.5m ($19.6 million). The nation's Information Commissioner's Office (ICO) accused the company of using children’s data and potentially exposing them to inappropriate content.“Children under 13 had their personal information collected and used in ways they could not understand, consent to or control,” UK Information Commissioner John Edwards wrote in a statement. “That left them potentially exposed to content they should not have seen. This is unacceptable and has resulted in today’s fine.”In July 2025, Reddit began requiring age verification to access adult content in the UK, in compliance with the Online Safety Act. However, that's only used to block under-18 users from sexually explicit, violent or other mature posts. The platform also prohibits users under 13 from accessing it altogether — and enforcement of that policy is lax. It merely requires users to declare, when signing up, that they're over 13. The ICO (accurately) described the method as \"easy to bypass.\"In its defense, Reddit told the BBC that it \"didn't require users to share information about their identities, regardless of age, because we are deeply committed to their privacy and safety.\" The company said it would appeal the decision. \"The ICO's insistence that we collect more private information on every UK user is counterintuitive and at odds with our strong belief in our users' online privacy and safety,\" the spokesperson added.\"It's concerning that a company the size of Reddit failed in its legal duty to protect the personal information of UK children,\" Edwards said. \"Companies operating online services likely to be accessed by children have a responsibility to protect those children by ensuring they’re not exposed to risks through the way their data is used. To do this, they need to be confident they know the age of their users and have appropriate, effective age assurance measures in place.”“Reddit failed to meet these expectations,” he added. “They must do better, and we are continuing to consider the age assurance controls now implemented by the platform.” The ICO also accused Reddit of failing to conduct a data protection impact assessment by January 2025.The Guardian notes that the £14.5m fine is the third-largest handed down by the ICO. It trails only a £20m fine for British Airways involving a data breach disclosure and an £18.4m penalty for Marriott Hotels for exposing over 300 million customer records in a hack.This article originally appeared on Engadget at https://www.engadget.com/social-media/reddit-fined-196-million-over-age-verification-checks-in-the-uk-173705048.html?src=rss",
          "content": "A common theme in online age verification laws is the tension between user privacy and preventing children from accessing harmful or inappropriate content. Now the UK is sending a not-so-subtle message to Reddit on the subject, to the tune of £14.5m ($19.6 million). The nation's Information Commissioner's Office (ICO) accused the company of using children’s data and potentially exposing them to inappropriate content.“Children under 13 had their personal information collected and used in ways they could not understand, consent to or control,” UK Information Commissioner John Edwards wrote in a statement. “That left them potentially exposed to content they should not have seen. This is unacceptable and has resulted in today’s fine.”In July 2025, Reddit began requiring age verification to access adult content in the UK, in compliance with the Online Safety Act. However, that's only used to block under-18 users from sexually explicit, violent or other mature posts. The platform also prohibits users under 13 from accessing it altogether — and enforcement of that policy is lax. It merely requires users to declare, when signing up, that they're over 13. The ICO (accurately) described the method as \"easy to bypass.\"In its defense, Reddit told the BBC that it \"didn't require users to share information about their identities, regardless of age, because we are deeply committed to their privacy and safety.\" The company said it would appeal the decision. \"The ICO's insistence that we collect more private information on every UK user is counterintuitive and at odds with our strong belief in our users' online privacy and safety,\" the spokesperson added.\"It's concerning that a company the size of Reddit failed in its legal duty to protect the personal information of UK children,\" Edwards said. \"Companies operating online services likely to be accessed by children have a responsibility to protect those children by ensuring they’re not exposed to risks through the way their data is used. To do this, they need to be confident they know the age of their users and have appropriate, effective age assurance measures in place.”“Reddit failed to meet these expectations,” he added. “They must do better, and we are continuing to consider the age assurance controls now implemented by the platform.” The ICO also accused Reddit of failing to conduct a data protection impact assessment by January 2025.The Guardian notes that the £14.5m fine is the third-largest handed down by the ICO. It trails only a £20m fine for British Airways involving a data breach disclosure and an £18.4m penalty for Marriott Hotels for exposing over 300 million customer records in a hack.This article originally appeared on Engadget at https://www.engadget.com/social-media/reddit-fined-196-million-over-age-verification-checks-in-the-uk-173705048.html?src=rss",
          "feed_position": 45
        }
      ],
      "featured_image": "https://images.ctfassets.net/jdtwqhzvc2n1/udBw424PYrASf0rQIqIll/713046aa22da63e2eed56e0d21d385fd/AT_T-SLMs.png?w=300&q=30",
      "popularity_score": 2033.7264297222223
    },
    {
      "id": "cluster_14",
      "coverage": 2,
      "updated_at": "Wed, 25 Feb 2026 23:15:01 -0500",
      "title": "Open-source tool Scrapling gains traction with OpenClaw users who want their bots to scrape sites without permission and has 200K+ downloads since its release (Reece Rogers/Wired)",
      "neutral_headline": "OpenClaw Users Are Allegedly Bypassing Anti-Bot Systems",
      "bullet_summary": [
        "Reported by TechMeme, Wired Tech"
      ],
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/260225/p60#a260225p60",
          "published_at": "Wed, 25 Feb 2026 23:15:01 -0500",
          "title": "Open-source tool Scrapling gains traction with OpenClaw users who want their bots to scrape sites without permission and has 200K+ downloads since its release (Reece Rogers/Wired)",
          "standfirst": "Reece Rogers / Wired: Open-source tool Scrapling gains traction with OpenClaw users who want their bots to scrape sites without permission and has 200K+ downloads since its release &mdash; An open source project called Scrapling is gaining traction with AI agent users who want their bots to scrape sites without permission.",
          "content": "Reece Rogers / Wired: Open-source tool Scrapling gains traction with OpenClaw users who want their bots to scrape sites without permission and has 200K+ downloads since its release &mdash; An open source project called Scrapling is gaining traction with AI agent users who want their bots to scrape sites without permission.",
          "feed_position": 11,
          "image_url": "http://www.techmeme.com/260225/i60.jpg"
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/openclaw-users-bypass-anti-bot-systems-cloudflare-scrapling/",
          "published_at": "Wed, 25 Feb 2026 19:00:00 +0000",
          "title": "OpenClaw Users Are Allegedly Bypassing Anti-Bot Systems",
          "standfirst": "An open source project called Scrapling is gaining traction with AI agent users who want their bots to scrape sites without permission.",
          "content": "An open source project called Scrapling is gaining traction with AI agent users who want their bots to scrape sites without permission.",
          "feed_position": 4,
          "image_url": "https://media.wired.com/photos/699de3a0e46e4fa7442b798a/master/pass/AI-Lab-OpenClaw-Users-Are-Attempting-to-Scrape-Sites-with-Anti-Bot-Protections-Business.jpg"
        }
      ],
      "featured_image": "http://www.techmeme.com/260225/i60.jpg",
      "popularity_score": 2016.4767075
    },
    {
      "id": "cluster_49",
      "coverage": 2,
      "updated_at": "2026-02-25T14:56:55-05:00",
      "title": "Google and Samsung just launched the AI features Apple couldn’t with Siri",
      "neutral_headline": "Google and Samsung just launched the AI features Apple couldn’t with Siri",
      "bullet_summary": [
        "It all sounds a bit like features Apple announced for Siri way back [&#8230;]",
        "Reported by The Verge, Wired Tech"
      ],
      "items": [
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/tech/884703/google-samsung-galaxy-s26-gemini-apple-siri",
          "published_at": "2026-02-25T14:56:55-05:00",
          "title": "Google and Samsung just launched the AI features Apple couldn’t with Siri",
          "standfirst": "Google just announced that Gemini will soon be able to take care of some multistep tasks on your phone, like ordering food or hailing a car, starting first with the Pixel 10, Pixel 10 Pro, and the just-announced Samsung Galaxy S26 phones. It all sounds a bit like features Apple announced for Siri way back [&#8230;]",
          "content": "Google just announced that Gemini will soon be able to take care of some multistep tasks on your phone, like ordering food or hailing a car, starting first with the Pixel 10, Pixel 10 Pro, and the just-announced Samsung Galaxy S26 phones. It all sounds a bit like features Apple announced for Siri way back at the 2024 Worldwide Developers Conference - before Apple delayed those planned features in March 2025 and which still aren't released. Onstage, Sameer Samat, Google's president of Android, showed off a demo of how Gemini's new agentic features would work to help wrangle a pizza dinner order from his busy family group chat. Samat asks Gem … Read the full story at The Verge.",
          "feed_position": 6
        },
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/tech/884210/google-gemini-samsung-s26-pixel-10-uber",
          "published_at": "2026-02-25T13:00:00-05:00",
          "title": "Google Gemini can book an Uber or order food for you on Pixel 10 and Galaxy S26",
          "standfirst": "Google's Gemini AI is getting one step closer to being more like an actual assistant. Starting with some Pixel 10 phones and the Samsung Galaxy S26 series, Gemini will be able to hail an Uber or put together a DoorDash order on its own. It's called task automation, and it starts with a prompt to [&#8230;]",
          "content": "Gemini can now prep a rideshare or grocery order, though you’ll have to submit the order yourself. | Image: Google Google's Gemini AI is getting one step closer to being more like an actual assistant. Starting with some Pixel 10 phones and the Samsung Galaxy S26 series, Gemini will be able to hail an Uber or put together a DoorDash order on its own. It's called task automation, and it starts with a prompt to Gemini - something like \"Get me an Uber to the Palace of Fine Arts.\" Gemini then launches the app in a virtual window on your device and goes through the process step-by-step. You can watch it all happen, with options to stop the automation or take control if necessary, or just let it run in the background while Gemini does its thing. The assistant … Read the full story at The Verge.",
          "feed_position": 9
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/google-gemini-task-automation-galaxy-s26-uber-doordash/",
          "published_at": "Wed, 25 Feb 2026 18:00:00 +0000",
          "title": "Gemini Can Now Book You an Uber or Order a DoorDash Meal on Your Phone. Here’s How It Works",
          "standfirst": "Starting with the Samsung Galaxy S26, Google’s Gemini can automate tasks in popular mobile apps. We got a live demo of the new feature in action.",
          "content": "Starting with the Samsung Galaxy S26, Google’s Gemini can automate tasks in popular mobile apps. We got a live demo of the new feature in action.",
          "feed_position": 6,
          "image_url": "https://media.wired.com/photos/699e2d79d54c22d6c9a6a418/master/pass/Google%20Gemini%20Automation%20on%20Galaxy%20S26%20SOURCE%20Julian%20Chokkattu(2).jpg"
        }
      ],
      "featured_image": "https://media.wired.com/photos/699e2d79d54c22d6c9a6a418/master/pass/Google%20Gemini%20Automation%20on%20Galaxy%20S26%20SOURCE%20Julian%20Chokkattu(2).jpg",
      "popularity_score": 2008.1750408333332
    },
    {
      "id": "cluster_33",
      "coverage": 1,
      "updated_at": "Wed, 25 Feb 2026 22:09:21 +0000",
      "title": "Musk has no proof OpenAI stole xAI trade secrets, judge rules, tossing lawsuit",
      "neutral_headline": "Musk has no proof OpenAI stole xAI trade secrets, judge rules, tossing lawsuit",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/02/judge-xai-cant-claim-openai-stole-trade-secrets-just-by-hiring-ex-staffers/",
          "published_at": "Wed, 25 Feb 2026 22:09:21 +0000",
          "title": "Musk has no proof OpenAI stole xAI trade secrets, judge rules, tossing lawsuit",
          "standfirst": "Even twisting an ex-employee's text to favor xAI's reading fails to sway judge.",
          "content": "Elon Musk appears to be grasping at straws in a lawsuit accusing OpenAI of poaching eight xAI employees in an allegedly unlawful bid to access xAI trade secrets connected to its data centers and chatbot, Grok. In a Tuesday order granting OpenAI's motion to dismiss, US District Judge Rita F. Lin said that xAI failed to provide evidence of any misconduct from OpenAI. Instead, xAI seemed fixated on a range of alleged conduct of former employees. But in assessing xAI's claims, Lin said that xAI failed to show proof that OpenAI induced any of these employees to steal trade secrets \"or that these former xAI employees used any stolen trade secrets once employed by OpenAI.\"Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-2259422080-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-2259422080-1024x648.jpg",
      "popularity_score": 358.38226305555554
    },
    {
      "id": "cluster_40",
      "coverage": 1,
      "updated_at": "Wed, 25 Feb 2026 20:53:54 +0000",
      "title": "Judge doesn't trust DOJ with search of devices seized from Wash. Post reporter",
      "neutral_headline": "Judge doesn't trust DOJ with search of devices seized from Wash. Post reporter",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/02/judge-doesnt-trust-doj-with-search-of-devices-seized-from-wash-post-reporter/",
          "published_at": "Wed, 25 Feb 2026 20:53:54 +0000",
          "title": "Judge doesn't trust DOJ with search of devices seized from Wash. Post reporter",
          "standfirst": "Court to search devices itself instead of letting government have full access.",
          "content": "A federal court will conduct a search of devices seized from a Washington Post reporter after a magistrate judge decided yesterday that the Department of Justice cannot be trusted to perform the search on its own. US Magistrate Judge William Porter criticized government prosecutors for not including key information in a search warrant application. The court wasn't aware of a 1980 law that limits searches and seizures of journalists' work materials when it approved the warrant, Porter acknowledged. The decision came six weeks after the FBI executed the search warrant at the Virginia home of reporter Hannah Natanson. Porter declined the Post and Natanson's request to return the devices immediately but decided on a court-led process to ensure that the search is limited to materials that may aid a criminal case against an alleged leaker who was in contact with Natanson. He also rescinded the portion of the search warrant that authorized the government to open, access, review, or otherwise examine the seized data.Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/washington-post-building-1152x648-1768424038.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/washington-post-building-1152x648-1768424038.jpg",
      "popularity_score": 328.12476305555555
    },
    {
      "id": "cluster_53",
      "coverage": 1,
      "updated_at": "Wed, 25 Feb 2026 19:29:50 +0000",
      "title": "Could a vaccine prevent dementia? Shingles shot data only getting stronger.",
      "neutral_headline": "Could a vaccine prevent dementia? Shingles shot data only getting stronger.",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2026/02/could-a-vaccine-prevent-dementia-shingles-shot-data-only-getting-stronger/",
          "published_at": "Wed, 25 Feb 2026 19:29:50 +0000",
          "title": "Could a vaccine prevent dementia? Shingles shot data only getting stronger.",
          "standfirst": "Latest data hints that benefits seen so far could be underestimates.",
          "content": "While lifesaving vaccines face a relentless onslaught from the Trump administration—with fervent anti-vaccine advocate Robert F. Kennedy Jr. leading the charge—scientific literature is building a wondrous story: A vaccine appears to prevent dementia, including Alzheimer's, and may even slow biological aging. For years, study after study has noted that older adults vaccinated against shingles seemed to have a lower risk of dementia. A study last month suggested the same vaccine appears to slow biological aging, including lowering markers of inflammation. \"Our study adds to a growing body of work suggesting that vaccines may play a role in healthy aging strategies beyond solely preventing acute illness,\" study author Eileen Crimmins, of the University of Southern California, said.Read full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-2056512898-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-2056512898-1152x648.jpg",
      "popularity_score": 316.72365194444444
    },
    {
      "id": "cluster_60",
      "coverage": 1,
      "updated_at": "Wed, 25 Feb 2026 18:27:27 +0000",
      "title": "2026 Lexus RZ 550e review: Likable, but it needs improvement",
      "neutral_headline": "2026 Lexus RZ 550e review: Likable, but it needs improvement",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2026/02/2026-lexus-rz-550e-review-likable-but-it-needs-improvement/",
          "published_at": "Wed, 25 Feb 2026 18:27:27 +0000",
          "title": "2026 Lexus RZ 550e review: Likable, but it needs improvement",
          "standfirst": "It's not very efficient, and the synthetic gearshifts aren't great, but I liked it?",
          "content": "Sometimes you drive a car you just don't gel with. The original Lexus RZ was such a case. It was Lexus' first battery EV, and I was less than impressed when I drove it in 2023. In fact, I compared it negatively to the extremely not-good Vinfast VF8. Lexus knew there was room for improvement, too, so it reworked the RZ with new motors, a new battery, and NACS charging for North America, among other tweaks, for model year 2026. A front-wheel drive RZ 350e is now the range's entry point at $47,295, and there's also a $58,295 all-wheel drive RZ 550e F Sport that tops the range. We spent a week with the latter. Mindful of how little I liked the first RZ I drove, I made sure to approach the 550e F Sport with an open mind. And despite a number of the car's shortcomings, I find I have warm feelings for the electric Lexus.Read full article Comments",
          "feed_position": 4,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/2026-Lexus-RZ-550e-1-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/2026-Lexus-RZ-550e-1-1152x648.jpg",
      "popularity_score": 310.6839297222222
    },
    {
      "id": "cluster_63",
      "coverage": 1,
      "updated_at": "Wed, 25 Feb 2026 18:21:38 +0000",
      "title": "RAM now represents 35 percent of bill of materials for HP PCs",
      "neutral_headline": "RAM now represents 35 percent of bill of materials for HP PCs",
      "bullet_summary": [
        "RAM represented about 15 to 18 percent of PC costs last quarter, HP said",
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/02/ram-now-represents-35-percent-of-bill-of-materials-for-hp-pcs/",
          "published_at": "Wed, 25 Feb 2026 18:21:38 +0000",
          "title": "RAM now represents 35 percent of bill of materials for HP PCs",
          "standfirst": "RAM represented about 15 to 18 percent of PC costs last quarter, HP said.",
          "content": "In an illustration of the severity of the current memory shortage, HP Inc. CFO Karen Parkhill said that RAM has gone from accounting for “roughly 15 percent to 18 percent” of HP PCs’ bill of materials in its fiscal Q4 2025 to “roughly 35 percent” for the rest of the year. Parkhill was speaking during HP’s Q1 2026 earnings call, where the company said it expects the total addressable market for its Personal Systems business to decline by double digits this calendar year, as higher prices hurt customer demand. “We have seen memory costs increase roughly 100 percent sequentially, and we do forecast that to further increase as we move into the fiscal year,” Parkhill said, per a transcript of the call by Seeking Alpha.Read full article Comments",
          "feed_position": 5,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-2252687789-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-2252687789-1152x648.jpg",
      "popularity_score": 289.5869852777778
    },
    {
      "id": "cluster_74",
      "coverage": 1,
      "updated_at": "Wed, 25 Feb 2026 15:46:08 +0000",
      "title": "Trump's MAHA influencer pick for surgeon general goes before Senate",
      "neutral_headline": "Trump's MAHA influencer pick for surgeon general goes before Senate",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2026/02/rfk-jr-ally-casey-means-faces-senate-for-surgeon-general-confirmation-hearing/",
          "published_at": "Wed, 25 Feb 2026 15:46:08 +0000",
          "title": "Trump's MAHA influencer pick for surgeon general goes before Senate",
          "standfirst": "Casey Means holds no active medical license and promotes alternative medicine.",
          "content": "Casey Means, President Trump's nominee for surgeon general, will appear before the Senate Health Committee on Wednesday and is likely to face scrutiny over her qualifications for becoming the country's top doctor. Though Means holds a medical degree from Stanford Medical School, she dropped out of her medical residency and holds no active medical license. Instead, she has pursued a career as a wellness influencer, embracing \"functional\" medicine, an ill-defined form of alternative medicine. She co-founded a company called Levels, which promotes intensive health tracking, including the use of continuous glucose monitoring for people without diabetes or prediabetes, which is not backed by evidence. Last year, an analysis by The Washington Post found that Means earned over half a million dollars between 2024 and 2025 from making deals with companies described as selling \"diagnostic testing,\" \"herbal remedies and wellness products,\" and \"teas, supplements, and elixirs.\"Read full article Comments",
          "feed_position": 6,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/Casey_Means_on_Ron_Johnson_Roundtable_Discussion-867x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/Casey_Means_on_Ron_Johnson_Roundtable_Discussion-867x648.jpg",
      "popularity_score": 276.9953186111111
    },
    {
      "id": "cluster_93",
      "coverage": 1,
      "updated_at": "Wed, 25 Feb 2026 00:05:05 +0000",
      "title": "Boozy chimps fail urine test, confirm hotly debated theory",
      "neutral_headline": "Boozy chimps fail urine test, confirm hotly debated theory",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/02/boozy-chimps-fail-urine-test-confirm-hotly-debated-theory/",
          "published_at": "Wed, 25 Feb 2026 00:05:05 +0000",
          "title": "Boozy chimps fail urine test, confirm hotly debated theory",
          "standfirst": "Spare a thought for the intrepid graduate students who spent last summer in Africa collecting chimp urine.",
          "content": "The urine of chimpanzees contains high levels of alcohol byproduct, most likely because the chimps regularly gorge themselves on fermented fruit, according to a new paper published in the journal Biology Letters. It's the latest evidence in support of a hotly debated theory regarding the evolutionary origins of human fondness for alcohol. As previously reported, in 2014, University of California, Berkeley (UCB) biologist Robert Dudley wrote a book called The Drunken Monkey: Why We Drink and Abuse Alcohol. His controversial “drunken monkey hypothesis” proposed that the human attraction to alcohol goes back about 18 million years, to the origin of the great apes, and that social communication and sharing food evolved to better identify the presence of fruit from a distance. At the time, skeptical scientists insisted that this was unlikely because chimpanzees and other primates just don’t eat fermented fruit or nectar. But reports of primates doing just that have grown over the ensuing two decades. Earlier this year, we reported that researchers had caught wild chimpanzees on camera engaging in what appears to be sharing fermented African breadfruit with measurable alcoholic content. That observational data was the first evidence of the sharing of alcoholic foods among nonhuman great apes in the wild. The authors measured the alcohol content of the fruit with a handy portable breathalyzer and found almost all of the fallen fruit (90 percent) contained some ethanol, with the ripest containing the highest levels—the equivalent of 0.61 percent ABV (alcohol by volume).Read full article Comments",
          "feed_position": 8,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/chimp1-1152x648-1771719191.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/chimp1-1152x648-1771719191.jpg",
      "popularity_score": 273
    },
    {
      "id": "cluster_75",
      "coverage": 1,
      "updated_at": "Wed, 25 Feb 2026 14:29:23 +0000",
      "title": "Pete Hegseth tells Anthropic to fall in line with DoD desires, or else",
      "neutral_headline": "Pete Hegseth tells Anthropic to fall in line with DoD desires, or else",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2026/02/pete-hegseth-wants-unfettered-access-to-anthropics-models-for-the-military/",
          "published_at": "Wed, 25 Feb 2026 14:29:23 +0000",
          "title": "Pete Hegseth tells Anthropic to fall in line with DoD desires, or else",
          "standfirst": "CEO was summoned to Washington after trying to limit military use of its technology.",
          "content": "US Defense Secretary Pete Hegseth has threatened to cut Anthropic from his department’s supply chain unless it agrees to sign off on its technology being used in all lawful military applications by Friday. The threat is the latest escalation in a feud between Anthropic and the department, triggered by the AI group’s refusal to give unfettered access to its models for classified military use, including domestic surveillance and deadly missions with no direct human control. Hegseth summoned Anthropic chief executive Dario Amodei to Washington for a meeting on Tuesday. During tense talks, the defense secretary threatened to cut the company out of the department’s supply chain or to invoke the Defense Production Act, a Cold War-era measure enabling the president to control domestic industry in the interest of national defense, said a person with knowledge of the talks.Read full article Comments",
          "feed_position": 7,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/hegseth-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/hegseth-1152x648.jpg",
      "popularity_score": 265.71615194444445
    },
    {
      "id": "cluster_96",
      "coverage": 1,
      "updated_at": "Tue, 24 Feb 2026 22:52:52 +0000",
      "title": "WBD says Paramount’s new higher offer could be “superior” to Netflix's",
      "neutral_headline": "WBD says Paramount’s new higher offer could be “superior” to Netflix's",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/02/paramount-increases-its-warner-bros-discovery-bid-by-1-per-share/",
          "published_at": "Tue, 24 Feb 2026 22:52:52 +0000",
          "title": "WBD says Paramount’s new higher offer could be “superior” to Netflix's",
          "standfirst": "WBD's board is still reviewing the offer.",
          "content": "Paramount Skydance increased its bid for Warner Bros. Discovery (WBD) from $30 per share to $31 per share, WBD said today. Amid a competing offer from Netflix for WBD’s movie studios and streaming businesses, WBD said that Paramount’s new bid “could reasonably be expected to lead to a ‘Company Superior Proposal.’” Under its revamped offer, Paramount would also pay the $7 billion regulatory termination fee that would arise should a Paramount-WBD merger fail to close due to antitrust regulation. The company, owned by David Ellison, also said it would pay $0.25 per share for every day the deal doesn’t close, starting on September 30, rather than the previous start date of December 31.Read full article Comments",
          "feed_position": 9,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2215193098-1152x648-1768255617.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2215193098-1152x648-1768255617.jpg",
      "popularity_score": 243
    },
    {
      "id": "cluster_106",
      "coverage": 1,
      "updated_at": "Tue, 24 Feb 2026 18:46:03 +0000",
      "title": "In a replay of 2019, Apple says a single desktop Mac will be manufactured in the US",
      "neutral_headline": "In a replay of 2019, Apple says a single desktop Mac will be manufactured in the US",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/apple/2026/02/in-a-replay-of-2019-apple-says-a-single-desktop-mac-will-be-manufactured-in-the-us/",
          "published_at": "Tue, 24 Feb 2026 18:46:03 +0000",
          "title": "In a replay of 2019, Apple says a single desktop Mac will be manufactured in the US",
          "standfirst": "Apple is still working to get favorable tariff treatment from the Trump administration.",
          "content": "Apple plans to start manufacturing the Mac mini in the United States later this year, the company announced today, as part of its $600 billion commitment to expand its domestic manufacturing operation. The Macs will be made in a facility in Houston, the same facility Apple uses for \"advanced AI server manufacturing.\" CEO Tim Cook says these AI servers are shipping \"ahead of schedule.\" The facility will also eventually provide \"hands-on training in advanced manufacturing techniques\" for students, Apple employees, \"and American businesses of all sizes.\" Apple and many other US tech companies have announced plans to expand their domestic manufacturing operations, just one element of a multi-prong strategy to secure favorable treatment from a Trump administration that has been happy to threaten Apple and others with steep tariffs to get what it wants. Today's Mac mini announcement is more subtle than the time Tim Cook delivered Trump a signed gold statue, but the goal is likely the same.Read full article Comments",
          "feed_position": 13,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/IMG_2326-1152x648.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/IMG_2326-1152x648.jpeg",
      "popularity_score": 145
    },
    {
      "id": "cluster_120",
      "coverage": 1,
      "updated_at": "Tue, 24 Feb 2026 15:24:02 +0000",
      "title": "Lamborghini cancels electric Lanzador as supercar buyers reject EVs",
      "neutral_headline": "Lamborghini cancels electric Lanzador as supercar buyers reject EVs",
      "bullet_summary": [
        "Investing heavily in battery EVs would be \"financially irresponsible,\" CEO said",
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2026/02/lamborghini-drops-ev-plan-in-favor-of-future-plug-in-hybrids/",
          "published_at": "Tue, 24 Feb 2026 15:24:02 +0000",
          "title": "Lamborghini cancels electric Lanzador as supercar buyers reject EVs",
          "standfirst": "Investing heavily in battery EVs would be \"financially irresponsible,\" CEO said.",
          "content": "For the last few years, Lamborghini has been in a quandary: What to do about an electric vehicle? Among the supercar brands, Lamborghini has always stood out as favoring drama over lap times. And while electric motors and their instant torque can make a car accelerate very quickly indeed, other than the G-forces, it happens with such little fuss. Working out how to imbue an EV with enough \"wow\" factor to wear the famous bull badge has proved so difficult that the company has thrown in the towel in favor of developing more plug-in hybrids. As part of Volkswagen Group, Lamborghini has access to the EV platforms used by fellow VW Group brands Audi and Porsche, so it's not a question of access to technology. Rather, the company just doesn't think it can sell the cars. As Tim Stevens found out for Ars last year, in this rarefied end of the car market, the customers just aren't interested in EVs. People paying six or even seven figures for a supercar, especially a Lamborghini, are not exercising restraint, and they don't want the car to do that, either. Speaking to the Sunday Times this weekend, Lamborghini CEO Stephan Winkelmann revealed that the Lanzador, an electric SUV under development for the past few years, was canceled in late 2025. \"Investing heavily in full-EV development when the market and customer base are not ready would be an expensive hobby, and financially irresponsible towards shareholders, customers [and] to our employees and their families,\" he told the paper.Read full article Comments",
          "feed_position": 16,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-1610564490-1152x648-1771945747.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-1610564490-1152x648-1771945747.jpg",
      "popularity_score": 139
    },
    {
      "id": "cluster_115",
      "coverage": 1,
      "updated_at": "Tue, 24 Feb 2026 16:43:27 +0000",
      "title": "50 mpg in a Nissan crossover? Testing the new E-Power hybrid system.",
      "neutral_headline": "50 mpg in a Nissan crossover? Testing the new E-Power hybrid system.",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2026/02/on-the-road-with-nissans-new-e-power-hybrid-coming-to-the-2027-rogue/",
          "published_at": "Tue, 24 Feb 2026 16:43:27 +0000",
          "title": "50 mpg in a Nissan crossover? Testing the new E-Power hybrid system.",
          "standfirst": "Nissan imported some Qashqais from Europe so we could sample the hybrid system.",
          "content": "While Toyota and Honda's showrooms are littered with electrified offerings, Nissan hasn't had much to counter. Globally, Nissan offers a series hybrid system called E-Power, but the company has been reluctant to offer it Stateside. If you ask anyone at the company about it, they'll tell you that while it makes sense in Europe, Japan, and other parts of Asia, it is not optimized for the type of driving we do this side of the pond. Nissan's hybrid offerings in North America have been lackluster at best. There was the Altima that borrowed Toyota's hybrid system from the Camry, and there was the Rogue hybrid that failed to deliver noticeably better fuel economy. And that's really it. That, however, is about to change with the company's third-generation system.Read full article Comments",
          "feed_position": 15,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/IMG_0763-1152x648.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/IMG_0763-1152x648.jpeg",
      "popularity_score": 138
    },
    {
      "id": "cluster_97",
      "coverage": 1,
      "updated_at": "Tue, 24 Feb 2026 22:40:08 +0000",
      "title": "Following 35% growth, solar has passed hydro on US grid",
      "neutral_headline": "Following 35% growth, solar has passed hydro on US grid",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/02/final-2025-data-is-in-us-energy-use-is-up-as-solar-passes-hydro/",
          "published_at": "Tue, 24 Feb 2026 22:40:08 +0000",
          "title": "Following 35% growth, solar has passed hydro on US grid",
          "standfirst": "Coal makes a bit of a comeback, if only by accident.",
          "content": "On Tuesday, the US Energy Information Administration released full-year data on how the country generated electricity in 2025. It's a bit of a good news/bad news situation. The bad news is that overall demand rose appreciably, and a fair chunk of that was met by additional coal use. On the good side, solar continued its run of astonishing growth, generating 35 percent more power than a year earlier and surpassing hydroelectric power for the first time. Shifting markets Overall, electrical consumption in the US rose by 2.8 percent, or about 121 terawatt-hours. Consumption had been largely flat for several decades, with efficiency and the decline of industry offsetting the effects of population and economic growth. There were plenty of year-to-year changes, however, driven by factors ranging from heating and cooling demand to a global pandemic. Given that history, the growth in demand in 2025 is a bit concerning, but it's not yet a clear signal that the factors that will inevitably drive growth have kicked in. (These factors include things like the switch to heat pumps, the electrification of transportation, and the growth in data centers. While the first two of those involve a more efficient use of energy overall, they involve electricity replacing direct use of fossil fuels, and so will increase demand on the grid.)Read full article Comments",
          "feed_position": 10,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-2255162141-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-2255162141-1152x648.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_99",
      "coverage": 1,
      "updated_at": "Tue, 24 Feb 2026 21:15:26 +0000",
      "title": "DJI sues the FCC for “carelessly” restricting its drones",
      "neutral_headline": "DJI sues the FCC for “carelessly” restricting its drones",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/02/dji-sues-the-fcc-for-carelessly-restricting-its-drones/",
          "published_at": "Tue, 24 Feb 2026 21:15:26 +0000",
          "title": "DJI sues the FCC for “carelessly” restricting its drones",
          "standfirst": "DJI lawsuit says company has been \"severely harmed by the FCC’s ruling.\"",
          "content": "DJI, the most popular consumer drone maker, is suing over the Federal Communications Commission (FCC)’s import ban against new, foreign-made drones, which has been in effect since December 23, 2025. On Tuesday, the Shenzhen-headquartered company filed a petition [PDF] with the US Court of Appeals for the Ninth Circuit that seeks to overturn the FCC’s decision to list DJI on its Covered List. The Covered List includes communications equipment and services that are \"deemed to pose an unacceptable risk to the national security of the United States or the security and safety of United States persons,” per the FCC. In its petition dated February 20, 2026, DJI said:Read full article Comments",
          "feed_position": 11,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-1436102852-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-1436102852-1152x648.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_102",
      "coverage": 1,
      "updated_at": "Tue, 24 Feb 2026 19:53:15 +0000",
      "title": "UK fines Reddit for not checking user ages aggressively enough",
      "neutral_headline": "UK fines Reddit for not checking user ages aggressively enough",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/02/uk-fines-reddit-for-not-checking-user-ages-aggressively-enough/",
          "published_at": "Tue, 24 Feb 2026 19:53:15 +0000",
          "title": "UK fines Reddit for not checking user ages aggressively enough",
          "standfirst": "UK agency alleges \"Reddit failed to apply any robust age assurance mechanism.\"",
          "content": "A UK regulator today fined Reddit £14.5 million ($19.6 million) for not verifying the ages of users. The UK Information Commissioner's Office (ICO) alleged that the failure to check ages resulted in Reddit illegally using children’s personal information. \"Our investigation found that Reddit failed to apply any robust age assurance mechanism and therefore did not have a lawful basis for processing the personal information of children under the age of 13... These failures meant Reddit was using children’s data unlawfully, potentially exposing them to inappropriate and harmful content,\" an ICO press release said. The ICO findings are based on Reddit's actions prior to its July 2025 rollout of a system that verifies UK users’ ages before letting them view adult content. But the ICO said it is still concerned about Reddit's post-July 2025 system because the company relies on users to declare their ages when opening an account.Read full article Comments",
          "feed_position": 12,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/07/reddit-icon-1152x648-1752522571.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/07/reddit-icon-1152x648-1752522571.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_113",
      "coverage": 1,
      "updated_at": "Tue, 24 Feb 2026 17:13:14 +0000",
      "title": "Inside the quixotic team trying to build an entire world in a 20-year-old game",
      "neutral_headline": "Inside the quixotic team trying to build an entire world in a 20-year-old game",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2026/02/inside-the-quixotic-team-trying-to-build-an-entire-world-in-a-20-year-old-game/",
          "published_at": "Tue, 24 Feb 2026 17:13:14 +0000",
          "title": "Inside the quixotic team trying to build an entire world in a 20-year-old game",
          "standfirst": "Stories and lessons learned from an impossibly large community modding project.",
          "content": "Despite being regarded as one of the greatest role-playing games of all time, The Elder Scrolls III: Morrowind disappointed some fans upon its release in 2002 because it didn't match the colossal scope of its predecessor, The Elder Scrolls II: Daggerfall. Almost immediately, fans began modding the remaining parts of the series’ fictional continent, Tamriel, into the game. Over 20 years later, thousands of volunteers have collaborated on the mod projects Tamriel Rebuilt and Project Tamriel, building a space comparable in size to a small country. Such projects often sputter out, but these have endured, thanks in part to a steady stream of small, manageable updates instead of larger, less frequent ones. A tale of (at least two) mods It's true that Daggerfall included an entire continent’s worth of content, but it was mostly composed of procedurally generated liminal space. By contrast, Morrowind contained just a single island—not even the entire province after which the game was named. The difference was that it was handcrafted.Read full article Comments",
          "feed_position": 14,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/Anvil-1152x648-1769206004.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/Anvil-1152x648-1769206004.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_123",
      "coverage": 1,
      "updated_at": "Tue, 24 Feb 2026 14:10:13 +0000",
      "title": "Meta could end up owning 10% of AMD in new chip deal",
      "neutral_headline": "Meta could end up owning 10% of AMD in new chip deal",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2026/02/meta-could-end-up-owning-of-10-amd-in-new-chip-deal/",
          "published_at": "Tue, 24 Feb 2026 14:10:13 +0000",
          "title": "Meta could end up owning 10% of AMD in new chip deal",
          "standfirst": "AMD will supply 6 gigawatts' worth of chips to buttress Meta's AI efforts.",
          "content": "Meta has struck a multi-billion dollar chip deal with AMD that could lead to the Facebook owner taking a 10 percent stake in the group, sending shares in the US chipmaker surging on Tuesday. The social media giant said it would acquire customized chips with a total capacity of 6 gigawatts from AMD as it races to develop and deploy its AI models. AMD’s chief executive Lisa Su said that “each gigawatt of compute is worth double-digit billions” under the deal.Read full article Comments",
          "feed_position": 17,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2024/07/meta-ai-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2024/07/meta-ai-1152x648.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_124",
      "coverage": 1,
      "updated_at": "Tue, 24 Feb 2026 14:00:17 +0000",
      "title": "Scientists crack the case of \"screeching\" Scotch tape",
      "neutral_headline": "Scientists crack the case of \"screeching\" Scotch tape",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/02/heres-why-scotch-tape-screeches-when-its-peeled/",
          "published_at": "Tue, 24 Feb 2026 14:00:17 +0000",
          "title": "Scientists crack the case of \"screeching\" Scotch tape",
          "standfirst": "Micro-cracks travel along the peeling tape at supersonic speeds, producing shock waves and sound pulses.",
          "content": "Scotch tape has been a household mainstay for nearly a century, but it still holds some scientific surprises. Researchers have discovered that the screeching sound emitted when one rapidly peels Scotch tape—akin to the screech of fingernails on a chalkboard—is the result of shock waves produced by micro-cracks propagating along the tape at supersonic speeds, according to a new paper published in the journal Physical Review E. It was a 3M engineer named Richard Drew who developed the first transparent sticky tape in 1930. The impetus came from car manufacturing, specifically two-color designs, where the adhesives used were so sticky they often removed the paint when peeled off; the paint then needed to be manually touched up. Drew found a sandpaper adhesive with just the right amount of stickiness and used it to coat a roll of cellophane tape. (Fun fact: Drew also co-invented the snail-style dispenser for the tape with his 3M colleague, John Borden.) The tape was hugely popular during the Great Depression; consumers used it to repair everyday items rather than replace them. That popularity has never waned. Scotch tape has also generated considerable interest among physicists. Back in 1939, scientists noticed that peeling tape could produce light—specifically, a glowing line where the tape end pulls away from the roll. The phenomenon was first recorded in the 17th century and is known as triboluminescence: the generation of light when a material is crushed, ripped, rubbed, or scratched. Diamonds, for instance, sometimes glow blue or red during the cutting process, while ceramics emit yellow-orange light when being cut by abrasive water jets.Read full article Comments",
          "feed_position": 18,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/scotch1-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/scotch1-1152x648.jpg",
      "popularity_score": 133
    }
  ]
}