{
  "updated_at": "2026-02-20T19:32:25.202Z",
  "clusters": [
    {
      "id": "cluster_2",
      "coverage": 3,
      "updated_at": "Fri, 20 Feb 2026 18:53:04 +0000",
      "title": "Tunic publisher claims TikTok ran 'racist, sexist' AI ads for one of its games without its knowledge",
      "neutral_headline": "The Morning After: What to expect from Apple’s March 4 hardware event",
      "bullet_summary": [
        "As reported by IGN, Finji alleges that one ad that went out on the platform was modified so it displayed a \"racist, sexualized\" representation of a character from one of its games",
        "\" Saltsman showed IGN evidence that Finji has both of these options turned off, which was also confirmed by a TikTok agent for the ad in question",
        "TikTok said that Finji’s campaign used a \"catalog ads format\" designed to \"demonstrate the performance benefits of combining carousel and video assets in Sales campaigns",
        "\" It said that this \"initiative\" helped advertisers \"achieve better results with less effort,\" but did not address the harmful content directly"
      ],
      "items": [
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/gaming/tunic-publisher-claims-tiktok-ran-racist-sexist-ai-ads-for-one-of-its-games-without-its-knowledge-185303395.html",
          "published_at": "Fri, 20 Feb 2026 18:53:04 +0000",
          "title": "Tunic publisher claims TikTok ran 'racist, sexist' AI ads for one of its games without its knowledge",
          "standfirst": "Indie publisher and developer Finji has accused TikTok of using generative AI to alter the ads for its games on the platform without its knowledge or permission. Finji, which published indie darlings like Night in the Woods and Tunic, said it only became aware of the seemingly modified ads after being alerted to them by followers of its official TikTok account. As reported by IGN, Finji alleges that one ad that went out on the platform was modified so it displayed a \"racist, sexualized\" representation of a character from one of its games. While it does advertise on TikTok, it told IGN that it has AI \"turned all the way off,\" but after CEO and co-founder Rebekah Saltsman received screenshots of the ads in question from fans, she approached TikTok to investigate. A number of Finji ads have appeared on TikTok, some that include montages of the company’s games, and others that are game-specific like this one for Usual June. According to IGN, the offending AI-modified ads (which are still posted as if they’re coming directly from Finji) appeared as slideshows. Some images don’t appear to be that different from the source, but one possibly AI-generated example seen by IGN depicts Usual June’s titular protagonist with \"a bikini bottom, impossibly large hips and thighs, and boots that rise up over her knees.\" Needless to say (and obvious from the official screenshot used as the lead image for this article), this is not how the character appears in the game. As for TikTok’s response, IGN printed a number of the platform’s replies to Finji’s complaints, in which it initially said, in part, that it could find no evidence that \"AI-generated assets or slideshow formats are being used.\" This was despite Finji sending the customer support page a screenshot of the clearly edited image mentioned above. In a subsequent exchange, TikTok appeared to acknowledge the evidence and assured the publisher it was \"no longer disputing whether this occurred.\" It added that it has escalated the issue internally and was investigating it thoroughly. TikTok does have a \"Smart Creative\" option on its ad platform, which essentially uses generative AI to modify user-created ads so that multiple versions are pushed out, with the ones its audience responds more positively to used more often. Another option is the “Automate Creative” features, which use AI to automatically optimize things like music, audio effects and general visual \"quality\" to \"enhance the user’s viewing experience.\" Saltsman showed IGN evidence that Finji has both of these options turned off, which was also confirmed by a TikTok agent for the ad in question. After a number of increasingly frustrated exchanges in which TikTok eventually admitted to Saltsman that the ad \"raises significant issues, including the unauthorized use of AI, the sexualization and misrepresentation of your characters, and the resulting commercial and reputational harm to your studio,\" the Finji co-founder was offered something of an explanation. TikTok said that Finji’s campaign used a \"catalog ads format\" designed to \"demonstrate the performance benefits of combining carousel and video assets in Sales campaigns.\" It said that this \"initiative\" helped advertisers \"achieve better results with less effort,\" but did not address the harmful content directly. Finji seemingly also opted into this ad format without knowing it had done so. TikTok declined to comment on the matter when approached by IGN. Saltsman was told the issue could not be escalated any higher, with communication not resolved at the time of IGN publishing its report. In a statement to the outlet, Saltsman said she was \"a bit shocked by TikTok’s complete lack of appropriate response to the mess they made.\" She went on to say that she expected both an apology and clear reassurance of how a similar issue would not reoccur, but was \"obviously not holding my breath for any of the above.\"This article originally appeared on Engadget at https://www.engadget.com/gaming/tunic-publisher-claims-tiktok-ran-racist-sexist-ai-ads-for-one-of-its-games-without-its-knowledge-185303395.html?src=rss",
          "content": "Indie publisher and developer Finji has accused TikTok of using generative AI to alter the ads for its games on the platform without its knowledge or permission. Finji, which published indie darlings like Night in the Woods and Tunic, said it only became aware of the seemingly modified ads after being alerted to them by followers of its official TikTok account. As reported by IGN, Finji alleges that one ad that went out on the platform was modified so it displayed a \"racist, sexualized\" representation of a character from one of its games. While it does advertise on TikTok, it told IGN that it has AI \"turned all the way off,\" but after CEO and co-founder Rebekah Saltsman received screenshots of the ads in question from fans, she approached TikTok to investigate. A number of Finji ads have appeared on TikTok, some that include montages of the company’s games, and others that are game-specific like this one for Usual June. According to IGN, the offending AI-modified ads (which are still posted as if they’re coming directly from Finji) appeared as slideshows. Some images don’t appear to be that different from the source, but one possibly AI-generated example seen by IGN depicts Usual June’s titular protagonist with \"a bikini bottom, impossibly large hips and thighs, and boots that rise up over her knees.\" Needless to say (and obvious from the official screenshot used as the lead image for this article), this is not how the character appears in the game. As for TikTok’s response, IGN printed a number of the platform’s replies to Finji’s complaints, in which it initially said, in part, that it could find no evidence that \"AI-generated assets or slideshow formats are being used.\" This was despite Finji sending the customer support page a screenshot of the clearly edited image mentioned above. In a subsequent exchange, TikTok appeared to acknowledge the evidence and assured the publisher it was \"no longer disputing whether this occurred.\" It added that it has escalated the issue internally and was investigating it thoroughly. TikTok does have a \"Smart Creative\" option on its ad platform, which essentially uses generative AI to modify user-created ads so that multiple versions are pushed out, with the ones its audience responds more positively to used more often. Another option is the “Automate Creative” features, which use AI to automatically optimize things like music, audio effects and general visual \"quality\" to \"enhance the user’s viewing experience.\" Saltsman showed IGN evidence that Finji has both of these options turned off, which was also confirmed by a TikTok agent for the ad in question. After a number of increasingly frustrated exchanges in which TikTok eventually admitted to Saltsman that the ad \"raises significant issues, including the unauthorized use of AI, the sexualization and misrepresentation of your characters, and the resulting commercial and reputational harm to your studio,\" the Finji co-founder was offered something of an explanation. TikTok said that Finji’s campaign used a \"catalog ads format\" designed to \"demonstrate the performance benefits of combining carousel and video assets in Sales campaigns.\" It said that this \"initiative\" helped advertisers \"achieve better results with less effort,\" but did not address the harmful content directly. Finji seemingly also opted into this ad format without knowing it had done so. TikTok declined to comment on the matter when approached by IGN. Saltsman was told the issue could not be escalated any higher, with communication not resolved at the time of IGN publishing its report. In a statement to the outlet, Saltsman said she was \"a bit shocked by TikTok’s complete lack of appropriate response to the mess they made.\" She went on to say that she expected both an apology and clear reassurance of how a similar issue would not reoccur, but was \"obviously not holding my breath for any of the above.\"This article originally appeared on Engadget at https://www.engadget.com/gaming/tunic-publisher-claims-tiktok-ran-racist-sexist-ai-ads-for-one-of-its-games-without-its-knowledge-185303395.html?src=rss",
          "feed_position": 0
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/big-tech/us-website-freedomgov-will-allow-europeans-to-view-hate-speech-and-other-blocked-content-130000014.html",
          "published_at": "Fri, 20 Feb 2026 13:00:00 +0000",
          "title": "US website 'freedom.gov' will allow Europeans to view hate speech and other blocked content",
          "standfirst": "The US State Department is building a web portal, where Europeans and anyone else can see online content banned by their governments, according to Reuters. It was supposed to be launched at Munich Security Conference last month, but some state department officials reportedly voiced their concerns about the project. The portal will be hosted on freedom.gov, which currently just shows the image above. “Freedom is Coming,” the homepage reads. “Information is power. Reclaim your human right to free expression. Get Ready.”Reuters says officials discussed making a virtual private network function available on the portal and making visitors’ traffic appear as if they were from the US, so they could see anything unavailable to them. While it’s a state department project, The Guardian has traced the domain to the Cybersecurity and Infrastructure Security Agency (CISA), which is a component of the US Department of Homeland Security. Homeland also serves as the administrator for the Immigration and Customs Enforcement (ICE). The project could drive the wedge further between the US and its European allies. European authorities don’t usually order broad censorships preventing their citizens from being able to access large parts of the internet. Typically, they only order the blocking of hate speech, terrorist propaganda, disinformation and anything illegal under the EU’s Digital Services Act or the UK’s Online Safety Act. “If the Trump administration is alleging that they’re gonna be bypassing content bans, what they’re gonna be helping users access in Europe is essentially hate speech, pornography, and child sexual abuse material,” Nina Jankowicz, who served as the executive director of Homeland Security’s Disinformation Governance Board, told The Guardian. The board was very short-lived and was disbanded a few months after it was formed, following complaints by Republican lawmakers that it would impinge on people’s rights to free speech. When asked about the project, the state department said it didn’t have a program specifically meant to circumvent censorship in Europe. But the spokesperson said: “Digital freedom is a priority for the State Department, however, and that includes the proliferation of privacy and censorship-circumvention technologies like VPNs.\"This article originally appeared on Engadget at https://www.engadget.com/big-tech/us-website-freedomgov-will-allow-europeans-to-view-hate-speech-and-other-blocked-content-130000014.html?src=rss",
          "content": "The US State Department is building a web portal, where Europeans and anyone else can see online content banned by their governments, according to Reuters. It was supposed to be launched at Munich Security Conference last month, but some state department officials reportedly voiced their concerns about the project. The portal will be hosted on freedom.gov, which currently just shows the image above. “Freedom is Coming,” the homepage reads. “Information is power. Reclaim your human right to free expression. Get Ready.”Reuters says officials discussed making a virtual private network function available on the portal and making visitors’ traffic appear as if they were from the US, so they could see anything unavailable to them. While it’s a state department project, The Guardian has traced the domain to the Cybersecurity and Infrastructure Security Agency (CISA), which is a component of the US Department of Homeland Security. Homeland also serves as the administrator for the Immigration and Customs Enforcement (ICE). The project could drive the wedge further between the US and its European allies. European authorities don’t usually order broad censorships preventing their citizens from being able to access large parts of the internet. Typically, they only order the blocking of hate speech, terrorist propaganda, disinformation and anything illegal under the EU’s Digital Services Act or the UK’s Online Safety Act. “If the Trump administration is alleging that they’re gonna be bypassing content bans, what they’re gonna be helping users access in Europe is essentially hate speech, pornography, and child sexual abuse material,” Nina Jankowicz, who served as the executive director of Homeland Security’s Disinformation Governance Board, told The Guardian. The board was very short-lived and was disbanded a few months after it was formed, following complaints by Republican lawmakers that it would impinge on people’s rights to free speech. When asked about the project, the state department said it didn’t have a program specifically meant to circumvent censorship in Europe. But the spokesperson said: “Digital freedom is a priority for the State Department, however, and that includes the proliferation of privacy and censorship-circumvention technologies like VPNs.\"This article originally appeared on Engadget at https://www.engadget.com/big-tech/us-website-freedomgov-will-allow-europeans-to-view-hate-speech-and-other-blocked-content-130000014.html?src=rss",
          "feed_position": 6
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/gaming/la-county-lawsuit-accuses-roblox-of-exposing-children-to-grooming-and-exploitation-124523028.html",
          "published_at": "Fri, 20 Feb 2026 12:45:23 +0000",
          "title": "LA County lawsuit accuses Roblox of exposing children to 'grooming and exploitation'",
          "standfirst": "Los Angeles County has sued Roblox for \"unfair and deceptive business practices,\" claiming the platform's moderation and age-verification systems are inadequate. \"Roblox portrays its platform as a safe and appropriate place for children to play,\" the complaint states. \"In reality, and as Roblox well knows, the design of its platform makes children easy prey for pedophiles.\" Representatives accused Roblox of failing to implement adequate platform safety features to prevent child endangerment. \"Specifically, Roblox has not effectively moderated game content or enforced age-appropriate restrictions and warnings established by the creators, allowing the predatory and inappropriate language and interactions between users to persist,\" the County stated. It also said the platform failed to disclose any danger to children, including sexual content and the risk of predators. Roblox rejected the allegations, saying the platform was built around safety. \"We have advanced safeguards that monitor our platform for harmful content and communications, and users cannot send or receive images via chat, avoiding one of the most prevalent opportunities for misuse seen elsewhere online,\" the company told the AFP. The LA county complaint is the latest in a string of lawsuits from US regions including Florida, Texas and Kentucky. The Attorney General in Louisiana also accused the company of having a \"lack of safety protocols\" that endanger the safety of children in favor of \"growth, revenue and profits.\" That state's lawsuit cited a specific example of a subject arrested last year that used voice-altering tech to mimic a younger feminine voice to lure and sexually exploit young players. Roblox has said that it has about 144 million daily active users around the world, with over 40 percent of them under the age of 13. However, it has faced repeated accusations that it doesn't do enough to protect young players. In 2024, Roblox banned players under 13 from accessing some types of in-game content and restricted their ability to message with other players outside of specific games. Last year, the company also began asking tens of millions of children to verify their age with a selfie. This article originally appeared on Engadget at https://www.engadget.com/gaming/la-county-lawsuit-accuses-roblox-of-exposing-children-to-grooming-and-exploitation-124523028.html?src=rss",
          "content": "Los Angeles County has sued Roblox for \"unfair and deceptive business practices,\" claiming the platform's moderation and age-verification systems are inadequate. \"Roblox portrays its platform as a safe and appropriate place for children to play,\" the complaint states. \"In reality, and as Roblox well knows, the design of its platform makes children easy prey for pedophiles.\" Representatives accused Roblox of failing to implement adequate platform safety features to prevent child endangerment. \"Specifically, Roblox has not effectively moderated game content or enforced age-appropriate restrictions and warnings established by the creators, allowing the predatory and inappropriate language and interactions between users to persist,\" the County stated. It also said the platform failed to disclose any danger to children, including sexual content and the risk of predators. Roblox rejected the allegations, saying the platform was built around safety. \"We have advanced safeguards that monitor our platform for harmful content and communications, and users cannot send or receive images via chat, avoiding one of the most prevalent opportunities for misuse seen elsewhere online,\" the company told the AFP. The LA county complaint is the latest in a string of lawsuits from US regions including Florida, Texas and Kentucky. The Attorney General in Louisiana also accused the company of having a \"lack of safety protocols\" that endanger the safety of children in favor of \"growth, revenue and profits.\" That state's lawsuit cited a specific example of a subject arrested last year that used voice-altering tech to mimic a younger feminine voice to lure and sexually exploit young players. Roblox has said that it has about 144 million daily active users around the world, with over 40 percent of them under the age of 13. However, it has faced repeated accusations that it doesn't do enough to protect young players. In 2024, Roblox banned players under 13 from accessing some types of in-game content and restricted their ability to message with other players outside of specific games. Last year, the company also began asking tens of millions of children to verify their age with a selfie. This article originally appeared on Engadget at https://www.engadget.com/gaming/la-county-lawsuit-accuses-roblox-of-exposing-children-to-grooming-and-exploitation-124523028.html?src=rss",
          "feed_position": 7
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/general/the-morning-after-engadget-newsletter-122534537.html",
          "published_at": "Fri, 20 Feb 2026 12:31:59 +0000",
          "title": "The Morning After: What to expect from Apple’s March 4 hardware event",
          "standfirst": "Apple has lined up its first event of the year. Already! It’s taking place in New York City on March 4 at 9AM ET, but the company hasn’t confirmed if it will stream the media event. It seems likely the event will be mainly iPads and MacBooks — so business as usual. However, it could include new entry-level MacBooks in a fresh array of colors. I think that’s what everyone’s reading into the lemon-and-lime tinged invitation. I’m very much up for a return of the colorful Mac. The first Mac I ever used was one of those bubbly orange iMacs, interning at a video-game magazine. Yes, a magazine. We’re also expecting a 2026 MacBook Air and refreshed 14- and 16-inch MacBook Pros, with the M5 Pro and M5 Max chips also breaking cover. Is it too early for an iPhone 17e? Perhaps. We’ll be reporting from the event. And for those asking about yesterday's newsletter, thanks for your continued support and we'll have more to say soon. — Mat Smith The other big stories (and deals) this morning Meta’s metaverse is going mobile-first Meta reportedly plans to release a smartwatch this year Ring could be planning to expand Search Party feature beyond dogs Netflix’s first MMA livestream is coming in May Rousey v. Carano. Netflix is streaming its very first live MMA fight on May 16. The combatants are Ronda Rousey, (last match 2016) and Gina Carano (2009). The streamer has had to pluck fighters out of retirement because more contemporary stars are under contract with various promotional entities. The featherweight bout will take place inside a hexagon cage and stream globally — hopefully, Netflix can keep its stream up. The fight is co-hosted by Most Valuable Productions, Jake Paul’s production company. Because of course it is. Continue reading. The Pixel 10a is your next midrange Android phone It launches March 5. Engadget The worst-kept secret in value-for-money phones remains Google’s Pixel A series. In recent years, the Android phone series has offered a great balance of specs, hardware design and software features that embarrass most phones in the same price point. Its camera performance is often better than devices that cost several hundred dollars more. It’s more of the same with the Pixel 10a. For $500, you get a 6.3-inch OLED screen with a 120Hz refresh rate and 3,000 nits of peak brightness, 8GB of RAM and a 48MP main camera, paired with a 13MP ultra-wide. Also: No. Camera. Bump. Innovation for $500, right there. Continue reading. Dyson’s tiny PencilVac gets turned into a floorwasher This is the PencilWash. Engadget I won’t shut up about floor cleaning. I’m 41. Dyson has crunched its wet-floor tech into the same cylindrical profile of its Penac. I like the size, but how does it clean? I’ll hold judgment till I’ve tried it. $600 is a lot more than a mop. Yes, I know that’s not the point. Continue reading.This article originally appeared on Engadget at https://www.engadget.com/general/the-morning-after-engadget-newsletter-122534537.html?src=rss",
          "content": "Apple has lined up its first event of the year. Already! It’s taking place in New York City on March 4 at 9AM ET, but the company hasn’t confirmed if it will stream the media event. It seems likely the event will be mainly iPads and MacBooks — so business as usual. However, it could include new entry-level MacBooks in a fresh array of colors. I think that’s what everyone’s reading into the lemon-and-lime tinged invitation. I’m very much up for a return of the colorful Mac. The first Mac I ever used was one of those bubbly orange iMacs, interning at a video-game magazine. Yes, a magazine. We’re also expecting a 2026 MacBook Air and refreshed 14- and 16-inch MacBook Pros, with the M5 Pro and M5 Max chips also breaking cover. Is it too early for an iPhone 17e? Perhaps. We’ll be reporting from the event. And for those asking about yesterday's newsletter, thanks for your continued support and we'll have more to say soon. — Mat Smith The other big stories (and deals) this morning Meta’s metaverse is going mobile-first Meta reportedly plans to release a smartwatch this year Ring could be planning to expand Search Party feature beyond dogs Netflix’s first MMA livestream is coming in May Rousey v. Carano. Netflix is streaming its very first live MMA fight on May 16. The combatants are Ronda Rousey, (last match 2016) and Gina Carano (2009). The streamer has had to pluck fighters out of retirement because more contemporary stars are under contract with various promotional entities. The featherweight bout will take place inside a hexagon cage and stream globally — hopefully, Netflix can keep its stream up. The fight is co-hosted by Most Valuable Productions, Jake Paul’s production company. Because of course it is. Continue reading. The Pixel 10a is your next midrange Android phone It launches March 5. Engadget The worst-kept secret in value-for-money phones remains Google’s Pixel A series. In recent years, the Android phone series has offered a great balance of specs, hardware design and software features that embarrass most phones in the same price point. Its camera performance is often better than devices that cost several hundred dollars more. It’s more of the same with the Pixel 10a. For $500, you get a 6.3-inch OLED screen with a 120Hz refresh rate and 3,000 nits of peak brightness, 8GB of RAM and a 48MP main camera, paired with a 13MP ultra-wide. Also: No. Camera. Bump. Innovation for $500, right there. Continue reading. Dyson’s tiny PencilVac gets turned into a floorwasher This is the PencilWash. Engadget I won’t shut up about floor cleaning. I’m 41. Dyson has crunched its wet-floor tech into the same cylindrical profile of its Penac. I like the size, but how does it clean? I’ll hold judgment till I’ve tried it. $600 is a lot more than a mop. Yes, I know that’s not the point. Continue reading.This article originally appeared on Engadget at https://www.engadget.com/general/the-morning-after-engadget-newsletter-122534537.html?src=rss",
          "feed_position": 9,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2026-02/79eae6d0-0e56-11f1-9576-67d827e26ed5"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/smartphones/best-cheap-android-phone-160029703.html",
          "published_at": "Fri, 20 Feb 2026 08:00:37 +0000",
          "title": "The best cheap Android phones to buy in 2026",
          "standfirst": "Getting a solid Android phone doesn’t necessitate spending a small fortune. The best budget models strike a great balance between price and performance, giving you smooth everyday use without cutting too many corners. Whether you’re scrolling social media, streaming your favorite shows or snapping photos of a night out, there’s an affordable Android phone that can handle it all.Cheaper phones have come a long way in recent years. Many now feature bright, fast displays, reliable cameras and battery life that lasts well into the next day. You might miss out on top-tier extras like the latest processor or ultra-high-resolution zoom, but what you get instead is value that makes sense. Some models even surprise with cameras that rival far pricier flagships, making them ideal for casual photographers or anyone who just wants to capture a great shot on the go.We’ve tested budget Android phones from brands like Google, Samsung and OnePlus to find the ones that deliver the most for less. These are the models that prove you don’t need a flagship price tag to get a dependable Android phone. Best budget Android phones for 2026 How cheap should you go for an Android phone? We tend to define a budget smartphone as costing between $150 and $350. Any lower and the device runs the risk of suffering from too many compromises in function, and above that, you cross over to pricier midrange handsets (if you're open to spending more, we shouted out a couple of our favorite flagship phones at the very end of this guide). But for those with a little wiggle room, there are some things to consider. For example, a child may be better off with a cheaper device, especially if it’s intended mainly for emergencies, WiFi browsing or texting parents (and not social media). On the higher end of this price spectrum, sub-$350 Samsung phones and other Android devices have come a long way thanks to improved performance, better phone cameras with low-light capabilities, fast charging, and nicer displays like AMOLED panels. This makes them a viable alternative to, say, a flagship handset with a premium design, even if you have the flexibility to spend more. What to look for in a cheap Android phone When it comes to cheap phones, you get what you pay for. Most smartphones in this price range are made out of plastic, though the fit and finish of a specific model can vary a lot based on price. A bright screen is also important. Typically you’ll get LCD panels with a 60Hz or 90Hz refresh rate, but some phones may have OLED or AMOLED screens with increased color saturation. Long battery life is critical as well, so we tend to favor devices with larger power cells of around 5,000 mAh. In this price range, performance can vary a lot, so look for devices with at least 8GB of RAM and processors that can deliver stutter-free visuals. It’s also important to consider support length: as periodic security updates and lengthy software support can extend the longevity of your device, which will save you money in the long run. Android phone FAQs What's the price difference for a cheap Android vs a cheap iPhone? iPhones tend to be more expensive compared to Android phones — even the cheapest iPhone, the iPhone SE, which starts from $429, is a harder pill to swallow compared to a cheap Android phone. In contrast, you can get your hands on a cheap Android device for as low as $100.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/best-cheap-android-phone-160029703.html?src=rss",
          "content": "Getting a solid Android phone doesn’t necessitate spending a small fortune. The best budget models strike a great balance between price and performance, giving you smooth everyday use without cutting too many corners. Whether you’re scrolling social media, streaming your favorite shows or snapping photos of a night out, there’s an affordable Android phone that can handle it all.Cheaper phones have come a long way in recent years. Many now feature bright, fast displays, reliable cameras and battery life that lasts well into the next day. You might miss out on top-tier extras like the latest processor or ultra-high-resolution zoom, but what you get instead is value that makes sense. Some models even surprise with cameras that rival far pricier flagships, making them ideal for casual photographers or anyone who just wants to capture a great shot on the go.We’ve tested budget Android phones from brands like Google, Samsung and OnePlus to find the ones that deliver the most for less. These are the models that prove you don’t need a flagship price tag to get a dependable Android phone. Best budget Android phones for 2026 How cheap should you go for an Android phone? We tend to define a budget smartphone as costing between $150 and $350. Any lower and the device runs the risk of suffering from too many compromises in function, and above that, you cross over to pricier midrange handsets (if you're open to spending more, we shouted out a couple of our favorite flagship phones at the very end of this guide). But for those with a little wiggle room, there are some things to consider. For example, a child may be better off with a cheaper device, especially if it’s intended mainly for emergencies, WiFi browsing or texting parents (and not social media). On the higher end of this price spectrum, sub-$350 Samsung phones and other Android devices have come a long way thanks to improved performance, better phone cameras with low-light capabilities, fast charging, and nicer displays like AMOLED panels. This makes them a viable alternative to, say, a flagship handset with a premium design, even if you have the flexibility to spend more. What to look for in a cheap Android phone When it comes to cheap phones, you get what you pay for. Most smartphones in this price range are made out of plastic, though the fit and finish of a specific model can vary a lot based on price. A bright screen is also important. Typically you’ll get LCD panels with a 60Hz or 90Hz refresh rate, but some phones may have OLED or AMOLED screens with increased color saturation. Long battery life is critical as well, so we tend to favor devices with larger power cells of around 5,000 mAh. In this price range, performance can vary a lot, so look for devices with at least 8GB of RAM and processors that can deliver stutter-free visuals. It’s also important to consider support length: as periodic security updates and lengthy software support can extend the longevity of your device, which will save you money in the long run. Android phone FAQs What's the price difference for a cheap Android vs a cheap iPhone? iPhones tend to be more expensive compared to Android phones — even the cheapest iPhone, the iPhone SE, which starts from $429, is a harder pill to swallow compared to a cheap Android phone. In contrast, you can get your hands on a cheap Android device for as low as $100.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/best-cheap-android-phone-160029703.html?src=rss",
          "feed_position": 13
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/technology/google-gemini-3-1-pro-first-impressions-a-deep-think-mini-with-adjustable",
          "published_at": "Thu, 19 Feb 2026 22:26:00 GMT",
          "title": "Google Gemini 3.1 Pro first impressions: a 'Deep Think Mini' with adjustable reasoning on demand",
          "standfirst": "For the past three months, Google&#x27;s Gemini 3 Pro has held its ground as one of the most capable frontier models available. But in the fast-moving world of AI, three months is a lifetime — and competitors have not been standing still.Earlier today, Google released Gemini 3.1 Pro, an update that brings a key innovation to the company&#x27;s workhorse power model: three levels of adjustable thinking that effectively turn it into a lightweight version of Google&#x27;s specialized Deep Think reasoning system.The release marks the first time Google has issued a \"point one\" update to a Gemini model, signaling a shift in the company&#x27;s release strategy from periodic full-version launches to more frequent incremental upgrades. More importantly for enterprise AI teams evaluating their model stack, 3.1 Pro&#x27;s new three-tier thinking system — low, medium, and high — gives developers and IT leaders a single model that can scale its reasoning effort dynamically, from quick responses for routine queries up to multi-minute deep reasoning sessions for complex problems.The model is rolling out now in preview across the Gemini API via Google AI Studio, Gemini CLI, Google&#x27;s agentic development platform Antigravity, Vertex AI, Gemini Enterprise, Android Studio, the consumer Gemini app, and NotebookLM.The &#x27;Deep Think Mini&#x27; effect: adjustable reasoning on demandThe most consequential feature in Gemini 3.1 Pro is not a single benchmark number — it is the introduction of a three-tier thinking level system that gives users fine-grained control over how much computational effort the model invests in each response.Gemini 3 Pro offered only two thinking modes: low and high. The new 3.1 Pro adds a medium setting (similar to the previous high) and, critically, overhauls what \"high\" means. When set to high, 3.1 Pro behaves as a \"mini version of Gemini Deep Think\" — the company&#x27;s specialized reasoning model that was updated just last week.The implication for enterprise deployment could be significant. Rather than routing requests to different specialized models based on task complexity — a common but operationally burdensome pattern — organizations can now use a single model endpoint and adjust reasoning depth based on the task at hand. Routine document summarization can run on low thinking with fast response times, while complex analytical tasks can be elevated to high thinking for Deep Think–caliber reasoning.Benchmark Performance: More Than Doubling Reasoning Over 3 ProGoogle&#x27;s published benchmarks tell a story of dramatic improvement, particularly in areas associated with reasoning and agentic capability.On ARC-AGI-2, a benchmark that evaluates a model&#x27;s ability to solve novel abstract reasoning patterns, 3.1 Pro scored 77.1% — more than double the 31.1% achieved by Gemini 3 Pro and substantially ahead of Anthropic&#x27;s Sonnet 4.6 (58.3%) and Opus 4.6 (68.8%). This result also eclipses OpenAI&#x27;s GPT-5.2 (52.9%).The gains extend across the board. On Humanity&#x27;s Last Exam, a rigorous academic reasoning benchmark, 3.1 Pro achieved 44.4% without tools, up from 37.5% for 3 Pro and ahead of both Claude Sonnet 4.6 (33.2%) and Opus 4.6 (40.0%). On GPQA Diamond, a scientific knowledge evaluation, 3.1 Pro reached 94.3%, outperforming all listed competitors.Where the results become particularly relevant for enterprise AI teams is in the agentic benchmarks — the evaluations that measure how well models perform when given tools and multi-step tasks, the kind of work that increasingly defines production AI deployments.On Terminal-Bench 2.0, which evaluates agentic terminal coding, 3.1 Pro scored 68.5% compared to 56.9% for its predecessor. On MCP Atlas, a benchmark measuring multi-step workflows using the Model Context Protocol, 3.1 Pro reached 69.2% — a 15-point improvement over 3 Pro&#x27;s 54.1% and nearly 10 points ahead of both Claude and GPT-5.2. And on BrowseComp, which tests agentic web search capability, 3.1 Pro achieved 85.9%, surging past 3 Pro&#x27;s 59.2%.Why Google chose a &#x27;0.1&#x27; release — and what it signalsThe versioning decision is itself noteworthy. Previous Gemini releases followed a pattern of dated previews — multiple 2.5 previews, for instance, before reaching general availability. The choice to designate this update as 3.1 rather than another 3 Pro preview suggests Google views the improvements as substantial enough to warrant a version increment, while the \"point one\" framing sets expectations that this is an evolution, not a revolution.Google&#x27;s blog post states that 3.1 Pro builds directly on lessons from the Gemini Deep Think series, incorporating techniques from both earlier and more recent versions. The benchmarks strongly suggest that reinforcement learning has played a central role in the gains, particularly on tasks like ARC-AGI-2, coding benchmarks, and agentic evaluations — exactly the domains where RL-based training environments can provide clear reward signals.The model is being released in preview rather than as a general availability launch, with Google stating it will continue making advancements in areas such as agentic workflows before moving to full GA.Competitive implications for your enterprise AI stackFor IT decision makers evaluating frontier model providers, Gemini 3.1 Pro&#x27;s release has to not only make them rethink which models to choose but also how to adapt to such a fast pace of change for their own products and services.The question now is whether this release triggers a response from competitors. Gemini 3 Pro&#x27;s original launch last November set off a wave of model releases across both proprietary and open-weight ecosystems. With 3.1 Pro reclaiming benchmark leadership in several critical categories, the pressure is on Anthropic, OpenAI, and the open-weight community to respond — and in the current AI landscape, that response is likely measured in weeks, not months.AvailabilityGemini 3.1 Pro is available now in preview through the Gemini API in Google AI Studio, Gemini CLI, Google Antigravity, and Android Studio for developers. Enterprise customers can access it through Vertex AI and Gemini Enterprise. Consumers on Google AI Pro and Ultra plans can access it through the Gemini app and NotebookLM.",
          "content": "For the past three months, Google&#x27;s Gemini 3 Pro has held its ground as one of the most capable frontier models available. But in the fast-moving world of AI, three months is a lifetime — and competitors have not been standing still.Earlier today, Google released Gemini 3.1 Pro, an update that brings a key innovation to the company&#x27;s workhorse power model: three levels of adjustable thinking that effectively turn it into a lightweight version of Google&#x27;s specialized Deep Think reasoning system.The release marks the first time Google has issued a \"point one\" update to a Gemini model, signaling a shift in the company&#x27;s release strategy from periodic full-version launches to more frequent incremental upgrades. More importantly for enterprise AI teams evaluating their model stack, 3.1 Pro&#x27;s new three-tier thinking system — low, medium, and high — gives developers and IT leaders a single model that can scale its reasoning effort dynamically, from quick responses for routine queries up to multi-minute deep reasoning sessions for complex problems.The model is rolling out now in preview across the Gemini API via Google AI Studio, Gemini CLI, Google&#x27;s agentic development platform Antigravity, Vertex AI, Gemini Enterprise, Android Studio, the consumer Gemini app, and NotebookLM.The &#x27;Deep Think Mini&#x27; effect: adjustable reasoning on demandThe most consequential feature in Gemini 3.1 Pro is not a single benchmark number — it is the introduction of a three-tier thinking level system that gives users fine-grained control over how much computational effort the model invests in each response.Gemini 3 Pro offered only two thinking modes: low and high. The new 3.1 Pro adds a medium setting (similar to the previous high) and, critically, overhauls what \"high\" means. When set to high, 3.1 Pro behaves as a \"mini version of Gemini Deep Think\" — the company&#x27;s specialized reasoning model that was updated just last week.The implication for enterprise deployment could be significant. Rather than routing requests to different specialized models based on task complexity — a common but operationally burdensome pattern — organizations can now use a single model endpoint and adjust reasoning depth based on the task at hand. Routine document summarization can run on low thinking with fast response times, while complex analytical tasks can be elevated to high thinking for Deep Think–caliber reasoning.Benchmark Performance: More Than Doubling Reasoning Over 3 ProGoogle&#x27;s published benchmarks tell a story of dramatic improvement, particularly in areas associated with reasoning and agentic capability.On ARC-AGI-2, a benchmark that evaluates a model&#x27;s ability to solve novel abstract reasoning patterns, 3.1 Pro scored 77.1% — more than double the 31.1% achieved by Gemini 3 Pro and substantially ahead of Anthropic&#x27;s Sonnet 4.6 (58.3%) and Opus 4.6 (68.8%). This result also eclipses OpenAI&#x27;s GPT-5.2 (52.9%).The gains extend across the board. On Humanity&#x27;s Last Exam, a rigorous academic reasoning benchmark, 3.1 Pro achieved 44.4% without tools, up from 37.5% for 3 Pro and ahead of both Claude Sonnet 4.6 (33.2%) and Opus 4.6 (40.0%). On GPQA Diamond, a scientific knowledge evaluation, 3.1 Pro reached 94.3%, outperforming all listed competitors.Where the results become particularly relevant for enterprise AI teams is in the agentic benchmarks — the evaluations that measure how well models perform when given tools and multi-step tasks, the kind of work that increasingly defines production AI deployments.On Terminal-Bench 2.0, which evaluates agentic terminal coding, 3.1 Pro scored 68.5% compared to 56.9% for its predecessor. On MCP Atlas, a benchmark measuring multi-step workflows using the Model Context Protocol, 3.1 Pro reached 69.2% — a 15-point improvement over 3 Pro&#x27;s 54.1% and nearly 10 points ahead of both Claude and GPT-5.2. And on BrowseComp, which tests agentic web search capability, 3.1 Pro achieved 85.9%, surging past 3 Pro&#x27;s 59.2%.Why Google chose a &#x27;0.1&#x27; release — and what it signalsThe versioning decision is itself noteworthy. Previous Gemini releases followed a pattern of dated previews — multiple 2.5 previews, for instance, before reaching general availability. The choice to designate this update as 3.1 rather than another 3 Pro preview suggests Google views the improvements as substantial enough to warrant a version increment, while the \"point one\" framing sets expectations that this is an evolution, not a revolution.Google&#x27;s blog post states that 3.1 Pro builds directly on lessons from the Gemini Deep Think series, incorporating techniques from both earlier and more recent versions. The benchmarks strongly suggest that reinforcement learning has played a central role in the gains, particularly on tasks like ARC-AGI-2, coding benchmarks, and agentic evaluations — exactly the domains where RL-based training environments can provide clear reward signals.The model is being released in preview rather than as a general availability launch, with Google stating it will continue making advancements in areas such as agentic workflows before moving to full GA.Competitive implications for your enterprise AI stackFor IT decision makers evaluating frontier model providers, Gemini 3.1 Pro&#x27;s release has to not only make them rethink which models to choose but also how to adapt to such a fast pace of change for their own products and services.The question now is whether this release triggers a response from competitors. Gemini 3 Pro&#x27;s original launch last November set off a wave of model releases across both proprietary and open-weight ecosystems. With 3.1 Pro reclaiming benchmark leadership in several critical categories, the pressure is on Anthropic, OpenAI, and the open-weight community to respond — and in the current AI landscape, that response is likely measured in weeks, not months.AvailabilityGemini 3.1 Pro is available now in preview through the Gemini API in Google AI Studio, Gemini CLI, Google Antigravity, and Android Studio for developers. Enterprise customers can access it through Vertex AI and Gemini Enterprise. Consumers on Google AI Pro and Ultra plans can access it through the Gemini app and NotebookLM.",
          "feed_position": 0,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/3QN1ZUexlvrsauz6g2NrrK/42bc7a43c49aab36315e98993de78af1/ClKBtgX7u8IrQZI9CACCZ.jpg?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/security/cx-security-gaps-ai-stack-blind-spots",
          "published_at": "Thu, 19 Feb 2026 20:30:00 GMT",
          "title": "How attackers hit 700 organizations through CX platforms your SOC already approved",
          "standfirst": "CX platforms process billions of unstructured interactions a year: Survey forms, review sites, social feeds, call center transcripts, all flowing into AI engines that trigger automated workflows touching payroll, CRM, and payment systems. No tool in a security operation center leader’s stack inspects what a CX platform’s AI engine is ingesting, and attackers figured this out. They poison the data feeding it, and the AI does the damage for them.The Salesloft/Drift breach in August 2025 proved exactly this. Attackers compromised Salesloft’s GitHub environment, stole Drift chatbot OAuth tokens, and accessed Salesforce environments across 700+ organizations, including Cloudflare, Palo Alto Networks, and Zscaler. It then scanned stolen data for AWS keys, Snowflake tokens, and plaintext passwords. And no malware was deployed.That gap is wider than most security leaders realize: 98% of organizations have a data loss prevention (DLP) program, but only 6% have dedicated resources, according to Proofpoint’s 2025 Voice of the CISO report, which surveyed 1,600 CISOs across 16 countries. And 81% of interactive intrusions now use legitimate access rather than malware, per CrowdStrike’s 2025 Threat Hunting Report. Cloud intrusions surged 136% in the first half of 2025.“Most security teams still classify experience management platforms as ‘survey tools,’ which sit in the same risk tier as a project management app,” Assaf Keren, chief security officer at Qualtrics and former CISO at PayPal, told VentureBeat in a recent interview. “This is a massive miscategorization. These platforms now connect to HRIS, CRM, and compensation engines.” Qualtrics alone processes 3.5 billion interactions annually, a figure the company says has doubled since 2023. Organizations can&#x27;t afford to skip steps on input integrity once AI enters the workflow.VentureBeat spent several weeks interviewing security leaders working to close this gap. Six control failures surfaced in every conversation.Six blind spots between the security stack and the AI engine1. DLP cannot see unstructured sentiment data leaving through standard API callsMost DLP policies classify structured personally identifiable information (PII): names, emails, and payment data. Open-text CX responses contain salary complaints, health disclosures, and executive criticism. None matches standard PII patterns. When a third-party AI tool pulls that data, the export looks like a routine API call. The DLP never fires.2. Zombie API tokens from finished campaigns are still liveAn example: Marketing ran a CX campaign six months ago, and the campaign ended. But the OAuth tokens connecting the CX platform to HRIS, CRM and payment systems were never revoked. That means each one is a lateral movement path sitting open.JPMorgan Chase CISO Patrick Opet flagged this risk in his April 2025 open letter, warning that SaaS integration models create “single-factor explicit trust between systems” through tokens “inadequately secured … vulnerable to theft and reuse.”3. Public input channels have no bot mitigation before data reaches the AI engineA web app firewall inspects HTTP payloads for a web application, but none of that coverage extends to a Trustpilot review, a Google Maps rating, or an open-text survey response that a CX platform ingests as legitimate input. Fraudulent sentiment flooding those channels is invisible to perimeter controls. VentureBeat asked security leaders and vendors whether anyone covers input channel integrity for public-facing data sources feeding CX AI engines; it turns out that the category does not exist yet.4. Lateral movement from a compromised CX platform runs through approved API calls“Adversaries aren’t breaking in, they’re logging in,” Daniel Bernard, chief business officer at CrowdStrike, told VentureBeat in an exclusive interview. “It’s a valid login. So from a third-party ISV perspective, you have a sign-in page, you have two-factor authentication. What else do you want from us?” The threat extends to human and non-human identities alike. Bernard described what follows: “All of a sudden, terabytes of data are being exported out. It’s non-standard usage. It’s going places where this user doesn’t go before.” A security information and event management (SIEM) system sees the authentication succeed. It does not see that behavioral shift. Without what Bernard called \"software posture management\" covering CX platforms, the lateral movement runs through connections that the security team already approved.5. Non-technical users hold admin privileges nobody reviewsMarketing, HR and customer success teams configure CX integrations because they need speed, but the SOC team may never see them. Security has to be an enabler, Keren says, or teams route around it. Any organization that cannot produce a current inventory of every CX platform integration and the admin credentials behind them has shadow admin exposure.6. Open-text feedback hits the database before PII gets maskedEmployee surveys capture complaints about managers by name, salary grievances and health disclosures. Customer feedback is just as exposed: account details, purchase history, service disputes. None of this hits a structured PII classifier because it arrives as free text. If a breach exposes it, attackers get unmasked personal information alongside the lateral movement path.Nobody owns this gapThese six failures share a root cause: SaaS security posture management has matured for Salesforce, ServiceNow, and other enterprise platforms. CX platforms never got the same treatment. Nobody monitors user activity, permissions or configurations inside an experience management platform, and policy enforcement on AI workflows processing that data does not exist. When bot-driven input or anomalous data exports hit the CX application layer, nothing detects them.Security teams are responding with what they have. Some are extending SSPM tools to cover CX platform configurations and permissions. API security gateways offer another path, inspecting token scopes and data flows between CX platforms and downstream systems. Identity-centric teams are applying CASB-style access controls to CX admin accounts.None of those approaches delivers what CX-layer security actually requires: continuous monitoring of who is accessing experience data, real-time visibility into misconfigurations before they become lateral movement paths, and automated protection that enforces policy without waiting for a quarterly review cycle.The first integration purpose-built for that gap connects posture management directly to the CX layer, giving security teams the same coverage over program activity, configurations, and data access that they already expect for Salesforce or ServiceNow. CrowdStrike&#x27;s Falcon Shield and the Qualtrics XM Platform are the pairing behind it. Security leaders VentureBeat interviewed said this is the control they have been building manually — and losing sleep over. The blast radius security teams are not measuringMost organizations have mapped the technical blast radius. “But not the business blast radius,” Keren said. When an AI engine triggers a compensation adjustment based on poisoned data, the damage is not a security incident. It is a wrong business decision executed at machine speed. That gap sits between the CISO, the CIO and the business unit owner. Today no one owns it. “When we use data to make business decisions, that data must be right,” Keren said.Run the audit, and start with the zombie tokens. That is where Drift-scale breaches begin. Start with a 30-day validation window. The AI will not wait.",
          "content": "CX platforms process billions of unstructured interactions a year: Survey forms, review sites, social feeds, call center transcripts, all flowing into AI engines that trigger automated workflows touching payroll, CRM, and payment systems. No tool in a security operation center leader’s stack inspects what a CX platform’s AI engine is ingesting, and attackers figured this out. They poison the data feeding it, and the AI does the damage for them.The Salesloft/Drift breach in August 2025 proved exactly this. Attackers compromised Salesloft’s GitHub environment, stole Drift chatbot OAuth tokens, and accessed Salesforce environments across 700+ organizations, including Cloudflare, Palo Alto Networks, and Zscaler. It then scanned stolen data for AWS keys, Snowflake tokens, and plaintext passwords. And no malware was deployed.That gap is wider than most security leaders realize: 98% of organizations have a data loss prevention (DLP) program, but only 6% have dedicated resources, according to Proofpoint’s 2025 Voice of the CISO report, which surveyed 1,600 CISOs across 16 countries. And 81% of interactive intrusions now use legitimate access rather than malware, per CrowdStrike’s 2025 Threat Hunting Report. Cloud intrusions surged 136% in the first half of 2025.“Most security teams still classify experience management platforms as ‘survey tools,’ which sit in the same risk tier as a project management app,” Assaf Keren, chief security officer at Qualtrics and former CISO at PayPal, told VentureBeat in a recent interview. “This is a massive miscategorization. These platforms now connect to HRIS, CRM, and compensation engines.” Qualtrics alone processes 3.5 billion interactions annually, a figure the company says has doubled since 2023. Organizations can&#x27;t afford to skip steps on input integrity once AI enters the workflow.VentureBeat spent several weeks interviewing security leaders working to close this gap. Six control failures surfaced in every conversation.Six blind spots between the security stack and the AI engine1. DLP cannot see unstructured sentiment data leaving through standard API callsMost DLP policies classify structured personally identifiable information (PII): names, emails, and payment data. Open-text CX responses contain salary complaints, health disclosures, and executive criticism. None matches standard PII patterns. When a third-party AI tool pulls that data, the export looks like a routine API call. The DLP never fires.2. Zombie API tokens from finished campaigns are still liveAn example: Marketing ran a CX campaign six months ago, and the campaign ended. But the OAuth tokens connecting the CX platform to HRIS, CRM and payment systems were never revoked. That means each one is a lateral movement path sitting open.JPMorgan Chase CISO Patrick Opet flagged this risk in his April 2025 open letter, warning that SaaS integration models create “single-factor explicit trust between systems” through tokens “inadequately secured … vulnerable to theft and reuse.”3. Public input channels have no bot mitigation before data reaches the AI engineA web app firewall inspects HTTP payloads for a web application, but none of that coverage extends to a Trustpilot review, a Google Maps rating, or an open-text survey response that a CX platform ingests as legitimate input. Fraudulent sentiment flooding those channels is invisible to perimeter controls. VentureBeat asked security leaders and vendors whether anyone covers input channel integrity for public-facing data sources feeding CX AI engines; it turns out that the category does not exist yet.4. Lateral movement from a compromised CX platform runs through approved API calls“Adversaries aren’t breaking in, they’re logging in,” Daniel Bernard, chief business officer at CrowdStrike, told VentureBeat in an exclusive interview. “It’s a valid login. So from a third-party ISV perspective, you have a sign-in page, you have two-factor authentication. What else do you want from us?” The threat extends to human and non-human identities alike. Bernard described what follows: “All of a sudden, terabytes of data are being exported out. It’s non-standard usage. It’s going places where this user doesn’t go before.” A security information and event management (SIEM) system sees the authentication succeed. It does not see that behavioral shift. Without what Bernard called \"software posture management\" covering CX platforms, the lateral movement runs through connections that the security team already approved.5. Non-technical users hold admin privileges nobody reviewsMarketing, HR and customer success teams configure CX integrations because they need speed, but the SOC team may never see them. Security has to be an enabler, Keren says, or teams route around it. Any organization that cannot produce a current inventory of every CX platform integration and the admin credentials behind them has shadow admin exposure.6. Open-text feedback hits the database before PII gets maskedEmployee surveys capture complaints about managers by name, salary grievances and health disclosures. Customer feedback is just as exposed: account details, purchase history, service disputes. None of this hits a structured PII classifier because it arrives as free text. If a breach exposes it, attackers get unmasked personal information alongside the lateral movement path.Nobody owns this gapThese six failures share a root cause: SaaS security posture management has matured for Salesforce, ServiceNow, and other enterprise platforms. CX platforms never got the same treatment. Nobody monitors user activity, permissions or configurations inside an experience management platform, and policy enforcement on AI workflows processing that data does not exist. When bot-driven input or anomalous data exports hit the CX application layer, nothing detects them.Security teams are responding with what they have. Some are extending SSPM tools to cover CX platform configurations and permissions. API security gateways offer another path, inspecting token scopes and data flows between CX platforms and downstream systems. Identity-centric teams are applying CASB-style access controls to CX admin accounts.None of those approaches delivers what CX-layer security actually requires: continuous monitoring of who is accessing experience data, real-time visibility into misconfigurations before they become lateral movement paths, and automated protection that enforces policy without waiting for a quarterly review cycle.The first integration purpose-built for that gap connects posture management directly to the CX layer, giving security teams the same coverage over program activity, configurations, and data access that they already expect for Salesforce or ServiceNow. CrowdStrike&#x27;s Falcon Shield and the Qualtrics XM Platform are the pairing behind it. Security leaders VentureBeat interviewed said this is the control they have been building manually — and losing sleep over. The blast radius security teams are not measuringMost organizations have mapped the technical blast radius. “But not the business blast radius,” Keren said. When an AI engine triggers a compensation adjustment based on poisoned data, the damage is not a security incident. It is a wrong business decision executed at machine speed. That gap sits between the CISO, the CIO and the business unit owner. Today no one owns it. “When we use data to make business decisions, that data must be right,” Keren said.Run the audit, and start with the zombie tokens. That is where Drift-scale breaches begin. Start with a 30-day validation window. The AI will not wait.",
          "feed_position": 1,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/43aX4cDa02bPoqhoIKZoZM/fbdb75fd26097eae87df002190cb9af5/final_hero.jpg?w=300&q=30"
        },
        {
          "source": "Guardian Tech",
          "url": "https://www.theguardian.com/technology/2026/feb/19/us-builds-website-that-will-allow-europeans-to-view-blocked-content",
          "published_at": "Thu, 19 Feb 2026 19:15:27 GMT",
          "title": "US builds website that will allow Europeans to view blocked content",
          "standfirst": "Freedom.gov appears to be administered by a branch of the Department of Homeland SecurityThe US has built a portal that will allow Europeans to view blocked content including alleged hate speech and terrorism, according to Reuters.The portal, “freedom.gov”, will allow worldwide users to circumvent government controls on their content. The site features a graphic of a ghostly horse galloping above the Earth, and the motto: “Information is power. Reclaim your human right to free expression. Get ready.” Continue reading...",
          "content": "Freedom.gov appears to be administered by a branch of the Department of Homeland SecurityThe US has built a portal that will allow Europeans to view blocked content including alleged hate speech and terrorism, according to Reuters.The portal, “freedom.gov”, will allow worldwide users to circumvent government controls on their content. The site features a graphic of a ghostly horse galloping above the Earth, and the motto: “Information is power. Reclaim your human right to free expression. Get ready.” Continue reading...",
          "feed_position": 5
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/entertainment/here-are-my-favorite-things-from-toy-fair-2026-183356720.html",
          "published_at": "Thu, 19 Feb 2026 18:33:56 +0000",
          "title": "Here are my favorite things from Toy Fair 2026",
          "standfirst": "Toy Fair 2026 just wrapped earlier this week and while I would have liked to spend even more time there, I have my own kids (and all their toys and trinkets) to look after. That said, there were a ton of cool new products on display at the Javits Center in New York City that set the stage for the rest of the year, so here's a quick look at some of the most interesting releases from the largest toy show in the Western Hemisphere. Transformers: The Movie 40th anniversary figures ($28 to $60)To celebrate the 40th anniversary of Transformers: The Movie, Hasbro is launching an apology tour to make up for traumatizing theatergoers with the death of the most beloved Autobot back in 1986. To kick things off, Hasbro is releasing a handful of new figures alongside re-releases for some popular bots including Astrotrain, Skywarp, Snarl and Shockwave. I want to give a special shout-out to the model for Kranix, which looks incredibly accurate, as if he just leapt off the movie screen. And even though his duck-billed spaceship alt-mode might look a bit awkward, I wouldn't have it any other way. The crown jewel of the line might be a near-life-size version of The Matrix of Leadership, which measures more than 15 inches wide and even plays Stan Bush's iconic song \"The Touch\" with the push of a button. Unfortunately, the appeal of the Matrix is so powerful that it's already sold out, including at third-party retailers like Big Bad Toy Store, which thankfully is still taking pre-orders for the rest of the lineup after the initial stock from Hasbro dried up.F1 Hot WheelsA collection of some of the new F1 Hot Wheels cars for 2026. Sam Rutherford for EngadgetHot Wheels has big plans for 2026 including a new line of Pantone-colored cars, Brick Shop models like the Elite Series Aston Martin (which comes with its own 1:64 scale car) and a Monster Truck Mutant Chaos set with actual slime. However, I'd argue the company's new F1 offerings are the cream of the crop. Not only are there a bunch of incredibly detailed 1:64 scale racecars with metal bodies, real rubber tires and accurate livery for all the big teams, there's also a new Downhill Circuit Race course that comes with three official vehicles (Mercedes, Haas and Ferrari) featuring multiple levels and the ability to overtake or crash into other cars. If you're like a lot of Americans who have recently fallen down the F1 rabbit hole due to Netflix's Drive to Survive, these new officially licensed miniatures are sure to hit the spot. The first five-pack set of cars is available now, with more arriving later this spring before the Downhill Circuit Race course drives by sometime this fall. Lego Star Wars with Smart Bricks ($40 to $160)Darth Vader's TIE fighter is an all-in-one set, which means it comes included with one of Lego's Smart Bricks, which isn't true for every kit. LegoWe've been eagerly awaiting the first batch of playsets featuring Lego's nifty Smart Brick after it debuted at CES. But now that the company has detailed eight new sets featuring its latest innovation, we're even more intrigued. For me, the three standout kits are the Millennium Falcon, Luke's Red Five X-Wing and Darth Vader's TIE fighter because acting out the Death Star trench run complete with reactive lights and sounds will never get old. I also have a soft spot for the Ewok minifigs that come with the AT-ST set. Alternatively, the Mos Eisley Cantina kit seems like a great way to highlight the smart brick's ability to play music or kick out some rowdy droids. The one thing to look out for, though, is the tag on the set that says whether it's Smart Play compatible or if it's an all-in-one set, because the former will need Smart Bricks from other kits to deliver Lego's newfound interactivity. Pre-orders for these are live now, with sets slated to ship on March 1. All the new K-pop Demon Hunters toysThe HUNTR/X Battle Rumi Deluxe Fashion Doll (right) might be my favorite of the bunch. Sam Rutherford for EngadgetRumi, Mira and Zoey may have been the biggest breakout stars of 2025 and Mattel is looking to keep that momentum going with a ton of new toys and figures for everyone's favorite demon hunters. There are three new singing dolls that can belt out the trio's hit \"Golden\" at the touch of a button and a deluxe figure of Rumi complete with her Four Tiger Sword. There are also a ton of other dolls and miniatures showcasing HUNTR/X, the Saja Boys and more. The one downside is that these products aren't coming out until the fall, so you'll have to tide yourself over with other K-pop-themed products for now. Hatchin' Yoshi ($50)If Rosalina isn't careful, Yoshi will become the biggest draw of the new Mario movie. Spin MastersYoshi seems poised to steal the spotlight from Rosalina in the upcoming Super Mario Galaxy Movie and this release from Spin Masters is only reinforcing the lovable green dino's aura. From inside his shell, Yoshi can burst out with his signature yell. After that, you can pat his nose to make his eyes light up or get him to rock when he's really happy. But if you want one, you're going to have to be vigilant. Pre-orders are already sold out, so you'll need to keep a close eye on retailers like Walmart when he officially goes on sale on February 20. Thames and Kosmos SolarFlowersNot only do the SolarFlowers look great, they're educational too. Thames & KosmosTechnically, these went on sale last month, but Thames & Kosmos' SolarFlowers caught my eye again at Toy Fair due to their combination of art and science. Available in four different styles, each kit features a model that you can build yourself or with your kids (recommended age 8+) that turns into a lasting showpiece. After putting the kinetic sculpture together, you can connect the included solar panel to bring the whole kit to life (no batteries required) and make the flowers spin for perpetual entertainment. Honorable mentionsUpcoming Masters of the Universe figuresSome upcoming figures from Mattel's line of Masters of the Universe figures. Sam Rutherford for EngadgetAs someone who grew up during the 80s and 90s, I'm trying to be optimistic about He-Man's return to the big screen later this summer and Mattel's new line of figures is certainly helping. To help prime people for the movie, there's a big range of upcoming toys highlighting He-Man, Skeletor, Battle Cat and more, all of which I would have absolutely loved as a kid. Those will be available later this spring.Fisher-Price Super Mario Little People collectionJust look how cute these are. Sam Rutherford for EngadgetIt's hard to gauge the excitement of toys aimed at one-year-olds when they can't read or get into Toy Fair. But as the parent of a toddler, I adore the partnership between Fisher-Price and Nintendo that has resulted in a line of Mario-themed Little People. All the big names are here, including Peach, Luigi and Bowser and there's even a couple of super cute playsets to go with them. But perhaps the best part is that a six-pack of figures and Bower's Airship costs under $25, which means your kid could be in for hours of fun without you spending a ton of money. This article originally appeared on Engadget at https://www.engadget.com/entertainment/here-are-my-favorite-things-from-toy-fair-2026-183356720.html?src=rss",
          "content": "Toy Fair 2026 just wrapped earlier this week and while I would have liked to spend even more time there, I have my own kids (and all their toys and trinkets) to look after. That said, there were a ton of cool new products on display at the Javits Center in New York City that set the stage for the rest of the year, so here's a quick look at some of the most interesting releases from the largest toy show in the Western Hemisphere. Transformers: The Movie 40th anniversary figures ($28 to $60)To celebrate the 40th anniversary of Transformers: The Movie, Hasbro is launching an apology tour to make up for traumatizing theatergoers with the death of the most beloved Autobot back in 1986. To kick things off, Hasbro is releasing a handful of new figures alongside re-releases for some popular bots including Astrotrain, Skywarp, Snarl and Shockwave. I want to give a special shout-out to the model for Kranix, which looks incredibly accurate, as if he just leapt off the movie screen. And even though his duck-billed spaceship alt-mode might look a bit awkward, I wouldn't have it any other way. The crown jewel of the line might be a near-life-size version of The Matrix of Leadership, which measures more than 15 inches wide and even plays Stan Bush's iconic song \"The Touch\" with the push of a button. Unfortunately, the appeal of the Matrix is so powerful that it's already sold out, including at third-party retailers like Big Bad Toy Store, which thankfully is still taking pre-orders for the rest of the lineup after the initial stock from Hasbro dried up.F1 Hot WheelsA collection of some of the new F1 Hot Wheels cars for 2026. Sam Rutherford for EngadgetHot Wheels has big plans for 2026 including a new line of Pantone-colored cars, Brick Shop models like the Elite Series Aston Martin (which comes with its own 1:64 scale car) and a Monster Truck Mutant Chaos set with actual slime. However, I'd argue the company's new F1 offerings are the cream of the crop. Not only are there a bunch of incredibly detailed 1:64 scale racecars with metal bodies, real rubber tires and accurate livery for all the big teams, there's also a new Downhill Circuit Race course that comes with three official vehicles (Mercedes, Haas and Ferrari) featuring multiple levels and the ability to overtake or crash into other cars. If you're like a lot of Americans who have recently fallen down the F1 rabbit hole due to Netflix's Drive to Survive, these new officially licensed miniatures are sure to hit the spot. The first five-pack set of cars is available now, with more arriving later this spring before the Downhill Circuit Race course drives by sometime this fall. Lego Star Wars with Smart Bricks ($40 to $160)Darth Vader's TIE fighter is an all-in-one set, which means it comes included with one of Lego's Smart Bricks, which isn't true for every kit. LegoWe've been eagerly awaiting the first batch of playsets featuring Lego's nifty Smart Brick after it debuted at CES. But now that the company has detailed eight new sets featuring its latest innovation, we're even more intrigued. For me, the three standout kits are the Millennium Falcon, Luke's Red Five X-Wing and Darth Vader's TIE fighter because acting out the Death Star trench run complete with reactive lights and sounds will never get old. I also have a soft spot for the Ewok minifigs that come with the AT-ST set. Alternatively, the Mos Eisley Cantina kit seems like a great way to highlight the smart brick's ability to play music or kick out some rowdy droids. The one thing to look out for, though, is the tag on the set that says whether it's Smart Play compatible or if it's an all-in-one set, because the former will need Smart Bricks from other kits to deliver Lego's newfound interactivity. Pre-orders for these are live now, with sets slated to ship on March 1. All the new K-pop Demon Hunters toysThe HUNTR/X Battle Rumi Deluxe Fashion Doll (right) might be my favorite of the bunch. Sam Rutherford for EngadgetRumi, Mira and Zoey may have been the biggest breakout stars of 2025 and Mattel is looking to keep that momentum going with a ton of new toys and figures for everyone's favorite demon hunters. There are three new singing dolls that can belt out the trio's hit \"Golden\" at the touch of a button and a deluxe figure of Rumi complete with her Four Tiger Sword. There are also a ton of other dolls and miniatures showcasing HUNTR/X, the Saja Boys and more. The one downside is that these products aren't coming out until the fall, so you'll have to tide yourself over with other K-pop-themed products for now. Hatchin' Yoshi ($50)If Rosalina isn't careful, Yoshi will become the biggest draw of the new Mario movie. Spin MastersYoshi seems poised to steal the spotlight from Rosalina in the upcoming Super Mario Galaxy Movie and this release from Spin Masters is only reinforcing the lovable green dino's aura. From inside his shell, Yoshi can burst out with his signature yell. After that, you can pat his nose to make his eyes light up or get him to rock when he's really happy. But if you want one, you're going to have to be vigilant. Pre-orders are already sold out, so you'll need to keep a close eye on retailers like Walmart when he officially goes on sale on February 20. Thames and Kosmos SolarFlowersNot only do the SolarFlowers look great, they're educational too. Thames & KosmosTechnically, these went on sale last month, but Thames & Kosmos' SolarFlowers caught my eye again at Toy Fair due to their combination of art and science. Available in four different styles, each kit features a model that you can build yourself or with your kids (recommended age 8+) that turns into a lasting showpiece. After putting the kinetic sculpture together, you can connect the included solar panel to bring the whole kit to life (no batteries required) and make the flowers spin for perpetual entertainment. Honorable mentionsUpcoming Masters of the Universe figuresSome upcoming figures from Mattel's line of Masters of the Universe figures. Sam Rutherford for EngadgetAs someone who grew up during the 80s and 90s, I'm trying to be optimistic about He-Man's return to the big screen later this summer and Mattel's new line of figures is certainly helping. To help prime people for the movie, there's a big range of upcoming toys highlighting He-Man, Skeletor, Battle Cat and more, all of which I would have absolutely loved as a kid. Those will be available later this spring.Fisher-Price Super Mario Little People collectionJust look how cute these are. Sam Rutherford for EngadgetIt's hard to gauge the excitement of toys aimed at one-year-olds when they can't read or get into Toy Fair. But as the parent of a toddler, I adore the partnership between Fisher-Price and Nintendo that has resulted in a line of Mario-themed Little People. All the big names are here, including Peach, Luigi and Bowser and there's even a couple of super cute playsets to go with them. But perhaps the best part is that a six-pack of figures and Bower's Airship costs under $25, which means your kid could be in for hours of fun without you spending a ton of money. This article originally appeared on Engadget at https://www.engadget.com/entertainment/here-are-my-favorite-things-from-toy-fair-2026-183356720.html?src=rss",
          "feed_position": 19,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/f1-hotwheels.jpg"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/technology/google-launches-gemini-3-1-pro-retaking-ai-crown-with-2x-reasoning",
          "published_at": "Thu, 19 Feb 2026 17:30:00 GMT",
          "title": "Google launches Gemini 3.1 Pro, retaking AI crown with 2X+ reasoning performance boost",
          "standfirst": "Late last year, Google briefly took the crown for most powerful AI model in the world with the launch of Gemini 3 Pro — only to be surpassed within weeks by OpenAI and Anthropic releasing new models, s is common in the fiercely competitive AI race.Now Google is back to retake the throne with an updated version of that flagship model: Gemini 3.1 Pro, positioned as a smarter baseline for tasks where a simple response is insufficient—targeting science, research, and engineering workflows that demand deep planning and synthesis.Already, evaluations by third-party firm Artificial Analysis show that Google&#x27;s Gemini 3.1 Pro has leapt to the front of the pack and is once more the most powerful and performant AI model in the world. A big leap in core reasoningThe most significant advancement in Gemini 3.1 Pro lies in its performance on rigorous logic benchmarks. Most notably, the model achieved a verified score of 77.1% on ARC-AGI-2. This specific benchmark is designed to evaluate a model&#x27;s ability to solve entirely new logic patterns it has not encountered during training. This result represents more than double the reasoning performance of the previous Gemini 3 Pro model.Beyond abstract logic, internal benchmarks indicate that 3.1 Pro is highly competitive across specialized domains:Scientific Knowledge: It scored 94.3% on GPQA Diamond.Coding: It reached an Elo of 2887 on LiveCodeBench Pro and scored 80.6% on SWE-Bench Verified.Multimodal Understanding: It achieved 92.6% on MMMLU.These technical gains are not just incremental; they represent a refinement in how the model handles \"thinking\" tokens and long-horizon tasks, providing a more reliable foundation for developers building autonomous agents.Improved vibe coding and 3D synthesisGoogle is demonstrating the model’s utility through \"intelligence applied\"—shifting the focus from chat interfaces to functional outputs. One of the most prominent features is the model&#x27;s ability to generate \"vibe-coded\" animated SVGs directly from text prompts. Because these are code-based rather than pixel-based, they remain scalable and maintain tiny file sizes compared to traditional video, boasting far more detailed, presentable and professional visuals for websites and presentations and other enterprise applications.Other showcased applications include:Complex System Synthesis: The model successfully configured a public telemetry stream to build a live aerospace dashboard visualizing the International Space Station’s orbit.Interactive Design: In one demo, 3.1 Pro coded a complex 3D starling murmuration that users can manipulate via hand-tracking, accompanied by a generative audio score.Creative Coding: The model translated the atmospheric themes of Emily Brontë’s Wuthering Heights into a functional, modern web design, demonstrating an ability to reason through tone and style rather than just literal text.Business impact and community reactionsEnterprise partners have already begun integrating the preview version of 3.1 Pro, reporting noticeable improvements in reliability and efficiency. Vladislav Tankov, Director of AI at JetBrains, noted a 15% quality improvement over previous versions, stating the model is \"stronger, faster... and more efficient, requiring fewer output tokens\". Other industry reactions include:Databricks: CTO Hanlin Tang reported that the model achieved \"best-in-class results\" on OfficeQA, a benchmark for grounded reasoning across tabular and unstructured data.Cartwheel: Co-founder Andrew Carr highlighted the model&#x27;s \"substantially improved understanding of 3D transformations,\" noting it resolved long-standing rotation order bugs in 3D animation pipelines.Hostinger Horizons: Head of Product Dainius Kavoliunas observed that the model understands the \"vibe\" behind a prompt, translating intent into style-accurate code for non-developers.Pricing, licensing, and availabilityFor developers, the most striking aspect of the 3.1 Pro release is the \"reasoning-to-dollar\" ratio. When Gemini 3 Pro launched, it was positioned in the mid-high price range at $2.00 per million input tokens for standard prompts. Gemini 3.1 Pro maintains this exact pricing structure, effectively offering a massive performance upgrade at no additional cost to API users.Input Price: $2.00 per 1M tokens for prompts up to 200k; $4.00 per 1M tokens for prompts over 200k.Output Price: $12.00 per 1M tokens for prompts up to 200k; $18.00 per 1M tokens for prompts over 200k.Context Caching: Billed at $0.20 to $0.40 per 1M tokens depending on prompt size, plus a storage fee of $4.50 per 1M tokens per hour.Search Grounding: 5,000 prompts per month are free, followed by a charge of $14 per 1,000 search queries.For consumers, the model is rolling out in the Gemini app and NotebookLM with higher limits for Google AI Pro and Ultra subscribers.Licensing implicationsAs a proprietary model offered through Vertex Studio in Google Cloud and the Gemini API, 3.1 Pro follows a standard commercial SaaS (Software as a Service) model rather than an open-source license. For enterprise users, this provides \"grounded reasoning\" within the security perimeter of Vertex AI, allowing businesses to operate on their own data with confidence. The \"Preview\" status allows Google to refine the model&#x27;s safety and performance before general availability, a common practice in high-stakes AI deployment.By doubling down on core reasoning and specialized benchmarks like ARC-AGI-2, Google is signaling that the next phase of the AI race will be won by models that can think through a problem, not just predict the next word.",
          "content": "Late last year, Google briefly took the crown for most powerful AI model in the world with the launch of Gemini 3 Pro — only to be surpassed within weeks by OpenAI and Anthropic releasing new models, s is common in the fiercely competitive AI race.Now Google is back to retake the throne with an updated version of that flagship model: Gemini 3.1 Pro, positioned as a smarter baseline for tasks where a simple response is insufficient—targeting science, research, and engineering workflows that demand deep planning and synthesis.Already, evaluations by third-party firm Artificial Analysis show that Google&#x27;s Gemini 3.1 Pro has leapt to the front of the pack and is once more the most powerful and performant AI model in the world. A big leap in core reasoningThe most significant advancement in Gemini 3.1 Pro lies in its performance on rigorous logic benchmarks. Most notably, the model achieved a verified score of 77.1% on ARC-AGI-2. This specific benchmark is designed to evaluate a model&#x27;s ability to solve entirely new logic patterns it has not encountered during training. This result represents more than double the reasoning performance of the previous Gemini 3 Pro model.Beyond abstract logic, internal benchmarks indicate that 3.1 Pro is highly competitive across specialized domains:Scientific Knowledge: It scored 94.3% on GPQA Diamond.Coding: It reached an Elo of 2887 on LiveCodeBench Pro and scored 80.6% on SWE-Bench Verified.Multimodal Understanding: It achieved 92.6% on MMMLU.These technical gains are not just incremental; they represent a refinement in how the model handles \"thinking\" tokens and long-horizon tasks, providing a more reliable foundation for developers building autonomous agents.Improved vibe coding and 3D synthesisGoogle is demonstrating the model’s utility through \"intelligence applied\"—shifting the focus from chat interfaces to functional outputs. One of the most prominent features is the model&#x27;s ability to generate \"vibe-coded\" animated SVGs directly from text prompts. Because these are code-based rather than pixel-based, they remain scalable and maintain tiny file sizes compared to traditional video, boasting far more detailed, presentable and professional visuals for websites and presentations and other enterprise applications.Other showcased applications include:Complex System Synthesis: The model successfully configured a public telemetry stream to build a live aerospace dashboard visualizing the International Space Station’s orbit.Interactive Design: In one demo, 3.1 Pro coded a complex 3D starling murmuration that users can manipulate via hand-tracking, accompanied by a generative audio score.Creative Coding: The model translated the atmospheric themes of Emily Brontë’s Wuthering Heights into a functional, modern web design, demonstrating an ability to reason through tone and style rather than just literal text.Business impact and community reactionsEnterprise partners have already begun integrating the preview version of 3.1 Pro, reporting noticeable improvements in reliability and efficiency. Vladislav Tankov, Director of AI at JetBrains, noted a 15% quality improvement over previous versions, stating the model is \"stronger, faster... and more efficient, requiring fewer output tokens\". Other industry reactions include:Databricks: CTO Hanlin Tang reported that the model achieved \"best-in-class results\" on OfficeQA, a benchmark for grounded reasoning across tabular and unstructured data.Cartwheel: Co-founder Andrew Carr highlighted the model&#x27;s \"substantially improved understanding of 3D transformations,\" noting it resolved long-standing rotation order bugs in 3D animation pipelines.Hostinger Horizons: Head of Product Dainius Kavoliunas observed that the model understands the \"vibe\" behind a prompt, translating intent into style-accurate code for non-developers.Pricing, licensing, and availabilityFor developers, the most striking aspect of the 3.1 Pro release is the \"reasoning-to-dollar\" ratio. When Gemini 3 Pro launched, it was positioned in the mid-high price range at $2.00 per million input tokens for standard prompts. Gemini 3.1 Pro maintains this exact pricing structure, effectively offering a massive performance upgrade at no additional cost to API users.Input Price: $2.00 per 1M tokens for prompts up to 200k; $4.00 per 1M tokens for prompts over 200k.Output Price: $12.00 per 1M tokens for prompts up to 200k; $18.00 per 1M tokens for prompts over 200k.Context Caching: Billed at $0.20 to $0.40 per 1M tokens depending on prompt size, plus a storage fee of $4.50 per 1M tokens per hour.Search Grounding: 5,000 prompts per month are free, followed by a charge of $14 per 1,000 search queries.For consumers, the model is rolling out in the Gemini app and NotebookLM with higher limits for Google AI Pro and Ultra subscribers.Licensing implicationsAs a proprietary model offered through Vertex Studio in Google Cloud and the Gemini API, 3.1 Pro follows a standard commercial SaaS (Software as a Service) model rather than an open-source license. For enterprise users, this provides \"grounded reasoning\" within the security perimeter of Vertex AI, allowing businesses to operate on their own data with confidence. The \"Preview\" status allows Google to refine the model&#x27;s safety and performance before general availability, a common practice in high-stakes AI deployment.By doubling down on core reasoning and specialized benchmarks like ARC-AGI-2, Google is signaling that the next phase of the AI race will be won by models that can think through a problem, not just predict the next word.",
          "feed_position": 2,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/4WI6UovKEMHNOYRmLhUkWL/7353b15db9e6644396c21abfb95c9f42/odtwyodoZOZvjDt413OWa_05gXxMoM.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/orbital-ai-data-centers-could-work-but-they-might-ruin-earth-in-the-process-170000099.html",
          "published_at": "Thu, 19 Feb 2026 17:00:00 +0000",
          "title": "Orbital AI data centers could work, but they might ruin Earth in the process",
          "standfirst": "At the start of the month, Elon Musk announced that two of his companies — SpaceX and xAI — were merging, and would jointly launch a constellation of 1 million satellites to operate as orbital data centers. Musk's reputation might suggest otherwise, but according to experts, such a plan isn't a complete fantasy. However, if executed at the scale suggested, some of them believe it would have devastating effects on the environment and the sustainability of low Earth Earth orbit. Musk and others argue that putting data centers in space is practical given how much more efficient solar panels are away from Earth's atmosphere. In space, there are no clouds or weather events to obscure the sun, and in the correct orbit, solar panels can collect sunlight through much of the day. In combination with declining rocket launch costs and the price of powering AI data centers on Earth, Musk has said that within three years space will be the cheapest way to generate AI compute power. Ahead of the billionaire's announcement, SpaceX filed an eight-page application with the Federal Communications Commission detailing his plan. The company hopes to deposit the satellites in this massive cluster in altitudes ranging between 500km and 2000km. They would communicate with one another and SpaceX's Starlink constellation using laser \"optical links.\" Those Starlink satellites would then transmit inference requests to and from Earth. To power the entire effort, SpaceX has proposed putting the new constellation in sun-synchronous orbit, meaning the spacecraft would fly along the dividing line that separates the day and night sides of the planet. What a data center would endure in orbitAlmost immediately the plan was greeted with skepticism. How would SpaceX, for instance, cool millions of GPUs in space? At first glance, that might seem like a weird point to get hung up on — much of space being around -450 Fahrenheit — but the reality is more complicated. In the near vacuum of space, the only way to dissipate heat is to slowly radiate it out, and in direct sunlight, objects can easily overheat. As one commenter on Hacker News succinctly put it, \"a satellite is, if nothing else, a fantastic thermos.\"Scott Manley, who, before he created one of the most popular space-focused channels on YouTube, was a software engineer and studied computational physics and astronomy, argues SpaceX has already solved that problem at a smaller scale with Starlink. He points to the company's latest V3 model, which has about 30 square meters of solar panels. \"They have a bunch of electronics in the middle, which are taking that power and doing stuff with it. Now, some of that power is being beamed away as radio waves, but there's a lot of thermal power that's being generated and then having to be dissipated. So they already have a platform that's running electronics off of power, and so it's not a massive leap to turn into something doing compute.\"The larger V3 @Starlink satellites that will deploy from Starship will bring gigabit connectivity to users and are designed to add 60 Tera-bits-per-second of downlink capacity to the Starlink network.That's more than 20 times the capacity added with every V2 Mini launch on… pic.twitter.com/N0Vl9psbm3— SpaceX (@SpaceX) October 13, 2025 Kevin Hicks, a former NASA systems engineer who worked on the Curiosity rover mission, is more skeptical. \"Satellites with the primary goal of processing large amounts of compute requests would generate more heat than pretty much any other type of satellite,\" he said. \"Cooling them is another aspect of the design which is theoretically possible but would require a ton of extra work and complexity, and I have doubts about the durability of such a cooling system.\" What about radiation then? There's a reason NASA relies on ancient hardware like the PowerPC 750 CPU found inside the Perseverance rover: Older chips feature larger transistors, making them more resilient to bit flips — errors in processing caused most often by cosmic radiation — that might scramble a computation. \"Binary ones and zeroes are about the presence or absence of electrons, and the amount of charge required to represent a 'one' goes down as the transistors get smaller and smaller,\" explains Benjamin Lee, professor of computer and information science at the University of Pennsylvania. Space is full of energized particles traveling at incredible velocities, and the latest GPUs are built on the smallest, most advanced processing nodes to create transistor-dense silicon. Not a great combination.\"My concern about radiation is that we don't know how many bit flips will occur when you deploy the most advanced chips and hundreds of gigabytes of memory up there,\" said Professor Lee, pointing to preliminary research by Google on the subject. As part of Project Suncatcher, its own effort to explore the viability of space-based data centers, the company put one of its Trillium TPUs in front of a proton beam to bombard it with radiation. It found the silicon was \"surprisingly radiation-hard for space applications.\" While those results were promising, Professor Lee points out we just don't know how resilient GPUs are to radiation at this scale. \"Even though modern computer architectures can detect and sometimes correct for those errors, having to do that again and again will slow down or add overhead to space-based computation,\" he said. Space engineer Andrew McCalip, who's done a deep dive on the economics of orbital data centers, is more optimistic, pointing to the natural resilience of AI models. \"They don't require 100 percent perfect error-free runs. They're inherently very noisy, very stochastic,\" he explains, adding that part of the training for modern AI systems involves \"injecting random noise into different layers.\" Even if SpaceX could harden its GPUs against radiation, the company would still lose satellites to GPUs that break down. If you know anything about data centers here on Earth, it's that they require constant maintenance. Components like SSDs and GPUs die all the time. Musk has claimed SpaceX's AI satellites would require \"little\" in the way of operating or maintenance costs. That's only true if you accept the narrowest possible interpretation of what maintaining a fleet of AI satellites would entail.\"I think that there's no case in which repair makes sense. It's a fly till you die scenario,\" says McCalip. From an economic perspective, McCalip argues the projected death rate of GPUs in space represents \"one of the biggest uncertainties\" of the orbital data center model. McCalip's put that number at nine percent on the basis of a study Meta published following the release of its Llama 3 model (which, incidentally, measured hardware failures on Earth.) But the reality is no one knows what the attrition rate of those chips will be until they're in space. Orbital data centers also likely wouldn't be a direct replacement for their terrestrial counterparts. SpaceX's application specifically mentions inference as the primary use case for its new constellation. Inference is the practical side of running an AI system. It sees a model apply its learning to data it hasn't seen before, like a prompt you write in ChatGPT, to make predictions and generate content. In other words, AI models would still need to be trained on Earth, and it's not clear that the process could be offloaded to a constellation of satellites. \"My initial thinking is that computations that require a lot of coordination, like AI training, may end up being tricky to get right at scale up there,\" says Professor Lee. Kessler syndromeIn 1978, a pair of NASA scientists proposed a scenario where low Earth orbit could become so dense with space junk that collisions between those objects would begin to cascade. That scenario is known as Kessler syndrome. One estimate from satellite tracking website Orbiting Now puts the number of objects in orbit around the planet at approximately 15,600. Another estimate from NASA suggests there are 45,000 human-made objects orbiting Earth. No matter the number, what's currently in orbit represents a fraction of the 1 million additional satellites Musk wants to launch. According to Aaron Boley, professor of physics and astronomy at the University of British Columbia and co-director of the Outer Space Institute, forward-looking modeling of Earth's orbit above 700 kilometers — where part of SpaceX's proposed cluster would live — suggests that area of space is already showing signs of Kessler syndrome. While it takes less time for debris to clear in low Earth orbit, Professor Boley says there's already enough material in that region of space where there could be a cascading effect from a major collision. Debris could, in a worst case scenario, take a decade to clear up. In turn, that could lead to disruptions in global communications, climate monitoring missions and more. \"You could get to the point where you're just launching material in, and you could ask yourself how many satellites can I afford to lose? Can you reconstitute your constellation faster than you're losing parts of it because of debris?\" says Boley. \"That's a horrible future in terms of the environmental perspective\" In particular, it would limit opportunities for humans to fly into low Earth orbit. \"Could you operate in it? Yeah, but it would come with higher and higher costs,\" adds Boley. \"The entire world is struggling with the problem of how we safely fly multiple mega constellations,\" says Richard DalBello, who previously ran the Traffic Coordination System for Space (TraCSS) at the US Department of Commerce. Right now, there is no common global space situational awareness (SSA) system, and government and satellite operators are using uncoordinated national and commercial systems that are likely producing different results. At the start of the year, SpaceX lowered the orbit of thousands of Starlink satellites after one of them nearly collided with a Chinese satellite. SpaceX has its own in-house SSA system called Stargaze, which it uses to fly its more than 7,000 Starlink satellites. According to DalBello, competing operators can receive SSA data from SpaceX, but to do so they must share their satellite position information. “Assuming data sharing, it is likely Stargaze can make an important contribution to spaceflight safety\" says DalBello. “SpaceX is likely to have success with US and other commercial operators, but without the assistance of the federal government, other governments — particularly China — will likely be unwilling to share their satellite and SSA data.\" According to DalBello, the Biden administration was unable to make meaningful progress on the next-generation TraCSS system, in part because Congress was initially reluctant to fund the program. Meanwhile, the current Trump administration hasn't shown interest in advancing the work that began during the president's first term. Even if the regulatory situation suddenly changes and the world's governments agree on an international SSA system, SpaceX launching 1 million satellites along the day-night terminator would see the company effectively monopolize one of the Earth's most valuable and important orbits. Professor Boley argues we should view our planet's orbits as a resource that belongs to everyone. \"Every time you put a satellite up, you use part of that resource. Now someone else can't use it.\" And as Hicks points out, even a single cascade of colliding satellites would prevent that space from being used for scientific endeavors. \"You would have to wait years for that debris to slowly come back into the atmosphere and burn up. In the meantime, that debris is taking up space that could be used for climate monitoring missions or any other types of missions that governments want to launch.\" A blow to the atmosphereSeparately, the constant churn of Starship launches and re-entry of dead satellites would have a potentially dire impact on our planet's atmosphere. \"We're not prepared for it,\" Boley flatly says of the latter. \"We're not prepared for what's happening now, and what's happening now is already potentially bad.\" According to Musk's \"basic math,\" SpaceX could add 100 gigawatts of AI compute capacity annually by launching a million tons of satellite per year. McCalip estimates a 100-gigawatt buildout alone would necessitate about 25,000 Starship flights. Many of the metals found in satellites, including aluminum, magnesium and lithium, in combination with the exhaust rockets release into the atmosphere, can have complicated effects on the health of the planet. For instance, they can affect polar cloud formations, which in turn can facilitate ozone layer destruction through the chemical reactions that occur on their surfaces. According to Boley, the problem is we just don't know how severe those environmental factors could become at the scale Musk has proposed, and SpaceX has provided us with precious few details on its mitigation plans. All it has said is that its plan would \"achieve transformative cost and energy efficiency while significantly reducing the environmental impact associated with terrestrial data centers.\" Even if SpaceX could and does go out its way to mitigate the atmospheric effects of constant rocket flights, those spacecraft still need to be manufactured here on Earth. At one of his previous roles, Hicks studied rocket emissions and found the supply chains needed to build them produce an \"order of magnitude\" more carbon emissions than the rockets themselves. SpaceX plans to fly its new satellites in a sun-synchronous orbit, meaning for much of the year, they'll be sunlit. Each new Starlink generation has been larger and heavier than the one before it, with SpaceX stating in a recent filing that its upcoming V3 model could weigh up to 2,000 kilograms, up from the 575 kilograms of the V2 Mini Optimized. While we don't know the exact dimensions of the company's still-hypothetical AI satellites, they will almost certainly be bigger than their Starlink counterparts. SpaceX has done more than most space operators to reduce the brightness of its satellites, but Professor Boley says he expects that this new constellation will be \"strikingly bright\" when moving through the night sky. In aggregate, he estimates they will almost certainly be harmful to scientific research here on Earth, limiting what terrestrial observatories can see. \"You're going to see them with the naked eye. You're going to see them with cameras. It's going to be like living near an airport where you see all these things flying over just after sunset and the next couple of hours after sunset,\" says Manley. \"I don't know if I want to have my entire sunset be just a band of satellites constantly shooting overhead.\"There are good reasons to make some spacecraft capable of doing AI inference. For instance, Professor Lee suggests it would make orbital imaging satellites more useful, as those spacecraft could do on-site analysis, instead of sending high-resolution files over long distances, saving time in the process. But the dose, as they say, makes the poison.\"There's a lot of excitement about the many possibilities that can be brought to society and humanity through continued access to space, but the promise of prosperity is not permission to be reckless,\" he says. \"At this moment, we're allowing that excitement to overtake that more measured progression [...] those impacts don't just impact outer space but Earth as well.\" This article originally appeared on Engadget at https://www.engadget.com/ai/orbital-ai-data-centers-could-work-but-they-might-ruin-earth-in-the-process-170000099.html?src=rss",
          "content": "At the start of the month, Elon Musk announced that two of his companies — SpaceX and xAI — were merging, and would jointly launch a constellation of 1 million satellites to operate as orbital data centers. Musk's reputation might suggest otherwise, but according to experts, such a plan isn't a complete fantasy. However, if executed at the scale suggested, some of them believe it would have devastating effects on the environment and the sustainability of low Earth Earth orbit. Musk and others argue that putting data centers in space is practical given how much more efficient solar panels are away from Earth's atmosphere. In space, there are no clouds or weather events to obscure the sun, and in the correct orbit, solar panels can collect sunlight through much of the day. In combination with declining rocket launch costs and the price of powering AI data centers on Earth, Musk has said that within three years space will be the cheapest way to generate AI compute power. Ahead of the billionaire's announcement, SpaceX filed an eight-page application with the Federal Communications Commission detailing his plan. The company hopes to deposit the satellites in this massive cluster in altitudes ranging between 500km and 2000km. They would communicate with one another and SpaceX's Starlink constellation using laser \"optical links.\" Those Starlink satellites would then transmit inference requests to and from Earth. To power the entire effort, SpaceX has proposed putting the new constellation in sun-synchronous orbit, meaning the spacecraft would fly along the dividing line that separates the day and night sides of the planet. What a data center would endure in orbitAlmost immediately the plan was greeted with skepticism. How would SpaceX, for instance, cool millions of GPUs in space? At first glance, that might seem like a weird point to get hung up on — much of space being around -450 Fahrenheit — but the reality is more complicated. In the near vacuum of space, the only way to dissipate heat is to slowly radiate it out, and in direct sunlight, objects can easily overheat. As one commenter on Hacker News succinctly put it, \"a satellite is, if nothing else, a fantastic thermos.\"Scott Manley, who, before he created one of the most popular space-focused channels on YouTube, was a software engineer and studied computational physics and astronomy, argues SpaceX has already solved that problem at a smaller scale with Starlink. He points to the company's latest V3 model, which has about 30 square meters of solar panels. \"They have a bunch of electronics in the middle, which are taking that power and doing stuff with it. Now, some of that power is being beamed away as radio waves, but there's a lot of thermal power that's being generated and then having to be dissipated. So they already have a platform that's running electronics off of power, and so it's not a massive leap to turn into something doing compute.\"The larger V3 @Starlink satellites that will deploy from Starship will bring gigabit connectivity to users and are designed to add 60 Tera-bits-per-second of downlink capacity to the Starlink network.That's more than 20 times the capacity added with every V2 Mini launch on… pic.twitter.com/N0Vl9psbm3— SpaceX (@SpaceX) October 13, 2025 Kevin Hicks, a former NASA systems engineer who worked on the Curiosity rover mission, is more skeptical. \"Satellites with the primary goal of processing large amounts of compute requests would generate more heat than pretty much any other type of satellite,\" he said. \"Cooling them is another aspect of the design which is theoretically possible but would require a ton of extra work and complexity, and I have doubts about the durability of such a cooling system.\" What about radiation then? There's a reason NASA relies on ancient hardware like the PowerPC 750 CPU found inside the Perseverance rover: Older chips feature larger transistors, making them more resilient to bit flips — errors in processing caused most often by cosmic radiation — that might scramble a computation. \"Binary ones and zeroes are about the presence or absence of electrons, and the amount of charge required to represent a 'one' goes down as the transistors get smaller and smaller,\" explains Benjamin Lee, professor of computer and information science at the University of Pennsylvania. Space is full of energized particles traveling at incredible velocities, and the latest GPUs are built on the smallest, most advanced processing nodes to create transistor-dense silicon. Not a great combination.\"My concern about radiation is that we don't know how many bit flips will occur when you deploy the most advanced chips and hundreds of gigabytes of memory up there,\" said Professor Lee, pointing to preliminary research by Google on the subject. As part of Project Suncatcher, its own effort to explore the viability of space-based data centers, the company put one of its Trillium TPUs in front of a proton beam to bombard it with radiation. It found the silicon was \"surprisingly radiation-hard for space applications.\" While those results were promising, Professor Lee points out we just don't know how resilient GPUs are to radiation at this scale. \"Even though modern computer architectures can detect and sometimes correct for those errors, having to do that again and again will slow down or add overhead to space-based computation,\" he said. Space engineer Andrew McCalip, who's done a deep dive on the economics of orbital data centers, is more optimistic, pointing to the natural resilience of AI models. \"They don't require 100 percent perfect error-free runs. They're inherently very noisy, very stochastic,\" he explains, adding that part of the training for modern AI systems involves \"injecting random noise into different layers.\" Even if SpaceX could harden its GPUs against radiation, the company would still lose satellites to GPUs that break down. If you know anything about data centers here on Earth, it's that they require constant maintenance. Components like SSDs and GPUs die all the time. Musk has claimed SpaceX's AI satellites would require \"little\" in the way of operating or maintenance costs. That's only true if you accept the narrowest possible interpretation of what maintaining a fleet of AI satellites would entail.\"I think that there's no case in which repair makes sense. It's a fly till you die scenario,\" says McCalip. From an economic perspective, McCalip argues the projected death rate of GPUs in space represents \"one of the biggest uncertainties\" of the orbital data center model. McCalip's put that number at nine percent on the basis of a study Meta published following the release of its Llama 3 model (which, incidentally, measured hardware failures on Earth.) But the reality is no one knows what the attrition rate of those chips will be until they're in space. Orbital data centers also likely wouldn't be a direct replacement for their terrestrial counterparts. SpaceX's application specifically mentions inference as the primary use case for its new constellation. Inference is the practical side of running an AI system. It sees a model apply its learning to data it hasn't seen before, like a prompt you write in ChatGPT, to make predictions and generate content. In other words, AI models would still need to be trained on Earth, and it's not clear that the process could be offloaded to a constellation of satellites. \"My initial thinking is that computations that require a lot of coordination, like AI training, may end up being tricky to get right at scale up there,\" says Professor Lee. Kessler syndromeIn 1978, a pair of NASA scientists proposed a scenario where low Earth orbit could become so dense with space junk that collisions between those objects would begin to cascade. That scenario is known as Kessler syndrome. One estimate from satellite tracking website Orbiting Now puts the number of objects in orbit around the planet at approximately 15,600. Another estimate from NASA suggests there are 45,000 human-made objects orbiting Earth. No matter the number, what's currently in orbit represents a fraction of the 1 million additional satellites Musk wants to launch. According to Aaron Boley, professor of physics and astronomy at the University of British Columbia and co-director of the Outer Space Institute, forward-looking modeling of Earth's orbit above 700 kilometers — where part of SpaceX's proposed cluster would live — suggests that area of space is already showing signs of Kessler syndrome. While it takes less time for debris to clear in low Earth orbit, Professor Boley says there's already enough material in that region of space where there could be a cascading effect from a major collision. Debris could, in a worst case scenario, take a decade to clear up. In turn, that could lead to disruptions in global communications, climate monitoring missions and more. \"You could get to the point where you're just launching material in, and you could ask yourself how many satellites can I afford to lose? Can you reconstitute your constellation faster than you're losing parts of it because of debris?\" says Boley. \"That's a horrible future in terms of the environmental perspective\" In particular, it would limit opportunities for humans to fly into low Earth orbit. \"Could you operate in it? Yeah, but it would come with higher and higher costs,\" adds Boley. \"The entire world is struggling with the problem of how we safely fly multiple mega constellations,\" says Richard DalBello, who previously ran the Traffic Coordination System for Space (TraCSS) at the US Department of Commerce. Right now, there is no common global space situational awareness (SSA) system, and government and satellite operators are using uncoordinated national and commercial systems that are likely producing different results. At the start of the year, SpaceX lowered the orbit of thousands of Starlink satellites after one of them nearly collided with a Chinese satellite. SpaceX has its own in-house SSA system called Stargaze, which it uses to fly its more than 7,000 Starlink satellites. According to DalBello, competing operators can receive SSA data from SpaceX, but to do so they must share their satellite position information. “Assuming data sharing, it is likely Stargaze can make an important contribution to spaceflight safety\" says DalBello. “SpaceX is likely to have success with US and other commercial operators, but without the assistance of the federal government, other governments — particularly China — will likely be unwilling to share their satellite and SSA data.\" According to DalBello, the Biden administration was unable to make meaningful progress on the next-generation TraCSS system, in part because Congress was initially reluctant to fund the program. Meanwhile, the current Trump administration hasn't shown interest in advancing the work that began during the president's first term. Even if the regulatory situation suddenly changes and the world's governments agree on an international SSA system, SpaceX launching 1 million satellites along the day-night terminator would see the company effectively monopolize one of the Earth's most valuable and important orbits. Professor Boley argues we should view our planet's orbits as a resource that belongs to everyone. \"Every time you put a satellite up, you use part of that resource. Now someone else can't use it.\" And as Hicks points out, even a single cascade of colliding satellites would prevent that space from being used for scientific endeavors. \"You would have to wait years for that debris to slowly come back into the atmosphere and burn up. In the meantime, that debris is taking up space that could be used for climate monitoring missions or any other types of missions that governments want to launch.\" A blow to the atmosphereSeparately, the constant churn of Starship launches and re-entry of dead satellites would have a potentially dire impact on our planet's atmosphere. \"We're not prepared for it,\" Boley flatly says of the latter. \"We're not prepared for what's happening now, and what's happening now is already potentially bad.\" According to Musk's \"basic math,\" SpaceX could add 100 gigawatts of AI compute capacity annually by launching a million tons of satellite per year. McCalip estimates a 100-gigawatt buildout alone would necessitate about 25,000 Starship flights. Many of the metals found in satellites, including aluminum, magnesium and lithium, in combination with the exhaust rockets release into the atmosphere, can have complicated effects on the health of the planet. For instance, they can affect polar cloud formations, which in turn can facilitate ozone layer destruction through the chemical reactions that occur on their surfaces. According to Boley, the problem is we just don't know how severe those environmental factors could become at the scale Musk has proposed, and SpaceX has provided us with precious few details on its mitigation plans. All it has said is that its plan would \"achieve transformative cost and energy efficiency while significantly reducing the environmental impact associated with terrestrial data centers.\" Even if SpaceX could and does go out its way to mitigate the atmospheric effects of constant rocket flights, those spacecraft still need to be manufactured here on Earth. At one of his previous roles, Hicks studied rocket emissions and found the supply chains needed to build them produce an \"order of magnitude\" more carbon emissions than the rockets themselves. SpaceX plans to fly its new satellites in a sun-synchronous orbit, meaning for much of the year, they'll be sunlit. Each new Starlink generation has been larger and heavier than the one before it, with SpaceX stating in a recent filing that its upcoming V3 model could weigh up to 2,000 kilograms, up from the 575 kilograms of the V2 Mini Optimized. While we don't know the exact dimensions of the company's still-hypothetical AI satellites, they will almost certainly be bigger than their Starlink counterparts. SpaceX has done more than most space operators to reduce the brightness of its satellites, but Professor Boley says he expects that this new constellation will be \"strikingly bright\" when moving through the night sky. In aggregate, he estimates they will almost certainly be harmful to scientific research here on Earth, limiting what terrestrial observatories can see. \"You're going to see them with the naked eye. You're going to see them with cameras. It's going to be like living near an airport where you see all these things flying over just after sunset and the next couple of hours after sunset,\" says Manley. \"I don't know if I want to have my entire sunset be just a band of satellites constantly shooting overhead.\"There are good reasons to make some spacecraft capable of doing AI inference. For instance, Professor Lee suggests it would make orbital imaging satellites more useful, as those spacecraft could do on-site analysis, instead of sending high-resolution files over long distances, saving time in the process. But the dose, as they say, makes the poison.\"There's a lot of excitement about the many possibilities that can be brought to society and humanity through continued access to space, but the promise of prosperity is not permission to be reckless,\" he says. \"At this moment, we're allowing that excitement to overtake that more measured progression [...] those impacts don't just impact outer space but Earth as well.\" This article originally appeared on Engadget at https://www.engadget.com/ai/orbital-ai-data-centers-could-work-but-they-might-ruin-earth-in-the-process-170000099.html?src=rss",
          "feed_position": 23
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/big-tech/west-virginia-is-suing-apple-alleging-negligence-over-csam-materials-164647648.html",
          "published_at": "Thu, 19 Feb 2026 16:46:50 +0000",
          "title": "West Virginia is suing Apple alleging negligence over CSAM materials",
          "standfirst": "The office of the Attorney General for West Virginia announced Thursday that it has filed a lawsuit against Apple alleging that the company had \"knowingly\" allowed its iCloud platform \"to be used as a vehicle for distributing and storing child sexual abuse material.\" The state alleges this went on for years but drew no action from the tech giant \"under the guise of user privacy.\" In the lawsuit, the state repeatedly cites a text from Apple executive Eric Friedman, in which he calls iCloud \"the greatest platform for distributing child porn\" in a conversation with another Apple executive. These messages were first uncovered by The Verge in 2021 within discovery documents for the Epic Games v. Apple trial. In the conversation, Friedman says while some other platforms prioritize safety over privacy, Apple's priorities \"are the inverse.\" The state further alleges that detection technology to help root out and report CSAM exists, but that Apple chooses not to implement it. Apple indeed considered scanning iCloud Photos for CSAM in 2021, but abandoned these plans after pushback stemming from privacy concerns. In 2024 Apple was sued by a group of over 2,500 victims of child sexual abuse, citing nearly identical claims and alleging that Apple's failure to implement these features led to the victims' harm as images of them circulated through the company's servers. At the time Apple told Engadget, “child sexual abuse material is abhorrent and we are committed to fighting the ways predators put children at risk. We are urgently and actively innovating to combat these crimes without compromising the security and privacy of all our users.\" The case in West Virginia would mark the first time a governmental body is bringing such an action against the iPhone maker. The state says it is seeking injunctive relief that would compel Apple to implement effective CSAM detection measures as well as damages. We have reached out to Apple for comment on the suit and will update if we hear back.This article originally appeared on Engadget at https://www.engadget.com/big-tech/west-virginia-is-suing-apple-alleging-negligence-over-csam-materials-164647648.html?src=rss",
          "content": "The office of the Attorney General for West Virginia announced Thursday that it has filed a lawsuit against Apple alleging that the company had \"knowingly\" allowed its iCloud platform \"to be used as a vehicle for distributing and storing child sexual abuse material.\" The state alleges this went on for years but drew no action from the tech giant \"under the guise of user privacy.\" In the lawsuit, the state repeatedly cites a text from Apple executive Eric Friedman, in which he calls iCloud \"the greatest platform for distributing child porn\" in a conversation with another Apple executive. These messages were first uncovered by The Verge in 2021 within discovery documents for the Epic Games v. Apple trial. In the conversation, Friedman says while some other platforms prioritize safety over privacy, Apple's priorities \"are the inverse.\" The state further alleges that detection technology to help root out and report CSAM exists, but that Apple chooses not to implement it. Apple indeed considered scanning iCloud Photos for CSAM in 2021, but abandoned these plans after pushback stemming from privacy concerns. In 2024 Apple was sued by a group of over 2,500 victims of child sexual abuse, citing nearly identical claims and alleging that Apple's failure to implement these features led to the victims' harm as images of them circulated through the company's servers. At the time Apple told Engadget, “child sexual abuse material is abhorrent and we are committed to fighting the ways predators put children at risk. We are urgently and actively innovating to combat these crimes without compromising the security and privacy of all our users.\" The case in West Virginia would mark the first time a governmental body is bringing such an action against the iPhone maker. The state says it is seeking injunctive relief that would compel Apple to implement effective CSAM detection measures as well as damages. We have reached out to Apple for comment on the suit and will update if we hear back.This article originally appeared on Engadget at https://www.engadget.com/big-tech/west-virginia-is-suing-apple-alleging-negligence-over-csam-materials-164647648.html?src=rss",
          "feed_position": 24
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/data/rapidata-emerges-to-shorten-ai-model-development-cycles-from-months-to-days",
          "published_at": "Thu, 19 Feb 2026 14:00:00 GMT",
          "title": "Rapidata emerges to shorten AI model development cycles from months to days with near real-time RLHF",
          "standfirst": "Despite growing chatter about a future when much human work is automated by AI, one of the ironies of this current tech boom is how stubbornly reliant on human beings it remains, specifically the process of training AI models using reinforcement learning from human feedback (RLHF). At its simplest, RLHF is a tutoring system: after an AI is trained on curated data, it still makes mistakes or sounds robotic. Human contractors are then hired en masse by AI labs to rate and rank a new model&#x27;s outputs while it trains, and the model learns from their ratings, adjusting its behavior to offer higher-rated outputs. This process is all the more important as AI expands to produce multimedia outputs like video, audio, and imagery which may have more nuanced and subjective measures of quality. Historically, this tutoring process has been a massive logistical headache and PR nightmare for AI companies, relying on fragmented networks of foreign contractors and static labeling pools in specific, low-income geographic hubs, cast by the media as low wage — even exploitative. It&#x27;s also inefficient: requiring AI labs wait weeks or months for a single batch of feedback, delaying model progress. Now a new startup has emerged to make the process far more efficient: Rapidata&#x27;s platform effectively \"gamifies\" RLHF by pushing said review tasks around the globe to nearly 20 million users of popular apps, including Duolingo or Candy Crush, in the form of short, opt-in review tasks they can choose to complete in place of watching mobile ads, with data sent back to a commissioning AI lab instantly. As shared with VentureBeat in a press release, this platform allows AI labs to \"iterate on models in near-real-time,\" significantly shortening development timelines compared to traditional methods.CEO and founder Jason Corkill stated in the same release that Rapidata makes \"human judgment available at a global scale and near real time, unlocking a future where AI teams can run constant feedback loops and build systems that evolve every day instead of every release cycle.\"\"Rapidata treats RLHF as high-speed infrastructure rather than a manual labor problem. Today, the company exclusively announced to us at VentureBeat its emergence with an $8.5 million seed round co-led by Canaan Partners and IA Ventures, with participation from Acequia Capital and BlueYard, to scale its unique approach to on-demand human data.The pub conversation that built a human cloudThe genesis of Rapidata was born not in a boardroom, but at a table over a few beers. When Corkill was a student at ETH Zurich, working in robotics and computer vision, when he hit the wall that every AI engineer eventually faces: the data annotation bottleneck.\"Specifically, I&#x27;ve been working in robotics, AI and computer vision for quite a few years now, studied at ETH here in Zurich, and just always was frustrated with data annotation,\" Corkill recalled in a recent interview. \"Always when you needed humans or human data annotation, that&#x27;s kind of when your project was stopped in its tracks, because up until then, you could move it forward by just pushing longer nights. But when you needed the large scale human annotation, you had to go to someone and then wait for a few weeks\".Frustrated by this delay, Corkill and his co-founders realized that the existing labor model for AI was fundamentally broken for a world moving at the speed of modern compute. While compute scales exponentially, the traditional human workforce—bound by manual onboarding, regional hiring, and slow payment cycles—does not. Rapidata was born from the idea that human judgment could be delivered as a globally distributed, near-instantaneous service.Technology: Turning digital footprints into training dataThe core innovation of Rapidata lies in its distribution method. Rather than hiring full-time annotators in specific regions, Rapidata leverages the existing attention economy of the mobile app world. By partnering with third-party apps like Candy Crush or Duolingo, Rapidata offers users a choice: watch a traditional ad or spend a few seconds providing feedback for an AI model.\"The users are asked, &#x27;Hey, would you rather instead of watching ads and having, you know, companies buy your eyeballs like that, would you rather like annotate some data, give feedback?&#x27;\" Corkill explained. According to Corkill, between 50% and 60% of users opt for the feedback task over a traditional video advertisement.This \"crowd intelligence\" approach allows AI teams to tap into a diverse, global demographic at an unprecedented scale.The global network: Rapidata currently reaches between 15 and 20 million people.Massive parallelism: The platform can process 1.5 million human annotations in a single hour.Speed: Feedback cycles that previously took weeks or months are reduced to hours or even minutes.Quality control: The platform builds trust and expertise profiles for respondents over time, ensuring that complex questions are matched with the most relevant human judges.Anonymity: While users are tracked via anonymized IDs to ensure consistency and reliability, Rapidata does not collect personal identities, maintaining privacy while optimizing for data quality.Online RLHF: Moving into the GPUThe most significant technological leap Rapidata is enabling is what Corkill describes as \"online RLHF\". Traditionally, AI is trained in disconnected batches: you train the model, stop, send data to humans, wait weeks for labels, and then resume. This creates a \"circle\" of information that often lacks fresh human input.Rapidata is moving this judgment directly into the training loop. Because their network is so fast, they can integrate via API directly with the GPUs running the model.\"We&#x27;ve always had this idea of reinforcement learning for human feedback... so far, you always had to do it like in batches,\" Corkill said. \"Now, if you go all the way down, we have a few clients now where, because we&#x27;re so fast, we can be directly, basically in the process, like in in the processor on the GPU right, and the GPU calculate some output, and it can immediately request from us in a distributed fashion. &#x27;Oh, I need, I need, I need a human to look at this.&#x27; I get the answer and then apply that loss, which has not been possible so far\".Currently, the platform supports roughly 5,500 humans per minute providing live feedback to models running on thousands of GPUs. This prevents \"reward model hacking,\" where two AI models trick each other in a feedback loop, by grounding the training in actual human nuance.Product: Solving for taste and global contextAs AI moves beyond simple object recognition into generative media, the requirements for data labeling have evolved from objective tagging to subjective \"taste-based\" curation. It is no longer just about \"is this a cat?\" but rather \"is this voice synthesis convincing?\" or \"which of these two summaries feels more professional?\".Lily Clifford, CEO of the voice AI startup Rime, notes that Rapidata has been transformative for testing models in real-world contexts. \"Previously, gathering meaningful feedback meant cobbling together vendors and surveys, segment by segment, or country by country, which didn’t scale,\" Clifford said. Using Rapidata, Rime can reach the right audiences—whether in Sweden, Serbia, or the United States—and see how models perform in real customer workflows in days, not months.\"Most models are factually correct, but I&#x27;m sure you&#x27;re you have received emails that feel, you know, not authentic, right?\" Corkill noted. \"You can smell an AI email, you can smell an AI image or a video, it&#x27;s immediately clear to you... these models still don&#x27;t feel human, and you need human feedback to do that\".The economic and operational shiftFrom an operational standpoint, Rapidata positions itself as an infrastructure layer that eliminates the need for companies to manage their own custom annotation operations. By providing a scalable network, the company is lowering the barrier to entry for AI teams that previously struggled with the cost and complexity of traditional feedback loops.Jared Newman of Canaan Partners, who led the investment, suggests that this infrastructure is essential for the next generation of AI. \"Every serious AI deployment depends on human judgment somewhere in the lifecycle,\" Newman said. \"As models move from expertise-based tasks to taste-based curation, the demand for scalable human feedback will grow dramatically\".A future of human useWhile the current focus is on the model labs of the Bay Area, Corkill sees a future where the AI models themselves become the primary customers of human judgment. He calls this \"human use\".In this vision, a car designer AI wouldn&#x27;t just generate a generic vehicle; it could programmatically call Rapidata to ask 25,000 people in the French market what they think of a specific aesthetic, iterate on that feedback, and refine its design within hours.\"Society is in constant flux,\" Corkill noted, addressing the trend of using AI to simulate human behavior. \"If they simulate a society now, the simulation will be stable for and maybe mirror ours for a few months, but then it completely changes, because society has changed and has developed completely differently\".By creating a distributed, programmatic way to access human brain capacity worldwide, Rapidata is positioning itself as the vital interconnect between silicon and society. With $8.5 million in new funding, the company plans to move aggressively to ensure that as AI scales, the human element is no longer a bottleneck, but a real-time feature.",
          "content": "Despite growing chatter about a future when much human work is automated by AI, one of the ironies of this current tech boom is how stubbornly reliant on human beings it remains, specifically the process of training AI models using reinforcement learning from human feedback (RLHF). At its simplest, RLHF is a tutoring system: after an AI is trained on curated data, it still makes mistakes or sounds robotic. Human contractors are then hired en masse by AI labs to rate and rank a new model&#x27;s outputs while it trains, and the model learns from their ratings, adjusting its behavior to offer higher-rated outputs. This process is all the more important as AI expands to produce multimedia outputs like video, audio, and imagery which may have more nuanced and subjective measures of quality. Historically, this tutoring process has been a massive logistical headache and PR nightmare for AI companies, relying on fragmented networks of foreign contractors and static labeling pools in specific, low-income geographic hubs, cast by the media as low wage — even exploitative. It&#x27;s also inefficient: requiring AI labs wait weeks or months for a single batch of feedback, delaying model progress. Now a new startup has emerged to make the process far more efficient: Rapidata&#x27;s platform effectively \"gamifies\" RLHF by pushing said review tasks around the globe to nearly 20 million users of popular apps, including Duolingo or Candy Crush, in the form of short, opt-in review tasks they can choose to complete in place of watching mobile ads, with data sent back to a commissioning AI lab instantly. As shared with VentureBeat in a press release, this platform allows AI labs to \"iterate on models in near-real-time,\" significantly shortening development timelines compared to traditional methods.CEO and founder Jason Corkill stated in the same release that Rapidata makes \"human judgment available at a global scale and near real time, unlocking a future where AI teams can run constant feedback loops and build systems that evolve every day instead of every release cycle.\"\"Rapidata treats RLHF as high-speed infrastructure rather than a manual labor problem. Today, the company exclusively announced to us at VentureBeat its emergence with an $8.5 million seed round co-led by Canaan Partners and IA Ventures, with participation from Acequia Capital and BlueYard, to scale its unique approach to on-demand human data.The pub conversation that built a human cloudThe genesis of Rapidata was born not in a boardroom, but at a table over a few beers. When Corkill was a student at ETH Zurich, working in robotics and computer vision, when he hit the wall that every AI engineer eventually faces: the data annotation bottleneck.\"Specifically, I&#x27;ve been working in robotics, AI and computer vision for quite a few years now, studied at ETH here in Zurich, and just always was frustrated with data annotation,\" Corkill recalled in a recent interview. \"Always when you needed humans or human data annotation, that&#x27;s kind of when your project was stopped in its tracks, because up until then, you could move it forward by just pushing longer nights. But when you needed the large scale human annotation, you had to go to someone and then wait for a few weeks\".Frustrated by this delay, Corkill and his co-founders realized that the existing labor model for AI was fundamentally broken for a world moving at the speed of modern compute. While compute scales exponentially, the traditional human workforce—bound by manual onboarding, regional hiring, and slow payment cycles—does not. Rapidata was born from the idea that human judgment could be delivered as a globally distributed, near-instantaneous service.Technology: Turning digital footprints into training dataThe core innovation of Rapidata lies in its distribution method. Rather than hiring full-time annotators in specific regions, Rapidata leverages the existing attention economy of the mobile app world. By partnering with third-party apps like Candy Crush or Duolingo, Rapidata offers users a choice: watch a traditional ad or spend a few seconds providing feedback for an AI model.\"The users are asked, &#x27;Hey, would you rather instead of watching ads and having, you know, companies buy your eyeballs like that, would you rather like annotate some data, give feedback?&#x27;\" Corkill explained. According to Corkill, between 50% and 60% of users opt for the feedback task over a traditional video advertisement.This \"crowd intelligence\" approach allows AI teams to tap into a diverse, global demographic at an unprecedented scale.The global network: Rapidata currently reaches between 15 and 20 million people.Massive parallelism: The platform can process 1.5 million human annotations in a single hour.Speed: Feedback cycles that previously took weeks or months are reduced to hours or even minutes.Quality control: The platform builds trust and expertise profiles for respondents over time, ensuring that complex questions are matched with the most relevant human judges.Anonymity: While users are tracked via anonymized IDs to ensure consistency and reliability, Rapidata does not collect personal identities, maintaining privacy while optimizing for data quality.Online RLHF: Moving into the GPUThe most significant technological leap Rapidata is enabling is what Corkill describes as \"online RLHF\". Traditionally, AI is trained in disconnected batches: you train the model, stop, send data to humans, wait weeks for labels, and then resume. This creates a \"circle\" of information that often lacks fresh human input.Rapidata is moving this judgment directly into the training loop. Because their network is so fast, they can integrate via API directly with the GPUs running the model.\"We&#x27;ve always had this idea of reinforcement learning for human feedback... so far, you always had to do it like in batches,\" Corkill said. \"Now, if you go all the way down, we have a few clients now where, because we&#x27;re so fast, we can be directly, basically in the process, like in in the processor on the GPU right, and the GPU calculate some output, and it can immediately request from us in a distributed fashion. &#x27;Oh, I need, I need, I need a human to look at this.&#x27; I get the answer and then apply that loss, which has not been possible so far\".Currently, the platform supports roughly 5,500 humans per minute providing live feedback to models running on thousands of GPUs. This prevents \"reward model hacking,\" where two AI models trick each other in a feedback loop, by grounding the training in actual human nuance.Product: Solving for taste and global contextAs AI moves beyond simple object recognition into generative media, the requirements for data labeling have evolved from objective tagging to subjective \"taste-based\" curation. It is no longer just about \"is this a cat?\" but rather \"is this voice synthesis convincing?\" or \"which of these two summaries feels more professional?\".Lily Clifford, CEO of the voice AI startup Rime, notes that Rapidata has been transformative for testing models in real-world contexts. \"Previously, gathering meaningful feedback meant cobbling together vendors and surveys, segment by segment, or country by country, which didn’t scale,\" Clifford said. Using Rapidata, Rime can reach the right audiences—whether in Sweden, Serbia, or the United States—and see how models perform in real customer workflows in days, not months.\"Most models are factually correct, but I&#x27;m sure you&#x27;re you have received emails that feel, you know, not authentic, right?\" Corkill noted. \"You can smell an AI email, you can smell an AI image or a video, it&#x27;s immediately clear to you... these models still don&#x27;t feel human, and you need human feedback to do that\".The economic and operational shiftFrom an operational standpoint, Rapidata positions itself as an infrastructure layer that eliminates the need for companies to manage their own custom annotation operations. By providing a scalable network, the company is lowering the barrier to entry for AI teams that previously struggled with the cost and complexity of traditional feedback loops.Jared Newman of Canaan Partners, who led the investment, suggests that this infrastructure is essential for the next generation of AI. \"Every serious AI deployment depends on human judgment somewhere in the lifecycle,\" Newman said. \"As models move from expertise-based tasks to taste-based curation, the demand for scalable human feedback will grow dramatically\".A future of human useWhile the current focus is on the model labs of the Bay Area, Corkill sees a future where the AI models themselves become the primary customers of human judgment. He calls this \"human use\".In this vision, a car designer AI wouldn&#x27;t just generate a generic vehicle; it could programmatically call Rapidata to ask 25,000 people in the French market what they think of a specific aesthetic, iterate on that feedback, and refine its design within hours.\"Society is in constant flux,\" Corkill noted, addressing the trend of using AI to simulate human behavior. \"If they simulate a society now, the simulation will be stable for and maybe mirror ours for a few months, but then it completely changes, because society has changed and has developed completely differently\".By creating a distributed, programmatic way to access human brain capacity worldwide, Rapidata is positioning itself as the vital interconnect between silicon and society. With $8.5 million in new funding, the company plans to move aggressively to ensure that as AI scales, the human element is no longer a bottleneck, but a real-time feature.",
          "feed_position": 3,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/6A3hRqADsdiALNRF8aUM8e/09c213e4e98031ecb62ef459a6de8967/r8BFky--_XqHqt4iCIRmm.jpg?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/data/the-last-mile-data-problem-is-stalling-enterprise-agentic-ai-golden",
          "published_at": "Thu, 19 Feb 2026 13:00:00 GMT",
          "title": "The 'last-mile' data problem is stalling enterprise agentic AI — 'golden pipelines' aim to fix it",
          "standfirst": "Traditional ETL tools like dbt or Fivetran prepare data for reporting: structured analytics and dashboards with stable schemas. AI applications need something different: preparing messy, evolving operational data for model inference in real-time. Empromptu calls this distinction \"inference integrity\" versus \"reporting integrity.\" Instead of treating data preparation as a separate discipline, golden pipelines integrate normalization directly into the AI application workflow, collapsing what typically requires 14 days of manual engineering into under an hour, the company says. Empromptu&#x27;s \"golden pipeline\" approach is a way to accelerate data preparation and make sure that data is accurate.The company works primarily with mid-market and enterprise customers in regulated industries where data accuracy and compliance are non-negotiable. Fintech is Empromptu&#x27;s fastest-growing vertical, with additional customers in healthcare and legal tech. The platform is HIPAA compliant and SOC 2 certified.\"Enterprise AI doesn&#x27;t break at the model layer, it breaks when messy data meets real users,\" Shanea Leven, CEO and co-founder of Empromptu told VentureBeat in an exclusive interview. \"Golden pipelines bring data ingestion, preparation and governance directly into the AI application workflow so teams can build systems that actually work in production.\"How golden pipelines workGolden pipelines operate as an automated layer that sits between raw operational data and AI application features. The system handles five core functions. First, it ingests data from any source including files, databases, APIs and unstructured documents. It then processes that data through automated inspection and cleaning, structuring with schema definitions, and labeling and enrichment to fill gaps and classify records. Built-in governance and compliance checks include audit trails, access controls and privacy enforcement.The technical approach combines deterministic preprocessing with AI-assisted normalization. Instead of hard-coding every transformation, the system identifies inconsistencies, infers missing structure and generates classifications based on model context. Every transformation is logged and tied directly to downstream AI evaluation.The evaluation loop is central to how golden pipelines function. If data normalization reduces downstream accuracy, the system catches it through continuous evaluation against production behavior. That feedback coupling between data preparation and model performance distinguishes golden pipelines from traditional ETL tools, according to Leven.Golden pipelines are embedded directly into the Empromptu Builder and run automatically as part of creating an AI application. From the user&#x27;s perspective, teams are building AI features. Under the hood, golden pipelines ensure the data feeding those features is clean, structured, governed and ready for production use.Reporting integrity versus inference integrityLeven positions golden pipelines as solving a fundamentally different problem than traditional ETL tools like dbt, Fivetran or Databricks.\"Dbt and Fivetran are optimized for reporting integrity. Golden pipelines are optimized for inference integrity,\" Leven said. \"Traditional ETL tools are designed to move and transform structured data based on predefined rules. They assume schema stability, known transformations and relatively static logic.\"\"We&#x27;re not replacing dbt or Fivetran, enterprises will continue to use those for warehouse integrity and structured reporting,\" Leven said. \"Golden pipelines sit closer to the AI application layer. They solve the last-mile problem: how do you take real-world, imperfect operational data and make it usable for AI features without months of manual wrangling?\"The trust argument for AI-driven normalization rests on auditability and continuous evaluation. \"It is not unsupervised magic. It is reviewable, auditable and continuously evaluated against production behavior,\" Leven said. \"If normalization reduces downstream accuracy, the evaluation loop catches it. That feedback coupling between data preparation and model performance is something traditional ETL pipelines do not provide.\"Customer deployment: VOW tackles high-stakes event dataThe golden pipeline approach is already having an impact in the real world.Event management platform VOW handles high-profile events for organizations like GLAAD as well as multiple sports organizations. When GLAAD plans an event, data populates across sponsor invites, ticket purchases, tables, seats and more. The process happens quickly and data consistency is non-negotiable.\"Our data is more complex than the average platform,\" Jennifer Brisman, CEO of VOW, told VentureBeat. \"When GLAAD plans an event that data gets populated across sponsor invites, ticket purchases, tables and seats, and more. And it all has to happen very quickly.\"VOW was writing regex scripts manually. When the company decided to build an AI-generated floor plan feature that updated data in near real-time and populated information across the platform, ensuring data accuracy became critical. Golden Pipelines automated the process of extracting data from floor plans that often arrived messy, inconsistent and unstructured, then formatting and sending it without extensive manual effort across the engineering team.VOW initially used Empromptu for AI-generated floor plan analysis that neither Google&#x27;s AI team nor Amazon&#x27;s AI team could solve. The company is now rewriting its entire platform on Empromptu&#x27;s system.What this means for enterprise AI deploymentsGolden pipelines target a specific deployment pattern: organizations building integrated AI applications where data preparation is currently a manual bottleneck between prototype and production. The approach makes less sense for teams that already have mature data engineering organizations with established ETL processes optimized for their specific domains, or for organizations building standalone AI models rather than integrated applications.The decision point is whether data preparation is blocking AI velocity in the organization. If data scientists are preparing datasets for experimentation that engineering teams then rebuild from scratch for production, integrated data prep addresses that gap. If the bottleneck is elsewhere in the AI development lifecycle, it won&#x27;t. The trade-off is platform integration vs tool flexibility. Teams using golden pipelines commit to an integrated approach where data preparation, AI application development and governance happen in a single platform. Organizations that prefer assembling best-of-breed tools for each function will find that approach limiting. The benefit is eliminating handoffs between data prep and application development. The cost is reduced optionality in how those functions are implemented.",
          "content": "Traditional ETL tools like dbt or Fivetran prepare data for reporting: structured analytics and dashboards with stable schemas. AI applications need something different: preparing messy, evolving operational data for model inference in real-time. Empromptu calls this distinction \"inference integrity\" versus \"reporting integrity.\" Instead of treating data preparation as a separate discipline, golden pipelines integrate normalization directly into the AI application workflow, collapsing what typically requires 14 days of manual engineering into under an hour, the company says. Empromptu&#x27;s \"golden pipeline\" approach is a way to accelerate data preparation and make sure that data is accurate.The company works primarily with mid-market and enterprise customers in regulated industries where data accuracy and compliance are non-negotiable. Fintech is Empromptu&#x27;s fastest-growing vertical, with additional customers in healthcare and legal tech. The platform is HIPAA compliant and SOC 2 certified.\"Enterprise AI doesn&#x27;t break at the model layer, it breaks when messy data meets real users,\" Shanea Leven, CEO and co-founder of Empromptu told VentureBeat in an exclusive interview. \"Golden pipelines bring data ingestion, preparation and governance directly into the AI application workflow so teams can build systems that actually work in production.\"How golden pipelines workGolden pipelines operate as an automated layer that sits between raw operational data and AI application features. The system handles five core functions. First, it ingests data from any source including files, databases, APIs and unstructured documents. It then processes that data through automated inspection and cleaning, structuring with schema definitions, and labeling and enrichment to fill gaps and classify records. Built-in governance and compliance checks include audit trails, access controls and privacy enforcement.The technical approach combines deterministic preprocessing with AI-assisted normalization. Instead of hard-coding every transformation, the system identifies inconsistencies, infers missing structure and generates classifications based on model context. Every transformation is logged and tied directly to downstream AI evaluation.The evaluation loop is central to how golden pipelines function. If data normalization reduces downstream accuracy, the system catches it through continuous evaluation against production behavior. That feedback coupling between data preparation and model performance distinguishes golden pipelines from traditional ETL tools, according to Leven.Golden pipelines are embedded directly into the Empromptu Builder and run automatically as part of creating an AI application. From the user&#x27;s perspective, teams are building AI features. Under the hood, golden pipelines ensure the data feeding those features is clean, structured, governed and ready for production use.Reporting integrity versus inference integrityLeven positions golden pipelines as solving a fundamentally different problem than traditional ETL tools like dbt, Fivetran or Databricks.\"Dbt and Fivetran are optimized for reporting integrity. Golden pipelines are optimized for inference integrity,\" Leven said. \"Traditional ETL tools are designed to move and transform structured data based on predefined rules. They assume schema stability, known transformations and relatively static logic.\"\"We&#x27;re not replacing dbt or Fivetran, enterprises will continue to use those for warehouse integrity and structured reporting,\" Leven said. \"Golden pipelines sit closer to the AI application layer. They solve the last-mile problem: how do you take real-world, imperfect operational data and make it usable for AI features without months of manual wrangling?\"The trust argument for AI-driven normalization rests on auditability and continuous evaluation. \"It is not unsupervised magic. It is reviewable, auditable and continuously evaluated against production behavior,\" Leven said. \"If normalization reduces downstream accuracy, the evaluation loop catches it. That feedback coupling between data preparation and model performance is something traditional ETL pipelines do not provide.\"Customer deployment: VOW tackles high-stakes event dataThe golden pipeline approach is already having an impact in the real world.Event management platform VOW handles high-profile events for organizations like GLAAD as well as multiple sports organizations. When GLAAD plans an event, data populates across sponsor invites, ticket purchases, tables, seats and more. The process happens quickly and data consistency is non-negotiable.\"Our data is more complex than the average platform,\" Jennifer Brisman, CEO of VOW, told VentureBeat. \"When GLAAD plans an event that data gets populated across sponsor invites, ticket purchases, tables and seats, and more. And it all has to happen very quickly.\"VOW was writing regex scripts manually. When the company decided to build an AI-generated floor plan feature that updated data in near real-time and populated information across the platform, ensuring data accuracy became critical. Golden Pipelines automated the process of extracting data from floor plans that often arrived messy, inconsistent and unstructured, then formatting and sending it without extensive manual effort across the engineering team.VOW initially used Empromptu for AI-generated floor plan analysis that neither Google&#x27;s AI team nor Amazon&#x27;s AI team could solve. The company is now rewriting its entire platform on Empromptu&#x27;s system.What this means for enterprise AI deploymentsGolden pipelines target a specific deployment pattern: organizations building integrated AI applications where data preparation is currently a manual bottleneck between prototype and production. The approach makes less sense for teams that already have mature data engineering organizations with established ETL processes optimized for their specific domains, or for organizations building standalone AI models rather than integrated applications.The decision point is whether data preparation is blocking AI velocity in the organization. If data scientists are preparing datasets for experimentation that engineering teams then rebuild from scratch for production, integrated data prep addresses that gap. If the bottleneck is elsewhere in the AI development lifecycle, it won&#x27;t. The trade-off is platform integration vs tool flexibility. Teams using golden pipelines commit to an integrated approach where data preparation, AI application development and governance happen in a single platform. Organizations that prefer assembling best-of-breed tools for each function will find that approach limiting. The benefit is eliminating handoffs between data prep and application development. The cost is reduced optionality in how those functions are implemented.",
          "feed_position": 4,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/5egQ46IjwiShQrV06KpeEk/785fd79433bb0a678b4ab1d2fbf88fb3/golden-pipeline-smk1.jpg?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/audio/speakers/best-portable-bluetooth-speakers-133004551.html",
          "published_at": "Thu, 19 Feb 2026 10:00:35 +0000",
          "title": "The 16 best portable Bluetooth speakers for 2026",
          "standfirst": "Portable Bluetooth speakers have become an easy default for listening away from your desk or living room. They’re the kind of tech you grab without thinking, whether you’re heading outside, cleaning the house or packing for a weekend away. The best portable options manage to sound bigger than they look, delivering clear audio without weighing down your bag.Battery life and durability matter just as much as sound quality now. Many modern speakers are built to survive splashes, dust and the occasional drop, while still offering quick pairing and stable connections. Some are designed for solo listening, others are meant to fill a space with music and keep going for hours.We’ve tested a wide mix of portable Bluetooth speakers to see which ones are actually worth carrying around. Whether you want something small and simple or a speaker that can anchor a get-together, these are the models that stood out. Best portable Bluetooth speakers: $50 to $200 Best portable Bluetooth speakers: $200 to $450 Best portable Bluetooth speakers: $450 and higher Factors to consider in a portable Bluetooth speaker Weather-proofing IP ratings (Ingress Protection) are the alphanumeric indicators you often see in a product’s spec sheet that define water and dust resistance. It’s usually a combo of two numbers with the first indicating solid object ingress and the second being water. The former goes from 0 (no protection) to 6 (dustproof). The water-resistance rating goes from 0 (no protection) to 9 (protected against immersion and high pressure jets). When an X is used instead of a number, that means the product wasn’t tested for resistance. If it’s a waterproof speaker, it may have some innate resistance to solids, but there’s no guarantee. IP67 is a common rating these days indicating highly resistant and potentially rugged speakers often featured in audio products like outdoor speakers. These are safe for quick dunks in the pool or tub and should be more than OK in the rain or in the shower. They’re also good options for the beach, playground and other rough environs. Additionally, speakers with ports and a high rating will often include a tight-fitting cover over the charging or auxiliary ports. If you plan on using the ports, that may limit the product's rated ability to fend off the elements. When looking for the best portable Bluetooth speaker, consider the IP rating and also how you plan to use your Bluetooth speaker when making your decision. It may be worth splurging on a better sounding model with a lower IP rating if you’ll mostly be using it indoors, for instance. Battery life The focus of this guide is on the best portable speakers, and while “portable” can be a relative term, these devices are generally for people who are likely to find themselves far from a power outlet. These days, around 12 hours of playtime seems to be the baseline but obviously, the more battery life you can get out of a speaker, the better, especially if you plan to listen to podcasts or music on the go. That said, be careful when looking at battery specs, as they frequently list a maximum runtime (“up to” x amount of hours). This usually means they tested at a low to mid volume. If you like your tunes loud with punchy bass, it can often end up cutting the expected usage time in half or more. Luckily, some manufacturers also list the expected hours of battery life when used at full volume and that transparency is appreciated. Bear in mind, however, that not all of the best Bluetooth speakers use the same charging port. Some support USB-C charging, while others use micro-USB, and some may even come with an adapter for added convenience. Additionally, if your audio system or mini Bluetooth speaker also happens to have Wi-Fi connectivity, they're usually designed for always-on functionality. Unlike normal Bluetooth speakers that go to sleep after a short period without use, these will usually stay awake (to listen for your commands) and slowly run down the battery. If you're out and about, you'll want to remember to turn these speakers off manually when not in use to maximize battery life. Range Bluetooth 5 offers better range and more reliable connectivity than its predecessors, making it a great feature to look for in the best Bluetooth speaker. That said, Bluetooth range can still be tricky. Some companies list their product’s longest possible range, usually outdoors and in an unobstructed line-of-sight test environment. Other companies stick with a 30-foot range on the spec sheet and leave it at that, even though they may be running Bluetooth 4.x or 5.x. That’s likely underselling the speaker's potential, but unpredictable environments can affect range and there’s little point in promising the moon only to get complaints. I’ve seen signal drop issues when crouching down, with my phone in the front pocket of my jeans, and barely 30 feet away from a speaker inside my apartment. I ran into this issue across several devices regardless of their listed Bluetooth connectivity range. If you’re hosting a patio party and duck inside, it’s wise to keep any wireless Bluetooth speakers relatively close by just in case. It’s hard to gauge what aspects of any environment may interfere with a Bluetooth signal. In general, take range specs around 100 feet or more as a perfect-world scenario. Latency This is a minor mention for those out there who use a speaker for their computer output, or as a mini Bluetooth soundbar solution for setups like a monitor and streaming box. It’s annoying to find that your speaker’s latency isn’t low enough to avoid lip sync issues. Luckily, it seems that most speakers these days don’t often have these problems. Only a handful of the few dozen speakers I tried had persistent, noticeable lip-sync issues. Aside from occasional blips, all of our picks worked well in this regard. If you plan to frequently use a speaker for video playback, look for devices with the most recent Bluetooth 5 technology and lower latency codecs like aptX. Also make sure the speaker is close to the source device as distance can be a factor. To avoid the issue altogether, though, consider getting one with a wired auxiliary input. Extra features Some speakers don’t just play music — they bring the party to life with built-in LED light effects and a full-on light show that syncs to your music. If you love a bit of visual flair with your tunes, it’s worth checking out models that offer LED light customization options. Sound quality also plays a huge role in picking the right speaker. The best Bluetooth speaker should deliver a balanced mix of punchy bass, clear highs and strong vocals. Many models also include customizable sound modes that let you tweak the EQ to better suit different genres — whether you’re blasting EDM, listening to a podcast, or just want a more immersive experience that would impress even an audiophile. If aesthetics matter, many models come in a tiny size that makes them extra portable, with plenty of color options to match your personal style. Whether you want a sleek black speaker or a vibrant eye-catching design, there are plenty of choices to fit your vibe. Other portable Bluetooth speakers we tested Sonos Roam While there's a lot to like about the Sonos Roam, there are plenty of other Bluetooth speakers with more features and better battery life. In our review, we gave the Roam a score of 87, praising it for its good sound quality, durable waterproof design and ability to work well within an existing Sonos speaker ecosystem. But the price is just fine at $180, and we found Bluetooth speakers that offer more at lower price points. Plus, the Roam taps out at 10 hours of battery life, and all of our top picks can run for longer than that on a single charge. Monoprice Soundstage3 The Monoprice Soundstage3 offers relatively big sound at a midrange $250 price, with a variety of inputs rarely found on a portable Bluetooth speaker. The boxy, minimalist design is no nonsense, even if it's more of a less-rugged, bookshelf-styled homebody. While the speaker puts out crisp highs alongside booming lows, we found the bass can overpower the rest of the output, so it's not for everyone. And after using the speaker for many months, we also found the low-slung, poorly labeled button panel along the top can be a bit annoying to use. If you want a speaker for road trips, favor mids and highs, and plan on using physical buttons for volume control and input selections, there are better options out there. JBL Boombox 3 Fans of JBL’s bluetooth speaker sound profile who want to crank up the volume, but also want a rugged and portable option, may enjoy the JBL Boombox 3. It’s a decent grab-and-go speaker with a very loud output, although it's not as good as some of the loud-speaker styled options for long-throw sound and big outdoor areas. However, the price for this speaker line remains prohibitively expensive compared to other options with big sound that cover a bit more ground. If the JBL brand is your thing and you like the rugged, portable form factor, we recommend looking for discounts, or shopping around and exploring the available options including the (less portable) JBL PartyBox series. Soundcore Motion X500 Soundcore speakers have generally been good and often reasonably priced. The Motion X500 loosely falls into that category. It has a tall, metallic lunchbox vibe with a fixed handle and pumps out a respectable 40 watts of crisp, clear sound for its size. It can get pretty loud and serves up a good dose of bass, although its primarily a front-facing speaker. There’s LDAC hi-res audio support for Android users, but the main selling point on this is spatial audio. This is done through an EQ change and the activation of a small, up-firing driver. There’s a slight benefit from this if you’re up close and directly in front of it, but it’s not a total game changer for your listening experience. The original pre-order price of $130 made it a decent option in terms of bang for your buck. But it went up to $170 at launch, making it less appealing even if it’s still a good middle-of-the-road option if you want small-ish, clear and loud. If you can find one on sale for the lower price, it’s definitely worth considering. There’s also the larger and louder X600 ($200) if the overall concept is working for you. Portable Bluetooth speaker FAQs How does a Bluetooth speaker work? Bluetooth technology lets devices connect and exchange data over short distances using ultra high frequency (UHF) radio waves. It’s the frequency range that’s carved out for industrial, scientific and medical purposes, called the 2.4GHz ISM spectrum band. This range is available worldwide, making it easy for companies to use with devices for global markets. Bluetooth speakers include this tech, which lets them communicate with source devices like smartphones, tablets or computers in order to exchange data. The two devices pair by sharing a unique code and will work within the proscribed range for the device and Bluetooth version. Ever since Bluetooth 4.0 was released over a decade ago, new iterations usually improve on range, use less power and offer expanded connectivity with features like multipoint (allowing more than one device to be connected at the same time, for instance). Who should buy a Portable Bluetooth speaker? If you want to play music while you’re out-and-about on something other than headphones, a portable Bluetooth speaker is probably what you want. There’s a broad range of devices for all types of circumstances. Many adventurous people will want a relatively lightweight portable that’s rugged enough to handle the elements while also packing enough charge to play for hours on end. Others may simply need a speaker they can move around the house or use in the backyard. In this case, you can choose larger less rugged models that may offer better sound. This article originally appeared on Engadget at https://www.engadget.com/audio/speakers/best-portable-bluetooth-speakers-133004551.html?src=rss",
          "content": "Portable Bluetooth speakers have become an easy default for listening away from your desk or living room. They’re the kind of tech you grab without thinking, whether you’re heading outside, cleaning the house or packing for a weekend away. The best portable options manage to sound bigger than they look, delivering clear audio without weighing down your bag.Battery life and durability matter just as much as sound quality now. Many modern speakers are built to survive splashes, dust and the occasional drop, while still offering quick pairing and stable connections. Some are designed for solo listening, others are meant to fill a space with music and keep going for hours.We’ve tested a wide mix of portable Bluetooth speakers to see which ones are actually worth carrying around. Whether you want something small and simple or a speaker that can anchor a get-together, these are the models that stood out. Best portable Bluetooth speakers: $50 to $200 Best portable Bluetooth speakers: $200 to $450 Best portable Bluetooth speakers: $450 and higher Factors to consider in a portable Bluetooth speaker Weather-proofing IP ratings (Ingress Protection) are the alphanumeric indicators you often see in a product’s spec sheet that define water and dust resistance. It’s usually a combo of two numbers with the first indicating solid object ingress and the second being water. The former goes from 0 (no protection) to 6 (dustproof). The water-resistance rating goes from 0 (no protection) to 9 (protected against immersion and high pressure jets). When an X is used instead of a number, that means the product wasn’t tested for resistance. If it’s a waterproof speaker, it may have some innate resistance to solids, but there’s no guarantee. IP67 is a common rating these days indicating highly resistant and potentially rugged speakers often featured in audio products like outdoor speakers. These are safe for quick dunks in the pool or tub and should be more than OK in the rain or in the shower. They’re also good options for the beach, playground and other rough environs. Additionally, speakers with ports and a high rating will often include a tight-fitting cover over the charging or auxiliary ports. If you plan on using the ports, that may limit the product's rated ability to fend off the elements. When looking for the best portable Bluetooth speaker, consider the IP rating and also how you plan to use your Bluetooth speaker when making your decision. It may be worth splurging on a better sounding model with a lower IP rating if you’ll mostly be using it indoors, for instance. Battery life The focus of this guide is on the best portable speakers, and while “portable” can be a relative term, these devices are generally for people who are likely to find themselves far from a power outlet. These days, around 12 hours of playtime seems to be the baseline but obviously, the more battery life you can get out of a speaker, the better, especially if you plan to listen to podcasts or music on the go. That said, be careful when looking at battery specs, as they frequently list a maximum runtime (“up to” x amount of hours). This usually means they tested at a low to mid volume. If you like your tunes loud with punchy bass, it can often end up cutting the expected usage time in half or more. Luckily, some manufacturers also list the expected hours of battery life when used at full volume and that transparency is appreciated. Bear in mind, however, that not all of the best Bluetooth speakers use the same charging port. Some support USB-C charging, while others use micro-USB, and some may even come with an adapter for added convenience. Additionally, if your audio system or mini Bluetooth speaker also happens to have Wi-Fi connectivity, they're usually designed for always-on functionality. Unlike normal Bluetooth speakers that go to sleep after a short period without use, these will usually stay awake (to listen for your commands) and slowly run down the battery. If you're out and about, you'll want to remember to turn these speakers off manually when not in use to maximize battery life. Range Bluetooth 5 offers better range and more reliable connectivity than its predecessors, making it a great feature to look for in the best Bluetooth speaker. That said, Bluetooth range can still be tricky. Some companies list their product’s longest possible range, usually outdoors and in an unobstructed line-of-sight test environment. Other companies stick with a 30-foot range on the spec sheet and leave it at that, even though they may be running Bluetooth 4.x or 5.x. That’s likely underselling the speaker's potential, but unpredictable environments can affect range and there’s little point in promising the moon only to get complaints. I’ve seen signal drop issues when crouching down, with my phone in the front pocket of my jeans, and barely 30 feet away from a speaker inside my apartment. I ran into this issue across several devices regardless of their listed Bluetooth connectivity range. If you’re hosting a patio party and duck inside, it’s wise to keep any wireless Bluetooth speakers relatively close by just in case. It’s hard to gauge what aspects of any environment may interfere with a Bluetooth signal. In general, take range specs around 100 feet or more as a perfect-world scenario. Latency This is a minor mention for those out there who use a speaker for their computer output, or as a mini Bluetooth soundbar solution for setups like a monitor and streaming box. It’s annoying to find that your speaker’s latency isn’t low enough to avoid lip sync issues. Luckily, it seems that most speakers these days don’t often have these problems. Only a handful of the few dozen speakers I tried had persistent, noticeable lip-sync issues. Aside from occasional blips, all of our picks worked well in this regard. If you plan to frequently use a speaker for video playback, look for devices with the most recent Bluetooth 5 technology and lower latency codecs like aptX. Also make sure the speaker is close to the source device as distance can be a factor. To avoid the issue altogether, though, consider getting one with a wired auxiliary input. Extra features Some speakers don’t just play music — they bring the party to life with built-in LED light effects and a full-on light show that syncs to your music. If you love a bit of visual flair with your tunes, it’s worth checking out models that offer LED light customization options. Sound quality also plays a huge role in picking the right speaker. The best Bluetooth speaker should deliver a balanced mix of punchy bass, clear highs and strong vocals. Many models also include customizable sound modes that let you tweak the EQ to better suit different genres — whether you’re blasting EDM, listening to a podcast, or just want a more immersive experience that would impress even an audiophile. If aesthetics matter, many models come in a tiny size that makes them extra portable, with plenty of color options to match your personal style. Whether you want a sleek black speaker or a vibrant eye-catching design, there are plenty of choices to fit your vibe. Other portable Bluetooth speakers we tested Sonos Roam While there's a lot to like about the Sonos Roam, there are plenty of other Bluetooth speakers with more features and better battery life. In our review, we gave the Roam a score of 87, praising it for its good sound quality, durable waterproof design and ability to work well within an existing Sonos speaker ecosystem. But the price is just fine at $180, and we found Bluetooth speakers that offer more at lower price points. Plus, the Roam taps out at 10 hours of battery life, and all of our top picks can run for longer than that on a single charge. Monoprice Soundstage3 The Monoprice Soundstage3 offers relatively big sound at a midrange $250 price, with a variety of inputs rarely found on a portable Bluetooth speaker. The boxy, minimalist design is no nonsense, even if it's more of a less-rugged, bookshelf-styled homebody. While the speaker puts out crisp highs alongside booming lows, we found the bass can overpower the rest of the output, so it's not for everyone. And after using the speaker for many months, we also found the low-slung, poorly labeled button panel along the top can be a bit annoying to use. If you want a speaker for road trips, favor mids and highs, and plan on using physical buttons for volume control and input selections, there are better options out there. JBL Boombox 3 Fans of JBL’s bluetooth speaker sound profile who want to crank up the volume, but also want a rugged and portable option, may enjoy the JBL Boombox 3. It’s a decent grab-and-go speaker with a very loud output, although it's not as good as some of the loud-speaker styled options for long-throw sound and big outdoor areas. However, the price for this speaker line remains prohibitively expensive compared to other options with big sound that cover a bit more ground. If the JBL brand is your thing and you like the rugged, portable form factor, we recommend looking for discounts, or shopping around and exploring the available options including the (less portable) JBL PartyBox series. Soundcore Motion X500 Soundcore speakers have generally been good and often reasonably priced. The Motion X500 loosely falls into that category. It has a tall, metallic lunchbox vibe with a fixed handle and pumps out a respectable 40 watts of crisp, clear sound for its size. It can get pretty loud and serves up a good dose of bass, although its primarily a front-facing speaker. There’s LDAC hi-res audio support for Android users, but the main selling point on this is spatial audio. This is done through an EQ change and the activation of a small, up-firing driver. There’s a slight benefit from this if you’re up close and directly in front of it, but it’s not a total game changer for your listening experience. The original pre-order price of $130 made it a decent option in terms of bang for your buck. But it went up to $170 at launch, making it less appealing even if it’s still a good middle-of-the-road option if you want small-ish, clear and loud. If you can find one on sale for the lower price, it’s definitely worth considering. There’s also the larger and louder X600 ($200) if the overall concept is working for you. Portable Bluetooth speaker FAQs How does a Bluetooth speaker work? Bluetooth technology lets devices connect and exchange data over short distances using ultra high frequency (UHF) radio waves. It’s the frequency range that’s carved out for industrial, scientific and medical purposes, called the 2.4GHz ISM spectrum band. This range is available worldwide, making it easy for companies to use with devices for global markets. Bluetooth speakers include this tech, which lets them communicate with source devices like smartphones, tablets or computers in order to exchange data. The two devices pair by sharing a unique code and will work within the proscribed range for the device and Bluetooth version. Ever since Bluetooth 4.0 was released over a decade ago, new iterations usually improve on range, use less power and offer expanded connectivity with features like multipoint (allowing more than one device to be connected at the same time, for instance). Who should buy a Portable Bluetooth speaker? If you want to play music while you’re out-and-about on something other than headphones, a portable Bluetooth speaker is probably what you want. There’s a broad range of devices for all types of circumstances. Many adventurous people will want a relatively lightweight portable that’s rugged enough to handle the elements while also packing enough charge to play for hours on end. Others may simply need a speaker they can move around the house or use in the backyard. In this case, you can choose larger less rugged models that may offer better sound. This article originally appeared on Engadget at https://www.engadget.com/audio/speakers/best-portable-bluetooth-speakers-133004551.html?src=rss",
          "feed_position": 33
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/new-agent-framework-matches-human-engineered-ai-systems-and-adds-zero",
          "published_at": "Wed, 18 Feb 2026 22:00:00 GMT",
          "title": "New agent framework matches human-engineered AI systems — and adds zero inference cost to deploy",
          "standfirst": "Agents built on top of today&#x27;s models often break with simple changes — a new library, a workflow modification — and require a human engineer to fix it. That&#x27;s one of the most persistent challenges in deploying AI for the enterprise: creating agents that can adapt to dynamic environments without constant hand-holding. While today&#x27;s models are powerful, they are largely static.To address this, researchers at the University of California, Santa Barbara have developed Group-Evolving Agents (GEA), a new framework that enables groups of AI agents to evolve together, sharing experiences and reusing their innovations to autonomously improve over time.In experiments on complex coding and software engineering tasks, GEA substantially outperformed existing self-improving frameworks. Perhaps most notably for enterprise decision-makers, the system autonomously evolved agents that matched or exceeded the performance of frameworks painstakingly designed by human experts.The limitations of &#x27;lone wolf&#x27; evolutionMost existing agentic AI systems rely on fixed architectures designed by engineers. These systems often struggle to move beyond the capability boundaries imposed by their initial designs. To solve this, researchers have long sought to create self-evolving agents that can autonomously modify their own code and structure to overcome their initial limits. This capability is essential for handling open-ended environments where the agent must continuously explore new solutions.However, current approaches to self-evolution have a major structural flaw. As the researchers note in their paper, most systems are inspired by biological evolution and are designed around \"individual-centric\" processes. These methods typically use a tree-structured approach: a single \"parent\" agent is selected to produce offspring, creating distinct evolutionary branches that remain strictly isolated from one another.This isolation creates a silo effect. An agent in one branch cannot access the data, tools, or workflows discovered by an agent in a parallel branch. If a specific lineage fails to be selected for the next generation, any valuable discovery made by that agent, such as a novel debugging tool or a more efficient testing workflow, dies out with it.In their paper, the researchers question the necessity of adhering to this biological metaphor. \"AI agents are not biological individuals,\" they argue. \"Why should their evolution remain constrained by biological paradigms?\"The collective intelligence of Group-Evolving AgentsGEA shifts the paradigm by treating a group of agents, rather than an individual, as the fundamental unit of evolution.The process begins by selecting a group of parent agents from an existing archive. To ensure a healthy mix of stability and innovation, GEA selects these agents based on a combined score of performance (competence in solving tasks) and novelty (how distinct their capabilities are from others).Unlike traditional systems where an agent only learns from its direct parent, GEA creates a shared pool of collective experience. This pool contains the evolutionary traces from all members of the parent group, including code modifications, successful solutions to tasks, and tool invocation histories. Every agent in the group gains access to this collective history, allowing them to learn from the breakthroughs and mistakes of their peers.A “Reflection Module,” powered by a large language model, analyzes this collective history to identify group-wide patterns. For instance, if one agent discovers a high-performing debugging tool while another perfects a testing workflow, the system extracts both insights. Based on this analysis, the system generates high-level \"evolution directives\" that guide the creation of the child group. This ensures the next generation possesses the combined strengths of all their parents, rather than just the traits of a single lineage.However, this hive-mind approach works best when success is objective, such as in coding tasks. \"For less deterministic domains (e.g., creative generation), evaluation signals are weaker,\" Zhaotian Weng and Xin Eric Wang, co-authors of the paper, told VentureBeat in written comments. \"Blindly sharing outputs and experiences may introduce low-quality experiences that act as noise. This suggests the need for stronger experience filtering mechanisms\" for subjective tasks.GEA in actionThe researchers tested GEA against the current state-of-the-art self-evolving baseline, the Darwin Godel Machine (DGM), on two rigorous benchmarks. The results demonstrated a massive leap in capability without increasing the number of agents used.This collaborative approach also makes the system more robust against failure. In their experiments, the researchers intentionally broke agents by manually injecting bugs into their implementations. GEA was able to repair these critical bugs in an average of 1.4 iterations, while the baseline took 5 iterations. The system effectively leverages the \"healthy\" members of the group to diagnose and patch the compromised ones.On SWE-bench Verified, a benchmark consisting of real GitHub issues including bugs and feature requests, GEA achieved a 71.0% success rate, compared to the baseline&#x27;s 56.7%. This translates to a significant boost in autonomous engineering throughput, meaning the agents are far more capable of handling real-world software maintenance. Similarly, on Polyglot, which tests code generation across diverse programming languages, GEA achieved 88.3% against the baseline&#x27;s 68.3%, indicating high adaptability to different tech stacks.For enterprise R&D teams, the most critical finding is that GEA allows AI to design itself as effectively as human engineers. On SWE-bench, GEA’s 71.0% success rate effectively matches the performance of OpenHands, the top human-designed open-source framework. On Polyglot, GEA significantly outperformed Aider, a popular coding assistant, which achieved 52.0%. This suggests that organizations may eventually reduce their reliance on large teams of prompt engineers to tweak agent frameworks, as the agents can meta-learn these optimizations autonomously.This efficiency extends to cost management. \"GEA is explicitly a two-stage system: (1) agent evolution, then (2) inference/deployment,\" the researchers said. \"After evolution, you deploy a single evolved agent... so enterprise inference cost is essentially unchanged versus a standard single-agent setup.\"The success of GEA stems largely from its ability to consolidate improvements. The researchers tracked specific innovations invented by the agents during the evolutionary process. In the baseline approach, valuable tools often appeared in isolated branches but failed to propagate because those specific lineages ended. In GEA, the shared experience model ensured these tools were adopted by the best-performing agents. The top GEA agent integrated traits from 17 unique ancestors (representing 28% of the population) whereas the best baseline agent integrated traits from only 9. In effect, GEA creates a \"super-employee\" that possesses the combined best practices of the entire group.\"A GEA-inspired workflow in production would allow agents to first attempt a few independent fixes when failures occur,\" the researchers explained regarding this self-healing capability. \"A reflection agent (typically powered by a strong foundation model) can then summarize the outcomes... and guide a more comprehensive system update.\"Furthermore, the improvements discovered by GEA are not tied to a specific underlying model. Agents evolved using one model, such as Claude, maintained their performance gains even when the underlying engine was swapped to another model family, such as GPT-5.1 or GPT-o3-mini. This transferability offers enterprises the flexibility to switch model providers without losing the custom architectural optimizations their agents have learned.For industries with strict compliance requirements, the idea of self-modifying code might sound risky. To address this, the authors said: \"We expect enterprise deployments to include non-evolvable guardrails, such as sandboxed execution, policy constraints, and verification layers.\"While the researchers plan to release the official code soon, developers can already begin implementing the GEA architecture conceptually on top of existing agent frameworks. The system requires three key additions to a standard agent stack: an “experience archive” to store evolutionary traces, a “reflection module” to analyze group patterns, and an “updating module” that allows the agent to modify its own code based on those insights.Looking ahead, the framework could democratize advanced agent development. \"One promising direction is hybrid evolution pipelines,\" the researchers said, \"where smaller models explore early to accumulate diverse experiences, and stronger models later guide evolution using those experiences.\"",
          "content": "Agents built on top of today&#x27;s models often break with simple changes — a new library, a workflow modification — and require a human engineer to fix it. That&#x27;s one of the most persistent challenges in deploying AI for the enterprise: creating agents that can adapt to dynamic environments without constant hand-holding. While today&#x27;s models are powerful, they are largely static.To address this, researchers at the University of California, Santa Barbara have developed Group-Evolving Agents (GEA), a new framework that enables groups of AI agents to evolve together, sharing experiences and reusing their innovations to autonomously improve over time.In experiments on complex coding and software engineering tasks, GEA substantially outperformed existing self-improving frameworks. Perhaps most notably for enterprise decision-makers, the system autonomously evolved agents that matched or exceeded the performance of frameworks painstakingly designed by human experts.The limitations of &#x27;lone wolf&#x27; evolutionMost existing agentic AI systems rely on fixed architectures designed by engineers. These systems often struggle to move beyond the capability boundaries imposed by their initial designs. To solve this, researchers have long sought to create self-evolving agents that can autonomously modify their own code and structure to overcome their initial limits. This capability is essential for handling open-ended environments where the agent must continuously explore new solutions.However, current approaches to self-evolution have a major structural flaw. As the researchers note in their paper, most systems are inspired by biological evolution and are designed around \"individual-centric\" processes. These methods typically use a tree-structured approach: a single \"parent\" agent is selected to produce offspring, creating distinct evolutionary branches that remain strictly isolated from one another.This isolation creates a silo effect. An agent in one branch cannot access the data, tools, or workflows discovered by an agent in a parallel branch. If a specific lineage fails to be selected for the next generation, any valuable discovery made by that agent, such as a novel debugging tool or a more efficient testing workflow, dies out with it.In their paper, the researchers question the necessity of adhering to this biological metaphor. \"AI agents are not biological individuals,\" they argue. \"Why should their evolution remain constrained by biological paradigms?\"The collective intelligence of Group-Evolving AgentsGEA shifts the paradigm by treating a group of agents, rather than an individual, as the fundamental unit of evolution.The process begins by selecting a group of parent agents from an existing archive. To ensure a healthy mix of stability and innovation, GEA selects these agents based on a combined score of performance (competence in solving tasks) and novelty (how distinct their capabilities are from others).Unlike traditional systems where an agent only learns from its direct parent, GEA creates a shared pool of collective experience. This pool contains the evolutionary traces from all members of the parent group, including code modifications, successful solutions to tasks, and tool invocation histories. Every agent in the group gains access to this collective history, allowing them to learn from the breakthroughs and mistakes of their peers.A “Reflection Module,” powered by a large language model, analyzes this collective history to identify group-wide patterns. For instance, if one agent discovers a high-performing debugging tool while another perfects a testing workflow, the system extracts both insights. Based on this analysis, the system generates high-level \"evolution directives\" that guide the creation of the child group. This ensures the next generation possesses the combined strengths of all their parents, rather than just the traits of a single lineage.However, this hive-mind approach works best when success is objective, such as in coding tasks. \"For less deterministic domains (e.g., creative generation), evaluation signals are weaker,\" Zhaotian Weng and Xin Eric Wang, co-authors of the paper, told VentureBeat in written comments. \"Blindly sharing outputs and experiences may introduce low-quality experiences that act as noise. This suggests the need for stronger experience filtering mechanisms\" for subjective tasks.GEA in actionThe researchers tested GEA against the current state-of-the-art self-evolving baseline, the Darwin Godel Machine (DGM), on two rigorous benchmarks. The results demonstrated a massive leap in capability without increasing the number of agents used.This collaborative approach also makes the system more robust against failure. In their experiments, the researchers intentionally broke agents by manually injecting bugs into their implementations. GEA was able to repair these critical bugs in an average of 1.4 iterations, while the baseline took 5 iterations. The system effectively leverages the \"healthy\" members of the group to diagnose and patch the compromised ones.On SWE-bench Verified, a benchmark consisting of real GitHub issues including bugs and feature requests, GEA achieved a 71.0% success rate, compared to the baseline&#x27;s 56.7%. This translates to a significant boost in autonomous engineering throughput, meaning the agents are far more capable of handling real-world software maintenance. Similarly, on Polyglot, which tests code generation across diverse programming languages, GEA achieved 88.3% against the baseline&#x27;s 68.3%, indicating high adaptability to different tech stacks.For enterprise R&D teams, the most critical finding is that GEA allows AI to design itself as effectively as human engineers. On SWE-bench, GEA’s 71.0% success rate effectively matches the performance of OpenHands, the top human-designed open-source framework. On Polyglot, GEA significantly outperformed Aider, a popular coding assistant, which achieved 52.0%. This suggests that organizations may eventually reduce their reliance on large teams of prompt engineers to tweak agent frameworks, as the agents can meta-learn these optimizations autonomously.This efficiency extends to cost management. \"GEA is explicitly a two-stage system: (1) agent evolution, then (2) inference/deployment,\" the researchers said. \"After evolution, you deploy a single evolved agent... so enterprise inference cost is essentially unchanged versus a standard single-agent setup.\"The success of GEA stems largely from its ability to consolidate improvements. The researchers tracked specific innovations invented by the agents during the evolutionary process. In the baseline approach, valuable tools often appeared in isolated branches but failed to propagate because those specific lineages ended. In GEA, the shared experience model ensured these tools were adopted by the best-performing agents. The top GEA agent integrated traits from 17 unique ancestors (representing 28% of the population) whereas the best baseline agent integrated traits from only 9. In effect, GEA creates a \"super-employee\" that possesses the combined best practices of the entire group.\"A GEA-inspired workflow in production would allow agents to first attempt a few independent fixes when failures occur,\" the researchers explained regarding this self-healing capability. \"A reflection agent (typically powered by a strong foundation model) can then summarize the outcomes... and guide a more comprehensive system update.\"Furthermore, the improvements discovered by GEA are not tied to a specific underlying model. Agents evolved using one model, such as Claude, maintained their performance gains even when the underlying engine was swapped to another model family, such as GPT-5.1 or GPT-o3-mini. This transferability offers enterprises the flexibility to switch model providers without losing the custom architectural optimizations their agents have learned.For industries with strict compliance requirements, the idea of self-modifying code might sound risky. To address this, the authors said: \"We expect enterprise deployments to include non-evolvable guardrails, such as sandboxed execution, policy constraints, and verification layers.\"While the researchers plan to release the official code soon, developers can already begin implementing the GEA architecture conceptually on top of existing agent frameworks. The system requires three key additions to a standard agent stack: an “experience archive” to store evolutionary traces, a “reflection module” to analyze group patterns, and an “updating module” that allows the agent to modify its own code based on those insights.Looking ahead, the framework could democratize advanced agent development. \"One promising direction is hybrid evolution pipelines,\" the researchers said, \"where smaller models explore early to accumulate diverse experiences, and stronger models later guide evolution using those experiences.\"",
          "feed_position": 5,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/2Izl318JbInekR2BSYLBaq/4eddc806d26f5ee7d3567dece9c185ce/Self-evolving_agents.jpg?w=300&q=30"
        }
      ],
      "featured_image": "https://s.yimg.com/os/creatr-uploaded-images/2026-02/79eae6d0-0e56-11f1-9576-67d827e26ed5",
      "popularity_score": 3019.3441105555557
    },
    {
      "id": "cluster_32",
      "coverage": 2,
      "updated_at": "Fri, 20 Feb 2026 16:32:58 +0000",
      "title": "Supreme Court Rules Most of Donald Trump’s Tariffs Are Illegal",
      "neutral_headline": "Supreme Court Rules Most of Donald Trump’s Tariffs Are Illegal",
      "bullet_summary": [
        "Reported by Wired Tech, Ars Technica"
      ],
      "items": [
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/supreme-court-trump-tariffs-ruling/",
          "published_at": "Fri, 20 Feb 2026 16:32:58 +0000",
          "title": "Supreme Court Rules Most of Donald Trump’s Tariffs Are Illegal",
          "standfirst": "In a 6-3 ruling, justices upended the Trump administration’s signature economic policy, potentially putting the US government on the hook for at least $175 billion in tariff refunds.",
          "content": "In a 6-3 ruling, justices upended the Trump administration’s signature economic policy, potentially putting the US government on the hook for at least $175 billion in tariff refunds.",
          "feed_position": 3,
          "image_url": "https://media.wired.com/photos/6965882806400ecd3e99bc26/master/pass/Supreme-Court-Ruling-on-Trumps-Tariffs-Business-2240481670.jpg"
        },
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/02/supreme-court-blocks-trumps-emergency-tariffs-billions-in-refunds-may-be-owed/",
          "published_at": "Fri, 20 Feb 2026 15:37:15 +0000",
          "title": "Supreme Court blocks Trump's emergency tariffs, billions in refunds may be owed",
          "standfirst": "Economists estimated more than $175 billion may need to be refunded.",
          "content": "The Supreme Court ruled Friday that Donald Trump was not authorized to implement emergency tariffs to ostensibly block illegal drug flows and offset trade deficits. It's not immediately clear what the ruling may mean for businesses that paid various \"reciprocal\" tariffs that Trump changed frequently, raising and lowering rates at will during tense negotiations with the United States' biggest trade partners. Divided 6-3, Supreme Court justices remanded the cases to lower courts, concluding that the International Emergency Economic Powers Act (IEEPA) does not give Trump power to impose tariffs.Read full article Comments",
          "feed_position": 5,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-2261294684-1024x648.jpg"
        }
      ],
      "featured_image": "https://media.wired.com/photos/6965882806400ecd3e99bc26/master/pass/Supreme-Court-Ruling-on-Trumps-Tariffs-Business-2240481670.jpg",
      "popularity_score": 2017.0091105555555
    },
    {
      "id": "cluster_50",
      "coverage": 2,
      "updated_at": "Fri, 20 Feb 2026 10:10:02 -0500",
      "title": "OpenAI says users aged 18 to 24 account for nearly 50% and under-30s represent 80% of ChatGPT messages in India; 35% of chats are related to professional tasks (Ivan Mehta/TechCrunch)",
      "neutral_headline": "OpenAI says 18- to 24-year-olds account for nearly 50% of ChatGPT usage in India",
      "bullet_summary": [
        "The company said on Friday that users between 18 and 24 years &hellip;",
        "The company said on Friday that users between 18 and 24 years of age account for nearly 50% of all messages sent by Indians to ChatGPT, and users under 30 account for 80% of usage in the country"
      ],
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/260220/p7#a260220p7",
          "published_at": "Fri, 20 Feb 2026 10:10:02 -0500",
          "title": "OpenAI says users aged 18 to 24 account for nearly 50% and under-30s represent 80% of ChatGPT messages in India; 35% of chats are related to professional tasks (Ivan Mehta/TechCrunch)",
          "standfirst": "Ivan Mehta / TechCrunch: OpenAI says users aged 18 to 24 account for nearly 50% and under-30s represent 80% of ChatGPT messages in India; 35% of chats are related to professional tasks &mdash; OpenAI seems to have found product-market fit with young Indians. The company said on Friday that users between 18 and 24 years &hellip;",
          "content": "Ivan Mehta / TechCrunch: OpenAI says users aged 18 to 24 account for nearly 50% and under-30s represent 80% of ChatGPT messages in India; 35% of chats are related to professional tasks &mdash; OpenAI seems to have found product-market fit with young Indians. The company said on Friday that users between 18 and 24 years &hellip;",
          "feed_position": 7,
          "image_url": "http://www.techmeme.com/260220/i7.jpg"
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2026/02/20/openai-says-18-to-24-year-olds-account-for-nearly-50-of-chatgpt-usage-in-india/",
          "published_at": "Fri, 20 Feb 2026 13:57:03 +0000",
          "title": "OpenAI says 18- to 24-year-olds account for nearly 50% of ChatGPT usage in India",
          "standfirst": "The company said on Friday that users between 18 and 24 years of age account for nearly 50% of all messages sent by Indians to ChatGPT, and users under 30 account for 80% of usage in the country.",
          "content": "The company said on Friday that users between 18 and 24 years of age account for nearly 50% of all messages sent by Indians to ChatGPT, and users under 30 account for 80% of usage in the country.",
          "feed_position": 13
        }
      ],
      "featured_image": "http://www.techmeme.com/260220/i7.jpg",
      "popularity_score": 2015.6268883333332
    },
    {
      "id": "cluster_59",
      "coverage": 2,
      "updated_at": "Fri, 20 Feb 2026 14:13:32 +0000",
      "title": "An AI coding bot took down Amazon Web Services",
      "neutral_headline": "An AI coding bot took down Amazon Web Services",
      "bullet_summary": [
        "Reported by Ars Technica, TechMeme"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2026/02/an-ai-coding-bot-took-down-amazon-web-services/",
          "published_at": "Fri, 20 Feb 2026 14:13:32 +0000",
          "title": "An AI coding bot took down Amazon Web Services",
          "standfirst": "Blames \"user error, not AI error\" for incident in December involving its Kiro tool.",
          "content": "Amazon’s cloud unit has suffered at least two outages due to errors involving its own AI tools, leading some employees to raise doubts about the US tech giant’s push to roll out these coding assistants. Amazon Web Services experienced a 13-hour interruption to one system used by its customers in mid-December after engineers allowed its Kiro AI coding tool to make certain changes, according to four people familiar with the matter. The people said the agentic tool, which can take autonomous actions on behalf of users, determined that the best course of action was to “delete and recreate the environment.”Read full article Comments",
          "feed_position": 7,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2022/12/GettyImages-1192325886-1024x648.jpg"
        },
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/260220/p1#a260220p1",
          "published_at": "Fri, 20 Feb 2026 00:45:01 -0500",
          "title": "Sources: Amazon's AI tools have caused at least two AWS outages, including a 13-hour disruption in December; Amazon says it was \"user error, not AI error\" (Rafe Rosner-Uddin/Financial Times)",
          "standfirst": "Rafe Rosner-Uddin / Financial Times: Sources: Amazon's AI tools have caused at least two AWS outages, including a 13-hour disruption in December; Amazon says it was &ldquo;user error, not AI error&rdquo; &mdash; Tech giant blames &lsquo;user error, not AI error&rsquo; for incident in December involving its Kiro tool",
          "content": "Rafe Rosner-Uddin / Financial Times: Sources: Amazon's AI tools have caused at least two AWS outages, including a 13-hour disruption in December; Amazon says it was &ldquo;user error, not AI error&rdquo; &mdash; Tech giant blames &lsquo;user error, not AI error&rsquo; for incident in December involving its Kiro tool",
          "feed_position": 13,
          "image_url": "http://www.techmeme.com/260220/i1.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2022/12/GettyImages-1192325886-1024x648.jpg",
      "popularity_score": 2014.6852216666666
    },
    {
      "id": "cluster_3",
      "coverage": 1,
      "updated_at": "Fri, 20 Feb 2026 18:35:43 +0000",
      "title": "Wikipedia blacklists Archive.today, starts removing 695,000 archive links",
      "neutral_headline": "Wikipedia blacklists Archive.today, starts removing 695,000 archive links",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/02/wikipedia-bans-archive-today-after-site-executed-ddos-and-altered-web-captures/",
          "published_at": "Fri, 20 Feb 2026 18:35:43 +0000",
          "title": "Wikipedia blacklists Archive.today, starts removing 695,000 archive links",
          "standfirst": "If DDoSing a blog wasn't bad enough, archive site also tampered with web snapshots.",
          "content": "The English-language edition of Wikipedia is blacklisting Archive.today after the controversial archive site was used to direct a distributed denial of service (DDoS) attack against a blog. In the course of discussing whether Archive.today should be deprecated because of the DDoS, Wikipedia editors discovered that the archive site altered snapshots of webpages to insert the name of the blogger who was targeted by the DDoS. The alterations were apparently fueled by a grudge against the blogger over a post that described how the Archive.today maintainer hid their identity behind several aliases. \"There is consensus to immediately deprecate archive.today, and, as soon as practicable, add it to the spam blacklist (or create an edit filter that blocks adding new links), and remove all links to it,\" stated an update today on Wikipedia's Archive.today discussion. \"There is a strong consensus that Wikipedia should not direct its readers towards a website that hijacks users' computers to run a DDoS attack (see WP:ELNO#3). Additionally, evidence has been presented that archive.today's operators have altered the content of archived pages, rendering it unreliable.\"Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/wikipedia-1152x648-1771611351.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/wikipedia-1152x648-1771611351.jpg",
      "popularity_score": 352.0549438888889
    },
    {
      "id": "cluster_16",
      "coverage": 1,
      "updated_at": "Fri, 20 Feb 2026 17:26:59 +0000",
      "title": "Why Final Fantasy is now targeting PC as its \"lead platform\"",
      "neutral_headline": "Why Final Fantasy is now targeting PC as its \"lead platform\"",
      "bullet_summary": [
        "Director says PC is the \"foundation\" when targeting \"high-end environments first",
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2026/02/why-final-fantasy-is-now-targeting-pc-as-its-lead-platform/",
          "published_at": "Fri, 20 Feb 2026 17:26:59 +0000",
          "title": "Why Final Fantasy is now targeting PC as its \"lead platform\"",
          "standfirst": "Director says PC is the \"foundation\" when targeting \"high-end environments first.\"",
          "content": "For a long time now, PC gamers have been used to the Final Fantasy series treating their platform as somewhat secondary to the game's core console versions. There are some signs that may be starting to change, though, as director Naoki Hamaguchi has confirmed that the PC is now the \"lead platform\" for development of the Final Fantasy VII Remake trilogy. In a recent interview with Automaton, Hamaguchi clarified that the team takes the relatively common practice of creating visual assets for its multiplatform games by targeting \"high-end environments first,\" then performing a \"reduction\" for less powerful platforms. These days, that means \"our 3D assets are created at the highest quality level based on PC as the foundation,\" he said. Players have already noticed this graphical difference in the PC version of Final Fantasy VII Rebirth, Hamaguchi said, and \"our philosophy will not change for the third installment.\" While PC gaming is only \"gradually expanding in Japan,\" Hamaguchi said the rapid growth in international PC gamers has led the company to \"develop assets with the broad PC market in mind.\"Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2024/09/clouddress-1152x648.png"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2024/09/clouddress-1152x648.png",
      "popularity_score": 340.9093883333333
    },
    {
      "id": "cluster_24",
      "coverage": 1,
      "updated_at": "Fri, 20 Feb 2026 17:03:06 +0000",
      "title": "\"Million-year-old\" fossil skulls from China are far older—and not Denisovans",
      "neutral_headline": "\"Million-year-old\" fossil skulls from China are far older—and not Denisovans",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/02/new-dates-on-chinese-fossils-raise-question-of-how-many-times-we-left-africa/",
          "published_at": "Fri, 20 Feb 2026 17:03:06 +0000",
          "title": "\"Million-year-old\" fossil skulls from China are far older—and not Denisovans",
          "standfirst": "The revised age may help make sense of 2-million-year-old stone tools elsewhere in China.",
          "content": "Two skulls from Yunxian, in northern China, aren’t ancestors of Denisovans after all; they’re actually the oldest known Homo erectus fossils in eastern Asia. A recent study has re-dated the skulls to about 1.77 million years old, which makes them the oldest hominin remains found so far in East Asia. Their age means that Homo erectus (an extinct common ancestor of our species, Neanderthals, and Denisovans) must have spread across the continent much earlier and much faster than we’d previously given them credit for. It also sheds new light on who was making stone tools at some even older archaeological sites in China. Homo erectus spread like wildfire Yunxian is an important—and occasionally contentious—archaeological site on the banks of central China’s Han River. Along with hundreds of stone tools and animal bones, the layers of river sediment have yielded three nearly complete hominin skulls (only two of which have been described in a publication so far). Shantou University paleoanthropologist Hua Tu and his colleagues measured the ratio of two isotopes, aluminum-26 and beryllium-10, in grains of quartz from the sediment layer that once held the skulls. The results suggest that Homo erectus lived and died along the Han River 1.77 million years ago. That's just 130,000 years after the species first appeared in Africa.Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/09/yunxian3-985x648.png"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/09/yunxian3-985x648.png",
      "popularity_score": 330.5113327777778
    },
    {
      "id": "cluster_31",
      "coverage": 1,
      "updated_at": "Fri, 20 Feb 2026 16:40:31 +0000",
      "title": "It's outright war for the Iron Throne in House of the Dragon S3 teaser",
      "neutral_headline": "It's outright war for the Iron Throne in House of the Dragon S3 teaser",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/culture/2026/02/its-outright-war-for-the-iron-throne-in-house-of-the-dragon-s3-teaser/",
          "published_at": "Fri, 20 Feb 2026 16:40:31 +0000",
          "title": "It's outright war for the Iron Throne in House of the Dragon S3 teaser",
          "standfirst": "\"The king has abdicated his throne. A new line is coming. A new line of unsullied kings.\"",
          "content": "With HBO's critically acclaimed A Knight of the Seven Kingdoms gearing up for its season finale on Sunday, it's time to check in on that other Game of Thrones spinoff: the far darker House of the Dragon, which now has a suitably ominous teaser for its upcoming third season. (Spoilers for the first two seasons below.) The series is set nearly 200 years before the events of Game of Thrones, when dragons were still a fixture of Westeros, and chronicles the beginning of the end of House Targaryen’s reign. The primary source material is Fire and Blood, a fictional history of the Targaryen kings written by George R.R. Martin. As book readers know, those events culminated in a civil war and the extinction of the dragons—at least until Daenerys Targaryen came along.Read full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/dragon1-1152x648-1771601003.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/dragon1-1152x648-1771601003.jpg",
      "popularity_score": 320.13494388888887
    },
    {
      "id": "cluster_33",
      "coverage": 1,
      "updated_at": "Fri, 20 Feb 2026 16:30:21 +0000",
      "title": "Nintendo brings GBA-era Pokémon to the Switch, but not Switch Online subscribers",
      "neutral_headline": "Nintendo brings GBA-era Pokémon to the Switch, but not Switch Online subscribers",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2026/02/pokemon-red-and-greens-gba-remakes-are-getting-re-released-on-switch-for-20-a-pop/",
          "published_at": "Fri, 20 Feb 2026 16:30:21 +0000",
          "title": "Nintendo brings GBA-era Pokémon to the Switch, but not Switch Online subscribers",
          "standfirst": "Games appear to be mostly unmodified ports of the well-regarded remakes.",
          "content": "For my money, the 2004 Game Boy Advance re-releases of Pokémon FireRed and LeafGreen are still the best versions of the original Pokémon games. They fixed most of the bugs and balance issues present in the originals—partly by also including the rosters from Gold/Silver and Ruby/Sapphire—but they're more faithful to the original gameplay, battling and catching mechanics, and graphics than the 2018 Let's Go, Pikachu/Eevee! adaptations for the Switch. Someone at Nintendo apparently agrees, as the company announced today that it's re-releasing those games for the original Switch (and, by extension, the Switch 2, though no Switch 2-specific features were announced). The games will be available after a planned Pokémon Presents stream at 9 am Eastern/6 am Pacific on February 27. Subscribers to the Switch Online + Expansion Pack are in for a disappointment, though. Instead of releasing FireRed and LeafGreen as part of the Switch Online Game Boy Advance collection, Nintendo will release both titles as standalone purchases that will run you $20 apiece. This means that players without a subscription will be able to buy and play the games. But given how few GBA games are available for the Switch Online service and how infrequently new ones are released, it does rankle to see otherwise unmodified ports of a prominent game bypass subscribers entirely.Read full article Comments",
          "feed_position": 4,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/pokemon-fire-red-switch-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/pokemon-fire-red-switch-1152x648.jpg",
      "popularity_score": 309.96549944444445
    },
    {
      "id": "cluster_55",
      "coverage": 1,
      "updated_at": "Fri, 20 Feb 2026 14:31:05 +0000",
      "title": "Tesla slashes Cybertruck prices as it tries to move (unpainted) metal",
      "neutral_headline": "Tesla slashes Cybertruck prices as it tries to move (unpainted) metal",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2026/02/tesla-slashes-cybertruck-prices-as-it-tries-to-move-unpainted-metal/",
          "published_at": "Fri, 20 Feb 2026 14:31:05 +0000",
          "title": "Tesla slashes Cybertruck prices as it tries to move (unpainted) metal",
          "standfirst": "The stainless steel pickup truck is Tesla's first real flop.",
          "content": "Last night, Tesla made some hefty cuts to Cybertruck pricing in an effort to stimulate some sales. The bombastic tri-motor \"Cyberbeast\" is $15,000 cheaper at $99,990, albeit by dropping some previously free features like supercharging and FSD. And there's now a new $59,990 entry-level model, a dual-motor configuration with a range of 325 miles (523 km) and the same 4.1-second 0–60 mph (0-97 km/h) time as the $79,990 premium all-wheel drive version. That actually makes the new entry-level model a good deal, at least in terms of Cybertrucks. Last year, the company introduced and then eliminated a single-motor rear-wheel drive variant, which found few takers when priced at $69,990; an extra motor for $10,000 less is quite a savings, and actually slightly cheaper than the price originally advertised for the RWD truck. As you might expect, Tesla has made some changes to get down to the new price. The range and 0–60 mph time might be the same as the more expensive dual-motor Cybertruck, but towing capacity is reduced from 11,000 lbs (4,990 kg) to 7,000 lbs (3,175kg), and cargo capacity drops from 2,500 lbs (1,134 kg) to 2,006 lbs (910 kg).Read full article Comments",
          "feed_position": 6,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-2259708169-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-2259708169-1152x648.jpg",
      "popularity_score": 308.97772166666664
    },
    {
      "id": "cluster_72",
      "coverage": 1,
      "updated_at": "Fri, 20 Feb 2026 12:11:28 +0000",
      "title": "Microsoft deletes blog telling users to train AI on pirated Harry Potter books",
      "neutral_headline": "Microsoft deletes blog telling users to train AI on pirated Harry Potter books",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/02/microsoft-removes-guide-on-how-to-train-llms-on-pirated-harry-potter-books/",
          "published_at": "Fri, 20 Feb 2026 12:11:28 +0000",
          "title": "Microsoft deletes blog telling users to train AI on pirated Harry Potter books",
          "standfirst": "The now-deleted Harry Potter dataset was \"mistakenly\" marked public domain.",
          "content": "Following backlash in a Hacker News thread, Microsoft deleted a blog post that critics said encouraged developers to pirate Harry Potter books to train AI models that could then be used to create AI slop. The blog, which is archived here, was written in November 2024 by a senior product manager, Pooja Kamath. According to her LinkedIn, Kamath has been at Microsoft for more than a decade and remains with the company. In 2024, Microsoft tapped her to promote a new feature that the blog said made it easier to \"add generative AI features to your own applications with just a few lines of code using Azure SQL DB, LangChain, and LLMs.\" What better way to show \"engaging and relatable examples\" of Microsoft's new feature that would \"resonate with a wide audience\" than to \"use a well-known dataset\" like Harry Potter books, the blog said.Read full article Comments",
          "feed_position": 8,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/AI-generated-Harry-Potter-image-via-Microsoft-blog-1152x648-1771545041.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/AI-generated-Harry-Potter-image-via-Microsoft-blog-1152x648-1771545041.jpg",
      "popularity_score": 292.65077722222225
    },
    {
      "id": "cluster_73",
      "coverage": 1,
      "updated_at": "Fri, 20 Feb 2026 12:00:28 +0000",
      "title": "Rocket Report: Chinese launch firm raises big money; Falcon 9 back to the Bahamas",
      "neutral_headline": "Rocket Report: Chinese launch firm raises big money; Falcon 9 back to the Bahamas",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2026/02/rocket-report-chinese-launch-firm-raises-big-money-falcon-9-back-to-the-bahamas/",
          "published_at": "Fri, 20 Feb 2026 12:00:28 +0000",
          "title": "Rocket Report: Chinese launch firm raises big money; Falcon 9 back to the Bahamas",
          "standfirst": "The company that attempted China's first orbital-class rocket landing says it will soon try again.",
          "content": "Welcome to Edition 8.30 of the Rocket Report! As I write this week's edition, NASA's Space Launch System rocket is undergoing a second countdown rehearsal at Kennedy Space Center, Florida. The outcome of the test will determine whether NASA has a shot at launching the Artemis II mission around the Moon next month, or if the launch will be delayed until April or later. The finicky fueling line for the rocket's core stage is the center of attention after a hydrogen leak cut short a practice countdown earlier this month. As always, we welcome reader submissions. If you don't want to miss an issue, please subscribe using the box below (the form will not appear on AMP-enabled versions of the site). Each report will include information on small-, medium-, and heavy-lift rockets, as well as a quick look ahead at the next three launches on the calendar. Who is actually investing in sovereign launch? No one will supplant American and Chinese dominance in the space launch arena any time soon, but several longtime US allies now see sovereign access to space as a national security imperative, Ars reports. Taking advantage of private launch initiatives already underway within their own borders, several middle and regional powers have approved substantial government funding for commercial startups to help them reach the launch pad. Australia, Canada, Germany, and Spain are among the nations that currently lack the ability to independently put their own satellites into orbit, but they are now spending money to establish a domestic launch industry. Others talk a big game but haven’t committed the cash to back up their ambitions.Read full article Comments",
          "feed_position": 9,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/HBifCunX0AAeDpk-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/HBifCunX0AAeDpk-1152x648.jpg",
      "popularity_score": 270.4674438888889
    },
    {
      "id": "cluster_134",
      "coverage": 1,
      "updated_at": "Thu, 19 Feb 2026 14:11:55 +0000",
      "title": "OpenClaw security fears lead Meta, other AI firms to restrict its use",
      "neutral_headline": "OpenClaw security fears lead Meta, other AI firms to restrict its use",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2026/02/openclaw-security-fears-lead-meta-other-ai-firms-to-restrict-its-use/",
          "published_at": "Thu, 19 Feb 2026 14:11:55 +0000",
          "title": "OpenClaw security fears lead Meta, other AI firms to restrict its use",
          "standfirst": "The viral agentic AI tool is known for being highly capable but also wildly unpredictable.",
          "content": "Last month, Jason Grad issued a late-night warning to the 20 employees at his tech startup. “You've likely seen Clawdbot trending on X/LinkedIn. While cool, it is currently unvetted and high-risk for our environment,\" he wrote in a Slack message with a red siren emoji. “Please keep Clawdbot off all company hardware and away from work-linked accounts.” Grad isn’t the only tech executive who has raised concerns to staff about the experimental agentic AI tool, which was briefly known as MoltBot and is now named OpenClaw. A Meta executive says he recently told his team to keep OpenClaw off their regular work laptops or risk losing their jobs. The executive told reporters he believes the software is unpredictable and could lead to a privacy breach if used in otherwise secure environments. He spoke on the condition of anonymity to speak frankly. Peter Steinberger, OpenClaw’s solo founder, launched it as a free, open source tool last November. But its popularity surged last month as other coders contributed features and began sharing their experiences using it on social media. Last week, Steinberger joined ChatGPT developer OpenAI, which says it will keep OpenClaw open source and support it through a foundation.Read full article Comments",
          "feed_position": 18,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/bluecrayfish-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/bluecrayfish-1152x648.jpg",
      "popularity_score": 158
    },
    {
      "id": "cluster_110",
      "coverage": 1,
      "updated_at": "Thu, 19 Feb 2026 22:44:25 +0000",
      "title": "Lawsuit: ChatGPT told student he was \"meant for greatness\"—then came psychosis",
      "neutral_headline": "Lawsuit: ChatGPT told student he was \"meant for greatness\"—then came psychosis",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/02/before-psychosis-chatgpt-told-man-he-was-an-oracle-new-lawsuit-alleges/",
          "published_at": "Thu, 19 Feb 2026 22:44:25 +0000",
          "title": "Lawsuit: ChatGPT told student he was \"meant for greatness\"—then came psychosis",
          "standfirst": "\"AI Injury Attorneys\" target the chatbot design itself.",
          "content": "A Georgia college student named Darian DeCruise has sued OpenAI, alleging that a recently deprecated version of ChatGPT “convinced him that he was an oracle” and “pushed him into psychosis.” This case, which was first reported by ALM, marks the 11th such known lawsuit to be filed against OpenAI that involves mental health breakdowns allegedly caused by the chatbot. Other incidents have ranged from highly questionable medical and health advice to a man who took his own life, apparently after similarly sycophantic conversations with ChatGPT. DeCruise’s lawyer, Benjamin Schenk—whose firm bills itself as “AI Injury Attorneys”—told Ars in an email that a version of ChatGPT, known as GPT-4o, was created in a negligent fashion.Read full article Comments",
          "feed_position": 10,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2023/02/chatgpt-logo-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2023/02/chatgpt-logo-1024x648.jpg",
      "popularity_score": 148
    },
    {
      "id": "cluster_126",
      "coverage": 1,
      "updated_at": "Thu, 19 Feb 2026 17:42:14 +0000",
      "title": "Google announces Gemini 3.1 Pro, says it's better at complex problem-solving",
      "neutral_headline": "Google announces Gemini 3.1 Pro, says it's better at complex problem-solving",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/google/2026/02/google-announces-gemini-3-1-pro-says-its-better-at-complex-problem-solving/",
          "published_at": "Thu, 19 Feb 2026 17:42:14 +0000",
          "title": "Google announces Gemini 3.1 Pro, says it's better at complex problem-solving",
          "standfirst": "Google says 3.1 Pro is ready for \"your hardest challenges.\"",
          "content": "Another day, another Google AI model. Google has really been pumping out new AI tools lately, having just released Gemini 3 in November. Today, it's bumping the flagship model to version 3.1. The new Gemini 3.1 Pro is rolling out (in preview) for developers and consumers today with the promise of better problem-solving and reasoning capabilities. Google announced improvements to its Deep Think tool last week, and apparently, the \"core intelligence\" behind that update was Gemini 3.1 Pro. As usual, Google's latest model announcement comes with a plethora of benchmarks that show mostly modest improvements. In the popular Humanity's Last Exam, which tests advanced domain-specific knowledge, Gemini 3.1 Pro scored a record 44.4 percent. Gemini 3 Pro managed 37.5 percent, while OpenAI's GPT 5.2 got 34.5 percent. Credit: Google Read full article Comments",
          "feed_position": 16,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/gemini-3.1_pro-1152x648.png"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/gemini-3.1_pro-1152x648.png",
      "popularity_score": 145
    },
    {
      "id": "cluster_115",
      "coverage": 1,
      "updated_at": "Thu, 19 Feb 2026 20:04:09 +0000",
      "title": "Diablo II’s new Warlock is a great excuse to revisit a classic game",
      "neutral_headline": "Diablo II’s new Warlock is a great excuse to revisit a classic game",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2026/02/diablo-iis-new-warlock-is-a-great-excuse-to-revisit-a-classic-game/",
          "published_at": "Thu, 19 Feb 2026 20:04:09 +0000",
          "title": "Diablo II’s new Warlock is a great excuse to revisit a classic game",
          "standfirst": "New skill tree paths offer a fun twist on some generally familiar mechanics.",
          "content": "Diablo II is one of those storied classic PC games that's pretty much always fun to come back to—so much so that some players have put thousands of hours into the game over more than two decades. Across all those years, though, the game itself has barely changed, becoming something of a familiar, comfortable blanket of hellfire for longtime players. That makes last week's introduction of a new playable Warlock class in Diablo II Resurrected’s new \"Reign of the Warlock\" DLC a pretty big deal. And after playing through a few Acts with the Warlock over the recent holiday weekend, I found the new option to be a great excuse to come back to a game that's overdue for a shot in the arm. War-locked in How your Warlock build goes depends heavily on which of the three main upgrade branches you choose to go down. Of these, I found the Eldritch branch had been the most interesting and fun to explore. That's in large part because of a new skill that lets you levitate a powerful two-handed weapon in front of you while still holding a strong shield in your hands. It seems like a small change, but my relief was palpable in this playthrough as I was able to avoid these kinds of tough choices between defense and offense as I juggled my inventory.Read full article Comments",
          "feed_position": 13,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/warlocksigil.png"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/warlocksigil.png",
      "popularity_score": 139
    },
    {
      "id": "cluster_124",
      "coverage": 1,
      "updated_at": "Thu, 19 Feb 2026 18:22:29 +0000",
      "title": "F1: Preseason tests show how different 2026 will be",
      "neutral_headline": "F1: Preseason tests show how different 2026 will be",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2026/02/f1-preseason-tests-shows-how-different-2026-will-be/",
          "published_at": "Thu, 19 Feb 2026 18:22:29 +0000",
          "title": "F1: Preseason tests show how different 2026 will be",
          "standfirst": "Everyone's trying to get mileage as F1 undergoes huge technical changes.",
          "content": "It's just two weeks until F1 gets underway in Australia, and teams are currently in Bahrain, midway through their third and final preseason test. The 2026 season promises to be wildly different from those of the past few years, with all-new cars, engines, hybrid systems, and sustainable fuels entering the mix and shaking up the established order. You shouldn't read too much into times from preseason testing. The cars don't have to conform to the in-season rules as teams test new components or fit-test rigs; for example, glowing brake discs could once again be seen on some cars that weren't running wheel covers at an earlier test, something we're unlikely to see during actual races. You also don't know how much fuel—and therefore extra weight—anyone is carrying. In the past, some teams have even made headlines by running too light to set more competitive lap times in an effort to impress potential sponsors. And as the name explains, it's a test, so drivers will be following run plans devised with their engineers to learn specific things about their new cars. Or as one Internet wag once put it, the times mean as much as \"a bacon briefcase.\"Read full article Comments",
          "feed_position": 15,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-2260744865-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-2260744865-1152x648.jpg",
      "popularity_score": 138
    },
    {
      "id": "cluster_111",
      "coverage": 1,
      "updated_at": "Thu, 19 Feb 2026 21:59:10 +0000",
      "title": "NASA chief classifies Starliner flight as \"Type A\" mishap, says agency made mistakes",
      "neutral_headline": "NASA chief classifies Starliner flight as \"Type A\" mishap, says agency made mistakes",
      "bullet_summary": [
        "\"The most troubling failure revealed by this investigation is not hardware",
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2026/02/nasa-chief-classifies-starliner-flight-as-type-a-mishap-says-agency-made-mistakes/",
          "published_at": "Thu, 19 Feb 2026 21:59:10 +0000",
          "title": "NASA chief classifies Starliner flight as \"Type A\" mishap, says agency made mistakes",
          "standfirst": "\"The most troubling failure revealed by this investigation is not hardware.\"",
          "content": "NASA on Thursday announced it has formally classified the 2024 crewed flight of the Starliner spacecraft as a \"Type A\" mishap, an acknowledgement that the test flight was a serious failure. As part of the announcement, NASA Administrator Jared Isaacman sent an agency-wide letter that recognized the shortcomings of both Starliner's developer, Boeing, as well as the space agency itself. Starliner flew under the auspices of NASA's Commercial Crew Program, in which the agency procures astronaut transportation services to the International Space Station. \"We are taking ownership of our shortcomings,\" Isaacman said.Read full article Comments",
          "feed_position": 11,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2024/09/GettyImages-2156180680-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2024/09/GettyImages-2156180680-1152x648.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_112",
      "coverage": 1,
      "updated_at": "Thu, 19 Feb 2026 21:30:02 +0000",
      "title": "Rubik’s WOWCube adds complexity, possibility by reinventing the puzzle cube",
      "neutral_headline": "Rubik’s WOWCube adds complexity, possibility by reinventing the puzzle cube",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/02/rubiks-wowcube-adds-complexity-possibility-by-reinventing-the-puzzle-cube/",
          "published_at": "Thu, 19 Feb 2026 21:30:02 +0000",
          "title": "Rubik’s WOWCube adds complexity, possibility by reinventing the puzzle cube",
          "standfirst": "Technology is a double-edged sword in the $399 Rubik's Cube-inspired toy.",
          "content": "There’s something special about the gadget that \"just works.\" Technology can open opportunities for those devices but also complicate and weigh down products that have done just fine without things like sensors and software. So when a product like the beloved Rubik’s Cube gets stuffed with wires, processors, and rechargeable batteries, there’s demand for it to be not just on par with the original—but markedly better. The Cubios Rubik’s WOWCube successfully breathes fresh life into the classic puzzle, but it’s also an example of when too much technology can cannibalize a gadget’s main appeal.Read full article Comments",
          "feed_position": 12,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/lead-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/lead-1152x648.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_120",
      "coverage": 1,
      "updated_at": "Thu, 19 Feb 2026 19:38:08 +0000",
      "title": "From chickens to humans, animals think \"bouba\" sounds round",
      "neutral_headline": "From chickens to humans, animals think \"bouba\" sounds round",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/02/newly-hatched-chickens-form-the-same-sound-association-we-do/",
          "published_at": "Thu, 19 Feb 2026 19:38:08 +0000",
          "title": "From chickens to humans, animals think \"bouba\" sounds round",
          "standfirst": "There seems to be a deep-seated association between sounds and shapes.",
          "content": "Does \"bouba\" sound round to you? How about \"maluma\"? Neither are real words, but we've known for decades that people who hear them tend to associate them with round objects. There have been plenty of ideas put forward about why that would be the case, and most of them have turned out to be wrong. Now, in perhaps the weirdest bit of evidence to date, researchers have found that even newly hatched chickens seem to associate \"bouba\" with round shapes. The initial finding dates all the way back to 1947, when someone discovered that people associated some word-like sounds with rounded shapes, and others with spiky ones. In the years since, that association got formalized as the bouba/kiki effect, received a fair bit of experimental attention, and ended up with an extensive Wikipedia entry. One of the initial ideas to explain it was similarity to actual words (either phonetically or via the characters used to spell them), but then studies with speakers of different languages and alphabets showed that it is likely a general human tendency. The association also showed up in infants as young as 4 months old, well before they master speaking or spelling. Attempts to find the bouba/kiki effects in other primates, however, came up empty. That led to some speculation that it might be evidence of a strictly human processing ability that underlies our capacity to learn sophisticated languages.Read full article Comments",
          "feed_position": 14,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-104303509-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-104303509-1152x648.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_130",
      "coverage": 1,
      "updated_at": "Thu, 19 Feb 2026 16:26:34 +0000",
      "title": "Zero grip, maximum fun: A practical guide to getting into amateur ice racing",
      "neutral_headline": "Zero grip, maximum fun: A practical guide to getting into amateur ice racing",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2026/02/zero-grip-maximum-fun-a-practical-guide-to-getting-into-amateur-ice-racing/",
          "published_at": "Thu, 19 Feb 2026 16:26:34 +0000",
          "title": "Zero grip, maximum fun: A practical guide to getting into amateur ice racing",
          "standfirst": "Where we're racing, we don't need roads.",
          "content": "In Formula One, grip is everything. The world's best engineers devote their careers to designing cars that maximize downforce and grip to squeeze every bit of performance out of a set of four humble tires. These cars punish their drivers by slinging them at six Gs through corners and offer similar levels of abuse in braking. It's all wildly impressive, but I've long maintained that those drivers are not the ones having the most fun. When it comes to sheer enjoyment, grip is highly overrated, and if you want proof of that, you need to try ice racing. Should you be lucky enough to live somewhere that gets cold enough consistently enough, all you need is a good set of tires and a car that's willing and able. That, of course, and a desire to spend more time driving sideways than straight. I've been ice racing for well over 20 years now, and I'm here to tell you that there's no greater thrill on four wheels than sliding through a corner a few inches astern of a hard-charging competitor.Read full article Comments",
          "feed_position": 17,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/2026-Ice-Racing-005-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/2026-Ice-Racing-005-1152x648.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_136",
      "coverage": 1,
      "updated_at": "Thu, 19 Feb 2026 13:32:52 +0000",
      "title": "Rare gifted word-learner dogs like to share their toys",
      "neutral_headline": "Rare gifted word-learner dogs like to share their toys",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/02/rare-gifted-word-learner-dogs-like-to-share-their-toys/",
          "published_at": "Thu, 19 Feb 2026 13:32:52 +0000",
          "title": "Rare gifted word-learner dogs like to share their toys",
          "standfirst": "\"It raises the possibility that social motivation plays a role in why some dogs end up learning object names.\"",
          "content": "We love hearing about the latest findings coming out of an Eötvös Loránd University (ELU) research group focused on gifted word learner (GWL) dogs—if only for the pictures of adorable doggoes playing with their toys. Just last month, we learned that such dogs can learn the labels for new toys just by overhearing their owners talking about those toys. The group is back with yet another new paper, published in the journal Animal Cognition, presenting evidence that GWL dogs have a preference for novel toys and like to share them with their owners. That social interaction seems to be the key to the unique cognitive abilities of these rare dogs. As previously reported, ELU co-author Claudia Fugazza has been studying canine behavior and cognition for several years as part of the Genius Dog Challenge. For instance, the group’s 2022 study discovered that dogs store key sensory features about their toys—notably what they look like and how they smell—and recall those features when searching for the named toy. Prior studies had suggested that dogs typically rely on vision, or a combination of sight and smell, to locate target objects. GWL dogs can also identify objects based on verbal labels. Last fall, Fugazza’s group discovered that certain dogs can not only memorize the names of objects like their favorite toys, but also extend those labels to entirely new objects with a similar function, regardless of whether or not they are similar in appearance. It’s a cognitively advanced ability known as “label extension,” and for animals to acquire it usually involves years of intensive training in captivity. But the dogs in this new study developed the ability to classify their toys by function with no formal training, merely by playing naturally with their owners. It’s akin to a person calling a hammer and a rock by the same name, or a child understanding that “cup” can describe a mug, a glass, or a tumbler because they serve the same function.Read full article Comments",
          "feed_position": 19,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/09/doggo5-1152x648-1771357654.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/09/doggo5-1152x648-1771357654.jpg",
      "popularity_score": 133
    }
  ]
}