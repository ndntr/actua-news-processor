{
  "updated_at": "2026-02-23T19:54:15.854Z",
  "clusters": [
    {
      "id": "cluster_6",
      "coverage": 2,
      "updated_at": "Mon, 23 Feb 2026 18:51:26 +0000",
      "title": "Falcon Northwest FragBox review: A compact gaming rig that does everything right",
      "neutral_headline": "Falcon Northwest FragBox review: A compact gaming rig that does everything right",
      "bullet_summary": [
        "\"There are truly no modifications to the architecture except for the addition of a special token,\" Kirchenbauer said",
        "The experiments revealed a clear sweet spot between speed and accuracy",
        "\"Our recommendation would be to tune/adapt the model for MTP using samples from the special industrial domain,\" Kirchenbauer said",
        "However, Kirchenbauer sees \"no clear barriers to integration\" and confirmed the team is \"working with some systems experts to identify the shortest path to integration"
      ],
      "items": [
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/falcon-northwest-fragbox-review-a-compact-gaming-rig-that-does-everything-right-130000837.html",
          "published_at": "Mon, 23 Feb 2026 18:51:26 +0000",
          "title": "Falcon Northwest FragBox review: A compact gaming rig that does everything right",
          "standfirst": "Mafia: The Old Country demands to be played on an enormous screen. As much as I love my 32-inch Alienware OLED gaming monitor, it doesn't do justice to Mafia's cinematic vistas of Sicily. But, I also wanted to play that game in its full 4K glory, with none of the compromises of today's game consoles. So why not just shove a tiny gaming desktop under my home theater? Enter the Fragbox, Falcon Northwest's revamped small form factor gaming PC. While it's very expensive, starting at $3,997, it's incredibly powerful and gives you the freedom to easily upgrade the hardware down the line. I know what you're thinking: \"A $4,000 desktop, in this economy?\" That pricing also doesn't include upgrading from the stock NVIDIA's RTX 5070 GPU, as well as adding more RAM and larger SSDs, all of which could drive the price up thousands more. I initially planned to review the FragBox back in early December 2025, before the AI-induced RAMaggedon made memory, storage and other components dramatically more expensive. Falcon Northwest is mainly known as a boutique and high-end system builder, so its wealthier clientele can likely weather the pricing storm. If you're looking for a deal, though, you won't find it here. So what, exactly, is a FragBox? Imagine a typical mid-tower desktop squashed down to a system that's only 10.2-inches tall, 10.5-inches wide and 15.9-inches deep. When Falcon initially debuted the FragBox in 2004, it was notable for being a genuinely small PC that used full-sized parts. That's still a main selling point today: It can still fit in large NVIDIA GPUs, including the beefy RTX 5090, as well as either Intel's latest Core Ultra chips or AMD's Ryzen 9000 CPUs. A huge 280mm radiator sits at the top pulling out hot air, and it also serves as an All-in-One (AIO) liquid cooler for the CPU. At 25 pounds, the FragBox isn't exactly light, but its sturdy metal handle makes it easy to move around. Most mid-tower desktops usually weigh between 20 and 35 pounds, depending on their case material. But they're also much larger and harder to squeeze into tight spaces. The FragBox's relatively squat size makes it easy to shove into a home entertainment center, or just sit on the corner of your desk. If you need a bit more height clearance, you can also remove the handle from the top panel. Just be sure there’s enough room for some airflow — all of that heat has to go somewhere, right? Falcon Northwest FragBox Devindra Hardawar for Engadget Despite its density, the FragBox's elegant design makes it a cinch to access to all of the system's components. Just unscrew the side and top panels and you can easily remove the GPU, RAM, storage and other major components. There are three slots of M.2 SSDs, as well as two locations for 2.5-inch drives and a spot for a large 3.5-inch HDD. The system is bundled with a 1,200W power supply, which should be more than enough to handle future GPUs and CPUs. Ports are plentiful as well: There are two USB-A and one USB-C connections right up front, alongside a headphone jack. On the rear, you've got your typical assortment of mid-tower connections, including four USB-A 2.0 connections, seven USB-A 3 ports, one 20G USB-C 3.2 port, 2.5G Ethernet, HDMI and DisplayPort. Our RTX 5090 review unit also included three DisplayPort jacks and one HDMI connection (which you'll see on most GPUs). Wi-Fi 6E was also built into our unit, but Falcon says that Wi-Fi 7 is now standard with new builds. Falcon Northwest FragBox Devindra Hardawar for Engadget The FragBox, thankfully, lacks the garish LEDs and cheesy thermal glass you find on more ostentatious gaming rigs. Falcon Northwest's aluminum case looks and feels stately, like an old-school luxury car. If you want something flashier, you can shell out an additional $400 for a custom UV printed case or $149 for a UV-printed front panel. Our review unit was equipped with AMD's Ryzen 9950X3D CPU, NVIDIA's RTX 5090, 96GB of DDR5 RAM and a 2TB SSD, which adds up to a whopping $7,995. Five months ago, it would have cost $7,047 —- you can thank the RAM shortage for the price jump. Even before benchmarking or running any games, I expected it to be a beast. In PCMark 10, the FragBox scored a whopping 13,810, which is around 500 points higher than my mid-tower system with the same CPU and GPU. It also scored the highest 3DMark Speedway and Port Royal ray tracing scores I've ever seen. Even more impressive, the FragBox's fans were barely audible under load, and the CPU and GPU sat at a chill 52C and 65C, respectively CPU GeekBench 6 CPU GeekBench 6 GPU Cinebench 2024 Falcon Northwest FragBox 3,445/22,787 390,148 N/A Desktop with AMD Ryzen 9 9950X3D, RTX 5090 3,366/18,950 381,400 134/2,124 Desktop with AMD Ryzen 9 7900X, RTX 5090 2,822/14,216 358,253 113/1,103 Apple Mac Studio M4 Max 4,090/26,394 116,028 190/2066 To get back to my initial point, it ran Mafia: The Old Country in 4K flawlessly, with every graphics setting cranked all the way up. While playing on my 120-inch projector home theater setup, the game reached 62 fps natively, and flipping on DLSS upscaling and frame generation bumped that up to 120 fps. Not that you need a super higher framerate for a slow-paced, mostly cinematic action game. I was just happy to be playing without any compromises — even the PS5 Pro can't reach the same level of graphical fidelity as the monstrously powerful RTX 5090. Falcon Northwest FragBox Devindra Hardawar for Engadget I'm no stranger to big-screen PC gaming, but previously I've had to run a laughably long HDMI cable from my desktop to make it work. I'm just too old for that mess now. And it also doesn't work consistently, especially at higher framerates, thanks to the massive bandwidth required to pump out 4K at high refresh rates. In-home game streaming is also an option, but that's not great when you're blowing games up to an enormous TV or projector screen. It's just too hard to ignore the imperfections of streaming compression. (Admittedly, I need to test newer high-bandwidth options, especially after I was impressed by NVIDIA's GeForce Now upgrade last year.) The FragBox also made it easy to jump into all of my recent Steam titles, including Mewgeneics and Arc Raiders on a big screen. Unfortunately, Windows itself remains a key stumbling block for home theater PC gaming. You'll still need to keep a keyboard and PC around to deal with the initial OS configuration. And even once I enabled Steam's Big Picture mode, which offers excellent controller options, I still occasionally had to deal with Windows Updates and other annoyances. Falcon Northwest FragBox Devindra Hardawar for Engadget Microsoft is currently trying to optimize Windows for gaming handhelds, and it's reportedly doing even more to make a future PC-powered Xbox feel more console-like. For now, though, using a Windows PC in your home theater doesn't feel much different than it did a decade ago. Steam is your savior, Windows is your enemy. Or you could just save thousands of dollars and buy a $500 PlayStation 5 or $700 PS5 Pro, instead. The latter will still get you smooth framerates and a healthy dose of ray tracing, without the annoyance of Windows, keyboards and mice. But if you just want a compact and insanely powerful gaming desktop, and you don't mind spending a premium, it's hard to deny that the FragBox gets everything right. Update 2/23, 1:48PM: Added updated information about Wi-Fi 7, handle removability and pricing.This article originally appeared on Engadget at https://www.engadget.com/computing/falcon-northwest-fragbox-review-a-compact-gaming-rig-that-does-everything-right-130000837.html?src=rss",
          "content": "Mafia: The Old Country demands to be played on an enormous screen. As much as I love my 32-inch Alienware OLED gaming monitor, it doesn't do justice to Mafia's cinematic vistas of Sicily. But, I also wanted to play that game in its full 4K glory, with none of the compromises of today's game consoles. So why not just shove a tiny gaming desktop under my home theater? Enter the Fragbox, Falcon Northwest's revamped small form factor gaming PC. While it's very expensive, starting at $3,997, it's incredibly powerful and gives you the freedom to easily upgrade the hardware down the line. I know what you're thinking: \"A $4,000 desktop, in this economy?\" That pricing also doesn't include upgrading from the stock NVIDIA's RTX 5070 GPU, as well as adding more RAM and larger SSDs, all of which could drive the price up thousands more. I initially planned to review the FragBox back in early December 2025, before the AI-induced RAMaggedon made memory, storage and other components dramatically more expensive. Falcon Northwest is mainly known as a boutique and high-end system builder, so its wealthier clientele can likely weather the pricing storm. If you're looking for a deal, though, you won't find it here. So what, exactly, is a FragBox? Imagine a typical mid-tower desktop squashed down to a system that's only 10.2-inches tall, 10.5-inches wide and 15.9-inches deep. When Falcon initially debuted the FragBox in 2004, it was notable for being a genuinely small PC that used full-sized parts. That's still a main selling point today: It can still fit in large NVIDIA GPUs, including the beefy RTX 5090, as well as either Intel's latest Core Ultra chips or AMD's Ryzen 9000 CPUs. A huge 280mm radiator sits at the top pulling out hot air, and it also serves as an All-in-One (AIO) liquid cooler for the CPU. At 25 pounds, the FragBox isn't exactly light, but its sturdy metal handle makes it easy to move around. Most mid-tower desktops usually weigh between 20 and 35 pounds, depending on their case material. But they're also much larger and harder to squeeze into tight spaces. The FragBox's relatively squat size makes it easy to shove into a home entertainment center, or just sit on the corner of your desk. If you need a bit more height clearance, you can also remove the handle from the top panel. Just be sure there’s enough room for some airflow — all of that heat has to go somewhere, right? Falcon Northwest FragBox Devindra Hardawar for Engadget Despite its density, the FragBox's elegant design makes it a cinch to access to all of the system's components. Just unscrew the side and top panels and you can easily remove the GPU, RAM, storage and other major components. There are three slots of M.2 SSDs, as well as two locations for 2.5-inch drives and a spot for a large 3.5-inch HDD. The system is bundled with a 1,200W power supply, which should be more than enough to handle future GPUs and CPUs. Ports are plentiful as well: There are two USB-A and one USB-C connections right up front, alongside a headphone jack. On the rear, you've got your typical assortment of mid-tower connections, including four USB-A 2.0 connections, seven USB-A 3 ports, one 20G USB-C 3.2 port, 2.5G Ethernet, HDMI and DisplayPort. Our RTX 5090 review unit also included three DisplayPort jacks and one HDMI connection (which you'll see on most GPUs). Wi-Fi 6E was also built into our unit, but Falcon says that Wi-Fi 7 is now standard with new builds. Falcon Northwest FragBox Devindra Hardawar for Engadget The FragBox, thankfully, lacks the garish LEDs and cheesy thermal glass you find on more ostentatious gaming rigs. Falcon Northwest's aluminum case looks and feels stately, like an old-school luxury car. If you want something flashier, you can shell out an additional $400 for a custom UV printed case or $149 for a UV-printed front panel. Our review unit was equipped with AMD's Ryzen 9950X3D CPU, NVIDIA's RTX 5090, 96GB of DDR5 RAM and a 2TB SSD, which adds up to a whopping $7,995. Five months ago, it would have cost $7,047 —- you can thank the RAM shortage for the price jump. Even before benchmarking or running any games, I expected it to be a beast. In PCMark 10, the FragBox scored a whopping 13,810, which is around 500 points higher than my mid-tower system with the same CPU and GPU. It also scored the highest 3DMark Speedway and Port Royal ray tracing scores I've ever seen. Even more impressive, the FragBox's fans were barely audible under load, and the CPU and GPU sat at a chill 52C and 65C, respectively CPU GeekBench 6 CPU GeekBench 6 GPU Cinebench 2024 Falcon Northwest FragBox 3,445/22,787 390,148 N/A Desktop with AMD Ryzen 9 9950X3D, RTX 5090 3,366/18,950 381,400 134/2,124 Desktop with AMD Ryzen 9 7900X, RTX 5090 2,822/14,216 358,253 113/1,103 Apple Mac Studio M4 Max 4,090/26,394 116,028 190/2066 To get back to my initial point, it ran Mafia: The Old Country in 4K flawlessly, with every graphics setting cranked all the way up. While playing on my 120-inch projector home theater setup, the game reached 62 fps natively, and flipping on DLSS upscaling and frame generation bumped that up to 120 fps. Not that you need a super higher framerate for a slow-paced, mostly cinematic action game. I was just happy to be playing without any compromises — even the PS5 Pro can't reach the same level of graphical fidelity as the monstrously powerful RTX 5090. Falcon Northwest FragBox Devindra Hardawar for Engadget I'm no stranger to big-screen PC gaming, but previously I've had to run a laughably long HDMI cable from my desktop to make it work. I'm just too old for that mess now. And it also doesn't work consistently, especially at higher framerates, thanks to the massive bandwidth required to pump out 4K at high refresh rates. In-home game streaming is also an option, but that's not great when you're blowing games up to an enormous TV or projector screen. It's just too hard to ignore the imperfections of streaming compression. (Admittedly, I need to test newer high-bandwidth options, especially after I was impressed by NVIDIA's GeForce Now upgrade last year.) The FragBox also made it easy to jump into all of my recent Steam titles, including Mewgeneics and Arc Raiders on a big screen. Unfortunately, Windows itself remains a key stumbling block for home theater PC gaming. You'll still need to keep a keyboard and PC around to deal with the initial OS configuration. And even once I enabled Steam's Big Picture mode, which offers excellent controller options, I still occasionally had to deal with Windows Updates and other annoyances. Falcon Northwest FragBox Devindra Hardawar for Engadget Microsoft is currently trying to optimize Windows for gaming handhelds, and it's reportedly doing even more to make a future PC-powered Xbox feel more console-like. For now, though, using a Windows PC in your home theater doesn't feel much different than it did a decade ago. Steam is your savior, Windows is your enemy. Or you could just save thousands of dollars and buy a $500 PlayStation 5 or $700 PS5 Pro, instead. The latter will still get you smooth framerates and a healthy dose of ray tracing, without the annoyance of Windows, keyboards and mice. But if you just want a compact and insanely powerful gaming desktop, and you don't mind spending a premium, it's hard to deny that the FragBox gets everything right. Update 2/23, 1:48PM: Added updated information about Wi-Fi 7, handle removability and pricing.This article originally appeared on Engadget at https://www.engadget.com/computing/falcon-northwest-fragbox-review-a-compact-gaming-rig-that-does-everything-right-130000837.html?src=rss",
          "feed_position": 2,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/falcon_northwest_fragbox_2.jpg"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/researchers-baked-3x-inference-speedups-directly-into-llm-weights-without",
          "published_at": "Mon, 23 Feb 2026 17:00:00 GMT",
          "title": "Researchers baked 3x inference speedups directly into LLM weights — without speculative decoding",
          "standfirst": "As agentic AI workflows multiply the cost and latency of long reasoning chains, a team from the University of Maryland, Lawrence Livermore National Labs, Columbia University and TogetherAI has found a way to bake 3x throughput gains directly into a model&#x27;s weights.Unlike speculative decoding, which requires a separate drafting model, this approach requires no additional infrastructure — just a single special token added to the model&#x27;s existing architecture.The limits of next-token predictionNext-token prediction — generating text one token per forward pass — creates a throughput ceiling that becomes painfully expensive when models need to produce thousands of tokens. This bottleneck is especially problematic in reasoning models, which frequently generate thousands of “chain of thought” tokens before producing the final response, leading to a slow and expensive user experience.Multi-token prediction (MTP) offers an alternative training paradigm that allows a language model to produce multiple tokens simultaneously in a single forward pass. For example, the model can be trained to predict a block of tokens all at once instead of just the immediate next token.John Kirchenbauer, a doctorate candidate in computer science at the University of Maryland and co-author of the paper, told VentureBeat that as we move toward agentic workflows, the focus is shifting from overall throughput to single-user speed. \"Today, with ultra-long thinking traces being the norm and agentic outer loops multiplying out those costs even further, latency is becoming as equally important a dimension of overall serving efficiency as gross tokens per second per hardware unit (tps/GPU),\" Kirchenbauer said. He said that while standard batched next-token prediction is already optimal for overall throughput, the new approach \"strive[s] to saturate the GPU with just a single user&#x27;s query to decrease latency for that single user.\"Other methods exist, but they come with drawbacks. \"It&#x27;s worth noting that speculative decoding, and diffusion LLMs as an efficiency focused alternative to next token prediction (NTP), are both latency focused acceleration techniques,\" Kirchenbauer said. But speculative decoding requires deploying and managing an auxiliary \"drafting\" model, which spends more absolute compute to draft and verify. MTP, on the other hand, \"leverages a similar sort of tradeoff, it&#x27;s just simpler to serve and scientifically interesting in its own right.\"Current MTP paradigms have limitations, however. The standard objective for training a language model for MTP involves comparing its predictions against ground-truth text from a dataset. The pitfall is that this standard training teaches the model to predict the probability of a token at a specific position independently, rather than caring about the joint relationship between a sequence of tokens.If a model tries to predict multiple tokens at once using this standard method, two major problems occur. The first is grammatical mismatch. For example, if a model predicts two words following the prefix \"The zookeeper fed the,\" it might sample independently and produce a mismatched phrase like \"panda meat\" or \"lion bamboo\" instead of \"panda bamboo\" and “lion meat.”The second issue is degenerate repetition. Because typical text is unpredictable, a model trying to predict a token 100 positions into the future against a standard dataset will just predict \"the,\" since it is the most common word in English. This results in the model outputting nonsense like \"...the the the...\" for far-future positions.Multi-token prediction via self-distillationTo solve the issues of generating multiple tokens, the researchers propose a novel training technique that uses a student-teacher scheme. A student model, which is the model learning to predict multiple tokens, generates a deterministic multi-token block. A teacher model, acting as a strong standard next-token prediction language model, evaluates that block. The teacher acts as a critic, calculating how likely and coherent the student&#x27;s proposed sequence is. If the student proposes a mismatched phrase like \"lion bamboo,\" the teacher assigns it a high loss, teaching the student to avoid that construction.The paradigm is inspired by on-policy reinforcement learning because the student model is not simply memorizing static text. It generates a full rollout (sequence of actions in RL parlance) instantly in parallel on a single forward pass and receives a reward based on how good the teacher thinks it is. Unlike static supervised methods where training pairs are fixed in advance, the feedback here is dynamic, generated from the student&#x27;s own outputs in real time. The strong teacher also verifies the coherence of the tokens, which prevents the student model from learning degenerate outputs like repeated words.For developers, the beauty of this approach lies in its simplicity. \"There are truly no modifications to the architecture except for the addition of a special token,\" Kirchenbauer said. By co-opting an unused slot in a model&#x27;s existing embedding matrix to act as an <MTP> mask token, the technique converts sequential operations into parallel ones. \"Any standard next token prediction language model can be adapted in this way... the internal implementation — MoE, windowed attention, SSM layers, etc. — are left untouched and present no barrier to adaptation.\"For engineering teams, this means the adaptation can be applied to models already in production without rebuilding pipelines. Generating multiple tokens at the same time can still hurt the accuracy of the response at inference time. To maximize generation speed without sacrificing the quality of the output, the authors introduce an adaptive decoding strategy called ConfAdapt.ConfAdapt evaluates a confidence threshold, such as 90%, at each step. The model generates a block of tokens, but it only keeps the tokens that meet or exceed this high-confidence threshold. When the upcoming text is highly predictable or structural, the model&#x27;s confidence is very high. It will accept and output a large chunk of tokens all at once, saving significant computational time on easy tokens. It then focuses its costly single-token passes on harder tokens that require more computational effort.Putting multi-token prediction to the testTo see how the training paradigm performed in practice, the researchers applied their method to popular open-weight instruction-tuned models. They tested the strong general-purpose model Llama-3.1-8B-Magpie and the smaller, efficient Qwen3-4B-Instruct-2507, which is often chosen for cost-sensitive enterprise deployments. Both models were tuned on MetaMathQA, a dataset of synthetic grade school math problems that rely heavily on reasoning traces.The experiments revealed a clear sweet spot between speed and accuracy. Using the ConfAdapt strategy, the Llama-3.1-8B model achieved a 3x speedup with less than a 3% drop in accuracy on math benchmarks. The Qwen3-4B model achieved the same 3x speedup with a slightly higher 7% drop in accuracy. More aggressive settings could hit 5x speedups, though they came with steeper accuracy penalties.How this translates to real-world tasks depends on predictability. \"As the ConfAdapt approach naturally tailors the acceleration to the inherent entropy in the domain, when the model &#x27;knows&#x27; exactly what comes next it can emit it in a single pass,\" he noted, leading to massive acceleration on predictable tasks, while using more steps for uncertain outputs.The speedups also transferred across domains that were not included in the multi-token prediction training phase. This included tasks within the same domain as the training data, like math and reasoning, as well as open-ended tasks such as creative writing and summarization.Despite this transfer learning, enterprises deploying these models for specialized tasks shouldn&#x27;t rely on it entirely. \"Our recommendation would be to tune/adapt the model for MTP using samples from the special industrial domain,\" Kirchenbauer said. \"The best performance is likely achieved if the MTP adaptation is performed using prompts from the deployment domain.\"Serving compatibility and the road aheadThe research team released their trained models on Hugging Face and will soon release the code for their MTP framework. Infrastructure teams integrating these models into vLLM or SGLang will need to account for changes in how batching and KV caching are handled — but that&#x27;s a one-time engineering investment, not an ongoing burden. However, Kirchenbauer sees \"no clear barriers to integration\" and confirmed the team is \"working with some systems experts to identify the shortest path to integration.\"Kirchenbauer&#x27;s advice for teams wanting to test the released models: start with toy prompts like counting or repeating a phrase to see ConfAdapt&#x27;s gains in action, then adapt the model using samples from your specific deployment domain for best results. \"Overall we do expect that a production-ready implementation of our approach could simplify the lifecycle of building and deploying low-latency agentic models,\" Kirchenbauer concluded. \"While existing acceleration techniques for NTP models focus almost solely on inference harnesses and logic, our approach just bakes some of the complexity into the model itself making it largely complementary to existing work.\"",
          "content": "As agentic AI workflows multiply the cost and latency of long reasoning chains, a team from the University of Maryland, Lawrence Livermore National Labs, Columbia University and TogetherAI has found a way to bake 3x throughput gains directly into a model&#x27;s weights.Unlike speculative decoding, which requires a separate drafting model, this approach requires no additional infrastructure — just a single special token added to the model&#x27;s existing architecture.The limits of next-token predictionNext-token prediction — generating text one token per forward pass — creates a throughput ceiling that becomes painfully expensive when models need to produce thousands of tokens. This bottleneck is especially problematic in reasoning models, which frequently generate thousands of “chain of thought” tokens before producing the final response, leading to a slow and expensive user experience.Multi-token prediction (MTP) offers an alternative training paradigm that allows a language model to produce multiple tokens simultaneously in a single forward pass. For example, the model can be trained to predict a block of tokens all at once instead of just the immediate next token.John Kirchenbauer, a doctorate candidate in computer science at the University of Maryland and co-author of the paper, told VentureBeat that as we move toward agentic workflows, the focus is shifting from overall throughput to single-user speed. \"Today, with ultra-long thinking traces being the norm and agentic outer loops multiplying out those costs even further, latency is becoming as equally important a dimension of overall serving efficiency as gross tokens per second per hardware unit (tps/GPU),\" Kirchenbauer said. He said that while standard batched next-token prediction is already optimal for overall throughput, the new approach \"strive[s] to saturate the GPU with just a single user&#x27;s query to decrease latency for that single user.\"Other methods exist, but they come with drawbacks. \"It&#x27;s worth noting that speculative decoding, and diffusion LLMs as an efficiency focused alternative to next token prediction (NTP), are both latency focused acceleration techniques,\" Kirchenbauer said. But speculative decoding requires deploying and managing an auxiliary \"drafting\" model, which spends more absolute compute to draft and verify. MTP, on the other hand, \"leverages a similar sort of tradeoff, it&#x27;s just simpler to serve and scientifically interesting in its own right.\"Current MTP paradigms have limitations, however. The standard objective for training a language model for MTP involves comparing its predictions against ground-truth text from a dataset. The pitfall is that this standard training teaches the model to predict the probability of a token at a specific position independently, rather than caring about the joint relationship between a sequence of tokens.If a model tries to predict multiple tokens at once using this standard method, two major problems occur. The first is grammatical mismatch. For example, if a model predicts two words following the prefix \"The zookeeper fed the,\" it might sample independently and produce a mismatched phrase like \"panda meat\" or \"lion bamboo\" instead of \"panda bamboo\" and “lion meat.”The second issue is degenerate repetition. Because typical text is unpredictable, a model trying to predict a token 100 positions into the future against a standard dataset will just predict \"the,\" since it is the most common word in English. This results in the model outputting nonsense like \"...the the the...\" for far-future positions.Multi-token prediction via self-distillationTo solve the issues of generating multiple tokens, the researchers propose a novel training technique that uses a student-teacher scheme. A student model, which is the model learning to predict multiple tokens, generates a deterministic multi-token block. A teacher model, acting as a strong standard next-token prediction language model, evaluates that block. The teacher acts as a critic, calculating how likely and coherent the student&#x27;s proposed sequence is. If the student proposes a mismatched phrase like \"lion bamboo,\" the teacher assigns it a high loss, teaching the student to avoid that construction.The paradigm is inspired by on-policy reinforcement learning because the student model is not simply memorizing static text. It generates a full rollout (sequence of actions in RL parlance) instantly in parallel on a single forward pass and receives a reward based on how good the teacher thinks it is. Unlike static supervised methods where training pairs are fixed in advance, the feedback here is dynamic, generated from the student&#x27;s own outputs in real time. The strong teacher also verifies the coherence of the tokens, which prevents the student model from learning degenerate outputs like repeated words.For developers, the beauty of this approach lies in its simplicity. \"There are truly no modifications to the architecture except for the addition of a special token,\" Kirchenbauer said. By co-opting an unused slot in a model&#x27;s existing embedding matrix to act as an <MTP> mask token, the technique converts sequential operations into parallel ones. \"Any standard next token prediction language model can be adapted in this way... the internal implementation — MoE, windowed attention, SSM layers, etc. — are left untouched and present no barrier to adaptation.\"For engineering teams, this means the adaptation can be applied to models already in production without rebuilding pipelines. Generating multiple tokens at the same time can still hurt the accuracy of the response at inference time. To maximize generation speed without sacrificing the quality of the output, the authors introduce an adaptive decoding strategy called ConfAdapt.ConfAdapt evaluates a confidence threshold, such as 90%, at each step. The model generates a block of tokens, but it only keeps the tokens that meet or exceed this high-confidence threshold. When the upcoming text is highly predictable or structural, the model&#x27;s confidence is very high. It will accept and output a large chunk of tokens all at once, saving significant computational time on easy tokens. It then focuses its costly single-token passes on harder tokens that require more computational effort.Putting multi-token prediction to the testTo see how the training paradigm performed in practice, the researchers applied their method to popular open-weight instruction-tuned models. They tested the strong general-purpose model Llama-3.1-8B-Magpie and the smaller, efficient Qwen3-4B-Instruct-2507, which is often chosen for cost-sensitive enterprise deployments. Both models were tuned on MetaMathQA, a dataset of synthetic grade school math problems that rely heavily on reasoning traces.The experiments revealed a clear sweet spot between speed and accuracy. Using the ConfAdapt strategy, the Llama-3.1-8B model achieved a 3x speedup with less than a 3% drop in accuracy on math benchmarks. The Qwen3-4B model achieved the same 3x speedup with a slightly higher 7% drop in accuracy. More aggressive settings could hit 5x speedups, though they came with steeper accuracy penalties.How this translates to real-world tasks depends on predictability. \"As the ConfAdapt approach naturally tailors the acceleration to the inherent entropy in the domain, when the model &#x27;knows&#x27; exactly what comes next it can emit it in a single pass,\" he noted, leading to massive acceleration on predictable tasks, while using more steps for uncertain outputs.The speedups also transferred across domains that were not included in the multi-token prediction training phase. This included tasks within the same domain as the training data, like math and reasoning, as well as open-ended tasks such as creative writing and summarization.Despite this transfer learning, enterprises deploying these models for specialized tasks shouldn&#x27;t rely on it entirely. \"Our recommendation would be to tune/adapt the model for MTP using samples from the special industrial domain,\" Kirchenbauer said. \"The best performance is likely achieved if the MTP adaptation is performed using prompts from the deployment domain.\"Serving compatibility and the road aheadThe research team released their trained models on Hugging Face and will soon release the code for their MTP framework. Infrastructure teams integrating these models into vLLM or SGLang will need to account for changes in how batching and KV caching are handled — but that&#x27;s a one-time engineering investment, not an ongoing burden. However, Kirchenbauer sees \"no clear barriers to integration\" and confirmed the team is \"working with some systems experts to identify the shortest path to integration.\"Kirchenbauer&#x27;s advice for teams wanting to test the released models: start with toy prompts like counting or repeating a phrase to see ConfAdapt&#x27;s gains in action, then adapt the model using samples from your specific deployment domain for best results. \"Overall we do expect that a production-ready implementation of our approach could simplify the lifecycle of building and deploying low-latency agentic models,\" Kirchenbauer concluded. \"While existing acceleration techniques for NTP models focus almost solely on inference harnesses and logic, our approach just bakes some of the complexity into the model itself making it largely complementary to existing work.\"",
          "feed_position": 0,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/7lB8UaMsO4LhTkCf5Tf7Yf/40524ebbaf93e89ba37322f9753fdd03/multi-token_prediction.jpg?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/security/anthropic-claude-code-security-reasoning-vulnerability-hunting",
          "published_at": "Mon, 23 Feb 2026 15:44:00 GMT",
          "title": "Anthropic's Claude Code Security is available now after finding 500+ vulnerabilities: how security leaders should respond",
          "standfirst": "Anthropic pointed its most advanced AI model, Claude Opus 4.6, at production open-source codebases and found a plethora of security holes: more than 500 high-severity vulnerabilities that had survived decades of expert review and millions of hours of fuzzing, with each candidate vetted through internal and external security review before disclosure. Fifteen days later, the company productized the capability and launched Claude Code Security.Security directors responsible for seven-figure vulnerability management stacks should expect a common question from their boards in the next review cycle. VentureBeat anticipates the emails and conversations will start with, \"How do we add reasoning-based scanning before attackers get there first?\", because as Anthropic&#x27;s review found, simply pointing an AI model at exposed code can be enough to identify — and in the case of malicious actors, exploit — security lapses in production code. The answer matters more than the number, and it is primarily structural: how your tooling and processes allocate work between pattern-based scanners and reasoning-based analysis. CodeQL and the tools built on it match code against known patterns. Claude Code Security, which Anthropic launched February 20 as a limited research preview, reasons about code the way a human security researcher would. It follows how data moves through an application and catches flaws in business logic and access control that no rule set covers.The board conversation security leaders need to have this weekFive hundred newly discovered zero-days is less a scare statistic than a standing budget justification for rethinking how you fund code security. The reasoning capability Claude Code Security represents, and its inevitable competitors, need to drive the procurement conversation. Static application security testing (SAST) catches known vulnerability classes. Reasoning-based scanners find what pattern-matching was never designed to detect. Both have a role.Anthropic published the zero-day research on February 5. Fifteen days later, they shipped the product. While it&#x27;s the same model and capabilities, it is now available to Enterprise and Team customers.What Claude does that CodeQL couldn&#x27;tGitHub has offered CodeQL-based scanning through Advanced Security for years, and added Copilot Autofix in August 2024 to generate LLM-suggested fixes for alerts. Security teams rely on it. But the detection boundary is the CodeQL rule set, and everything outside that boundary stays invisible.Claude Code Security extends that boundary by generating and testing its own hypotheses about how data and control flow through an application, including cases where no existing rule set describes. CodeQL solves the problem it was built to solve: data-flow analysis within predefined queries. It tells you whether tainted input reaches a dangerous function.CodeQL is not designed to autonomously read a project&#x27;s commit history, infer an incomplete patch, trace that logic into another file, and then assemble a working proof-of-concept exploit end to end. Claude did exactly that on GhostScript, OpenSC, and CGIF, each time using a different reasoning strategy.\"The real shift is from pattern-matching to hypothesis generation,\" said Merritt Baer, CSO at Enkrypt AI, advisor to Andesite and AppOmni, and former Deputy CISO at AWS, in an exclusive interview with VentureBeat. \"That&#x27;s a step-function increase in discovery power, and it demands equally strong human and technical controls.\"Three proof points from Anthropic&#x27;s published methodology show where pattern-matching ends and hypothesis generation begins.Commit history analysis across files. GhostScript is a widely deployed utility for processing PostScript and PDF files. Fuzzing turned up nothing, and neither did manual analysis. Then Claude pulled the Git commit history, found a patch that added stack bounds checking for font handling in gstype1.c, and reversed the logic: if the fix was needed there, every other call to that function without the fix was still vulnerable. In gdevpsfx.c, a completely different file, the call to the same function lacked the bounds checking patched elsewhere. Claude built a working proof-of-concept crash. No CodeQL rule describes that bug today. The maintainers have since patched it.Reasoning about preconditions that fuzzers can&#x27;t reach. OpenSC processes smart card data. Standard approaches failed here, too, so Claude searched the repository for function calls that are frequently vulnerable and found a location where multiple strcat operations ran in succession without length checking on the output buffer. Fuzzers rarely reached that code path because too many preconditions stood in the way. Claude reasoned about which code fragments looked interesting, constructed a buffer overflow, and proved the vulnerability.Algorithm-level edge cases that no coverage metric catches. CGIF is a library for processing GIF files. This vulnerability required understanding how LZW compression builds a dictionary of tokens. CGIF assumed compressed output would always be smaller than uncompressed input, which is almost always true. Claude recognized that if the LZW dictionary filled up and triggered resets, the compressed output could exceed the uncompressed size, overflowing the buffer. Even 100% branch coverage wouldn&#x27;t catch this. The flaw demands a particular sequence of operations that exercises an edge case in the compression algorithm itself. Random input generation almost never produces it. Claude did.Baer sees something broader in that progression. \"The challenge with reasoning isn&#x27;t accuracy, it&#x27;s agency,\" she told VentureBeat. \"Once a system can form hypotheses and pursue them, you&#x27;ve shifted from a lookup tool to something that can explore your environment in ways that are harder to predict and constrain.\"How Anthropic validated 500+ findingsAnthropic placed Claude inside a sandboxed virtual machine with standard utilities and vulnerability analysis tools. The red team didn&#x27;t provide any specialized instructions, custom harnesses, or task-specific prompting. Just the model and the code.The red team focused on memory corruption vulnerabilities because they&#x27;re the easiest to confirm objectively. Crash monitoring and address sanitizers don&#x27;t leave room for debate. Claude filtered its own output, deduplicating and reprioritizing before human researchers touched anything. When the confirmed count kept climbing, Anthropic brought in external security professionals to validate findings and write patches.Every target was an open-source project underpinning enterprise systems and critical infrastructure. Small teams maintain many of them, staffed by volunteers, not security professionals. When a vulnerability sits in one of these projects for a decade, every product that pulls from it inherits the risk.Anthropic didn&#x27;t start with the product launch. The defensive research spans more than a year. The company entered Claude in competitive Capture-the-Flag events where it ranked in the top 3% of PicoCTF globally, solved 19 of 20 challenges in the HackTheBox AI vs Human CTF, and placed 6th out of 9 teams defending live networks against human red team attacks at Western Regional CCDC. Anthropic also partnered with Pacific Northwest National Laboratory to test Claude against a simulated water treatment plant. PNNL&#x27;s researchers estimated that the model completed adversary emulation in three hours. The traditional process takes multiple weeks.The dual-use question security leaders can&#x27;t avoidThe same reasoning that finds a vulnerability can help an attacker exploit one. Frontier Red Team leader Logan Graham acknowledged this directly to Fortune&#x27;s Sharon Goldman. He told Fortune the models can now explore codebases autonomously and follow investigative leads faster than a junior security researcher.Gabby Curtis, Anthropic&#x27;s communications lead, told VentureBeat in an exclusive interview the company built Claude Code Security to make defensive capabilities more widely available, \"tipping the scales towards defenders.\" She was equally direct about the tension: \"The same reasoning that helps Claude find and fix a vulnerability could help an attacker exploit it, so we&#x27;re being deliberate about how we release this.\"In interviews with more than 40 CISOs across industries, VentureBeat found that formal governance frameworks for reasoning-based scanning tools are the exception, not the norm. The most common responses are that the area was considered so nascent that many CISOs didn&#x27;t think this capability would arrive so early in 2026.The question every security director has to answer before deploying this: if I give my team a tool that finds zero-days through reasoning, have I unintentionally expanded my internal threat surface?\"You didn&#x27;t weaponize your internal surface, you revealed it,\" Baer told VentureBeat. \"These tools can be helpful, but they also may surface latent risk faster and more scalably. The same tool that finds zero-days for defense can expose gaps in your threat model. Keep in mind that most intrusions don&#x27;t come from zero-days, they come from misconfigurations.\"\"In addition to the access and attack path risk, there is IP risk,\" she said. \"Not just exfiltration, but transformation. Reasoning models can internalize and re-express proprietary insights in ways that blur the line between use and leakage.\"The release is deliberately constrained. Enterprise and Team customers only, through a limited research preview. Open-source maintainers apply for free expedited access. Findings go through multi-stage self-verification before reaching an analyst, with severity ratings and confidence scores attached. Every patch requires human approval.Anthropic also built detection into the model itself. In a blog post detailing the safeguards, the company described deploying probes that measure activations within the model as it generates responses, with new cyber-specific probes designed to track potential misuse. On the enforcement side, Anthropic is expanding its response capabilities to include real-time intervention, including blocking traffic it detects as malicious.Graham was direct with Axios: the models are extremely good at finding vulnerabilities, and he expects them to get much better still. VentureBeat asked Anthropic for the false-positive rate before and after self-verification, the number of disclosed vulnerabilities with patches landed versus still in triage, and the specific safeguards that distinguish attacker use from defender use. The lead researcher on the 500-vulnerability project was unavailable, and the company declined to share specific attacker-detection mechanisms to avoid tipping off threat actors.\"Offense and defense are converging in capability,\" Baer said. \"The differentiator is oversight. If you can&#x27;t audit and bound how the tool is used, you&#x27;ve created another risk.\"That speed advantage doesn&#x27;t favor defenders by default. It favors whoever adopts it first. Security directors who move early set the terms.Anthropic isn&#x27;t alone. The pattern is repeating.Security researcher Sean Heelan used OpenAI&#x27;s o3 model with no custom tooling and no agentic framework to discover CVE-2025-37899, a previously unknown use-after-free vulnerability in the Linux kernel&#x27;s SMB implementation. The model analyzed over 12,000 lines of code and identified a race condition that traditional static analysis tools consistently missed because detecting it requires understanding concurrent thread interactions across connections.Separately, AI security startup AISLE discovered all 12 zero-day vulnerabilities announced in OpenSSL&#x27;s January 2026 security patch, including a rare high-severity finding (CVE-2025-15467, a stack buffer overflow in CMS message parsing that is potentially remotely exploitable without valid key material). AISLE co-founder and chief scientist Stanislav Fort reported that his team&#x27;s AI system accounted for 13 of the 14 total OpenSSL CVEs assigned in 2025. OpenSSL is among the most scrutinized cryptographic libraries on the planet. Fuzzers have run against it for years. The AI found what they were not designed to find.The window is already openThose 500 vulnerabilities live in open-source projects that enterprise applications depend on. Anthropic is disclosing and patching, but the window between discovery and adoption of those patches is where attackers operate today.The same model improvements behind Claude Code Security are available to anyone with API access.If your team is evaluating these capabilities, the limited research preview is the right place to start, with clearly defined data handling rules, audit logging, and success criteria agreed up front.",
          "content": "Anthropic pointed its most advanced AI model, Claude Opus 4.6, at production open-source codebases and found a plethora of security holes: more than 500 high-severity vulnerabilities that had survived decades of expert review and millions of hours of fuzzing, with each candidate vetted through internal and external security review before disclosure. Fifteen days later, the company productized the capability and launched Claude Code Security.Security directors responsible for seven-figure vulnerability management stacks should expect a common question from their boards in the next review cycle. VentureBeat anticipates the emails and conversations will start with, \"How do we add reasoning-based scanning before attackers get there first?\", because as Anthropic&#x27;s review found, simply pointing an AI model at exposed code can be enough to identify — and in the case of malicious actors, exploit — security lapses in production code. The answer matters more than the number, and it is primarily structural: how your tooling and processes allocate work between pattern-based scanners and reasoning-based analysis. CodeQL and the tools built on it match code against known patterns. Claude Code Security, which Anthropic launched February 20 as a limited research preview, reasons about code the way a human security researcher would. It follows how data moves through an application and catches flaws in business logic and access control that no rule set covers.The board conversation security leaders need to have this weekFive hundred newly discovered zero-days is less a scare statistic than a standing budget justification for rethinking how you fund code security. The reasoning capability Claude Code Security represents, and its inevitable competitors, need to drive the procurement conversation. Static application security testing (SAST) catches known vulnerability classes. Reasoning-based scanners find what pattern-matching was never designed to detect. Both have a role.Anthropic published the zero-day research on February 5. Fifteen days later, they shipped the product. While it&#x27;s the same model and capabilities, it is now available to Enterprise and Team customers.What Claude does that CodeQL couldn&#x27;tGitHub has offered CodeQL-based scanning through Advanced Security for years, and added Copilot Autofix in August 2024 to generate LLM-suggested fixes for alerts. Security teams rely on it. But the detection boundary is the CodeQL rule set, and everything outside that boundary stays invisible.Claude Code Security extends that boundary by generating and testing its own hypotheses about how data and control flow through an application, including cases where no existing rule set describes. CodeQL solves the problem it was built to solve: data-flow analysis within predefined queries. It tells you whether tainted input reaches a dangerous function.CodeQL is not designed to autonomously read a project&#x27;s commit history, infer an incomplete patch, trace that logic into another file, and then assemble a working proof-of-concept exploit end to end. Claude did exactly that on GhostScript, OpenSC, and CGIF, each time using a different reasoning strategy.\"The real shift is from pattern-matching to hypothesis generation,\" said Merritt Baer, CSO at Enkrypt AI, advisor to Andesite and AppOmni, and former Deputy CISO at AWS, in an exclusive interview with VentureBeat. \"That&#x27;s a step-function increase in discovery power, and it demands equally strong human and technical controls.\"Three proof points from Anthropic&#x27;s published methodology show where pattern-matching ends and hypothesis generation begins.Commit history analysis across files. GhostScript is a widely deployed utility for processing PostScript and PDF files. Fuzzing turned up nothing, and neither did manual analysis. Then Claude pulled the Git commit history, found a patch that added stack bounds checking for font handling in gstype1.c, and reversed the logic: if the fix was needed there, every other call to that function without the fix was still vulnerable. In gdevpsfx.c, a completely different file, the call to the same function lacked the bounds checking patched elsewhere. Claude built a working proof-of-concept crash. No CodeQL rule describes that bug today. The maintainers have since patched it.Reasoning about preconditions that fuzzers can&#x27;t reach. OpenSC processes smart card data. Standard approaches failed here, too, so Claude searched the repository for function calls that are frequently vulnerable and found a location where multiple strcat operations ran in succession without length checking on the output buffer. Fuzzers rarely reached that code path because too many preconditions stood in the way. Claude reasoned about which code fragments looked interesting, constructed a buffer overflow, and proved the vulnerability.Algorithm-level edge cases that no coverage metric catches. CGIF is a library for processing GIF files. This vulnerability required understanding how LZW compression builds a dictionary of tokens. CGIF assumed compressed output would always be smaller than uncompressed input, which is almost always true. Claude recognized that if the LZW dictionary filled up and triggered resets, the compressed output could exceed the uncompressed size, overflowing the buffer. Even 100% branch coverage wouldn&#x27;t catch this. The flaw demands a particular sequence of operations that exercises an edge case in the compression algorithm itself. Random input generation almost never produces it. Claude did.Baer sees something broader in that progression. \"The challenge with reasoning isn&#x27;t accuracy, it&#x27;s agency,\" she told VentureBeat. \"Once a system can form hypotheses and pursue them, you&#x27;ve shifted from a lookup tool to something that can explore your environment in ways that are harder to predict and constrain.\"How Anthropic validated 500+ findingsAnthropic placed Claude inside a sandboxed virtual machine with standard utilities and vulnerability analysis tools. The red team didn&#x27;t provide any specialized instructions, custom harnesses, or task-specific prompting. Just the model and the code.The red team focused on memory corruption vulnerabilities because they&#x27;re the easiest to confirm objectively. Crash monitoring and address sanitizers don&#x27;t leave room for debate. Claude filtered its own output, deduplicating and reprioritizing before human researchers touched anything. When the confirmed count kept climbing, Anthropic brought in external security professionals to validate findings and write patches.Every target was an open-source project underpinning enterprise systems and critical infrastructure. Small teams maintain many of them, staffed by volunteers, not security professionals. When a vulnerability sits in one of these projects for a decade, every product that pulls from it inherits the risk.Anthropic didn&#x27;t start with the product launch. The defensive research spans more than a year. The company entered Claude in competitive Capture-the-Flag events where it ranked in the top 3% of PicoCTF globally, solved 19 of 20 challenges in the HackTheBox AI vs Human CTF, and placed 6th out of 9 teams defending live networks against human red team attacks at Western Regional CCDC. Anthropic also partnered with Pacific Northwest National Laboratory to test Claude against a simulated water treatment plant. PNNL&#x27;s researchers estimated that the model completed adversary emulation in three hours. The traditional process takes multiple weeks.The dual-use question security leaders can&#x27;t avoidThe same reasoning that finds a vulnerability can help an attacker exploit one. Frontier Red Team leader Logan Graham acknowledged this directly to Fortune&#x27;s Sharon Goldman. He told Fortune the models can now explore codebases autonomously and follow investigative leads faster than a junior security researcher.Gabby Curtis, Anthropic&#x27;s communications lead, told VentureBeat in an exclusive interview the company built Claude Code Security to make defensive capabilities more widely available, \"tipping the scales towards defenders.\" She was equally direct about the tension: \"The same reasoning that helps Claude find and fix a vulnerability could help an attacker exploit it, so we&#x27;re being deliberate about how we release this.\"In interviews with more than 40 CISOs across industries, VentureBeat found that formal governance frameworks for reasoning-based scanning tools are the exception, not the norm. The most common responses are that the area was considered so nascent that many CISOs didn&#x27;t think this capability would arrive so early in 2026.The question every security director has to answer before deploying this: if I give my team a tool that finds zero-days through reasoning, have I unintentionally expanded my internal threat surface?\"You didn&#x27;t weaponize your internal surface, you revealed it,\" Baer told VentureBeat. \"These tools can be helpful, but they also may surface latent risk faster and more scalably. The same tool that finds zero-days for defense can expose gaps in your threat model. Keep in mind that most intrusions don&#x27;t come from zero-days, they come from misconfigurations.\"\"In addition to the access and attack path risk, there is IP risk,\" she said. \"Not just exfiltration, but transformation. Reasoning models can internalize and re-express proprietary insights in ways that blur the line between use and leakage.\"The release is deliberately constrained. Enterprise and Team customers only, through a limited research preview. Open-source maintainers apply for free expedited access. Findings go through multi-stage self-verification before reaching an analyst, with severity ratings and confidence scores attached. Every patch requires human approval.Anthropic also built detection into the model itself. In a blog post detailing the safeguards, the company described deploying probes that measure activations within the model as it generates responses, with new cyber-specific probes designed to track potential misuse. On the enforcement side, Anthropic is expanding its response capabilities to include real-time intervention, including blocking traffic it detects as malicious.Graham was direct with Axios: the models are extremely good at finding vulnerabilities, and he expects them to get much better still. VentureBeat asked Anthropic for the false-positive rate before and after self-verification, the number of disclosed vulnerabilities with patches landed versus still in triage, and the specific safeguards that distinguish attacker use from defender use. The lead researcher on the 500-vulnerability project was unavailable, and the company declined to share specific attacker-detection mechanisms to avoid tipping off threat actors.\"Offense and defense are converging in capability,\" Baer said. \"The differentiator is oversight. If you can&#x27;t audit and bound how the tool is used, you&#x27;ve created another risk.\"That speed advantage doesn&#x27;t favor defenders by default. It favors whoever adopts it first. Security directors who move early set the terms.Anthropic isn&#x27;t alone. The pattern is repeating.Security researcher Sean Heelan used OpenAI&#x27;s o3 model with no custom tooling and no agentic framework to discover CVE-2025-37899, a previously unknown use-after-free vulnerability in the Linux kernel&#x27;s SMB implementation. The model analyzed over 12,000 lines of code and identified a race condition that traditional static analysis tools consistently missed because detecting it requires understanding concurrent thread interactions across connections.Separately, AI security startup AISLE discovered all 12 zero-day vulnerabilities announced in OpenSSL&#x27;s January 2026 security patch, including a rare high-severity finding (CVE-2025-15467, a stack buffer overflow in CMS message parsing that is potentially remotely exploitable without valid key material). AISLE co-founder and chief scientist Stanislav Fort reported that his team&#x27;s AI system accounted for 13 of the 14 total OpenSSL CVEs assigned in 2025. OpenSSL is among the most scrutinized cryptographic libraries on the planet. Fuzzers have run against it for years. The AI found what they were not designed to find.The window is already openThose 500 vulnerabilities live in open-source projects that enterprise applications depend on. Anthropic is disclosing and patching, but the window between discovery and adoption of those patches is where attackers operate today.The same model improvements behind Claude Code Security are available to anyone with API access.If your team is evaluating these capabilities, the limited research preview is the right place to start, with clearly defined data handling rules, audit logging, and success criteria agreed up front.",
          "feed_position": 1,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/4yR2yRPMyVDENsc3LePH0g/470f944f258db5254dc0ee056e52b1c9/hero_anthropic_story.jpg?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/laptops/best-affordable-windows-laptops-123000512.html",
          "published_at": "Mon, 23 Feb 2026 10:01:25 +0000",
          "title": "The best cheap Windows laptops for 2026",
          "standfirst": "You don’t need to spend a fortune to get a capable Windows laptop. For everyday tasks like web browsing, writing documents, streaming video or handling schoolwork, a well-chosen budget machine can still deliver a smooth, reliable experience. The challenge is cutting through the noise to find affordable options that balance performance, build quality and battery life without serious compromises.For many buyers, timing is no longer optional. With Windows 10 support now officially over, upgrading has become a necessity rather than a nice-to-have. The picks below focus on cheap Windows laptops that can handle day-to-day workloads comfortably while keeping you current on software and security updates. If you’re open to spending more for extra power or premium features, our broader guide to the best Windows laptops covers higher-end alternatives as well. What to look for in a budget-friendly Windows laptop While you can do a lot even when spending little on a Windows laptop, you must set your expectations accordingly. The biggest downside when purchasing a budget laptop (of any kind, really) is limited power. You’ll want to carefully consider a few specs, the most important among them being the processor (CPU). Many Windows laptops under $500 run on Intel Celeron or Pentium chipsets, but you can find some with Core i3/i5 and AMD Ryzen 3/5 CPUs at the higher end of the price spectrum. We recommend getting the most powerful CPU you can afford because it will dictate how fast the computer will feel overall. Memory (RAM) is also important because, the more you have, the easier it will be for the laptop to manage things like a dozen browser tabs while you edit a Word document and stream music in the background. When it comes to storage, consider how much you want to save locally. If you primarily work in Google Docs or save most things in the cloud, you may not need a machine with a ton of onboard storage. Just remember that your digital space will also be taken up by apps, so it may be worth getting a little extra storage than you think you need if you know you’ll be downloading big programs. A final side note: solid state drives (SSDs) are ubiquitous at this point, not to mention faster and more efficient than hard drives (HDDs), so we recommend getting a laptop with that type of storage. As for screens, there’s a healthy mix of HD (720p resolution) and FHD (1080p) options in this price range and we recommend springing for a notebook with a 1080p display if you can. Touchscreens aren’t as common in the budget space as standard panels, but you’ll only really miss one if you get a 2-in-1 laptop. Before we get to our recommended specs for a cheap Windows laptop, it’s worth mentioning that Microsoft clearly lays out the true minimum requirements for any Windows 11 machine. Those include a 1GHz or faster processor that includes two or more cores, at least 4GB of RAM and 64GB of available storage space. That’s the bare minimum to run Windows 11; we recommend giving yourself some wiggle room by choosing a machine that will perform well now and for years to come. Specs to look for in an affordable Windows laptop CPU: Intel Core i3 or AMD Ryzen 3 processors, at minimum RAM: At least 8GB Storage: At least 128GB SSD Screen: At least 1080p FHD It’s essential to prioritize what’s important to you. But at the lower end of the budget, a good laptop may not offer everything you need, whereas a great one might. Although most machines come with features like Bluetooth, built-in Wi-Fi and additional ports, you might find not all of them come with the specifics you require, like an SD card slot, webcam, charger, and so on. Be sure to check the spec list of any laptop you’re considering before you buy, especially if you need specific connectors and capabilities. See Also: Best Laptops for 2026 Best Gaming Laptops Best 2-in-1 Laptops for 2026 Best Chromebooks Best Laptops for College Students As for Copilot+, don’t expect to see much of it on truly affordable Windows laptops just yet. Microsoft’s AI features and Copilot assistant require certain specs to run, namely a powerful neural processing unit (NPU), 16GB of RAM and 256GB of storage. Currently, the cheapest Copilot+ AI PCs will run you about $700, so if you’re willing to pay more for those perks, check out our best laptops guide for more options. If you’re looking for either a gaming laptop or a “Windows on Arm” laptop, both categories will require you to spend more money than we’re discussing here. Best cheap Windows laptops for 2026 The cheap Windows laptop market moves fast, and — unlike nearly all of our other buying guides — we haven't necessarily tested each specific configuration listed below. However, the combination of these technical specifications and familiar brands represent exactly the sort of entry-level laptops we'd recommend to shoppers in this price range based on our thorough research and expert knowledge. What to know about the budget Windows laptop market The best cheap laptop models change all the time. Unlike more expensive, flagship machines, these notebooks can be updated a couple times each year. That can make it hard to track down a specific model at Amazon, Best Buy, Walmart or any other retailer. Also, we’ve seen prices vary widely depending on the configuration and retailer you’re looking at. You can ensure you’re getting a quality laptop by doing a few things. First and foremost, make sure you get a machine that follows the recommended specs we list above. Also, make sure you’re buying from a reputable retailer, including big-box stores like Walmart, Best Buy and Costco, online shops like Amazon or direct manufacturers like Dell, HP, Lenovo and others. If you have a physical store near you (likely a Best Buy in the US), it’s never a bad idea to go play around with some laptops in person before choosing one. If you decide to shop online from the likes of Amazon or Walmart, double check the seller of the laptop you’re considering. For example, many items on Amazon are “shipped and sold” by Amazon and those are typically the best options. You’ll see that information on Amazon on the right sidebar on a product page, under the Add to Cart and Buy Now buttons. Third-party sellers are common in the affordable laptop space. Amazon sometimes classifies laptop manufacturers as third-party sellers, so you may see a laptop shipped and sold by HP or Dell — that’s a good thing, since it’s coming directly from the manufacturer. However, there are other third-party electronics sellers out there. We recommend clicking on the third-party seller’s name on Amazon or Walmart (yes, Walmart has them, too) to see how much positive feedback and how many five-star ratings they’ve received from buyers. What about Chromebooks and tablets? You may be inclined to recommend a Chromebook or a tablet to anyone considering a budget Windows laptop computer. Those instincts aren’t wrong, but Chromebooks and tablets aren’t the best buy for everyone. Tablets have the most portability, but they will only work for the most mobile-competent users like kids who have been grabbing smartphones out of their parents’ hands since they’ve been dexterous enough to do so. Tablets can also be just as expensive as some of the cheapest Windows laptops, and that’s without a mouse or keyboard. Chromebooks are a good alternative for those that basically live in a browser, the trade-off being you must give up the “traditional desktop.” And Chrome OS is a more limited operating system than Windows when it comes to the programs you can install and run. What Windows laptops do well What can you realistically accomplish on a cheap Windows laptop? Quite a bit, especially if you’re doing one thing (or a limited number of things) at a time. They’re great for everyday tasks like web browsing, checking email, video streaming and more. All of those things can be done on Chromebooks as well, but Windows laptops have a big advantage in Microsoft Office. While yes, there is a browser based version, the native, desktop apps are considered a must have for many and will run smoothly on even the most bare-bones budget laptop. The only caveat is that you may run into some slowdown on low-powered devices if you’re multitasking or working with large data sets in Excel or a lot of photos and graphics in Powerpoint. When it comes to specs, a bright spot for Windows laptops is storage. Even the most affordable devices tend to have at least a 128GB solid state drive. That will come in handy if you prefer to keep your most important files saved locally on your laptop's hard drive. In contrast, cheaper Chromebooks often have less storage because they’re built on the assumption that you’ll save all of your documents in the cloud. Not only is that less convenient when you need to work offline, but it also limits the size of programs and files that you can download. So, Chromebooks aren't the best for hoarding Netflix shows before a long trip or for use as a gaming laptop. Windows also has thousands of apps that you can download from its app store. Chromebooks have some Chrome apps, numerous browser extensions and the ability to download Android apps, but quality control is… inconsistent. Android apps, in particular, often haven’t been optimized for Chrome OS, which makes for a wonky user experience. Windows may not have as many apps as Android, but at least the experience is fairly standard across the board. Windows also gives you the ability to download and use programs from other sources, like direct from the developer. You can run things like Adobe Creative Suite, certain VPNs and programs like GIMP, Audacity and ClipMate on a Windows device, which just isn’t possible on Chrome OS. Chromebooks limit you to the apps and programs in The Play Store and the Chrome Extensions store, reducing any others to unusable, space-sucking icons in your Downloads folder.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/best-affordable-windows-laptops-123000512.html?src=rss",
          "content": "You don’t need to spend a fortune to get a capable Windows laptop. For everyday tasks like web browsing, writing documents, streaming video or handling schoolwork, a well-chosen budget machine can still deliver a smooth, reliable experience. The challenge is cutting through the noise to find affordable options that balance performance, build quality and battery life without serious compromises.For many buyers, timing is no longer optional. With Windows 10 support now officially over, upgrading has become a necessity rather than a nice-to-have. The picks below focus on cheap Windows laptops that can handle day-to-day workloads comfortably while keeping you current on software and security updates. If you’re open to spending more for extra power or premium features, our broader guide to the best Windows laptops covers higher-end alternatives as well. What to look for in a budget-friendly Windows laptop While you can do a lot even when spending little on a Windows laptop, you must set your expectations accordingly. The biggest downside when purchasing a budget laptop (of any kind, really) is limited power. You’ll want to carefully consider a few specs, the most important among them being the processor (CPU). Many Windows laptops under $500 run on Intel Celeron or Pentium chipsets, but you can find some with Core i3/i5 and AMD Ryzen 3/5 CPUs at the higher end of the price spectrum. We recommend getting the most powerful CPU you can afford because it will dictate how fast the computer will feel overall. Memory (RAM) is also important because, the more you have, the easier it will be for the laptop to manage things like a dozen browser tabs while you edit a Word document and stream music in the background. When it comes to storage, consider how much you want to save locally. If you primarily work in Google Docs or save most things in the cloud, you may not need a machine with a ton of onboard storage. Just remember that your digital space will also be taken up by apps, so it may be worth getting a little extra storage than you think you need if you know you’ll be downloading big programs. A final side note: solid state drives (SSDs) are ubiquitous at this point, not to mention faster and more efficient than hard drives (HDDs), so we recommend getting a laptop with that type of storage. As for screens, there’s a healthy mix of HD (720p resolution) and FHD (1080p) options in this price range and we recommend springing for a notebook with a 1080p display if you can. Touchscreens aren’t as common in the budget space as standard panels, but you’ll only really miss one if you get a 2-in-1 laptop. Before we get to our recommended specs for a cheap Windows laptop, it’s worth mentioning that Microsoft clearly lays out the true minimum requirements for any Windows 11 machine. Those include a 1GHz or faster processor that includes two or more cores, at least 4GB of RAM and 64GB of available storage space. That’s the bare minimum to run Windows 11; we recommend giving yourself some wiggle room by choosing a machine that will perform well now and for years to come. Specs to look for in an affordable Windows laptop CPU: Intel Core i3 or AMD Ryzen 3 processors, at minimum RAM: At least 8GB Storage: At least 128GB SSD Screen: At least 1080p FHD It’s essential to prioritize what’s important to you. But at the lower end of the budget, a good laptop may not offer everything you need, whereas a great one might. Although most machines come with features like Bluetooth, built-in Wi-Fi and additional ports, you might find not all of them come with the specifics you require, like an SD card slot, webcam, charger, and so on. Be sure to check the spec list of any laptop you’re considering before you buy, especially if you need specific connectors and capabilities. See Also: Best Laptops for 2026 Best Gaming Laptops Best 2-in-1 Laptops for 2026 Best Chromebooks Best Laptops for College Students As for Copilot+, don’t expect to see much of it on truly affordable Windows laptops just yet. Microsoft’s AI features and Copilot assistant require certain specs to run, namely a powerful neural processing unit (NPU), 16GB of RAM and 256GB of storage. Currently, the cheapest Copilot+ AI PCs will run you about $700, so if you’re willing to pay more for those perks, check out our best laptops guide for more options. If you’re looking for either a gaming laptop or a “Windows on Arm” laptop, both categories will require you to spend more money than we’re discussing here. Best cheap Windows laptops for 2026 The cheap Windows laptop market moves fast, and — unlike nearly all of our other buying guides — we haven't necessarily tested each specific configuration listed below. However, the combination of these technical specifications and familiar brands represent exactly the sort of entry-level laptops we'd recommend to shoppers in this price range based on our thorough research and expert knowledge. What to know about the budget Windows laptop market The best cheap laptop models change all the time. Unlike more expensive, flagship machines, these notebooks can be updated a couple times each year. That can make it hard to track down a specific model at Amazon, Best Buy, Walmart or any other retailer. Also, we’ve seen prices vary widely depending on the configuration and retailer you’re looking at. You can ensure you’re getting a quality laptop by doing a few things. First and foremost, make sure you get a machine that follows the recommended specs we list above. Also, make sure you’re buying from a reputable retailer, including big-box stores like Walmart, Best Buy and Costco, online shops like Amazon or direct manufacturers like Dell, HP, Lenovo and others. If you have a physical store near you (likely a Best Buy in the US), it’s never a bad idea to go play around with some laptops in person before choosing one. If you decide to shop online from the likes of Amazon or Walmart, double check the seller of the laptop you’re considering. For example, many items on Amazon are “shipped and sold” by Amazon and those are typically the best options. You’ll see that information on Amazon on the right sidebar on a product page, under the Add to Cart and Buy Now buttons. Third-party sellers are common in the affordable laptop space. Amazon sometimes classifies laptop manufacturers as third-party sellers, so you may see a laptop shipped and sold by HP or Dell — that’s a good thing, since it’s coming directly from the manufacturer. However, there are other third-party electronics sellers out there. We recommend clicking on the third-party seller’s name on Amazon or Walmart (yes, Walmart has them, too) to see how much positive feedback and how many five-star ratings they’ve received from buyers. What about Chromebooks and tablets? You may be inclined to recommend a Chromebook or a tablet to anyone considering a budget Windows laptop computer. Those instincts aren’t wrong, but Chromebooks and tablets aren’t the best buy for everyone. Tablets have the most portability, but they will only work for the most mobile-competent users like kids who have been grabbing smartphones out of their parents’ hands since they’ve been dexterous enough to do so. Tablets can also be just as expensive as some of the cheapest Windows laptops, and that’s without a mouse or keyboard. Chromebooks are a good alternative for those that basically live in a browser, the trade-off being you must give up the “traditional desktop.” And Chrome OS is a more limited operating system than Windows when it comes to the programs you can install and run. What Windows laptops do well What can you realistically accomplish on a cheap Windows laptop? Quite a bit, especially if you’re doing one thing (or a limited number of things) at a time. They’re great for everyday tasks like web browsing, checking email, video streaming and more. All of those things can be done on Chromebooks as well, but Windows laptops have a big advantage in Microsoft Office. While yes, there is a browser based version, the native, desktop apps are considered a must have for many and will run smoothly on even the most bare-bones budget laptop. The only caveat is that you may run into some slowdown on low-powered devices if you’re multitasking or working with large data sets in Excel or a lot of photos and graphics in Powerpoint. When it comes to specs, a bright spot for Windows laptops is storage. Even the most affordable devices tend to have at least a 128GB solid state drive. That will come in handy if you prefer to keep your most important files saved locally on your laptop's hard drive. In contrast, cheaper Chromebooks often have less storage because they’re built on the assumption that you’ll save all of your documents in the cloud. Not only is that less convenient when you need to work offline, but it also limits the size of programs and files that you can download. So, Chromebooks aren't the best for hoarding Netflix shows before a long trip or for use as a gaming laptop. Windows also has thousands of apps that you can download from its app store. Chromebooks have some Chrome apps, numerous browser extensions and the ability to download Android apps, but quality control is… inconsistent. Android apps, in particular, often haven’t been optimized for Chrome OS, which makes for a wonky user experience. Windows may not have as many apps as Android, but at least the experience is fairly standard across the board. Windows also gives you the ability to download and use programs from other sources, like direct from the developer. You can run things like Adobe Creative Suite, certain VPNs and programs like GIMP, Audacity and ClipMate on a Windows device, which just isn’t possible on Chrome OS. Chromebooks limit you to the apps and programs in The Play Store and the Chrome Extensions store, reducing any others to unusable, space-sucking icons in your Downloads folder.This article originally appeared on Engadget at https://www.engadget.com/computing/laptops/best-affordable-windows-laptops-123000512.html?src=rss",
          "feed_position": 10,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2021-05/843ff380-b255-11eb-bddf-b4000d3cf728"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/audio/headphones/best-earbuds-for-android-devices-120015765.html",
          "published_at": "Mon, 23 Feb 2026 08:00:38 +0000",
          "title": "The best earbuds for Android devices in 2026",
          "standfirst": "If you’re using an Android phone, finding the right pair of wireless earbuds can take a little more work than it does for iPhone owners. Apple’s AirPods are tightly woven into iOS, but that same level of seamless integration doesn’t automatically carry over to Android. The good news is there are plenty of earbuds that play just as nicely with Android devices, and in some cases offer features AirPods simply don’t.From earbuds designed to pair especially well with Samsung Galaxy and Google Pixel phones to models that prioritize strong noise cancellation, long battery life or workout-friendly durability, the Android ecosystem has no shortage of solid options. We’ve tested a wide range of wireless earbuds to find the best picks for Android users, whether you’re after premium sound, reliable everyday performance or a more affordable alternative. Best Android earbuds for 2026 What to look for in wireless earbuds for Android devices Photo by Jeff Dunn / Engadget For the most part, the features you want from a set of “Android earbuds” are the same as what you want from any headphones. Great sound quality, a comfortable fit and sufficient battery life are still the foundations. Adequate water resistance is good for workouts, and nobody wants a crummy mic for making calls. Once you approach the $100 range, features like active noise cancellation (ANC), wireless charging, an ambient sound mode (which lets you better hear outside noise without turning off your music) and multipoint connectivity (the ability to pair with multiple devices simultaneously) should be expected. For Android devices specifically, there are a few extras to consider. A dedicated app that makes it easy to switch sound modes, customize the audio profile, locate your earbuds if they ever get misplaced or adjust other settings is strongly preferred. Features like Google Fast Pair or NFC-based pairing, which can help you avoid having to dig through your Bluetooth menu to connect your earbuds for the first time, are also nice perks. Some Android devices can also utilize higher-quality Bluetooth codecs such as aptX Adaptive or Sony’s LDAC — these aren’t nearly as important to audio quality as the actual architecture of your earbuds, but they can help wring out a little more detail if the buds are capable enough and you’re streaming lossless files. AptX Adaptive can also help reduce latency, which is good for streaming video or gaming. Diversity is Android’s greatest strength, but it also means that some wireless earbuds play nicer with certain devices, typically those made by the same company. Recent Samsung earbuds, for instance, come with a few perks that are only available if you use a Galaxy phone. We have a couple of recommendations related to this idea above. How we test Android earbuds Photo by Billy Steele/Engadget The best way to test earphones is simply to wear them as much as possible, so that’s what we do. We typically do this over a one- to two-week period, though embargo times occasionally force us to finish our review process a bit faster. We listen to a test playlist that includes several musical genres and podcasts, paying close attention to how each pair approaches the bass, mid and treble frequencies to get an accurate sense of its sound profile. We also test at high and low volumes to check for consistency in the tuning. We do not have access to a dummy head to take more objective measurements, but we’ll sometimes look to sites like Rtings, SoundGuys and others that do just to ensure our impressions are not wildly off-base. If a model supports custom EQ, we’ll tinker with that and use the available EQ presets to see if one sounds dramatically better than the others — though in general we base most of our impressions on the stock tuning each pair uses by default. To assess microphone quality, we record our own audio samples and take multiple calls with a partner both indoors and outside. For battery life, we play our test playlist on a loop with the volume around 75 percent and measure how long it takes for each set to drain. Where applicable, we do a thorough review of a pair’s companion app and test each available feature. While comfort is ultimately subjective, we take note of how secure each pair feels while we’re on the move. We also use certain pairs in especially crowded public spaces to get a better sense of their passive and active noise cancellation, as well as their ability to maintain a consistent Bluetooth connection. Recent updates February 2026: Updated to include new top picks. November 2025: The lightly updated Beats Powerbeats Fit replace the older Beats Fit Pro as our top pick for working out. We’ve also noted the new Google Pixel Buds 2a as a cheaper alternative to the Pixel Buds Pro 2, which remain our recommendation for Pixel phone users. August 2025: We’ve taken another sweep to ensure our advice is still up-to-date. May 2025: We’ve checked this guide to ensure our top picks still stand and noted a couple alternatives to the Noble Fokus Rex5, since that pair has had stock issues of late. We’re also keeping an eye on how the Trump administration’s tariff policy affects the pricing and stock of our recommendations (and the consumer tech industry as a whole). All of our picks are still available in their normal price ranges today, but we’ll update this guide if that changes. February 2025: The Noble FoKus Rex5 is our new \"best for sound quality\" pick, replacing the Sennheiser Momentum True Wireless 4. Our other recommendations remain unchanged. December 2024: We’ve lightly edited this guide for clarity and ensured that our current picks are still accurate.This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/best-earbuds-for-android-devices-120015765.html?src=rss",
          "content": "If you’re using an Android phone, finding the right pair of wireless earbuds can take a little more work than it does for iPhone owners. Apple’s AirPods are tightly woven into iOS, but that same level of seamless integration doesn’t automatically carry over to Android. The good news is there are plenty of earbuds that play just as nicely with Android devices, and in some cases offer features AirPods simply don’t.From earbuds designed to pair especially well with Samsung Galaxy and Google Pixel phones to models that prioritize strong noise cancellation, long battery life or workout-friendly durability, the Android ecosystem has no shortage of solid options. We’ve tested a wide range of wireless earbuds to find the best picks for Android users, whether you’re after premium sound, reliable everyday performance or a more affordable alternative. Best Android earbuds for 2026 What to look for in wireless earbuds for Android devices Photo by Jeff Dunn / Engadget For the most part, the features you want from a set of “Android earbuds” are the same as what you want from any headphones. Great sound quality, a comfortable fit and sufficient battery life are still the foundations. Adequate water resistance is good for workouts, and nobody wants a crummy mic for making calls. Once you approach the $100 range, features like active noise cancellation (ANC), wireless charging, an ambient sound mode (which lets you better hear outside noise without turning off your music) and multipoint connectivity (the ability to pair with multiple devices simultaneously) should be expected. For Android devices specifically, there are a few extras to consider. A dedicated app that makes it easy to switch sound modes, customize the audio profile, locate your earbuds if they ever get misplaced or adjust other settings is strongly preferred. Features like Google Fast Pair or NFC-based pairing, which can help you avoid having to dig through your Bluetooth menu to connect your earbuds for the first time, are also nice perks. Some Android devices can also utilize higher-quality Bluetooth codecs such as aptX Adaptive or Sony’s LDAC — these aren’t nearly as important to audio quality as the actual architecture of your earbuds, but they can help wring out a little more detail if the buds are capable enough and you’re streaming lossless files. AptX Adaptive can also help reduce latency, which is good for streaming video or gaming. Diversity is Android’s greatest strength, but it also means that some wireless earbuds play nicer with certain devices, typically those made by the same company. Recent Samsung earbuds, for instance, come with a few perks that are only available if you use a Galaxy phone. We have a couple of recommendations related to this idea above. How we test Android earbuds Photo by Billy Steele/Engadget The best way to test earphones is simply to wear them as much as possible, so that’s what we do. We typically do this over a one- to two-week period, though embargo times occasionally force us to finish our review process a bit faster. We listen to a test playlist that includes several musical genres and podcasts, paying close attention to how each pair approaches the bass, mid and treble frequencies to get an accurate sense of its sound profile. We also test at high and low volumes to check for consistency in the tuning. We do not have access to a dummy head to take more objective measurements, but we’ll sometimes look to sites like Rtings, SoundGuys and others that do just to ensure our impressions are not wildly off-base. If a model supports custom EQ, we’ll tinker with that and use the available EQ presets to see if one sounds dramatically better than the others — though in general we base most of our impressions on the stock tuning each pair uses by default. To assess microphone quality, we record our own audio samples and take multiple calls with a partner both indoors and outside. For battery life, we play our test playlist on a loop with the volume around 75 percent and measure how long it takes for each set to drain. Where applicable, we do a thorough review of a pair’s companion app and test each available feature. While comfort is ultimately subjective, we take note of how secure each pair feels while we’re on the move. We also use certain pairs in especially crowded public spaces to get a better sense of their passive and active noise cancellation, as well as their ability to maintain a consistent Bluetooth connection. Recent updates February 2026: Updated to include new top picks. November 2025: The lightly updated Beats Powerbeats Fit replace the older Beats Fit Pro as our top pick for working out. We’ve also noted the new Google Pixel Buds 2a as a cheaper alternative to the Pixel Buds Pro 2, which remain our recommendation for Pixel phone users. August 2025: We’ve taken another sweep to ensure our advice is still up-to-date. May 2025: We’ve checked this guide to ensure our top picks still stand and noted a couple alternatives to the Noble Fokus Rex5, since that pair has had stock issues of late. We’re also keeping an eye on how the Trump administration’s tariff policy affects the pricing and stock of our recommendations (and the consumer tech industry as a whole). All of our picks are still available in their normal price ranges today, but we’ll update this guide if that changes. February 2025: The Noble FoKus Rex5 is our new \"best for sound quality\" pick, replacing the Sennheiser Momentum True Wireless 4. Our other recommendations remain unchanged. December 2024: We’ve lightly edited this guide for clarity and ensured that our current picks are still accurate.This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/best-earbuds-for-android-devices-120015765.html?src=rss",
          "feed_position": 11,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2023-06/f9e8ef90-0c55-11ee-97db-1ddd4c19f474"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/ai-agents-are-delivering-real-roi-heres-what-1-100-developers-and-ctos",
          "published_at": "Mon, 23 Feb 2026 05:00:00 GMT",
          "title": "AI Agents are delivering real ROI — Here's what 1,100 developers and CTOs reveal about scaling them",
          "standfirst": "Presented by DigitalOceanFrom refactoring codebases to debugging production code, AI agents are already proving their value. But scaling them in production remains the exception, not the rule. In DigitalOcean’s 2026 Currents research report, based on a survey of more than 1,100 developers, CTOs, and founders, 67% of organizations using agents report productivity gains. Meanwhile, 60% of respondents say applications and agents represent the greatest long-term value in the AI stack. Yet, only 10% are scaling agents in production. The top blocker? Forty-nine percent cite the high cost of inference. It&#x27;s not just the price of a single API call. It&#x27;s the compounding cost as agents chain tasks and run autonomously. Nearly half of respondents now spend 76–100% of their AI budget on inference alone. This is a problem DigitalOcean is working to solve. What&#x27;s needed is infrastructure designed around inference economics: predictable performance, cost control under load, and fewer moving parts. That&#x27;s how 2026 becomes the year agents graduate from pilot to product.52% of companies are actively implementing AI solutions (including agents)Just a year ago when we ran this survey, only 35% of respondents were actively implementing AI solutions — most were still in exploration mode or running their first projects. Now it’s 52%. The shift from \"let&#x27;s see what this can do\" to \"let&#x27;s put this into production\" is well underway.There&#x27;s an agent boom underneath these numbers. 46% of those respondents are specifically deploying AI agents, autonomous systems that execute tasks on their own rather than wait for instructions at every step. OpenClaw (formerly Moltbot and Clawdbot) is one recent example, an open-source assistant that connects to messaging apps, browses the web, executes shell commands, and runs tasks autonomously.Where are those agents going? Mostly into code and operations:54% said code generation and refactoring, making it the clear frontrunner49% are automating internal operations45% are building customer support and chatbots43% are focused on business logic and task orchestration41% are using agents for written content generation27% are pursuing marketing workflow automation21% are conducting data analysisDevelopers are leading the charge here. For example, Y Combinator shared that a quarter of its Winter 2025 startups were building with codebases that are 95% AI-generated. Then there&#x27;s what Andrej Karpathy calls \"vibe coding\" — describing what you want in plain language and letting the AI write the code.The tooling has split to match different workflows. Cursor bakes AI into a VS Code fork for inline edits and rapid iteration. Claude Code runs in the terminal for deeper work across entire repositories. But both have moved well beyond autocomplete. These tools now operate in agentic loops, reading files, running tests, identifying failures, and iterating until the build passes. You describe a feature. The agent implements it. Some sessions stretch for hours — no one at the keyboard.But agents aren&#x27;t just for engineers. They&#x27;re making their way into marketing, customer success, and ops. We see this internally at DigitalOcean, too. Experimental showcases and hack days have surfaced demos of AI workflows to test ad copy at scale, personalize emails, and prioritize growth experiments.67% of organizations using agents report measurable productivity improvementsThe productivity question is the one everyone&#x27;s asking: are agents actually delivering results, or is this still hype? The data suggests the former. Overall, 67% of organizations using agents report measurable productivity improvements. And for some, the gains are substantial: 9% of respondents reported productivity increases of 75% or more. When asked what outcomes they&#x27;ve observed from using AI agents:53% said productivity and time savings for employees44% reported the creation of new business capabilities32% noted a reduced need to hire additional staff27% saw measurable cost savings26% reported improved customer experienceInternal research at Anthropic explores what these technologies unlock: when the company studied how its own engineers use Claude Code, it found that more than a quarter of AI-assisted work consisted of tasks that simply wouldn&#x27;t have been done otherwise. That includes scaling projects and building internal tools. It also includes exploratory work that previously wasn&#x27;t worth the time investment — but now is.What pushes those productivity numbers even higher? Agents are learning to work together. Google&#x27;s release of the Agent Development Kit as an open-source framework marked a shift from single-purpose agents to coordinated multi-agent systems that can discover one another, exchange information, and collaborate regardless of vendor or framework. That said, 14% have yet to see a benefit, and 19% say it&#x27;s too early to measure. From what we&#x27;re seeing, 2025 was largely a year of prototyping and experimentation, with 2026 shaping up to be when more teams move agents into production.60% bet on applications and agents as the biggest opportunity in AIBudgets follow the results. AI remains an active area of investment for the vast majority of organizations: only 4% of respondents said they don&#x27;t expect to invest in AI over the next 12 months. And where organizations are seeing productivity gains, they&#x27;re doubling down — on the application layer, not foundational infrastructure. When asked where respondents expect budget growth over the next 12 months, 37% pointed to applications and agents, more than double the share for infrastructure (14%) or platforms (17%). The long-term view is even stronger: 60% see applications and agents as the greatest opportunity in the AI stack, compared to just 19% for infrastructure. Market data backs this up. According to one report, the application layer captured $19 billion in 2025 — more than half of all generative AI spending. Coding tools led at $4 billion, representing 55% of departmental AI spend and the single largest category across the entire stack. Organizations are betting that the application layer, where AI actually touches users and workflows, will matter more than the underlying components.49% say the cost of running AI at scale is their top barrier to growthAgents only work if you can run them. And right now, inference is the bottleneck. Unlike training, which is a fixed upfront investment to build the model, each prompt to an agent generates tokens that incur a cost. That cost compounds with every reasoning step, retry, and self-correction cycle. At scale, this turns inference into an operational expense that can exceed the original investment in the model itself.When we asked respondents what limits their ability to scale AI, 49% identified the high cost of inference at scale as their top barrier. This tracks with where budgets are going: 44% of respondents now spend the majority of their AI budget (76-100%) on inference, not training.But solving for inference shouldn&#x27;t fall on developers. The complexity of optimizing GPU configurations, managing parallelization strategies, and fine-tuning model serving infrastructure is not the kind of work most teams should be doing themselves. That&#x27;s infrastructure-level complexity, and cloud providers need to absorb it.At DigitalOcean, this is central to how we think about our Gradient™ AI Inference Cloud. We&#x27;re investing in inference optimization so that the teams we serve don&#x27;t have to. Character.ai is a good example: they came to us needing to lower inference costs without sacrificing performance or latency. By migrating to our inference cloud platform and working closely with our team and AMD, they doubled their production inference throughput and reduced their cost per token by 50%. That kind of outcome is what becomes possible when the platform does the heavy lifting. As agents move from pilots to production, the companies that scale successfully will be the ones that aren&#x27;t stuck solving inference on their own. Wade Wegner is Chief Ecosystem and Growth Officer at DigitalOcean.Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "content": "Presented by DigitalOceanFrom refactoring codebases to debugging production code, AI agents are already proving their value. But scaling them in production remains the exception, not the rule. In DigitalOcean’s 2026 Currents research report, based on a survey of more than 1,100 developers, CTOs, and founders, 67% of organizations using agents report productivity gains. Meanwhile, 60% of respondents say applications and agents represent the greatest long-term value in the AI stack. Yet, only 10% are scaling agents in production. The top blocker? Forty-nine percent cite the high cost of inference. It&#x27;s not just the price of a single API call. It&#x27;s the compounding cost as agents chain tasks and run autonomously. Nearly half of respondents now spend 76–100% of their AI budget on inference alone. This is a problem DigitalOcean is working to solve. What&#x27;s needed is infrastructure designed around inference economics: predictable performance, cost control under load, and fewer moving parts. That&#x27;s how 2026 becomes the year agents graduate from pilot to product.52% of companies are actively implementing AI solutions (including agents)Just a year ago when we ran this survey, only 35% of respondents were actively implementing AI solutions — most were still in exploration mode or running their first projects. Now it’s 52%. The shift from \"let&#x27;s see what this can do\" to \"let&#x27;s put this into production\" is well underway.There&#x27;s an agent boom underneath these numbers. 46% of those respondents are specifically deploying AI agents, autonomous systems that execute tasks on their own rather than wait for instructions at every step. OpenClaw (formerly Moltbot and Clawdbot) is one recent example, an open-source assistant that connects to messaging apps, browses the web, executes shell commands, and runs tasks autonomously.Where are those agents going? Mostly into code and operations:54% said code generation and refactoring, making it the clear frontrunner49% are automating internal operations45% are building customer support and chatbots43% are focused on business logic and task orchestration41% are using agents for written content generation27% are pursuing marketing workflow automation21% are conducting data analysisDevelopers are leading the charge here. For example, Y Combinator shared that a quarter of its Winter 2025 startups were building with codebases that are 95% AI-generated. Then there&#x27;s what Andrej Karpathy calls \"vibe coding\" — describing what you want in plain language and letting the AI write the code.The tooling has split to match different workflows. Cursor bakes AI into a VS Code fork for inline edits and rapid iteration. Claude Code runs in the terminal for deeper work across entire repositories. But both have moved well beyond autocomplete. These tools now operate in agentic loops, reading files, running tests, identifying failures, and iterating until the build passes. You describe a feature. The agent implements it. Some sessions stretch for hours — no one at the keyboard.But agents aren&#x27;t just for engineers. They&#x27;re making their way into marketing, customer success, and ops. We see this internally at DigitalOcean, too. Experimental showcases and hack days have surfaced demos of AI workflows to test ad copy at scale, personalize emails, and prioritize growth experiments.67% of organizations using agents report measurable productivity improvementsThe productivity question is the one everyone&#x27;s asking: are agents actually delivering results, or is this still hype? The data suggests the former. Overall, 67% of organizations using agents report measurable productivity improvements. And for some, the gains are substantial: 9% of respondents reported productivity increases of 75% or more. When asked what outcomes they&#x27;ve observed from using AI agents:53% said productivity and time savings for employees44% reported the creation of new business capabilities32% noted a reduced need to hire additional staff27% saw measurable cost savings26% reported improved customer experienceInternal research at Anthropic explores what these technologies unlock: when the company studied how its own engineers use Claude Code, it found that more than a quarter of AI-assisted work consisted of tasks that simply wouldn&#x27;t have been done otherwise. That includes scaling projects and building internal tools. It also includes exploratory work that previously wasn&#x27;t worth the time investment — but now is.What pushes those productivity numbers even higher? Agents are learning to work together. Google&#x27;s release of the Agent Development Kit as an open-source framework marked a shift from single-purpose agents to coordinated multi-agent systems that can discover one another, exchange information, and collaborate regardless of vendor or framework. That said, 14% have yet to see a benefit, and 19% say it&#x27;s too early to measure. From what we&#x27;re seeing, 2025 was largely a year of prototyping and experimentation, with 2026 shaping up to be when more teams move agents into production.60% bet on applications and agents as the biggest opportunity in AIBudgets follow the results. AI remains an active area of investment for the vast majority of organizations: only 4% of respondents said they don&#x27;t expect to invest in AI over the next 12 months. And where organizations are seeing productivity gains, they&#x27;re doubling down — on the application layer, not foundational infrastructure. When asked where respondents expect budget growth over the next 12 months, 37% pointed to applications and agents, more than double the share for infrastructure (14%) or platforms (17%). The long-term view is even stronger: 60% see applications and agents as the greatest opportunity in the AI stack, compared to just 19% for infrastructure. Market data backs this up. According to one report, the application layer captured $19 billion in 2025 — more than half of all generative AI spending. Coding tools led at $4 billion, representing 55% of departmental AI spend and the single largest category across the entire stack. Organizations are betting that the application layer, where AI actually touches users and workflows, will matter more than the underlying components.49% say the cost of running AI at scale is their top barrier to growthAgents only work if you can run them. And right now, inference is the bottleneck. Unlike training, which is a fixed upfront investment to build the model, each prompt to an agent generates tokens that incur a cost. That cost compounds with every reasoning step, retry, and self-correction cycle. At scale, this turns inference into an operational expense that can exceed the original investment in the model itself.When we asked respondents what limits their ability to scale AI, 49% identified the high cost of inference at scale as their top barrier. This tracks with where budgets are going: 44% of respondents now spend the majority of their AI budget (76-100%) on inference, not training.But solving for inference shouldn&#x27;t fall on developers. The complexity of optimizing GPU configurations, managing parallelization strategies, and fine-tuning model serving infrastructure is not the kind of work most teams should be doing themselves. That&#x27;s infrastructure-level complexity, and cloud providers need to absorb it.At DigitalOcean, this is central to how we think about our Gradient™ AI Inference Cloud. We&#x27;re investing in inference optimization so that the teams we serve don&#x27;t have to. Character.ai is a good example: they came to us needing to lower inference costs without sacrificing performance or latency. By migrating to our inference cloud platform and working closely with our team and AMD, they doubled their production inference throughput and reduced their cost per token by 50%. That kind of outcome is what becomes possible when the platform does the heavy lifting. As agents move from pilots to production, the companies that scale successfully will be the ones that aren&#x27;t stuck solving inference on their own. Wade Wegner is Chief Ecosystem and Growth Officer at DigitalOcean.Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "feed_position": 2,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/6T8BoZdjL8FB8SPwV16gxU/174167a5afd38d806a5fb66859311d6e/AdobeStock_507970416.jpeg?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/shadow-mode-drift-alerts-and-audit-logs-inside-the-modern-audit-loop",
          "published_at": "Sun, 22 Feb 2026 19:00:00 GMT",
          "title": "Shadow mode, drift alerts and audit logs: Inside the modern audit loop",
          "standfirst": "Traditional software governance often uses static compliance checklists, quarterly audits and after-the-fact reviews. But this method can&#x27;t keep up with AI systems that change in real time. A machine learning (ML) model might retrain or drift between quarterly operational syncs. This means that, by the time an issue is discovered, hundreds of bad decisions could already have been made. This can be almost impossible to untangle. In the fast-paced world of AI, governance must be inline, not an after-the-fact compliance review. In other words, organizations must adopt what I call an “audit loop\": A continuous, integrated compliance process that operates in real-time alongside AI development and deployment, without halting innovation. This article explains how to implement such continuous AI compliance through shadow mode rollouts, drift and misuse monitoring and audit logs engineered for direct legal defensibility.From reactive checks to an inline “audit loop”When systems moved at the speed of people, it made sense to do compliance checks every so often. But AI doesn&#x27;t wait for the next review meeting. The change to an inline audit loop means audits will no longer occur just once in a while; they happen all the time. Compliance and risk management should be \"baked in\" to the AI lifecycle from development to production, rather than just post-deployment. This means establishing live metrics and guardrails that monitor AI behavior as it occurs and raise red flags as soon as something seems off. For instance, teams can set up drift detectors that automatically alert when a model&#x27;s predictions go off course from the training distribution, or when confidence scores fall below acceptable levels. Governance is no longer just a set of quarterly snapshots; it&#x27;s a streaming process with alerts that go off in real time when a system goes outside of its defined confidence bands.Cultural shift is equally important: Compliance teams must act less like after-the-fact auditors and more like AI co-pilots. In practice, this might mean compliance and AI engineers working together to define policy guardrails and continuously monitor key indicators. With the right tools and mindset, real-time AI governance can “nudge” and intervene early, helping teams course-correct without slowing down innovation. In fact, when done well, continuous governance builds trust rather than friction, providing shared visibility into AI operations for both builders and regulators, instead of unpleasant surprises after deployment. The following strategies illustrate how to achieve this balance.Shadow mode rollouts: Testing compliance safelyOne effective framework for continuous AI compliance is “shadow mode” deployments with new models or agent features. This means a new AI system is deployed in parallel with the existing system, receiving real production inputs but not influencing real decisions or user-facing outputs. The legacy model or process continues to handle decisions, while the new AI’s outputs are captured only for analysis. This provides a safe sandbox to vet the AI’s behavior under real conditions. According to global law firm Morgan Lewis: “Shadow-mode operation requires the AI to run in parallel without influencing live decisions until its performance is validated,” giving organizations a safe environment to test changes. Teams can discover problems early by comparing the shadow model&#x27;s decisions to expectations (the current model&#x27;s decisions). For instance, when a model is running in shadow mode, they can check to see if its inputs and predictions differ from those of the current production model or the patterns seen in training. Sudden changes could indicate bugs in the data pipeline, unexpected bias or drops in performance. In short, shadow mode is a way to check compliance in real time: It ensures that the model handles inputs correctly and meets policy standards (accuracy, fairness) before it is fully released. One AI security framework showed how this method worked: Teams first ran AI in shadow mode (AI makes suggestions but doesn&#x27;t act on its own), then compared AI and human inputs to determine trust. They only let the AI suggest actions with human approval after it was reliable. For instance, Prophet Security eventually let the AI make low-risk decisions on its own. Using phased rollouts gives people confidence that an AI system meets requirements and works as expected, without putting production or customers at risk during testing. Real-time drift and misuse detectionEven after an AI model is fully deployed, the compliance job is never \"done.\" Over time, AI systems can drift, meaning that their performance or outputs change due to new data patterns, model retraining or bad inputs. They can also be misused or lead to results that go against policy (for example, inappropriate content or biased decisions) in unexpected ways. To remain compliant, teams must set up monitoring signals and processes to catch these issues as they happen. In SLA monitoring, they may only check for uptime or latency. In AI monitoring, however, the system must be able to tell when outputs are not what they should be. For example, if a model suddenly starts giving biased or harmful results. This means setting \"confidence bands\" or quantitative limits for how a model should behave and setting automatic alerts when those limits are crossed.Some signals to monitor include:Data or concept drift: When input data distributions change significantly or model predictions diverge from training-time patterns. For example, a model’s accuracy on certain segments might drop as the incoming data shifts, a sign to investigate and possibly retrain.Anomalous or harmful outputs: When outputs trigger policy violations or ethical red flags. An AI content filter might flag if a generative model produces disallowed content, or a bias monitor might detect if decisions for a protected group begin to skew negatively. Contracts for AI services now often require vendors to detect and address such noncompliant results promptly.User misuse patterns: When unusual usage behavior suggests someone is trying to manipulate or misuse the AI. For instance, rapid-fire queries attempting prompt injection or adversarial inputs could be automatically flagged by the system’s telemetry as potential misuse.When a drift or misuse signal crosses a critical threshold, the system should support “intelligent escalation” rather than waiting for a quarterly review. In practice, this could mean triggering an automated mitigation or immediately alerting a human overseer. Leading organizations build in fail-safes like kill-switches, or the ability to suspend an AI’s actions the moment it behaves unpredictably or unsafely. For example, a service contract might allow a company to instantly pause an AI agent if it’s outputting suspect results, even if the AI provider hasn’t acknowledged a problem. Likewise, teams should have playbooks for rapid model rollback or retraining windows: If drift or errors are detected, there’s a plan to retrain the model (or revert to a safe state) within a defined timeframe. This kind of agile response is crucial; it recognizes that AI behavior may drift or degrade in ways that cannot be fixed with a simple patch, so swift retraining or tuning is part of the compliance loop.By continuously monitoring and reacting to drift and misuse signals, companies transform compliance from a periodic audit to an ongoing safety net. Issues are caught and addressed in hours or days, not months. The AI stays within acceptable bounds, and governance keeps pace with the AI’s own learning and adaptation, rather than trailing behind it. This not only protects users and stakeholders; it gives regulators and executives peace of mind that the AI is under constant watchful oversight, even as it evolves.Audit logs designed for legal defensibilityContinuous compliance also means continuously documenting what your AI is doing and why. Robust audit logs demonstrate compliance, both for internal accountability and external legal defensibility. However, logging for AI requires more than simplistic logs. Imagine an auditor or regulator asking: “Why did the AI make this decision, and did it follow approved policy?” Your logs should be able to answer that.A good AI audit log keeps a permanent, detailed record of every important action and decision AI makes, along with the reasons and context. Legal experts say these logs \"provide detailed, unchangeable records of AI system actions with exact timestamps and written reasons for decisions.\" They are important evidence in court. This means that every important inference, suggestion or independent action taken by AI should be recorded with metadata, such as timestamps, the model/version used, the input received, the output produced and (if possible) the reasoning or confidence behind that output. Modern compliance platforms stress logging not only the result (\"X action taken\") but also the rationale (\"X action taken because conditions Y and Z were met according to policy\"). These enhanced logs let an auditor see, for example, not just that an AI approved a user&#x27;s access, but that it was approved \"based on continuous usage and alignment with the user&#x27;s peer group,\" according to Attorney Aaron Hall.Audit logs should also be well-organized and difficult to change if they are to be legally sound. Techniques like immutable storage or cryptographic hashing of logs ensure that records can&#x27;t be changed. Log data should be protected by access controls and encryption so that sensitive information, such as security keys and personal data, is hidden or protected while still being open. In regulated industries, keeping these logs can show examiners that you are not only keeping track of AI&#x27;s outputs, but you are retaining records for review. Regulators are expecting companies to show more than that an AI was checked before it was released. They want to see that it is being monitored continuously and there is a forensic trail to analyze its behavior over time. This evidentiary backbone comes from complete audit trails that include data inputs, model versions and decision outputs. They make AI less of a \"black box\" and more of a system that can be tracked and held accountable.If there is a disagreement or an event (for example, an AI made a biased choice that hurt a customer), these logs are your legal lifeline. They help you figure out what went wrong. Was it a problem with the data, a model drift or misuse? Who was in charge of the process? Did we stick to the rules we set? Well-kept AI audit logs show that the company did its homework and had controls in place. This not only lowers the risk of legal problems but makes people more trusting of AI systems. With AI, teams and executives can be sure that every decision made is safe because it is open and accountable.Inline governance as an enabler, not a roadblockImplementing an “audit loop” of continuous AI compliance might sound like extra work, but in reality, it enables faster and safer AI delivery. By integrating governance into each stage of the AI lifecycle, from shadow mode trial runs to real-time monitoring to immutable logging, organizations can move quickly and responsibly. Issues are caught early, so they don’t snowball into major failures that require project-halting fixes later. Developers and data scientists can iterate on models without endless back-and-forth with compliance reviewers, because many compliance checks are automated and happen in parallel. Rather than slowing down delivery, this approach often accelerates it: Teams spend less time on reactive damage control or lengthy audits, and more time on innovation because they are confident that compliance is under control in the background.There are bigger benefits to continuous AI compliance, too. It gives end-users, business leaders and regulators a reason to believe that AI systems are being handled responsibly. When every AI decision is clearly recorded, watched and checked for quality, stakeholders are much more likely to accept AI solutions. This trust benefits the whole industry and society, not just individual businesses. An audit-loop governance model can stop AI failures and ensure AI behavior is in line with moral and legal standards. In fact, strong AI governance benefits the economy and the public because it encourages innovation and protection. It can unlock AI&#x27;s potential in important areas like finance, healthcare and infrastructure without putting safety or values at risk. As national and international standards for AI change quickly, U.S. companies that set a good example by always following the rules are at the forefront of trustworthy AI.People say that if your AI governance isn&#x27;t keeping up with your AI, it&#x27;s not really governance; it&#x27;s \"archaeology.\" Forward-thinking companies are realizing this and adopting audit loops. By doing so, they not only avoid problems but make compliance a competitive advantage, ensuring that faster delivery and better oversight go hand in hand.Dhyey Mavani is working to accelerate gen AI and computational mathematics. Editor&#x27;s note: The opinions expressed in this article are the authors&#x27; personal opinions and do not reflect the opinions of their employers.",
          "content": "Traditional software governance often uses static compliance checklists, quarterly audits and after-the-fact reviews. But this method can&#x27;t keep up with AI systems that change in real time. A machine learning (ML) model might retrain or drift between quarterly operational syncs. This means that, by the time an issue is discovered, hundreds of bad decisions could already have been made. This can be almost impossible to untangle. In the fast-paced world of AI, governance must be inline, not an after-the-fact compliance review. In other words, organizations must adopt what I call an “audit loop\": A continuous, integrated compliance process that operates in real-time alongside AI development and deployment, without halting innovation. This article explains how to implement such continuous AI compliance through shadow mode rollouts, drift and misuse monitoring and audit logs engineered for direct legal defensibility.From reactive checks to an inline “audit loop”When systems moved at the speed of people, it made sense to do compliance checks every so often. But AI doesn&#x27;t wait for the next review meeting. The change to an inline audit loop means audits will no longer occur just once in a while; they happen all the time. Compliance and risk management should be \"baked in\" to the AI lifecycle from development to production, rather than just post-deployment. This means establishing live metrics and guardrails that monitor AI behavior as it occurs and raise red flags as soon as something seems off. For instance, teams can set up drift detectors that automatically alert when a model&#x27;s predictions go off course from the training distribution, or when confidence scores fall below acceptable levels. Governance is no longer just a set of quarterly snapshots; it&#x27;s a streaming process with alerts that go off in real time when a system goes outside of its defined confidence bands.Cultural shift is equally important: Compliance teams must act less like after-the-fact auditors and more like AI co-pilots. In practice, this might mean compliance and AI engineers working together to define policy guardrails and continuously monitor key indicators. With the right tools and mindset, real-time AI governance can “nudge” and intervene early, helping teams course-correct without slowing down innovation. In fact, when done well, continuous governance builds trust rather than friction, providing shared visibility into AI operations for both builders and regulators, instead of unpleasant surprises after deployment. The following strategies illustrate how to achieve this balance.Shadow mode rollouts: Testing compliance safelyOne effective framework for continuous AI compliance is “shadow mode” deployments with new models or agent features. This means a new AI system is deployed in parallel with the existing system, receiving real production inputs but not influencing real decisions or user-facing outputs. The legacy model or process continues to handle decisions, while the new AI’s outputs are captured only for analysis. This provides a safe sandbox to vet the AI’s behavior under real conditions. According to global law firm Morgan Lewis: “Shadow-mode operation requires the AI to run in parallel without influencing live decisions until its performance is validated,” giving organizations a safe environment to test changes. Teams can discover problems early by comparing the shadow model&#x27;s decisions to expectations (the current model&#x27;s decisions). For instance, when a model is running in shadow mode, they can check to see if its inputs and predictions differ from those of the current production model or the patterns seen in training. Sudden changes could indicate bugs in the data pipeline, unexpected bias or drops in performance. In short, shadow mode is a way to check compliance in real time: It ensures that the model handles inputs correctly and meets policy standards (accuracy, fairness) before it is fully released. One AI security framework showed how this method worked: Teams first ran AI in shadow mode (AI makes suggestions but doesn&#x27;t act on its own), then compared AI and human inputs to determine trust. They only let the AI suggest actions with human approval after it was reliable. For instance, Prophet Security eventually let the AI make low-risk decisions on its own. Using phased rollouts gives people confidence that an AI system meets requirements and works as expected, without putting production or customers at risk during testing. Real-time drift and misuse detectionEven after an AI model is fully deployed, the compliance job is never \"done.\" Over time, AI systems can drift, meaning that their performance or outputs change due to new data patterns, model retraining or bad inputs. They can also be misused or lead to results that go against policy (for example, inappropriate content or biased decisions) in unexpected ways. To remain compliant, teams must set up monitoring signals and processes to catch these issues as they happen. In SLA monitoring, they may only check for uptime or latency. In AI monitoring, however, the system must be able to tell when outputs are not what they should be. For example, if a model suddenly starts giving biased or harmful results. This means setting \"confidence bands\" or quantitative limits for how a model should behave and setting automatic alerts when those limits are crossed.Some signals to monitor include:Data or concept drift: When input data distributions change significantly or model predictions diverge from training-time patterns. For example, a model’s accuracy on certain segments might drop as the incoming data shifts, a sign to investigate and possibly retrain.Anomalous or harmful outputs: When outputs trigger policy violations or ethical red flags. An AI content filter might flag if a generative model produces disallowed content, or a bias monitor might detect if decisions for a protected group begin to skew negatively. Contracts for AI services now often require vendors to detect and address such noncompliant results promptly.User misuse patterns: When unusual usage behavior suggests someone is trying to manipulate or misuse the AI. For instance, rapid-fire queries attempting prompt injection or adversarial inputs could be automatically flagged by the system’s telemetry as potential misuse.When a drift or misuse signal crosses a critical threshold, the system should support “intelligent escalation” rather than waiting for a quarterly review. In practice, this could mean triggering an automated mitigation or immediately alerting a human overseer. Leading organizations build in fail-safes like kill-switches, or the ability to suspend an AI’s actions the moment it behaves unpredictably or unsafely. For example, a service contract might allow a company to instantly pause an AI agent if it’s outputting suspect results, even if the AI provider hasn’t acknowledged a problem. Likewise, teams should have playbooks for rapid model rollback or retraining windows: If drift or errors are detected, there’s a plan to retrain the model (or revert to a safe state) within a defined timeframe. This kind of agile response is crucial; it recognizes that AI behavior may drift or degrade in ways that cannot be fixed with a simple patch, so swift retraining or tuning is part of the compliance loop.By continuously monitoring and reacting to drift and misuse signals, companies transform compliance from a periodic audit to an ongoing safety net. Issues are caught and addressed in hours or days, not months. The AI stays within acceptable bounds, and governance keeps pace with the AI’s own learning and adaptation, rather than trailing behind it. This not only protects users and stakeholders; it gives regulators and executives peace of mind that the AI is under constant watchful oversight, even as it evolves.Audit logs designed for legal defensibilityContinuous compliance also means continuously documenting what your AI is doing and why. Robust audit logs demonstrate compliance, both for internal accountability and external legal defensibility. However, logging for AI requires more than simplistic logs. Imagine an auditor or regulator asking: “Why did the AI make this decision, and did it follow approved policy?” Your logs should be able to answer that.A good AI audit log keeps a permanent, detailed record of every important action and decision AI makes, along with the reasons and context. Legal experts say these logs \"provide detailed, unchangeable records of AI system actions with exact timestamps and written reasons for decisions.\" They are important evidence in court. This means that every important inference, suggestion or independent action taken by AI should be recorded with metadata, such as timestamps, the model/version used, the input received, the output produced and (if possible) the reasoning or confidence behind that output. Modern compliance platforms stress logging not only the result (\"X action taken\") but also the rationale (\"X action taken because conditions Y and Z were met according to policy\"). These enhanced logs let an auditor see, for example, not just that an AI approved a user&#x27;s access, but that it was approved \"based on continuous usage and alignment with the user&#x27;s peer group,\" according to Attorney Aaron Hall.Audit logs should also be well-organized and difficult to change if they are to be legally sound. Techniques like immutable storage or cryptographic hashing of logs ensure that records can&#x27;t be changed. Log data should be protected by access controls and encryption so that sensitive information, such as security keys and personal data, is hidden or protected while still being open. In regulated industries, keeping these logs can show examiners that you are not only keeping track of AI&#x27;s outputs, but you are retaining records for review. Regulators are expecting companies to show more than that an AI was checked before it was released. They want to see that it is being monitored continuously and there is a forensic trail to analyze its behavior over time. This evidentiary backbone comes from complete audit trails that include data inputs, model versions and decision outputs. They make AI less of a \"black box\" and more of a system that can be tracked and held accountable.If there is a disagreement or an event (for example, an AI made a biased choice that hurt a customer), these logs are your legal lifeline. They help you figure out what went wrong. Was it a problem with the data, a model drift or misuse? Who was in charge of the process? Did we stick to the rules we set? Well-kept AI audit logs show that the company did its homework and had controls in place. This not only lowers the risk of legal problems but makes people more trusting of AI systems. With AI, teams and executives can be sure that every decision made is safe because it is open and accountable.Inline governance as an enabler, not a roadblockImplementing an “audit loop” of continuous AI compliance might sound like extra work, but in reality, it enables faster and safer AI delivery. By integrating governance into each stage of the AI lifecycle, from shadow mode trial runs to real-time monitoring to immutable logging, organizations can move quickly and responsibly. Issues are caught early, so they don’t snowball into major failures that require project-halting fixes later. Developers and data scientists can iterate on models without endless back-and-forth with compliance reviewers, because many compliance checks are automated and happen in parallel. Rather than slowing down delivery, this approach often accelerates it: Teams spend less time on reactive damage control or lengthy audits, and more time on innovation because they are confident that compliance is under control in the background.There are bigger benefits to continuous AI compliance, too. It gives end-users, business leaders and regulators a reason to believe that AI systems are being handled responsibly. When every AI decision is clearly recorded, watched and checked for quality, stakeholders are much more likely to accept AI solutions. This trust benefits the whole industry and society, not just individual businesses. An audit-loop governance model can stop AI failures and ensure AI behavior is in line with moral and legal standards. In fact, strong AI governance benefits the economy and the public because it encourages innovation and protection. It can unlock AI&#x27;s potential in important areas like finance, healthcare and infrastructure without putting safety or values at risk. As national and international standards for AI change quickly, U.S. companies that set a good example by always following the rules are at the forefront of trustworthy AI.People say that if your AI governance isn&#x27;t keeping up with your AI, it&#x27;s not really governance; it&#x27;s \"archaeology.\" Forward-thinking companies are realizing this and adopting audit loops. By doing so, they not only avoid problems but make compliance a competitive advantage, ensuring that faster delivery and better oversight go hand in hand.Dhyey Mavani is working to accelerate gen AI and computational mathematics. Editor&#x27;s note: The opinions expressed in this article are the authors&#x27; personal opinions and do not reflect the opinions of their employers.",
          "feed_position": 3,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/2lIgm3tWKNlbNcAqMNsFXB/d06b37a9da80c563b72a3c9311f38031/Audit_loop.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/smartphones/how-to-send-a-message-via-satellite-on-iphone-130000418.html",
          "published_at": "Sun, 22 Feb 2026 13:00:00 +0000",
          "title": "How to send a message via satellite on iPhone",
          "standfirst": "Apple’s satellite features were originally designed for emergencies, allowing iPhone users to contact emergency services when cellular and Wi-Fi coverage is unavailable. With recent versions of iOS, Apple has expanded those capabilities to include sending and receiving messages via satellite. This makes it possible to stay in touch with friends and family from remote locations where traditional networks do not reach, such as hiking trails, rural areas or offshore locations.Messaging via satellite is built directly into the iPhone and works automatically when no cellular or Wi-Fi signal is available. While it is not intended to replace regular messaging, it can be a useful backup when coverage drops.How to send a message via satelliteBefore you can get started, you’ll need to turn on iMessage before you’re off the grid. It’s also important to set up an emergency contact as well as members of your Family Sharing group prior to your departure. This will enable them to message you via SMS without the need to message them first. To send a message via satellite, open the Messages app when no cellular or Wi-Fi signal is available. If the feature is supported in the current location, the app will display a prompt indicating that satellite messaging is available.Selecting the option to connect via satellite launches a guided connection screen. Your iPhone will provide real-time instructions to help maintain alignment with the satellite. Once connected, a text message can be typed and sent, although delivery may take longer than usual.The iPhone will notify you when the message has been sent successfully. Replies from the recipient will also be delivered via satellite, as long as the connection remains active.What you need before you can send satellite messagesSending messages via satellite requires a compatible iPhone model and the correct software version. The feature is supported on iPhone models with satellite hardware, beginning with iPhone 14 and later. The device must be running a version of iOS (iOS 18 or higher) that supports satellite messaging, which Apple has continued to refine through recent iOS updates.The feature also depends on location and availability. Satellite messaging is currently supported in select regions, including the United States and parts of Canada, with expanded support rolling out gradually. The iPhone must be outdoors with a clear view of the sky, as trees, buildings and terrain can interfere with the satellite connection.Satellite messaging is not designed for continuous conversations. Messages are compressed and sent at a slower pace than standard texts, and delivery times can vary depending on conditions and satellite positioning.How satellite messaging works on iPhoneWhen an iPhone loses access to cellular and Wi-Fi networks, the system automatically detects that only satellite connectivity is available. Instead of failing to send, the Messages app prompts the user to connect to a satellite.On-screen instructions guide the user to position the phone correctly. This typically involves holding the device up and following directional prompts to align it with an overhead satellite. The phone uses built-in sensors to help maintain the connection while the message is being sent.Messages sent via satellite are text-only and use a reduced data format to ensure they can be transmitted reliably. Images, videos, audio messages and large attachments are not supported.Who can receive satellite messages?Satellite messages can be sent to contacts using iMessage or standard SMS, depending on the recipient’s device and settings. If the recipient is using an Apple device with iMessage enabled, the message will be delivered through Apple’s messaging system. If not, the message will be sent as a standard text.Recipients do not need a satellite-capable device to receive messages. From their perspective, the message appears similar to a regular text, though delivery times may be longer.Tips for getting a reliable connectionA clear view of the sky is essential for satellite messaging to work properly. Open areas with minimal obstructions offer the best results. Movement, heavy foliage and nearby structures can interrupt the connection.Because satellite bandwidth is limited, keeping messages short improves reliability and delivery speed. The iPhone may prompt the user to edit longer messages to fit within satellite constraints.Battery life is also a consideration. Maintaining a satellite connection uses more power than standard messaging, so it helps to conserve battery when relying on satellite features for extended periods.Limitations to keep in mindSatellite messaging is designed for occasional use when other networks are unavailable. It does not support group messages, media attachments or read receipts in the same way as standard messaging.Delivery times can range from under a minute to several minutes, depending on environmental conditions and satellite availability. The feature should not be relied upon for time-sensitive communication unless no other option is available.Apple has also noted that satellite features may be offered free for a limited period, with potential pricing or subscription requirements introduced in the future depending on region and carrier arrangements.When satellite messaging can be usefulMessaging via satellite can be helpful for travelers, hikers and anyone spending time in remote areas where coverage is unreliable. It offers a way to check in, share basic updates or request non-emergency assistance when traditional networks are unavailable.While it is not a replacement for emergency services, it complements Apple’s existing emergency satellite features by providing an additional communication option when users are off the grid.As Apple continues to expand satellite support, messaging via satellite is likely to become a more familiar part of the iPhone experience, particularly for users who regularly venture beyond the reach of cellular networks.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/how-to-send-a-message-via-satellite-on-iphone-130000418.html?src=rss",
          "content": "Apple’s satellite features were originally designed for emergencies, allowing iPhone users to contact emergency services when cellular and Wi-Fi coverage is unavailable. With recent versions of iOS, Apple has expanded those capabilities to include sending and receiving messages via satellite. This makes it possible to stay in touch with friends and family from remote locations where traditional networks do not reach, such as hiking trails, rural areas or offshore locations.Messaging via satellite is built directly into the iPhone and works automatically when no cellular or Wi-Fi signal is available. While it is not intended to replace regular messaging, it can be a useful backup when coverage drops.How to send a message via satelliteBefore you can get started, you’ll need to turn on iMessage before you’re off the grid. It’s also important to set up an emergency contact as well as members of your Family Sharing group prior to your departure. This will enable them to message you via SMS without the need to message them first. To send a message via satellite, open the Messages app when no cellular or Wi-Fi signal is available. If the feature is supported in the current location, the app will display a prompt indicating that satellite messaging is available.Selecting the option to connect via satellite launches a guided connection screen. Your iPhone will provide real-time instructions to help maintain alignment with the satellite. Once connected, a text message can be typed and sent, although delivery may take longer than usual.The iPhone will notify you when the message has been sent successfully. Replies from the recipient will also be delivered via satellite, as long as the connection remains active.What you need before you can send satellite messagesSending messages via satellite requires a compatible iPhone model and the correct software version. The feature is supported on iPhone models with satellite hardware, beginning with iPhone 14 and later. The device must be running a version of iOS (iOS 18 or higher) that supports satellite messaging, which Apple has continued to refine through recent iOS updates.The feature also depends on location and availability. Satellite messaging is currently supported in select regions, including the United States and parts of Canada, with expanded support rolling out gradually. The iPhone must be outdoors with a clear view of the sky, as trees, buildings and terrain can interfere with the satellite connection.Satellite messaging is not designed for continuous conversations. Messages are compressed and sent at a slower pace than standard texts, and delivery times can vary depending on conditions and satellite positioning.How satellite messaging works on iPhoneWhen an iPhone loses access to cellular and Wi-Fi networks, the system automatically detects that only satellite connectivity is available. Instead of failing to send, the Messages app prompts the user to connect to a satellite.On-screen instructions guide the user to position the phone correctly. This typically involves holding the device up and following directional prompts to align it with an overhead satellite. The phone uses built-in sensors to help maintain the connection while the message is being sent.Messages sent via satellite are text-only and use a reduced data format to ensure they can be transmitted reliably. Images, videos, audio messages and large attachments are not supported.Who can receive satellite messages?Satellite messages can be sent to contacts using iMessage or standard SMS, depending on the recipient’s device and settings. If the recipient is using an Apple device with iMessage enabled, the message will be delivered through Apple’s messaging system. If not, the message will be sent as a standard text.Recipients do not need a satellite-capable device to receive messages. From their perspective, the message appears similar to a regular text, though delivery times may be longer.Tips for getting a reliable connectionA clear view of the sky is essential for satellite messaging to work properly. Open areas with minimal obstructions offer the best results. Movement, heavy foliage and nearby structures can interrupt the connection.Because satellite bandwidth is limited, keeping messages short improves reliability and delivery speed. The iPhone may prompt the user to edit longer messages to fit within satellite constraints.Battery life is also a consideration. Maintaining a satellite connection uses more power than standard messaging, so it helps to conserve battery when relying on satellite features for extended periods.Limitations to keep in mindSatellite messaging is designed for occasional use when other networks are unavailable. It does not support group messages, media attachments or read receipts in the same way as standard messaging.Delivery times can range from under a minute to several minutes, depending on environmental conditions and satellite availability. The feature should not be relied upon for time-sensitive communication unless no other option is available.Apple has also noted that satellite features may be offered free for a limited period, with potential pricing or subscription requirements introduced in the future depending on region and carrier arrangements.When satellite messaging can be usefulMessaging via satellite can be helpful for travelers, hikers and anyone spending time in remote areas where coverage is unreliable. It offers a way to check in, share basic updates or request non-emergency assistance when traditional networks are unavailable.While it is not a replacement for emergency services, it complements Apple’s existing emergency satellite features by providing an additional communication option when users are off the grid.As Apple continues to expand satellite support, messaging via satellite is likely to become a more familiar part of the iPhone experience, particularly for users who regularly venture beyond the reach of cellular networks.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/how-to-send-a-message-via-satellite-on-iphone-130000418.html?src=rss",
          "feed_position": 18
        }
      ],
      "featured_image": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/falcon_northwest_fragbox_2.jpg",
      "popularity_score": 2018.9528183333334
    },
    {
      "id": "cluster_14",
      "coverage": 2,
      "updated_at": "Mon, 23 Feb 2026 18:11:08 +0000",
      "title": "OpenAI calls in the consultants for its enterprise push",
      "neutral_headline": "OpenAI calls in the consultants for its enterprise push",
      "bullet_summary": [
        "Reported by TechCrunch, TechMeme"
      ],
      "items": [
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2026/02/23/openai-calls-in-the-consultants-for-its-enterprise-push/",
          "published_at": "Mon, 23 Feb 2026 18:11:08 +0000",
          "title": "OpenAI calls in the consultants for its enterprise push",
          "standfirst": "OpenAI is partnering with four consulting giants in an effort to see more adoption of its OpenAI Frontier AI agent platform.",
          "content": "OpenAI is partnering with four consulting giants in an effort to see more adoption of its OpenAI Frontier AI agent platform.",
          "feed_position": 2
        },
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/260223/p15#a260223p15",
          "published_at": "Mon, 23 Feb 2026 10:35:01 -0500",
          "title": "OpenAI launches Frontier Alliances, entering into multiyear deals with Accenture, BCG, Capgemini, and McKinsey to help deploy its enterprise platform Frontier (Ashley Capoot/CNBC)",
          "standfirst": "Ashley Capoot / CNBC: OpenAI launches Frontier Alliances, entering into multiyear deals with Accenture, BCG, Capgemini, and McKinsey to help deploy its enterprise platform Frontier &mdash; OpenAI on Monday announced it is entering into multiyear partnerships with four consulting firms that will help the company deploy its enterprise platform called Frontier.",
          "content": "Ashley Capoot / CNBC: OpenAI launches Frontier Alliances, entering into multiyear deals with Accenture, BCG, Capgemini, and McKinsey to help deploy its enterprise platform Frontier &mdash; OpenAI on Monday announced it is entering into multiyear partnerships with four consulting firms that will help the company deploy its enterprise platform called Frontier.",
          "feed_position": 9,
          "image_url": "http://www.techmeme.com/260223/i15.jpg"
        }
      ],
      "featured_image": "http://www.techmeme.com/260223/i15.jpg",
      "popularity_score": 2018.2811516666666
    },
    {
      "id": "cluster_30",
      "coverage": 2,
      "updated_at": "Mon, 23 Feb 2026 16:41:22 +0000",
      "title": "Finnish quantum unicorn IQM set to go public",
      "neutral_headline": "Finnish quantum unicorn IQM set to go public",
      "bullet_summary": [
        "Reported by TechCrunch, TechMeme"
      ],
      "items": [
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2026/02/23/finnish-quantum-unicorn-iqm-set-to-go-public/",
          "published_at": "Mon, 23 Feb 2026 16:41:22 +0000",
          "title": "Finnish quantum unicorn IQM set to go public",
          "standfirst": "Finnish unicorn IQM plans to go public via a special purpose acquisition company (SPAC) valuing the company at approximately $1.8 billion — joining the growing cohort of quantum computing companies listed on U.S. stock markets.",
          "content": "Finnish unicorn IQM plans to go public via a special purpose acquisition company (SPAC) valuing the company at approximately $1.8 billion — joining the growing cohort of quantum computing companies listed on U.S. stock markets.",
          "feed_position": 6
        },
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/260223/p16#a260223p16",
          "published_at": "Mon, 23 Feb 2026 10:55:05 -0500",
          "title": "Finnish quantum computing company IQM plans to go public via a SPAC merger with New Jersey-based Real Asset Acquisition in a deal set to value it at $1.8B (Yazhou Sun/Bloomberg)",
          "standfirst": "Yazhou Sun / Bloomberg: Finnish quantum computing company IQM plans to go public via a SPAC merger with New Jersey-based Real Asset Acquisition in a deal set to value it at $1.8B &mdash; IQM Quantum Computers will go public through a merger with a blank-check vehicle in a deal expected to value the Finnish quantum computing firm &hellip;",
          "content": "Yazhou Sun / Bloomberg: Finnish quantum computing company IQM plans to go public via a SPAC merger with New Jersey-based Real Asset Acquisition in a deal set to value it at $1.8B &mdash; IQM Quantum Computers will go public through a merger with a blank-check vehicle in a deal expected to value the Finnish quantum computing firm &hellip;",
          "feed_position": 8,
          "image_url": "http://www.techmeme.com/img/pml.png"
        }
      ],
      "featured_image": "http://www.techmeme.com/img/pml.png",
      "popularity_score": 2016.7850405555555
    },
    {
      "id": "cluster_19",
      "coverage": 1,
      "updated_at": "Mon, 23 Feb 2026 17:45:29 +0000",
      "title": "New Microsoft gaming chief has \"no tolerance for bad AI\"",
      "neutral_headline": "New Microsoft gaming chief has \"no tolerance for bad AI\"",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2026/02/new-microsoft-gaming-chief-has-no-tolerance-for-bad-ai/",
          "published_at": "Mon, 23 Feb 2026 17:45:29 +0000",
          "title": "New Microsoft gaming chief has \"no tolerance for bad AI\"",
          "standfirst": "But Asha Sharma faces scrutiny for lack of gaming experience.",
          "content": "Last week's surprise departure of Phil Spencer from Microsoft led to the promotion of Asha Sharma, who comes to head Microsoft's gaming division after two years as president of the company's CoreAI Product group. Despite that recent history, Sharma says in a new interview that she has \"no tolerance for bad AI\" in game development. Speaking with Variety, Sharma noted that \"AI has long been part of gaming and will continue to be,\" before adding that \"great stories are created by humans.\" The interview comes after Sharma promised in an introductory memo: \"We will not chase short-term efficiency or flood our ecosystem with soulless AI slop. Games are and always will be art, crafted by humans, and created with the most innovative technology provided by us.\" Those statements seem like a clear line in the sand from Sharma against the use of AI tools in Microsoft's first-party game development, at the very least. But what separates \"bad AI\" and \"soulless AI slop\" from \"innovative technology\" that humans can use to create artful games is a matter of some significant debate in the gaming world.Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/sharma-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/sharma-1152x648.jpg",
      "popularity_score": 377.8536516666667
    },
    {
      "id": "cluster_47",
      "coverage": 1,
      "updated_at": "Mon, 23 Feb 2026 15:38:00 +0000",
      "title": "AIs can generate near-verbatim copies of novels from training data",
      "neutral_headline": "AIs can generate near-verbatim copies of novels from training data",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2026/02/ais-can-generate-near-verbatim-copies-of-novels-from-training-data/",
          "published_at": "Mon, 23 Feb 2026 15:38:00 +0000",
          "title": "AIs can generate near-verbatim copies of novels from training data",
          "standfirst": "LLMs memorize more training data than previously thought.",
          "content": "The world’s top AI models can be prompted to generate near-verbatim copies of bestselling novels, raising fresh questions about the industry’s claim that its systems do not store copyrighted works. A series of recent studies has shown that large language models from OpenAI, Google, Meta, Anthropic, and xAI memorize far more of their training data than previously thought. AI and legal experts told the FT this “memorization” ability could have serious ramifications on AI groups’ battle against dozens of copyright lawsuits around the world, as it undermines their core defense that LLMs “learn” from copyrighted works but do not store copies.Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/library-shelves-1152x648-1768598730.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/library-shelves-1152x648-1768598730.jpg",
      "popularity_score": 343.7289294444444
    },
    {
      "id": "cluster_26",
      "coverage": 1,
      "updated_at": "Mon, 23 Feb 2026 17:00:02 +0000",
      "title": "The 2026 Mazda CX-5, driven: It got bigger; plus, radical tech upgrade",
      "neutral_headline": "The 2026 Mazda CX-5, driven: It got bigger; plus, radical tech upgrade",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2026/02/the-2026-mazda-cx-5-driven-it-got-bigger-plus-radical-tech-upgrade/",
          "published_at": "Mon, 23 Feb 2026 17:00:02 +0000",
          "title": "The 2026 Mazda CX-5, driven: It got bigger; plus, radical tech upgrade",
          "standfirst": "Starting at $29,990, there's a lot to like about the all-new Mazda, but it's not perfect.",
          "content": "Mazda provided flights from Washington, DC, to San Diego and accommodation so Ars could drive the CX-5. Ars does not accept paid editorial content. ENCINITAS, Calif.—Its sales may have been buoyed of late by the big CX-90 and CX-70 SUVs, but for Mazda, the CX-5 is still where most of the action is. Unlike the similar-sized, similar-priced CX-50, which was designed just for North America, the all-new CX-5 is a global car, and it's also Mazda's standard-bearer for a range of new technologies. Gone is the basic but effective infotainment system, replaced by an all-new Google-based experience as Mazda starts its journey toward software-defined vehicles. There's even an in-house hybrid on the way, albeit not until next year. And it starts at a competitive $29,990. The new CX-5 is bigger than the car it replaces, 4.5 inches (114.5 mm) longer and half an inch (13 mm) wider than before, at 184.6 inches (4,689 mm) long, 73.2 inches (1,859 mm) wide, and 66.7 inches (1,694 mm) tall. Much of that extra space is between the axles—the wheelbase is now 110 inches (2,794 mm) long, which translates to more interior space. From the outside, there's a new light signature, and the way the bodywork curves around the front and wraps down the fenders gives me strong Range Rover vibes, even if I could never adequately capture what I'm talking about with a camera. As ever, Mazda's arresting Soul Red Crystal metallic paint (a $595 option) sparkles, even on a day when the sun remained hidden from view. The last time that Mazda evolved this compact crossover, it did so with a new upmarket interior. Since then, the brand has staked out that space across its model lineup, with cabins that punch well above their price tags. Happily, the company's designers haven't lost much mojo since then, with a restrained approach that looks good across the five different trim levels, each of which is a $2,000 step up from the one that precedes it. But if you're a current CX-5 driver, you'll find much has changed, perhaps not entirely for the better.Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/2026-Mazda-CX-5-1-1152x648-1771861550.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/2026-Mazda-CX-5-1-1152x648-1771861550.jpg",
      "popularity_score": 340.0961516666667
    },
    {
      "id": "cluster_66",
      "coverage": 1,
      "updated_at": "Mon, 23 Feb 2026 13:51:36 +0000",
      "title": "Review: Knight of the Seven Kingdoms brings back that Westeros magic",
      "neutral_headline": "Review: Knight of the Seven Kingdoms brings back that Westeros magic",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/culture/2026/02/review-knight-of-the-seven-kingdoms-brings-back-that-westeros-magic/",
          "published_at": "Mon, 23 Feb 2026 13:51:36 +0000",
          "title": "Review: Knight of the Seven Kingdoms brings back that Westeros magic",
          "standfirst": "Prequel series is just great storytelling, reminding GoT fans why they loved the original so much.",
          "content": "HBO has another critically acclaimed hit with A Knight of the Seven Kingdoms, based on George R.R. Martin’s Tales of Dunk and Egg novellas, and it deserves every bit of the praise heaped upon it. The immensely satisfying first season wrapped with last night's finale, dealing with the tragedy of the penultimate episode and setting the stage for the further adventures of Dunk and Egg. House of the Dragon is a solid series, but Knight of the Seven Kingdoms has reminded staunch GoT fans of everything they loved about the original series in the first place. (Spoilers below, but no major reveals until after the second gallery. We'll give you a heads up when we get there.) A Knight of the Seven Kingdoms adapts the first novella in the series, The Hedge Knight, and is set more than 50 years after the events of House of the Dragon. Dunk (Peter Claffey) is a lowly hedge knight who has just buried his aged mentor, Ser Arlan of Pennytree (Danny Webb). Ser Arlan was perhaps not the kindest of mentors and often stone drunk, but at least he was hung like the proverbial horse—as viewers discovered in a full-frontal moment that instantly went viral. Lacking any good employment options, Dunk decides to enter a local tournament, since he has inherited Ser Arlan's sword, shield, and three horses.Read full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/dunkTOP-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/dunkTOP-1152x648.jpg",
      "popularity_score": 327.9555961111111
    },
    {
      "id": "cluster_71",
      "coverage": 1,
      "updated_at": "Mon, 23 Feb 2026 12:00:45 +0000",
      "title": "The first cars bold enough to drive themselves",
      "neutral_headline": "The first cars bold enough to drive themselves",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/features/2026/02/the-first-cars-bold-enough-to-drive-themselves/",
          "published_at": "Mon, 23 Feb 2026 12:00:45 +0000",
          "title": "The first cars bold enough to drive themselves",
          "standfirst": "Quevedo's telekino of 1904 was the first step on the road to autonomous Waymos.",
          "content": "No one knows exactly when the vehicles we drive will finally wrest the steering wheel from us. But the age of the autonomous automobile isn’t some sudden Big Bang. It’s more of a slow crawl, one that started during the Roosevelt administration. And that’s Theodore, not Franklin. And not in America, but in Spain, by someone you’ve probably never heard of. His name was Leonardo Torres Quevedo, a Spanish engineer born in Santa Cruz, Spain, in 1852. Smart? In 1914, he developed a mechanical chess machine that autonomously played against humans. But more than a decade earlier, he pioneered the development of remote-control systems. What he wrought was brilliant, if crude—and certainly ahead of its time. The first wireless control It was called the Telekino, a name drawn from the Greek “tele,” meaning at a distance, and “kino,” meaning movement. Patented in Spain, France, and the United States, it was conceived as a way to prevent airship accidents. The Telekino transmitted wireless signals to a small receiver known as a coherer, which detected electromagnetic waves and transformed them into an electrical current. This current was amplified and sent on to electromagnets that slowly rotated a switch controlling the proper servomotor. Quevedo could issue 19 distinct commands to the systems of an airship without ever touching a control cable.Read full article Comments",
          "feed_position": 4,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/radio-controlled-vintage-cars-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/radio-controlled-vintage-cars-1152x648.jpg",
      "popularity_score": 302.10809611111114
    },
    {
      "id": "cluster_102",
      "coverage": 1,
      "updated_at": "Sat, 21 Feb 2026 23:54:38 +0000",
      "title": "NASA says it needs to haul the Artemis II rocket back to the hangar for repairs",
      "neutral_headline": "NASA says it needs to haul the Artemis II rocket back to the hangar for repairs",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2026/02/nasa-says-it-needs-to-haul-the-artemis-ii-rocket-back-to-the-hangar-for-repairs/",
          "published_at": "Sat, 21 Feb 2026 23:54:38 +0000",
          "title": "NASA says it needs to haul the Artemis II rocket back to the hangar for repairs",
          "standfirst": "\"Accessing and remediating any of these issues can only be performed in the VAB.\"",
          "content": "A day after NASA officials expressed optimism that they could be ready to launch the Artemis II mission around the Moon next month, the space agency's administrator announced Saturday that a new problem will require the removal of the rocket from its launch pad in Florida. The latest issue appeared Friday evening, when data showed an interruption in helium flow into the upper stage of the Space Launch System rocket, NASA Administrator Jared Isaacman wrote in a post on X. Isaacman posted a more thorough update Saturday, writing that engineers are still examining the potential cause of the problem, but any fixes must take place inside the Vehicle Assembly Building. That means NASA and contractor ground teams will immediately begin preparing to roll the 322-foot-tall (98-meter) SLS rocket off of Launch Complex 39B and back to the VAB. The rocket and its mobile launch platform will ride NASA's crawler-transporter for the 4-mile journey.Read full article Comments",
          "feed_position": 6,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/IMG_0016-1-1152x648-1771717658.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/IMG_0016-1-1152x648-1771717658.jpg",
      "popularity_score": 288
    },
    {
      "id": "cluster_96",
      "coverage": 1,
      "updated_at": "Sun, 22 Feb 2026 11:20:03 +0000",
      "title": "Study shows how rocket launches pollute the atmosphere",
      "neutral_headline": "Study shows how rocket launches pollute the atmosphere",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2026/02/study-shows-how-rocket-launches-pollute-the-atmosphere/",
          "published_at": "Sun, 22 Feb 2026 11:20:03 +0000",
          "title": "Study shows how rocket launches pollute the atmosphere",
          "standfirst": "Is the global atmospheric commons destined to be an industrial waste dumping ground?",
          "content": "New research published Thursday bolsters growing concerns that a handful of companies and countries are using the global atmospheric commons as a dumping ground for potentially toxic and climate-altering industrial waste byproducts from loosely regulated commercial space flights. The new study analyzed a plume of pollution trailing part of a Falcon rocket that crashed through the upper atmosphere on Feb. 19, 2025, after SpaceX lost control of its reentry. The rocket was launched earlier that month, carrying 20 to 22 Starlink satellites into orbit. The authors said it is the first time debris from a specific spacecraft disintegration has been traced and measured in the near-space region about 80 to 110 kilometers above Earth. Changes there can affect the stratosphere, where ozone and climate processes operate. Until recent years, human activities had little impact in that region.Read full article Comments",
          "feed_position": 5,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/54717981613_dab21dfbc3_k-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/54717981613_dab21dfbc3_k-1152x648.jpg",
      "popularity_score": 283
    }
  ]
}