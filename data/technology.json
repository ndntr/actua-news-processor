{
  "updated_at": "2026-02-19T23:23:25.983Z",
  "clusters": [
    {
      "id": "cluster_10",
      "coverage": 2,
      "updated_at": "Thu, 19 Feb 2026 22:26:00 GMT",
      "title": "Google Gemini 3.1 Pro first impressions: a 'Deep Think Mini' with adjustable reasoning on demand",
      "neutral_headline": "Here are my favorite things from Toy Fair 2026",
      "bullet_summary": [
        "Security leaders VentureBeat interviewed said this is the control they have been building manually — and losing sleep over",
        "“But not the business blast radius,” Keren said",
        "“When we use data to make business decisions, that data must be right,” Keren said",
        "In combination with declining rocket launch costs and the price of powering AI data centers on Earth, Musk has said that within three years space will be the cheapest way to generate AI compute power"
      ],
      "items": [
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/technology/google-gemini-3-1-pro-first-impressions-a-deep-think-mini-with-adjustable",
          "published_at": "Thu, 19 Feb 2026 22:26:00 GMT",
          "title": "Google Gemini 3.1 Pro first impressions: a 'Deep Think Mini' with adjustable reasoning on demand",
          "standfirst": "For the past three months, Google&#x27;s Gemini 3 Pro has held its ground as one of the most capable frontier models available. But in the fast-moving world of AI, three months is a lifetime — and competitors have not been standing still.Earlier today, Google released Gemini 3.1 Pro, an update that brings a key innovation to the company&#x27;s workhorse power model: three levels of adjustable thinking that effectively turn it into a lightweight version of Google&#x27;s specialized Deep Think reasoning system.The release marks the first time Google has issued a \"point one\" update to a Gemini model, signaling a shift in the company&#x27;s release strategy from periodic full-version launches to more frequent incremental upgrades. More importantly for enterprise AI teams evaluating their model stack, 3.1 Pro&#x27;s new three-tier thinking system — low, medium, and high — gives developers and IT leaders a single model that can scale its reasoning effort dynamically, from quick responses for routine queries up to multi-minute deep reasoning sessions for complex problems.The model is rolling out now in preview across the Gemini API via Google AI Studio, Gemini CLI, Google&#x27;s agentic development platform Antigravity, Vertex AI, Gemini Enterprise, Android Studio, the consumer Gemini app, and NotebookLM.The &#x27;Deep Think Mini&#x27; effect: adjustable reasoning on demandThe most consequential feature in Gemini 3.1 Pro is not a single benchmark number — it is the introduction of a three-tier thinking level system that gives users fine-grained control over how much computational effort the model invests in each response.Gemini 3 Pro offered only two thinking modes: low and high. The new 3.1 Pro adds a medium setting (similar to the previous high) and, critically, overhauls what \"high\" means. When set to high, 3.1 Pro behaves as a \"mini version of Gemini Deep Think\" — the company&#x27;s specialized reasoning model that was updated just last week.The implication for enterprise deployment could be significant. Rather than routing requests to different specialized models based on task complexity — a common but operationally burdensome pattern — organizations can now use a single model endpoint and adjust reasoning depth based on the task at hand. Routine document summarization can run on low thinking with fast response times, while complex analytical tasks can be elevated to high thinking for Deep Think–caliber reasoning.Benchmark Performance: More Than Doubling Reasoning Over 3 ProGoogle&#x27;s published benchmarks tell a story of dramatic improvement, particularly in areas associated with reasoning and agentic capability.On ARC-AGI-2, a benchmark that evaluates a model&#x27;s ability to solve novel abstract reasoning patterns, 3.1 Pro scored 77.1% — more than double the 31.1% achieved by Gemini 3 Pro and substantially ahead of Anthropic&#x27;s Sonnet 4.6 (58.3%) and Opus 4.6 (68.8%). This result also eclipses OpenAI&#x27;s GPT-5.2 (52.9%).The gains extend across the board. On Humanity&#x27;s Last Exam, a rigorous academic reasoning benchmark, 3.1 Pro achieved 44.4% without tools, up from 37.5% for 3 Pro and ahead of both Claude Sonnet 4.6 (33.2%) and Opus 4.6 (40.0%). On GPQA Diamond, a scientific knowledge evaluation, 3.1 Pro reached 94.3%, outperforming all listed competitors.Where the results become particularly relevant for enterprise AI teams is in the agentic benchmarks — the evaluations that measure how well models perform when given tools and multi-step tasks, the kind of work that increasingly defines production AI deployments.On Terminal-Bench 2.0, which evaluates agentic terminal coding, 3.1 Pro scored 68.5% compared to 56.9% for its predecessor. On MCP Atlas, a benchmark measuring multi-step workflows using the Model Context Protocol, 3.1 Pro reached 69.2% — a 15-point improvement over 3 Pro&#x27;s 54.1% and nearly 10 points ahead of both Claude and GPT-5.2. And on BrowseComp, which tests agentic web search capability, 3.1 Pro achieved 85.9%, surging past 3 Pro&#x27;s 59.2%.Why Google chose a &#x27;0.1&#x27; release — and what it signalsThe versioning decision is itself noteworthy. Previous Gemini releases followed a pattern of dated previews — multiple 2.5 previews, for instance, before reaching general availability. The choice to designate this update as 3.1 rather than another 3 Pro preview suggests Google views the improvements as substantial enough to warrant a version increment, while the \"point one\" framing sets expectations that this is an evolution, not a revolution.Google&#x27;s blog post states that 3.1 Pro builds directly on lessons from the Gemini Deep Think series, incorporating techniques from both earlier and more recent versions. The benchmarks strongly suggest that reinforcement learning has played a central role in the gains, particularly on tasks like ARC-AGI-2, coding benchmarks, and agentic evaluations — exactly the domains where RL-based training environments can provide clear reward signals.The model is being released in preview rather than as a general availability launch, with Google stating it will continue making advancements in areas such as agentic workflows before moving to full GA.Competitive implications for your enterprise AI stackFor IT decision makers evaluating frontier model providers, Gemini 3.1 Pro&#x27;s release has to not only make them rethink which models to choose but also how to adapt to such a fast pace of change for their own products and services.The question now is whether this release triggers a response from competitors. Gemini 3 Pro&#x27;s original launch last November set off a wave of model releases across both proprietary and open-weight ecosystems. With 3.1 Pro reclaiming benchmark leadership in several critical categories, the pressure is on Anthropic, OpenAI, and the open-weight community to respond — and in the current AI landscape, that response is likely measured in weeks, not months.AvailabilityGemini 3.1 Pro is available now in preview through the Gemini API in Google AI Studio, Gemini CLI, Google Antigravity, and Android Studio for developers. Enterprise customers can access it through Vertex AI and Gemini Enterprise. Consumers on Google AI Pro and Ultra plans can access it through the Gemini app and NotebookLM.",
          "content": "For the past three months, Google&#x27;s Gemini 3 Pro has held its ground as one of the most capable frontier models available. But in the fast-moving world of AI, three months is a lifetime — and competitors have not been standing still.Earlier today, Google released Gemini 3.1 Pro, an update that brings a key innovation to the company&#x27;s workhorse power model: three levels of adjustable thinking that effectively turn it into a lightweight version of Google&#x27;s specialized Deep Think reasoning system.The release marks the first time Google has issued a \"point one\" update to a Gemini model, signaling a shift in the company&#x27;s release strategy from periodic full-version launches to more frequent incremental upgrades. More importantly for enterprise AI teams evaluating their model stack, 3.1 Pro&#x27;s new three-tier thinking system — low, medium, and high — gives developers and IT leaders a single model that can scale its reasoning effort dynamically, from quick responses for routine queries up to multi-minute deep reasoning sessions for complex problems.The model is rolling out now in preview across the Gemini API via Google AI Studio, Gemini CLI, Google&#x27;s agentic development platform Antigravity, Vertex AI, Gemini Enterprise, Android Studio, the consumer Gemini app, and NotebookLM.The &#x27;Deep Think Mini&#x27; effect: adjustable reasoning on demandThe most consequential feature in Gemini 3.1 Pro is not a single benchmark number — it is the introduction of a three-tier thinking level system that gives users fine-grained control over how much computational effort the model invests in each response.Gemini 3 Pro offered only two thinking modes: low and high. The new 3.1 Pro adds a medium setting (similar to the previous high) and, critically, overhauls what \"high\" means. When set to high, 3.1 Pro behaves as a \"mini version of Gemini Deep Think\" — the company&#x27;s specialized reasoning model that was updated just last week.The implication for enterprise deployment could be significant. Rather than routing requests to different specialized models based on task complexity — a common but operationally burdensome pattern — organizations can now use a single model endpoint and adjust reasoning depth based on the task at hand. Routine document summarization can run on low thinking with fast response times, while complex analytical tasks can be elevated to high thinking for Deep Think–caliber reasoning.Benchmark Performance: More Than Doubling Reasoning Over 3 ProGoogle&#x27;s published benchmarks tell a story of dramatic improvement, particularly in areas associated with reasoning and agentic capability.On ARC-AGI-2, a benchmark that evaluates a model&#x27;s ability to solve novel abstract reasoning patterns, 3.1 Pro scored 77.1% — more than double the 31.1% achieved by Gemini 3 Pro and substantially ahead of Anthropic&#x27;s Sonnet 4.6 (58.3%) and Opus 4.6 (68.8%). This result also eclipses OpenAI&#x27;s GPT-5.2 (52.9%).The gains extend across the board. On Humanity&#x27;s Last Exam, a rigorous academic reasoning benchmark, 3.1 Pro achieved 44.4% without tools, up from 37.5% for 3 Pro and ahead of both Claude Sonnet 4.6 (33.2%) and Opus 4.6 (40.0%). On GPQA Diamond, a scientific knowledge evaluation, 3.1 Pro reached 94.3%, outperforming all listed competitors.Where the results become particularly relevant for enterprise AI teams is in the agentic benchmarks — the evaluations that measure how well models perform when given tools and multi-step tasks, the kind of work that increasingly defines production AI deployments.On Terminal-Bench 2.0, which evaluates agentic terminal coding, 3.1 Pro scored 68.5% compared to 56.9% for its predecessor. On MCP Atlas, a benchmark measuring multi-step workflows using the Model Context Protocol, 3.1 Pro reached 69.2% — a 15-point improvement over 3 Pro&#x27;s 54.1% and nearly 10 points ahead of both Claude and GPT-5.2. And on BrowseComp, which tests agentic web search capability, 3.1 Pro achieved 85.9%, surging past 3 Pro&#x27;s 59.2%.Why Google chose a &#x27;0.1&#x27; release — and what it signalsThe versioning decision is itself noteworthy. Previous Gemini releases followed a pattern of dated previews — multiple 2.5 previews, for instance, before reaching general availability. The choice to designate this update as 3.1 rather than another 3 Pro preview suggests Google views the improvements as substantial enough to warrant a version increment, while the \"point one\" framing sets expectations that this is an evolution, not a revolution.Google&#x27;s blog post states that 3.1 Pro builds directly on lessons from the Gemini Deep Think series, incorporating techniques from both earlier and more recent versions. The benchmarks strongly suggest that reinforcement learning has played a central role in the gains, particularly on tasks like ARC-AGI-2, coding benchmarks, and agentic evaluations — exactly the domains where RL-based training environments can provide clear reward signals.The model is being released in preview rather than as a general availability launch, with Google stating it will continue making advancements in areas such as agentic workflows before moving to full GA.Competitive implications for your enterprise AI stackFor IT decision makers evaluating frontier model providers, Gemini 3.1 Pro&#x27;s release has to not only make them rethink which models to choose but also how to adapt to such a fast pace of change for their own products and services.The question now is whether this release triggers a response from competitors. Gemini 3 Pro&#x27;s original launch last November set off a wave of model releases across both proprietary and open-weight ecosystems. With 3.1 Pro reclaiming benchmark leadership in several critical categories, the pressure is on Anthropic, OpenAI, and the open-weight community to respond — and in the current AI landscape, that response is likely measured in weeks, not months.AvailabilityGemini 3.1 Pro is available now in preview through the Gemini API in Google AI Studio, Gemini CLI, Google Antigravity, and Android Studio for developers. Enterprise customers can access it through Vertex AI and Gemini Enterprise. Consumers on Google AI Pro and Ultra plans can access it through the Gemini app and NotebookLM.",
          "feed_position": 0,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/3QN1ZUexlvrsauz6g2NrrK/42bc7a43c49aab36315e98993de78af1/ClKBtgX7u8IrQZI9CACCZ.jpg?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/security/cx-security-gaps-ai-stack-blind-spots",
          "published_at": "Thu, 19 Feb 2026 20:30:00 GMT",
          "title": "How attackers hit 700 organizations through CX platforms your SOC already approved",
          "standfirst": "CX platforms process billions of unstructured interactions a year: Survey forms, review sites, social feeds, call center transcripts, all flowing into AI engines that trigger automated workflows touching payroll, CRM, and payment systems. No tool in a security operation center leader’s stack inspects what a CX platform’s AI engine is ingesting, and attackers figured this out. They poison the data feeding it, and the AI does the damage for them.The Salesloft/Drift breach in August 2025 proved exactly this. Attackers compromised Salesloft’s GitHub environment, stole Drift chatbot OAuth tokens, and accessed Salesforce environments across 700+ organizations, including Cloudflare, Palo Alto Networks, and Zscaler. It then scanned stolen data for AWS keys, Snowflake tokens, and plaintext passwords. And no malware was deployed.That gap is wider than most security leaders realize: 98% of organizations have a data loss prevention (DLP) program, but only 6% have dedicated resources, according to Proofpoint’s 2025 Voice of the CISO report, which surveyed 1,600 CISOs across 16 countries. And 81% of interactive intrusions now use legitimate access rather than malware, per CrowdStrike’s 2025 Threat Hunting Report. Cloud intrusions surged 136% in the first half of 2025.“Most security teams still classify experience management platforms as ‘survey tools,’ which sit in the same risk tier as a project management app,” Assaf Keren, chief security officer at Qualtrics and former CISO at PayPal, told VentureBeat in a recent interview. “This is a massive miscategorization. These platforms now connect to HRIS, CRM, and compensation engines.” Qualtrics alone processes 3.5 billion interactions annually, a figure the company says has doubled since 2023. Organizations can&#x27;t afford to skip steps on input integrity once AI enters the workflow.VentureBeat spent several weeks interviewing security leaders working to close this gap. Six control failures surfaced in every conversation.Six blind spots between the security stack and the AI engine1. DLP cannot see unstructured sentiment data leaving through standard API callsMost DLP policies classify structured personally identifiable information (PII): names, emails, and payment data. Open-text CX responses contain salary complaints, health disclosures, and executive criticism. None matches standard PII patterns. When a third-party AI tool pulls that data, the export looks like a routine API call. The DLP never fires.2. Zombie API tokens from finished campaigns are still liveAn example: Marketing ran a CX campaign six months ago, and the campaign ended. But the OAuth tokens connecting the CX platform to HRIS, CRM and payment systems were never revoked. That means each one is a lateral movement path sitting open.JPMorgan Chase CISO Patrick Opet flagged this risk in his April 2025 open letter, warning that SaaS integration models create “single-factor explicit trust between systems” through tokens “inadequately secured … vulnerable to theft and reuse.”3. Public input channels have no bot mitigation before data reaches the AI engineA web app firewall inspects HTTP payloads for a web application, but none of that coverage extends to a Trustpilot review, a Google Maps rating, or an open-text survey response that a CX platform ingests as legitimate input. Fraudulent sentiment flooding those channels is invisible to perimeter controls. VentureBeat asked security leaders and vendors whether anyone covers input channel integrity for public-facing data sources feeding CX AI engines; it turns out that the category does not exist yet.4. Lateral movement from a compromised CX platform runs through approved API calls“Adversaries aren’t breaking in, they’re logging in,” Daniel Bernard, chief business officer at CrowdStrike, told VentureBeat in an exclusive interview. “It’s a valid login. So from a third-party ISV perspective, you have a sign-in page, you have two-factor authentication. What else do you want from us?” The threat extends to human and non-human identities alike. Bernard described what follows: “All of a sudden, terabytes of data are being exported out. It’s non-standard usage. It’s going places where this user doesn’t go before.” A security information and event management (SIEM) system sees the authentication succeed. It does not see that behavioral shift. Without what Bernard called \"software posture management\" covering CX platforms, the lateral movement runs through connections that the security team already approved.5. Non-technical users hold admin privileges nobody reviewsMarketing, HR and customer success teams configure CX integrations because they need speed, but the SOC team may never see them. Security has to be an enabler, Keren says, or teams route around it. Any organization that cannot produce a current inventory of every CX platform integration and the admin credentials behind them has shadow admin exposure.6. Open-text feedback hits the database before PII gets maskedEmployee surveys capture complaints about managers by name, salary grievances and health disclosures. Customer feedback is just as exposed: account details, purchase history, service disputes. None of this hits a structured PII classifier because it arrives as free text. If a breach exposes it, attackers get unmasked personal information alongside the lateral movement path.Nobody owns this gapThese six failures share a root cause: SaaS security posture management has matured for Salesforce, ServiceNow, and other enterprise platforms. CX platforms never got the same treatment. Nobody monitors user activity, permissions or configurations inside an experience management platform, and policy enforcement on AI workflows processing that data does not exist. When bot-driven input or anomalous data exports hit the CX application layer, nothing detects them.Security teams are responding with what they have. Some are extending SSPM tools to cover CX platform configurations and permissions. API security gateways offer another path, inspecting token scopes and data flows between CX platforms and downstream systems. Identity-centric teams are applying CASB-style access controls to CX admin accounts.None of those approaches delivers what CX-layer security actually requires: continuous monitoring of who is accessing experience data, real-time visibility into misconfigurations before they become lateral movement paths, and automated protection that enforces policy without waiting for a quarterly review cycle.The first integration purpose-built for that gap connects posture management directly to the CX layer, giving security teams the same coverage over program activity, configurations, and data access that they already expect for Salesforce or ServiceNow. CrowdStrike&#x27;s Falcon Shield and the Qualtrics XM Platform are the pairing behind it. Security leaders VentureBeat interviewed said this is the control they have been building manually — and losing sleep over. The blast radius security teams are not measuringMost organizations have mapped the technical blast radius. “But not the business blast radius,” Keren said. When an AI engine triggers a compensation adjustment based on poisoned data, the damage is not a security incident. It is a wrong business decision executed at machine speed. That gap sits between the CISO, the CIO and the business unit owner. Today no one owns it. “When we use data to make business decisions, that data must be right,” Keren said.Run the audit, and start with the zombie tokens. That is where Drift-scale breaches begin. Start with a 30-day validation window. The AI will not wait.",
          "content": "CX platforms process billions of unstructured interactions a year: Survey forms, review sites, social feeds, call center transcripts, all flowing into AI engines that trigger automated workflows touching payroll, CRM, and payment systems. No tool in a security operation center leader’s stack inspects what a CX platform’s AI engine is ingesting, and attackers figured this out. They poison the data feeding it, and the AI does the damage for them.The Salesloft/Drift breach in August 2025 proved exactly this. Attackers compromised Salesloft’s GitHub environment, stole Drift chatbot OAuth tokens, and accessed Salesforce environments across 700+ organizations, including Cloudflare, Palo Alto Networks, and Zscaler. It then scanned stolen data for AWS keys, Snowflake tokens, and plaintext passwords. And no malware was deployed.That gap is wider than most security leaders realize: 98% of organizations have a data loss prevention (DLP) program, but only 6% have dedicated resources, according to Proofpoint’s 2025 Voice of the CISO report, which surveyed 1,600 CISOs across 16 countries. And 81% of interactive intrusions now use legitimate access rather than malware, per CrowdStrike’s 2025 Threat Hunting Report. Cloud intrusions surged 136% in the first half of 2025.“Most security teams still classify experience management platforms as ‘survey tools,’ which sit in the same risk tier as a project management app,” Assaf Keren, chief security officer at Qualtrics and former CISO at PayPal, told VentureBeat in a recent interview. “This is a massive miscategorization. These platforms now connect to HRIS, CRM, and compensation engines.” Qualtrics alone processes 3.5 billion interactions annually, a figure the company says has doubled since 2023. Organizations can&#x27;t afford to skip steps on input integrity once AI enters the workflow.VentureBeat spent several weeks interviewing security leaders working to close this gap. Six control failures surfaced in every conversation.Six blind spots between the security stack and the AI engine1. DLP cannot see unstructured sentiment data leaving through standard API callsMost DLP policies classify structured personally identifiable information (PII): names, emails, and payment data. Open-text CX responses contain salary complaints, health disclosures, and executive criticism. None matches standard PII patterns. When a third-party AI tool pulls that data, the export looks like a routine API call. The DLP never fires.2. Zombie API tokens from finished campaigns are still liveAn example: Marketing ran a CX campaign six months ago, and the campaign ended. But the OAuth tokens connecting the CX platform to HRIS, CRM and payment systems were never revoked. That means each one is a lateral movement path sitting open.JPMorgan Chase CISO Patrick Opet flagged this risk in his April 2025 open letter, warning that SaaS integration models create “single-factor explicit trust between systems” through tokens “inadequately secured … vulnerable to theft and reuse.”3. Public input channels have no bot mitigation before data reaches the AI engineA web app firewall inspects HTTP payloads for a web application, but none of that coverage extends to a Trustpilot review, a Google Maps rating, or an open-text survey response that a CX platform ingests as legitimate input. Fraudulent sentiment flooding those channels is invisible to perimeter controls. VentureBeat asked security leaders and vendors whether anyone covers input channel integrity for public-facing data sources feeding CX AI engines; it turns out that the category does not exist yet.4. Lateral movement from a compromised CX platform runs through approved API calls“Adversaries aren’t breaking in, they’re logging in,” Daniel Bernard, chief business officer at CrowdStrike, told VentureBeat in an exclusive interview. “It’s a valid login. So from a third-party ISV perspective, you have a sign-in page, you have two-factor authentication. What else do you want from us?” The threat extends to human and non-human identities alike. Bernard described what follows: “All of a sudden, terabytes of data are being exported out. It’s non-standard usage. It’s going places where this user doesn’t go before.” A security information and event management (SIEM) system sees the authentication succeed. It does not see that behavioral shift. Without what Bernard called \"software posture management\" covering CX platforms, the lateral movement runs through connections that the security team already approved.5. Non-technical users hold admin privileges nobody reviewsMarketing, HR and customer success teams configure CX integrations because they need speed, but the SOC team may never see them. Security has to be an enabler, Keren says, or teams route around it. Any organization that cannot produce a current inventory of every CX platform integration and the admin credentials behind them has shadow admin exposure.6. Open-text feedback hits the database before PII gets maskedEmployee surveys capture complaints about managers by name, salary grievances and health disclosures. Customer feedback is just as exposed: account details, purchase history, service disputes. None of this hits a structured PII classifier because it arrives as free text. If a breach exposes it, attackers get unmasked personal information alongside the lateral movement path.Nobody owns this gapThese six failures share a root cause: SaaS security posture management has matured for Salesforce, ServiceNow, and other enterprise platforms. CX platforms never got the same treatment. Nobody monitors user activity, permissions or configurations inside an experience management platform, and policy enforcement on AI workflows processing that data does not exist. When bot-driven input or anomalous data exports hit the CX application layer, nothing detects them.Security teams are responding with what they have. Some are extending SSPM tools to cover CX platform configurations and permissions. API security gateways offer another path, inspecting token scopes and data flows between CX platforms and downstream systems. Identity-centric teams are applying CASB-style access controls to CX admin accounts.None of those approaches delivers what CX-layer security actually requires: continuous monitoring of who is accessing experience data, real-time visibility into misconfigurations before they become lateral movement paths, and automated protection that enforces policy without waiting for a quarterly review cycle.The first integration purpose-built for that gap connects posture management directly to the CX layer, giving security teams the same coverage over program activity, configurations, and data access that they already expect for Salesforce or ServiceNow. CrowdStrike&#x27;s Falcon Shield and the Qualtrics XM Platform are the pairing behind it. Security leaders VentureBeat interviewed said this is the control they have been building manually — and losing sleep over. The blast radius security teams are not measuringMost organizations have mapped the technical blast radius. “But not the business blast radius,” Keren said. When an AI engine triggers a compensation adjustment based on poisoned data, the damage is not a security incident. It is a wrong business decision executed at machine speed. That gap sits between the CISO, the CIO and the business unit owner. Today no one owns it. “When we use data to make business decisions, that data must be right,” Keren said.Run the audit, and start with the zombie tokens. That is where Drift-scale breaches begin. Start with a 30-day validation window. The AI will not wait.",
          "feed_position": 1,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/43aX4cDa02bPoqhoIKZoZM/fbdb75fd26097eae87df002190cb9af5/final_hero.jpg?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/entertainment/here-are-my-favorite-things-from-toy-fair-2026-183356720.html",
          "published_at": "Thu, 19 Feb 2026 18:33:56 +0000",
          "title": "Here are my favorite things from Toy Fair 2026",
          "standfirst": "Toy Fair 2026 just wrapped earlier this week and while I would have liked to spend even more time there, I have my own kids (and all their toys and trinkets) to look after. That said, there were a ton of cool new products on display at the Javits Center in New York City that set the stage for the rest of the year, so here's a quick look at some of the most interesting releases from the largest toy show in the Western Hemisphere. Transformers: The Movie 40th anniversary figures ($28 to $60)To celebrate the 40th anniversary of Transformers: The Movie, Hasbro is launching an apology tour to make up for traumatizing theatergoers with the death of the most beloved Autobot back in 1986. To kick things off, Hasbro is releasing a handful of new figures alongside re-releases for some popular bots including Astrotrain, Skywarp, Snarl and Shockwave. I want to give a special shout-out to the model for Kranix, which looks incredibly accurate, as if he just leapt off the movie screen. And even though his duck-billed spaceship alt-mode might look a bit awkward, I wouldn't have it any other way. The crown jewel of the line might be a near-life-size version of The Matrix of Leadership, which measures more than 15 inches wide and even plays Stan Bush's iconic song \"The Touch\" with the push of a button. Unfortunately, the appeal of the Matrix is so powerful that it's already sold out, including at third-party retailers like Big Bad Toy Store, which thankfully is still taking pre-orders for the rest of the lineup after the initial stock from Hasbro dried up.F1 Hot WheelsA collection of some of the new F1 Hot Wheels cars for 2026. Sam Rutherford for EngadgetHot Wheels has big plans for 2026 including a new line of Pantone-colored cars, Brick Shop models like the Elite Series Aston Martin (which comes with its own 1:64 scale car) and a Monster Truck Mutant Chaos set with actual slime. However, I'd argue the company's new F1 offerings are the cream of the crop. Not only are there a bunch of incredibly detailed 1:64 scale racecars with metal bodies, real rubber tires and accurate livery for all the big teams, there's also a new Downhill Circuit Race course that comes with three official vehicles (Mercedes, Haas and Ferrari) featuring multiple levels and the ability to overtake or crash into other cars. If you're like a lot of Americans who have recently fallen down the F1 rabbit hole due to Netflix's Drive to Survive, these new officially licensed miniatures are sure to hit the spot. The first five-pack set of cars is available now, with more arriving later this spring before the Downhill Circuit Race course drives by sometime this fall. Lego Star Wars with Smart Bricks ($40 to $160)Darth Vader's TIE fighter is an all-in-one set, which means it comes included with one of Lego's Smart Bricks, which isn't true for every kit. LegoWe've been eagerly awaiting the first batch of playsets featuring Lego's nifty Smart Brick after it debuted at CES. But now that the company has detailed eight new sets featuring its latest innovation, we're even more intrigued. For me, the three standout kits are the Millennium Falcon, Luke's Red Five X-Wing and Darth Vader's TIE fighter because acting out the Death Star trench run complete with reactive lights and sounds will never get old. I also have a soft spot for the Ewok minifigs that come with the AT-ST set. Alternatively, the Mos Eisley Cantina kit seems like a great way to highlight the smart brick's ability to play music or kick out some rowdy droids. The one thing to look out for, though, is the tag on the set that says whether it's Smart Play compatible or if it's an all-in-one set, because the former will need Smart Bricks from other kits to deliver Lego's newfound interactivity. Pre-orders for these are live now, with sets slated to ship on March 1. All the new K-pop Demon Hunters toysThe HUNTR/X Battle Rumi Deluxe Fashion Doll (right) might be my favorite of the bunch. Sam Rutherford for EngadgetRumi, Mira and Zoey may have been the biggest breakout stars of 2025 and Mattel is looking to keep that momentum going with a ton of new toys and figures for everyone's favorite demon hunters. There are three new singing dolls that can belt out the trio's hit \"Golden\" at the touch of a button and a deluxe figure of Rumi complete with her Four Tiger Sword. There are also a ton of other dolls and miniatures showcasing HUNTR/X, the Saja Boys and more. The one downside is that these products aren't coming out until the fall, so you'll have to tide yourself over with other K-pop-themed products for now. Hatchin' Yoshi ($50)If Rosalina isn't careful, Yoshi will become the biggest draw of the new Mario movie. Spin MastersYoshi seems poised to steal the spotlight from Rosalina in the upcoming Super Mario Galaxy Movie and this release from Spin Masters is only reinforcing the lovable green dino's aura. From inside his shell, Yoshi can burst out with his signature yell. After that, you can pat his nose to make his eyes light up or get him to rock when he's really happy. But if you want one, you're going to have to be vigilant. Pre-orders are already sold out, so you'll need to keep a close eye on retailers like Walmart when he officially goes on sale on February 20. Thames and Kosmos SolarFlowersNot only do the SolarFlowers look great, they're educational too. Thames & KosmosTechnically, these went on sale last month, but Thames & Kosmos' SolarFlowers caught my eye again at Toy Fair due to their combination of art and science. Available in four different styles, each kit features a model that you can build yourself or with your kids (recommended age 8+) that turns into a lasting showpiece. After putting the kinetic sculpture together, you can connect the included solar panel to bring the whole kit to life (no batteries required) and make the flowers spin for perpetual entertainment. Honorable mentionsUpcoming Masters of the Universe figuresSome upcoming figures from Mattel's line of Masters of the Universe figures. Sam Rutherford for EngadgetAs someone who grew up during the 80s and 90s, I'm trying to be optimistic about He-Man's return to the big screen later this summer and Mattel's new line of figures is certainly helping. To help prime people for the movie, there's a big range of upcoming toys highlighting He-Man, Skeletor, Battle Cat and more, all of which I would have absolutely loved as a kid. Those will be available later this spring.Fisher-Price Super Mario Little People collectionJust look how cute these are. Sam Rutherford for EngadgetIt's hard to gauge the excitement of toys aimed at one-year-olds when they can't read or get into Toy Fair. But as the parent of a toddler, I adore the partnership between Fisher-Price and Nintendo that has resulted in a line of Mario-themed Little People. All the big names are here, including Peach, Luigi and Bowser and there's even a couple of super cute playsets to go with them. But perhaps the best part is that a six-pack of figures and Bower's Airship costs under $25, which means your kid could be in for hours of fun without you spending a ton of money. This article originally appeared on Engadget at https://www.engadget.com/entertainment/here-are-my-favorite-things-from-toy-fair-2026-183356720.html?src=rss",
          "content": "Toy Fair 2026 just wrapped earlier this week and while I would have liked to spend even more time there, I have my own kids (and all their toys and trinkets) to look after. That said, there were a ton of cool new products on display at the Javits Center in New York City that set the stage for the rest of the year, so here's a quick look at some of the most interesting releases from the largest toy show in the Western Hemisphere. Transformers: The Movie 40th anniversary figures ($28 to $60)To celebrate the 40th anniversary of Transformers: The Movie, Hasbro is launching an apology tour to make up for traumatizing theatergoers with the death of the most beloved Autobot back in 1986. To kick things off, Hasbro is releasing a handful of new figures alongside re-releases for some popular bots including Astrotrain, Skywarp, Snarl and Shockwave. I want to give a special shout-out to the model for Kranix, which looks incredibly accurate, as if he just leapt off the movie screen. And even though his duck-billed spaceship alt-mode might look a bit awkward, I wouldn't have it any other way. The crown jewel of the line might be a near-life-size version of The Matrix of Leadership, which measures more than 15 inches wide and even plays Stan Bush's iconic song \"The Touch\" with the push of a button. Unfortunately, the appeal of the Matrix is so powerful that it's already sold out, including at third-party retailers like Big Bad Toy Store, which thankfully is still taking pre-orders for the rest of the lineup after the initial stock from Hasbro dried up.F1 Hot WheelsA collection of some of the new F1 Hot Wheels cars for 2026. Sam Rutherford for EngadgetHot Wheels has big plans for 2026 including a new line of Pantone-colored cars, Brick Shop models like the Elite Series Aston Martin (which comes with its own 1:64 scale car) and a Monster Truck Mutant Chaos set with actual slime. However, I'd argue the company's new F1 offerings are the cream of the crop. Not only are there a bunch of incredibly detailed 1:64 scale racecars with metal bodies, real rubber tires and accurate livery for all the big teams, there's also a new Downhill Circuit Race course that comes with three official vehicles (Mercedes, Haas and Ferrari) featuring multiple levels and the ability to overtake or crash into other cars. If you're like a lot of Americans who have recently fallen down the F1 rabbit hole due to Netflix's Drive to Survive, these new officially licensed miniatures are sure to hit the spot. The first five-pack set of cars is available now, with more arriving later this spring before the Downhill Circuit Race course drives by sometime this fall. Lego Star Wars with Smart Bricks ($40 to $160)Darth Vader's TIE fighter is an all-in-one set, which means it comes included with one of Lego's Smart Bricks, which isn't true for every kit. LegoWe've been eagerly awaiting the first batch of playsets featuring Lego's nifty Smart Brick after it debuted at CES. But now that the company has detailed eight new sets featuring its latest innovation, we're even more intrigued. For me, the three standout kits are the Millennium Falcon, Luke's Red Five X-Wing and Darth Vader's TIE fighter because acting out the Death Star trench run complete with reactive lights and sounds will never get old. I also have a soft spot for the Ewok minifigs that come with the AT-ST set. Alternatively, the Mos Eisley Cantina kit seems like a great way to highlight the smart brick's ability to play music or kick out some rowdy droids. The one thing to look out for, though, is the tag on the set that says whether it's Smart Play compatible or if it's an all-in-one set, because the former will need Smart Bricks from other kits to deliver Lego's newfound interactivity. Pre-orders for these are live now, with sets slated to ship on March 1. All the new K-pop Demon Hunters toysThe HUNTR/X Battle Rumi Deluxe Fashion Doll (right) might be my favorite of the bunch. Sam Rutherford for EngadgetRumi, Mira and Zoey may have been the biggest breakout stars of 2025 and Mattel is looking to keep that momentum going with a ton of new toys and figures for everyone's favorite demon hunters. There are three new singing dolls that can belt out the trio's hit \"Golden\" at the touch of a button and a deluxe figure of Rumi complete with her Four Tiger Sword. There are also a ton of other dolls and miniatures showcasing HUNTR/X, the Saja Boys and more. The one downside is that these products aren't coming out until the fall, so you'll have to tide yourself over with other K-pop-themed products for now. Hatchin' Yoshi ($50)If Rosalina isn't careful, Yoshi will become the biggest draw of the new Mario movie. Spin MastersYoshi seems poised to steal the spotlight from Rosalina in the upcoming Super Mario Galaxy Movie and this release from Spin Masters is only reinforcing the lovable green dino's aura. From inside his shell, Yoshi can burst out with his signature yell. After that, you can pat his nose to make his eyes light up or get him to rock when he's really happy. But if you want one, you're going to have to be vigilant. Pre-orders are already sold out, so you'll need to keep a close eye on retailers like Walmart when he officially goes on sale on February 20. Thames and Kosmos SolarFlowersNot only do the SolarFlowers look great, they're educational too. Thames & KosmosTechnically, these went on sale last month, but Thames & Kosmos' SolarFlowers caught my eye again at Toy Fair due to their combination of art and science. Available in four different styles, each kit features a model that you can build yourself or with your kids (recommended age 8+) that turns into a lasting showpiece. After putting the kinetic sculpture together, you can connect the included solar panel to bring the whole kit to life (no batteries required) and make the flowers spin for perpetual entertainment. Honorable mentionsUpcoming Masters of the Universe figuresSome upcoming figures from Mattel's line of Masters of the Universe figures. Sam Rutherford for EngadgetAs someone who grew up during the 80s and 90s, I'm trying to be optimistic about He-Man's return to the big screen later this summer and Mattel's new line of figures is certainly helping. To help prime people for the movie, there's a big range of upcoming toys highlighting He-Man, Skeletor, Battle Cat and more, all of which I would have absolutely loved as a kid. Those will be available later this spring.Fisher-Price Super Mario Little People collectionJust look how cute these are. Sam Rutherford for EngadgetIt's hard to gauge the excitement of toys aimed at one-year-olds when they can't read or get into Toy Fair. But as the parent of a toddler, I adore the partnership between Fisher-Price and Nintendo that has resulted in a line of Mario-themed Little People. All the big names are here, including Peach, Luigi and Bowser and there's even a couple of super cute playsets to go with them. But perhaps the best part is that a six-pack of figures and Bower's Airship costs under $25, which means your kid could be in for hours of fun without you spending a ton of money. This article originally appeared on Engadget at https://www.engadget.com/entertainment/here-are-my-favorite-things-from-toy-fair-2026-183356720.html?src=rss",
          "feed_position": 3,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/f1-hotwheels.jpg"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/technology/google-launches-gemini-3-1-pro-retaking-ai-crown-with-2x-reasoning",
          "published_at": "Thu, 19 Feb 2026 17:30:00 GMT",
          "title": "Google launches Gemini 3.1 Pro, retaking AI crown with 2X+ reasoning performance boost",
          "standfirst": "Late last year, Google briefly took the crown for most powerful AI model in the world with the launch of Gemini 3 Pro — only to be surpassed within weeks by OpenAI and Anthropic releasing new models, s is common in the fiercely competitive AI race.Now Google is back to retake the throne with an updated version of that flagship model: Gemini 3.1 Pro, positioned as a smarter baseline for tasks where a simple response is insufficient—targeting science, research, and engineering workflows that demand deep planning and synthesis.Already, evaluations by third-party firm Artificial Analysis show that Google&#x27;s Gemini 3.1 Pro has leapt to the front of the pack and is once more the most powerful and performant AI model in the world. A big leap in core reasoningThe most significant advancement in Gemini 3.1 Pro lies in its performance on rigorous logic benchmarks. Most notably, the model achieved a verified score of 77.1% on ARC-AGI-2. This specific benchmark is designed to evaluate a model&#x27;s ability to solve entirely new logic patterns it has not encountered during training. This result represents more than double the reasoning performance of the previous Gemini 3 Pro model.Beyond abstract logic, internal benchmarks indicate that 3.1 Pro is highly competitive across specialized domains:Scientific Knowledge: It scored 94.3% on GPQA Diamond.Coding: It reached an Elo of 2887 on LiveCodeBench Pro and scored 80.6% on SWE-Bench Verified.Multimodal Understanding: It achieved 92.6% on MMMLU.These technical gains are not just incremental; they represent a refinement in how the model handles \"thinking\" tokens and long-horizon tasks, providing a more reliable foundation for developers building autonomous agents.Improved vibe coding and 3D synthesisGoogle is demonstrating the model’s utility through \"intelligence applied\"—shifting the focus from chat interfaces to functional outputs. One of the most prominent features is the model&#x27;s ability to generate \"vibe-coded\" animated SVGs directly from text prompts. Because these are code-based rather than pixel-based, they remain scalable and maintain tiny file sizes compared to traditional video, boasting far more detailed, presentable and professional visuals for websites and presentations and other enterprise applications.Other showcased applications include:Complex System Synthesis: The model successfully configured a public telemetry stream to build a live aerospace dashboard visualizing the International Space Station’s orbit.Interactive Design: In one demo, 3.1 Pro coded a complex 3D starling murmuration that users can manipulate via hand-tracking, accompanied by a generative audio score.Creative Coding: The model translated the atmospheric themes of Emily Brontë’s Wuthering Heights into a functional, modern web design, demonstrating an ability to reason through tone and style rather than just literal text.Business impact and community reactionsEnterprise partners have already begun integrating the preview version of 3.1 Pro, reporting noticeable improvements in reliability and efficiency. Vladislav Tankov, Director of AI at JetBrains, noted a 15% quality improvement over previous versions, stating the model is \"stronger, faster... and more efficient, requiring fewer output tokens\". Other industry reactions include:Databricks: CTO Hanlin Tang reported that the model achieved \"best-in-class results\" on OfficeQA, a benchmark for grounded reasoning across tabular and unstructured data.Cartwheel: Co-founder Andrew Carr highlighted the model&#x27;s \"substantially improved understanding of 3D transformations,\" noting it resolved long-standing rotation order bugs in 3D animation pipelines.Hostinger Horizons: Head of Product Dainius Kavoliunas observed that the model understands the \"vibe\" behind a prompt, translating intent into style-accurate code for non-developers.Pricing, licensing, and availabilityFor developers, the most striking aspect of the 3.1 Pro release is the \"reasoning-to-dollar\" ratio. When Gemini 3 Pro launched, it was positioned in the mid-high price range at $2.00 per million input tokens for standard prompts. Gemini 3.1 Pro maintains this exact pricing structure, effectively offering a massive performance upgrade at no additional cost to API users.Input Price: $2.00 per 1M tokens for prompts up to 200k; $4.00 per 1M tokens for prompts over 200k.Output Price: $12.00 per 1M tokens for prompts up to 200k; $18.00 per 1M tokens for prompts over 200k.Context Caching: Billed at $0.20 to $0.40 per 1M tokens depending on prompt size, plus a storage fee of $4.50 per 1M tokens per hour.Search Grounding: 5,000 prompts per month are free, followed by a charge of $14 per 1,000 search queries.For consumers, the model is rolling out in the Gemini app and NotebookLM with higher limits for Google AI Pro and Ultra subscribers.Licensing implicationsAs a proprietary model offered through Vertex Studio in Google Cloud and the Gemini API, 3.1 Pro follows a standard commercial SaaS (Software as a Service) model rather than an open-source license. For enterprise users, this provides \"grounded reasoning\" within the security perimeter of Vertex AI, allowing businesses to operate on their own data with confidence. The \"Preview\" status allows Google to refine the model&#x27;s safety and performance before general availability, a common practice in high-stakes AI deployment.By doubling down on core reasoning and specialized benchmarks like ARC-AGI-2, Google is signaling that the next phase of the AI race will be won by models that can think through a problem, not just predict the next word.",
          "content": "Late last year, Google briefly took the crown for most powerful AI model in the world with the launch of Gemini 3 Pro — only to be surpassed within weeks by OpenAI and Anthropic releasing new models, s is common in the fiercely competitive AI race.Now Google is back to retake the throne with an updated version of that flagship model: Gemini 3.1 Pro, positioned as a smarter baseline for tasks where a simple response is insufficient—targeting science, research, and engineering workflows that demand deep planning and synthesis.Already, evaluations by third-party firm Artificial Analysis show that Google&#x27;s Gemini 3.1 Pro has leapt to the front of the pack and is once more the most powerful and performant AI model in the world. A big leap in core reasoningThe most significant advancement in Gemini 3.1 Pro lies in its performance on rigorous logic benchmarks. Most notably, the model achieved a verified score of 77.1% on ARC-AGI-2. This specific benchmark is designed to evaluate a model&#x27;s ability to solve entirely new logic patterns it has not encountered during training. This result represents more than double the reasoning performance of the previous Gemini 3 Pro model.Beyond abstract logic, internal benchmarks indicate that 3.1 Pro is highly competitive across specialized domains:Scientific Knowledge: It scored 94.3% on GPQA Diamond.Coding: It reached an Elo of 2887 on LiveCodeBench Pro and scored 80.6% on SWE-Bench Verified.Multimodal Understanding: It achieved 92.6% on MMMLU.These technical gains are not just incremental; they represent a refinement in how the model handles \"thinking\" tokens and long-horizon tasks, providing a more reliable foundation for developers building autonomous agents.Improved vibe coding and 3D synthesisGoogle is demonstrating the model’s utility through \"intelligence applied\"—shifting the focus from chat interfaces to functional outputs. One of the most prominent features is the model&#x27;s ability to generate \"vibe-coded\" animated SVGs directly from text prompts. Because these are code-based rather than pixel-based, they remain scalable and maintain tiny file sizes compared to traditional video, boasting far more detailed, presentable and professional visuals for websites and presentations and other enterprise applications.Other showcased applications include:Complex System Synthesis: The model successfully configured a public telemetry stream to build a live aerospace dashboard visualizing the International Space Station’s orbit.Interactive Design: In one demo, 3.1 Pro coded a complex 3D starling murmuration that users can manipulate via hand-tracking, accompanied by a generative audio score.Creative Coding: The model translated the atmospheric themes of Emily Brontë’s Wuthering Heights into a functional, modern web design, demonstrating an ability to reason through tone and style rather than just literal text.Business impact and community reactionsEnterprise partners have already begun integrating the preview version of 3.1 Pro, reporting noticeable improvements in reliability and efficiency. Vladislav Tankov, Director of AI at JetBrains, noted a 15% quality improvement over previous versions, stating the model is \"stronger, faster... and more efficient, requiring fewer output tokens\". Other industry reactions include:Databricks: CTO Hanlin Tang reported that the model achieved \"best-in-class results\" on OfficeQA, a benchmark for grounded reasoning across tabular and unstructured data.Cartwheel: Co-founder Andrew Carr highlighted the model&#x27;s \"substantially improved understanding of 3D transformations,\" noting it resolved long-standing rotation order bugs in 3D animation pipelines.Hostinger Horizons: Head of Product Dainius Kavoliunas observed that the model understands the \"vibe\" behind a prompt, translating intent into style-accurate code for non-developers.Pricing, licensing, and availabilityFor developers, the most striking aspect of the 3.1 Pro release is the \"reasoning-to-dollar\" ratio. When Gemini 3 Pro launched, it was positioned in the mid-high price range at $2.00 per million input tokens for standard prompts. Gemini 3.1 Pro maintains this exact pricing structure, effectively offering a massive performance upgrade at no additional cost to API users.Input Price: $2.00 per 1M tokens for prompts up to 200k; $4.00 per 1M tokens for prompts over 200k.Output Price: $12.00 per 1M tokens for prompts up to 200k; $18.00 per 1M tokens for prompts over 200k.Context Caching: Billed at $0.20 to $0.40 per 1M tokens depending on prompt size, plus a storage fee of $4.50 per 1M tokens per hour.Search Grounding: 5,000 prompts per month are free, followed by a charge of $14 per 1,000 search queries.For consumers, the model is rolling out in the Gemini app and NotebookLM with higher limits for Google AI Pro and Ultra subscribers.Licensing implicationsAs a proprietary model offered through Vertex Studio in Google Cloud and the Gemini API, 3.1 Pro follows a standard commercial SaaS (Software as a Service) model rather than an open-source license. For enterprise users, this provides \"grounded reasoning\" within the security perimeter of Vertex AI, allowing businesses to operate on their own data with confidence. The \"Preview\" status allows Google to refine the model&#x27;s safety and performance before general availability, a common practice in high-stakes AI deployment.By doubling down on core reasoning and specialized benchmarks like ARC-AGI-2, Google is signaling that the next phase of the AI race will be won by models that can think through a problem, not just predict the next word.",
          "feed_position": 2,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/4WI6UovKEMHNOYRmLhUkWL/7353b15db9e6644396c21abfb95c9f42/odtwyodoZOZvjDt413OWa_05gXxMoM.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/orbital-ai-data-centers-could-work-but-they-might-ruin-earth-in-the-process-170000099.html",
          "published_at": "Thu, 19 Feb 2026 17:00:00 +0000",
          "title": "Orbital AI data centers could work, but they might ruin Earth in the process",
          "standfirst": "At the start of the month, Elon Musk announced that two of his companies — SpaceX and xAI — were merging, and would jointly launch a constellation of 1 million satellites to operate as orbital data centers. Musk's reputation might suggest otherwise, but according to experts, such a plan isn't a complete fantasy. However, if executed at the scale suggested, some of them believe it would have devastating effects on the environment and the sustainability of low Earth Earth orbit. Musk and others argue that putting data centers in space is practical given how much more efficient solar panels are away from Earth's atmosphere. In space, there are no clouds or weather events to obscure the sun, and in the correct orbit, solar panels can collect sunlight through much of the day. In combination with declining rocket launch costs and the price of powering AI data centers on Earth, Musk has said that within three years space will be the cheapest way to generate AI compute power. Ahead of the billionaire's announcement, SpaceX filed an eight-page application with the Federal Communications Commission detailing his plan. The company hopes to deposit the satellites in this massive cluster in altitudes ranging between 500km and 2000km. They would communicate with one another and SpaceX's Starlink constellation using laser \"optical links.\" Those Starlink satellites would then transmit inference requests to and from Earth. To power the entire effort, SpaceX has proposed putting the new constellation in sun-synchronous orbit, meaning the spacecraft would fly along the dividing line that separates the day and night sides of the planet. What a data center would endure in orbitAlmost immediately the plan was greeted with skepticism. How would SpaceX, for instance, cool millions of GPUs in space? At first glance, that might seem like a weird point to get hung up on — much of space being around -450 Fahrenheit — but the reality is more complicated. In the near vacuum of space, the only way to dissipate heat is to slowly radiate it out, and in direct sunlight, objects can easily overheat. As one commenter on Hacker News succinctly put it, \"a satellite is, if nothing else, a fantastic thermos.\"Scott Manley, who, before he created one of the most popular space-focused channels on YouTube, was a software engineer and studied computational physics and astronomy, argues SpaceX has already solved that problem at a smaller scale with Starlink. He points to the company's latest V3 model, which has about 30 square meters of solar panels. \"They have a bunch of electronics in the middle, which are taking that power and doing stuff with it. Now, some of that power is being beamed away as radio waves, but there's a lot of thermal power that's being generated and then having to be dissipated. So they already have a platform that's running electronics off of power, and so it's not a massive leap to turn into something doing compute.\"The larger V3 @Starlink satellites that will deploy from Starship will bring gigabit connectivity to users and are designed to add 60 Tera-bits-per-second of downlink capacity to the Starlink network.That's more than 20 times the capacity added with every V2 Mini launch on… pic.twitter.com/N0Vl9psbm3— SpaceX (@SpaceX) October 13, 2025 Kevin Hicks, a former NASA systems engineer who worked on the Curiosity rover mission, is more skeptical. \"Satellites with the primary goal of processing large amounts of compute requests would generate more heat than pretty much any other type of satellite,\" he said. \"Cooling them is another aspect of the design which is theoretically possible but would require a ton of extra work and complexity, and I have doubts about the durability of such a cooling system.\" What about radiation then? There's a reason NASA relies on ancient hardware like the PowerPC 750 CPU found inside the Perseverance rover: Older chips feature larger transistors, making them more resilient to bit flips — errors in processing caused most often by cosmic radiation — that might scramble a computation. \"Binary ones and zeroes are about the presence or absence of electrons, and the amount of charge required to represent a 'one' goes down as the transistors get smaller and smaller,\" explains Benjamin Lee, professor of computer and information science at the University of Pennsylvania. Space is full of energized particles traveling at incredible velocities, and the latest GPUs are built on the smallest, most advanced processing nodes to create transistor-dense silicon. Not a great combination.\"My concern about radiation is that we don't know how many bit flips will occur when you deploy the most advanced chips and hundreds of gigabytes of memory up there,\" said Professor Lee, pointing to preliminary research by Google on the subject. As part of Project Suncatcher, its own effort to explore the viability of space-based data centers, the company put one of its Trillium TPUs in front of a proton beam to bombard it with radiation. It found the silicon was \"surprisingly radiation-hard for space applications.\" While those results were promising, Professor Lee points out we just don't know how resilient GPUs are to radiation at this scale. \"Even though modern computer architectures can detect and sometimes correct for those errors, having to do that again and again will slow down or add overhead to space-based computation,\" he said. Space engineer Andrew McCalip, who's done a deep dive on the economics of orbital data centers, is more optimistic, pointing to the natural resilience of AI models. \"They don't require 100 percent perfect error-free runs. They're inherently very noisy, very stochastic,\" he explains, adding that part of the training for modern AI systems involves \"injecting random noise into different layers.\" Even if SpaceX could harden its GPUs against radiation, the company would still lose satellites to GPUs that break down. If you know anything about data centers here on Earth, it's that they require constant maintenance. Components like SSDs and GPUs die all the time. Musk has claimed SpaceX's AI satellites would require \"little\" in the way of operating or maintenance costs. That's only true if you accept the narrowest possible interpretation of what maintaining a fleet of AI satellites would entail.\"I think that there's no case in which repair makes sense. It's a fly till you die scenario,\" says McCalip. From an economic perspective, McCalip argues the projected death rate of GPUs in space represents \"one of the biggest uncertainties\" of the orbital data center model. McCalip's put that number at nine percent on the basis of a study Meta published following the release of its Llama 3 model (which, incidentally, measured hardware failures on Earth.) But the reality is no one knows what the attrition rate of those chips will be until they're in space. Orbital data centers also likely wouldn't be a direct replacement for their terrestrial counterparts. SpaceX's application specifically mentions inference as the primary use case for its new constellation. Inference is the practical side of running an AI system. It sees a model apply its learning to data it hasn't seen before, like a prompt you write in ChatGPT, to make predictions and generate content. In other words, AI models would still need to be trained on Earth, and it's not clear that the process could be offloaded to a constellation of satellites. \"My initial thinking is that computations that require a lot of coordination, like AI training, may end up being tricky to get right at scale up there,\" says Professor Lee. Kessler syndromeIn 1978, a pair of NASA scientists proposed a scenario where low Earth orbit could become so dense with space junk that collisions between those objects would begin to cascade. That scenario is known as Kessler syndrome. One estimate from satellite tracking website Orbiting Now puts the number of objects in orbit around the planet at approximately 15,600. Another estimate from NASA suggests there are 45,000 human-made objects orbiting Earth. No matter the number, what's currently in orbit represents a fraction of the 1 million additional satellites Musk wants to launch. According to Aaron Boley, professor of physics and astronomy at the University of British Columbia and co-director of the Outer Space Institute, forward-looking modeling of Earth's orbit above 700 kilometers — where part of SpaceX's proposed cluster would live — suggests that area of space is already showing signs of Kessler syndrome. While it takes less time for debris to clear in low Earth orbit, Professor Boley says there's already enough material in that region of space where there could be a cascading effect from a major collision. Debris could, in a worst case scenario, take a decade to clear up. In turn, that could lead to disruptions in global communications, climate monitoring missions and more. \"You could get to the point where you're just launching material in, and you could ask yourself how many satellites can I afford to lose? Can you reconstitute your constellation faster than you're losing parts of it because of debris?\" says Boley. \"That's a horrible future in terms of the environmental perspective\" In particular, it would limit opportunities for humans to fly into low Earth orbit. \"Could you operate in it? Yeah, but it would come with higher and higher costs,\" adds Boley. \"The entire world is struggling with the problem of how we safely fly multiple mega constellations,\" says Richard DalBello, who previously ran the Traffic Coordination System for Space (TraCSS) at the US Department of Commerce. Right now, there is no common global space situational awareness (SSA) system, and government and satellite operators are using uncoordinated national and commercial systems that are likely producing different results. At the start of the year, SpaceX lowered the orbit of thousands of Starlink satellites after one of them nearly collided with a Chinese satellite. SpaceX has its own in-house SSA system called Stargaze, which it uses to fly its more than 7,000 Starlink satellites. According to DalBello, competing operators can receive SSA data from SpaceX, but to do so they must share their satellite position information. “Assuming data sharing, it is likely Stargaze can make an important contribution to spaceflight safety\" says DalBello. “SpaceX is likely to have success with US and other commercial operators, but without the assistance of the federal government, other governments — particularly China — will likely be unwilling to share their satellite and SSA data.\" According to DalBello, the Biden administration was unable to make meaningful progress on the next-generation TraCSS system, in part because Congress was initially reluctant to fund the program. Meanwhile, the current Trump administration hasn't shown interest in advancing the work that began during the president's first term. Even if the regulatory situation suddenly changes and the world's governments agree on an international SSA system, SpaceX launching 1 million satellites along the day-night terminator would see the company effectively monopolize one of the Earth's most valuable and important orbits. Professor Boley argues we should view our planet's orbits as a resource that belongs to everyone. \"Every time you put a satellite up, you use part of that resource. Now someone else can't use it.\" And as Hicks points out, even a single cascade of colliding satellites would prevent that space from being used for scientific endeavors. \"You would have to wait years for that debris to slowly come back into the atmosphere and burn up. In the meantime, that debris is taking up space that could be used for climate monitoring missions or any other types of missions that governments want to launch.\" A blow to the atmosphereSeparately, the constant churn of Starship launches and re-entry of dead satellites would have a potentially dire impact on our planet's atmosphere. \"We're not prepared for it,\" Boley flatly says of the latter. \"We're not prepared for what's happening now, and what's happening now is already potentially bad.\" According to Musk's \"basic math,\" SpaceX could add 100 gigawatts of AI compute capacity annually by launching a million tons of satellite per year. McCalip estimates a 100-gigawatt buildout alone would necessitate about 25,000 Starship flights. Many of the metals found in satellites, including aluminum, magnesium and lithium, in combination with the exhaust rockets release into the atmosphere, can have complicated effects on the health of the planet. For instance, they can affect polar cloud formations, which in turn can facilitate ozone layer destruction through the chemical reactions that occur on their surfaces. According to Boley, the problem is we just don't know how severe those environmental factors could become at the scale Musk has proposed, and SpaceX has provided us with precious few details on its mitigation plans. All it has said is that its plan would \"achieve transformative cost and energy efficiency while significantly reducing the environmental impact associated with terrestrial data centers.\" Even if SpaceX could and does go out its way to mitigate the atmospheric effects of constant rocket flights, those spacecraft still need to be manufactured here on Earth. At one of his previous roles, Hicks studied rocket emissions and found the supply chains needed to build them produce an \"order of magnitude\" more carbon emissions than the rockets themselves. SpaceX plans to fly its new satellites in a sun-synchronous orbit, meaning for much of the year, they'll be sunlit. Each new Starlink generation has been larger and heavier than the one before it, with SpaceX stating in a recent filing that its upcoming V3 model could weigh up to 2,000 kilograms, up from the 575 kilograms of the V2 Mini Optimized. While we don't know the exact dimensions of the company's still-hypothetical AI satellites, they will almost certainly be bigger than their Starlink counterparts. SpaceX has done more than most space operators to reduce the brightness of its satellites, but Professor Boley says he expects that this new constellation will be \"strikingly bright\" when moving through the night sky. In aggregate, he estimates they will almost certainly be harmful to scientific research here on Earth, limiting what terrestrial observatories can see. \"You're going to see them with the naked eye. You're going to see them with cameras. It's going to be like living near an airport where you see all these things flying over just after sunset and the next couple of hours after sunset,\" says Manley. \"I don't know if I want to have my entire sunset be just a band of satellites constantly shooting overhead.\"There are good reasons to make some spacecraft capable of doing AI inference. For instance, Professor Lee suggests it would make orbital imaging satellites more useful, as those spacecraft could do on-site analysis, instead of sending high-resolution files over long distances, saving time in the process. But the dose, as they say, makes the poison.\"There's a lot of excitement about the many possibilities that can be brought to society and humanity through continued access to space, but the promise of prosperity is not permission to be reckless,\" he says. \"At this moment, we're allowing that excitement to overtake that more measured progression [...] those impacts don't just impact outer space but Earth as well.\" This article originally appeared on Engadget at https://www.engadget.com/ai/orbital-ai-data-centers-could-work-but-they-might-ruin-earth-in-the-process-170000099.html?src=rss",
          "content": "At the start of the month, Elon Musk announced that two of his companies — SpaceX and xAI — were merging, and would jointly launch a constellation of 1 million satellites to operate as orbital data centers. Musk's reputation might suggest otherwise, but according to experts, such a plan isn't a complete fantasy. However, if executed at the scale suggested, some of them believe it would have devastating effects on the environment and the sustainability of low Earth Earth orbit. Musk and others argue that putting data centers in space is practical given how much more efficient solar panels are away from Earth's atmosphere. In space, there are no clouds or weather events to obscure the sun, and in the correct orbit, solar panels can collect sunlight through much of the day. In combination with declining rocket launch costs and the price of powering AI data centers on Earth, Musk has said that within three years space will be the cheapest way to generate AI compute power. Ahead of the billionaire's announcement, SpaceX filed an eight-page application with the Federal Communications Commission detailing his plan. The company hopes to deposit the satellites in this massive cluster in altitudes ranging between 500km and 2000km. They would communicate with one another and SpaceX's Starlink constellation using laser \"optical links.\" Those Starlink satellites would then transmit inference requests to and from Earth. To power the entire effort, SpaceX has proposed putting the new constellation in sun-synchronous orbit, meaning the spacecraft would fly along the dividing line that separates the day and night sides of the planet. What a data center would endure in orbitAlmost immediately the plan was greeted with skepticism. How would SpaceX, for instance, cool millions of GPUs in space? At first glance, that might seem like a weird point to get hung up on — much of space being around -450 Fahrenheit — but the reality is more complicated. In the near vacuum of space, the only way to dissipate heat is to slowly radiate it out, and in direct sunlight, objects can easily overheat. As one commenter on Hacker News succinctly put it, \"a satellite is, if nothing else, a fantastic thermos.\"Scott Manley, who, before he created one of the most popular space-focused channels on YouTube, was a software engineer and studied computational physics and astronomy, argues SpaceX has already solved that problem at a smaller scale with Starlink. He points to the company's latest V3 model, which has about 30 square meters of solar panels. \"They have a bunch of electronics in the middle, which are taking that power and doing stuff with it. Now, some of that power is being beamed away as radio waves, but there's a lot of thermal power that's being generated and then having to be dissipated. So they already have a platform that's running electronics off of power, and so it's not a massive leap to turn into something doing compute.\"The larger V3 @Starlink satellites that will deploy from Starship will bring gigabit connectivity to users and are designed to add 60 Tera-bits-per-second of downlink capacity to the Starlink network.That's more than 20 times the capacity added with every V2 Mini launch on… pic.twitter.com/N0Vl9psbm3— SpaceX (@SpaceX) October 13, 2025 Kevin Hicks, a former NASA systems engineer who worked on the Curiosity rover mission, is more skeptical. \"Satellites with the primary goal of processing large amounts of compute requests would generate more heat than pretty much any other type of satellite,\" he said. \"Cooling them is another aspect of the design which is theoretically possible but would require a ton of extra work and complexity, and I have doubts about the durability of such a cooling system.\" What about radiation then? There's a reason NASA relies on ancient hardware like the PowerPC 750 CPU found inside the Perseverance rover: Older chips feature larger transistors, making them more resilient to bit flips — errors in processing caused most often by cosmic radiation — that might scramble a computation. \"Binary ones and zeroes are about the presence or absence of electrons, and the amount of charge required to represent a 'one' goes down as the transistors get smaller and smaller,\" explains Benjamin Lee, professor of computer and information science at the University of Pennsylvania. Space is full of energized particles traveling at incredible velocities, and the latest GPUs are built on the smallest, most advanced processing nodes to create transistor-dense silicon. Not a great combination.\"My concern about radiation is that we don't know how many bit flips will occur when you deploy the most advanced chips and hundreds of gigabytes of memory up there,\" said Professor Lee, pointing to preliminary research by Google on the subject. As part of Project Suncatcher, its own effort to explore the viability of space-based data centers, the company put one of its Trillium TPUs in front of a proton beam to bombard it with radiation. It found the silicon was \"surprisingly radiation-hard for space applications.\" While those results were promising, Professor Lee points out we just don't know how resilient GPUs are to radiation at this scale. \"Even though modern computer architectures can detect and sometimes correct for those errors, having to do that again and again will slow down or add overhead to space-based computation,\" he said. Space engineer Andrew McCalip, who's done a deep dive on the economics of orbital data centers, is more optimistic, pointing to the natural resilience of AI models. \"They don't require 100 percent perfect error-free runs. They're inherently very noisy, very stochastic,\" he explains, adding that part of the training for modern AI systems involves \"injecting random noise into different layers.\" Even if SpaceX could harden its GPUs against radiation, the company would still lose satellites to GPUs that break down. If you know anything about data centers here on Earth, it's that they require constant maintenance. Components like SSDs and GPUs die all the time. Musk has claimed SpaceX's AI satellites would require \"little\" in the way of operating or maintenance costs. That's only true if you accept the narrowest possible interpretation of what maintaining a fleet of AI satellites would entail.\"I think that there's no case in which repair makes sense. It's a fly till you die scenario,\" says McCalip. From an economic perspective, McCalip argues the projected death rate of GPUs in space represents \"one of the biggest uncertainties\" of the orbital data center model. McCalip's put that number at nine percent on the basis of a study Meta published following the release of its Llama 3 model (which, incidentally, measured hardware failures on Earth.) But the reality is no one knows what the attrition rate of those chips will be until they're in space. Orbital data centers also likely wouldn't be a direct replacement for their terrestrial counterparts. SpaceX's application specifically mentions inference as the primary use case for its new constellation. Inference is the practical side of running an AI system. It sees a model apply its learning to data it hasn't seen before, like a prompt you write in ChatGPT, to make predictions and generate content. In other words, AI models would still need to be trained on Earth, and it's not clear that the process could be offloaded to a constellation of satellites. \"My initial thinking is that computations that require a lot of coordination, like AI training, may end up being tricky to get right at scale up there,\" says Professor Lee. Kessler syndromeIn 1978, a pair of NASA scientists proposed a scenario where low Earth orbit could become so dense with space junk that collisions between those objects would begin to cascade. That scenario is known as Kessler syndrome. One estimate from satellite tracking website Orbiting Now puts the number of objects in orbit around the planet at approximately 15,600. Another estimate from NASA suggests there are 45,000 human-made objects orbiting Earth. No matter the number, what's currently in orbit represents a fraction of the 1 million additional satellites Musk wants to launch. According to Aaron Boley, professor of physics and astronomy at the University of British Columbia and co-director of the Outer Space Institute, forward-looking modeling of Earth's orbit above 700 kilometers — where part of SpaceX's proposed cluster would live — suggests that area of space is already showing signs of Kessler syndrome. While it takes less time for debris to clear in low Earth orbit, Professor Boley says there's already enough material in that region of space where there could be a cascading effect from a major collision. Debris could, in a worst case scenario, take a decade to clear up. In turn, that could lead to disruptions in global communications, climate monitoring missions and more. \"You could get to the point where you're just launching material in, and you could ask yourself how many satellites can I afford to lose? Can you reconstitute your constellation faster than you're losing parts of it because of debris?\" says Boley. \"That's a horrible future in terms of the environmental perspective\" In particular, it would limit opportunities for humans to fly into low Earth orbit. \"Could you operate in it? Yeah, but it would come with higher and higher costs,\" adds Boley. \"The entire world is struggling with the problem of how we safely fly multiple mega constellations,\" says Richard DalBello, who previously ran the Traffic Coordination System for Space (TraCSS) at the US Department of Commerce. Right now, there is no common global space situational awareness (SSA) system, and government and satellite operators are using uncoordinated national and commercial systems that are likely producing different results. At the start of the year, SpaceX lowered the orbit of thousands of Starlink satellites after one of them nearly collided with a Chinese satellite. SpaceX has its own in-house SSA system called Stargaze, which it uses to fly its more than 7,000 Starlink satellites. According to DalBello, competing operators can receive SSA data from SpaceX, but to do so they must share their satellite position information. “Assuming data sharing, it is likely Stargaze can make an important contribution to spaceflight safety\" says DalBello. “SpaceX is likely to have success with US and other commercial operators, but without the assistance of the federal government, other governments — particularly China — will likely be unwilling to share their satellite and SSA data.\" According to DalBello, the Biden administration was unable to make meaningful progress on the next-generation TraCSS system, in part because Congress was initially reluctant to fund the program. Meanwhile, the current Trump administration hasn't shown interest in advancing the work that began during the president's first term. Even if the regulatory situation suddenly changes and the world's governments agree on an international SSA system, SpaceX launching 1 million satellites along the day-night terminator would see the company effectively monopolize one of the Earth's most valuable and important orbits. Professor Boley argues we should view our planet's orbits as a resource that belongs to everyone. \"Every time you put a satellite up, you use part of that resource. Now someone else can't use it.\" And as Hicks points out, even a single cascade of colliding satellites would prevent that space from being used for scientific endeavors. \"You would have to wait years for that debris to slowly come back into the atmosphere and burn up. In the meantime, that debris is taking up space that could be used for climate monitoring missions or any other types of missions that governments want to launch.\" A blow to the atmosphereSeparately, the constant churn of Starship launches and re-entry of dead satellites would have a potentially dire impact on our planet's atmosphere. \"We're not prepared for it,\" Boley flatly says of the latter. \"We're not prepared for what's happening now, and what's happening now is already potentially bad.\" According to Musk's \"basic math,\" SpaceX could add 100 gigawatts of AI compute capacity annually by launching a million tons of satellite per year. McCalip estimates a 100-gigawatt buildout alone would necessitate about 25,000 Starship flights. Many of the metals found in satellites, including aluminum, magnesium and lithium, in combination with the exhaust rockets release into the atmosphere, can have complicated effects on the health of the planet. For instance, they can affect polar cloud formations, which in turn can facilitate ozone layer destruction through the chemical reactions that occur on their surfaces. According to Boley, the problem is we just don't know how severe those environmental factors could become at the scale Musk has proposed, and SpaceX has provided us with precious few details on its mitigation plans. All it has said is that its plan would \"achieve transformative cost and energy efficiency while significantly reducing the environmental impact associated with terrestrial data centers.\" Even if SpaceX could and does go out its way to mitigate the atmospheric effects of constant rocket flights, those spacecraft still need to be manufactured here on Earth. At one of his previous roles, Hicks studied rocket emissions and found the supply chains needed to build them produce an \"order of magnitude\" more carbon emissions than the rockets themselves. SpaceX plans to fly its new satellites in a sun-synchronous orbit, meaning for much of the year, they'll be sunlit. Each new Starlink generation has been larger and heavier than the one before it, with SpaceX stating in a recent filing that its upcoming V3 model could weigh up to 2,000 kilograms, up from the 575 kilograms of the V2 Mini Optimized. While we don't know the exact dimensions of the company's still-hypothetical AI satellites, they will almost certainly be bigger than their Starlink counterparts. SpaceX has done more than most space operators to reduce the brightness of its satellites, but Professor Boley says he expects that this new constellation will be \"strikingly bright\" when moving through the night sky. In aggregate, he estimates they will almost certainly be harmful to scientific research here on Earth, limiting what terrestrial observatories can see. \"You're going to see them with the naked eye. You're going to see them with cameras. It's going to be like living near an airport where you see all these things flying over just after sunset and the next couple of hours after sunset,\" says Manley. \"I don't know if I want to have my entire sunset be just a band of satellites constantly shooting overhead.\"There are good reasons to make some spacecraft capable of doing AI inference. For instance, Professor Lee suggests it would make orbital imaging satellites more useful, as those spacecraft could do on-site analysis, instead of sending high-resolution files over long distances, saving time in the process. But the dose, as they say, makes the poison.\"There's a lot of excitement about the many possibilities that can be brought to society and humanity through continued access to space, but the promise of prosperity is not permission to be reckless,\" he says. \"At this moment, we're allowing that excitement to overtake that more measured progression [...] those impacts don't just impact outer space but Earth as well.\" This article originally appeared on Engadget at https://www.engadget.com/ai/orbital-ai-data-centers-could-work-but-they-might-ruin-earth-in-the-process-170000099.html?src=rss",
          "feed_position": 7
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/proton-vpn-two-year-subscriptions-are-70-percent-off-right-now-123000972.html",
          "published_at": "Thu, 19 Feb 2026 15:15:00 +0000",
          "title": "Proton VPN two-year subscriptions are 70 percent off right now",
          "standfirst": "Proton VPN is running a solid deal right now, dropping its two-year Proton VPN Plus plan to $2.99 per month. That works out to $72 billed upfront for the first 24 months, which represents a 70 percent discount compared to its regular pricing. We’ve rated Proton VPN highly thanks to its strong privacy credentials, transparent nonprofit backing and consistently fast performance. It’s one of the services we recommend in our guide to the best VPNs, and this deal also shows up alongside other standout offers in our ongoing roundup of the best VPN deals. It’s a good option if you’re looking to lock in long-term protection at a lower monthly cost.In our Proton VPN review, the service impressed us with consistently fast performance and strong privacy protections. We measured average download speeds at 88 percent of our unprotected connection and upload speeds at 98 percent, which is more than enough for 4K streaming, gaming and torrenting. It also unblocked Netflix in every region we tested, and while its Mac and iOS apps aren’t quite as polished as the Windows and Android versions, the service is still easy to install and largely set-it-and-forget-it across platforms. We gave Proton VPN a score of 90 out of 100.Proton VPN Plus is the company’s premium tier and includes access to its full server network, which now spans more than 15,000 servers across 120-plus countries. A single subscription covers up to 10 devices at once and unlocks features like NetShield ad and malware blocking, Secure Core “double hop” connections, split tunneling, custom DNS controls and priority customer support. Proton VPN Plus also supports fast P2P traffic on nearly all paid servers and includes VPN Accelerator, which helps maintain high speeds over long-distance connections.Right now, Proton VPN Plus is discounted to $2.99 per month when you commit to two years, billed as $72 upfront for the first 24 months. After that, the plan renews annually at $83.88. That’s a 70 percent discount compared to the standard monthly rate. As with Proton’s other paid plans, the subscription comes with a 30-day money-back guarantee, so you can try it risk-free if you’re not ready to lock in long term.This article originally appeared on Engadget at https://www.engadget.com/deals/proton-vpn-two-year-subscriptions-are-70-percent-off-right-now-123000972.html?src=rss",
          "content": "Proton VPN is running a solid deal right now, dropping its two-year Proton VPN Plus plan to $2.99 per month. That works out to $72 billed upfront for the first 24 months, which represents a 70 percent discount compared to its regular pricing. We’ve rated Proton VPN highly thanks to its strong privacy credentials, transparent nonprofit backing and consistently fast performance. It’s one of the services we recommend in our guide to the best VPNs, and this deal also shows up alongside other standout offers in our ongoing roundup of the best VPN deals. It’s a good option if you’re looking to lock in long-term protection at a lower monthly cost.In our Proton VPN review, the service impressed us with consistently fast performance and strong privacy protections. We measured average download speeds at 88 percent of our unprotected connection and upload speeds at 98 percent, which is more than enough for 4K streaming, gaming and torrenting. It also unblocked Netflix in every region we tested, and while its Mac and iOS apps aren’t quite as polished as the Windows and Android versions, the service is still easy to install and largely set-it-and-forget-it across platforms. We gave Proton VPN a score of 90 out of 100.Proton VPN Plus is the company’s premium tier and includes access to its full server network, which now spans more than 15,000 servers across 120-plus countries. A single subscription covers up to 10 devices at once and unlocks features like NetShield ad and malware blocking, Secure Core “double hop” connections, split tunneling, custom DNS controls and priority customer support. Proton VPN Plus also supports fast P2P traffic on nearly all paid servers and includes VPN Accelerator, which helps maintain high speeds over long-distance connections.Right now, Proton VPN Plus is discounted to $2.99 per month when you commit to two years, billed as $72 upfront for the first 24 months. After that, the plan renews annually at $83.88. That’s a 70 percent discount compared to the standard monthly rate. As with Proton’s other paid plans, the subscription comes with a 30-day money-back guarantee, so you can try it risk-free if you’re not ready to lock in long term.This article originally appeared on Engadget at https://www.engadget.com/deals/proton-vpn-two-year-subscriptions-are-70-percent-off-right-now-123000972.html?src=rss",
          "feed_position": 10
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/data/rapidata-emerges-to-shorten-ai-model-development-cycles-from-months-to-days",
          "published_at": "Thu, 19 Feb 2026 14:00:00 GMT",
          "title": "Rapidata emerges to shorten AI model development cycles from months to days with near real-time RLHF",
          "standfirst": "Despite growing chatter about a future when much human work is automated by AI, one of the ironies of this current tech boom is how stubbornly reliant on human beings it remains, specifically the process of training AI models using reinforcement learning from human feedback (RLHF). At its simplest, RLHF is a tutoring system: after an AI is trained on curated data, it still makes mistakes or sounds robotic. Human contractors are then hired en masse by AI labs to rate and rank a new model&#x27;s outputs while it trains, and the model learns from their ratings, adjusting its behavior to offer higher-rated outputs. This process is all the more important as AI expands to produce multimedia outputs like video, audio, and imagery which may have more nuanced and subjective measures of quality. Historically, this tutoring process has been a massive logistical headache and PR nightmare for AI companies, relying on fragmented networks of foreign contractors and static labeling pools in specific, low-income geographic hubs, cast by the media as low wage — even exploitative. It&#x27;s also inefficient: requiring AI labs wait weeks or months for a single batch of feedback, delaying model progress. Now a new startup has emerged to make the process far more efficient: Rapidata&#x27;s platform effectively \"gamifies\" RLHF by pushing said review tasks around the globe to nearly 20 million users of popular apps, including Duolingo or Candy Crush, in the form of short, opt-in review tasks they can choose to complete in place of watching mobile ads, with data sent back to a commissioning AI lab instantly. As shared with VentureBeat in a press release, this platform allows AI labs to \"iterate on models in near-real-time,\" significantly shortening development timelines compared to traditional methods.CEO and founder Jason Corkill stated in the same release that Rapidata makes \"human judgment available at a global scale and near real time, unlocking a future where AI teams can run constant feedback loops and build systems that evolve every day instead of every release cycle.\"\"Rapidata treats RLHF as high-speed infrastructure rather than a manual labor problem. Today, the company exclusively announced to us at VentureBeat its emergence with an $8.5 million seed round co-led by Canaan Partners and IA Ventures, with participation from Acequia Capital and BlueYard, to scale its unique approach to on-demand human data.The pub conversation that built a human cloudThe genesis of Rapidata was born not in a boardroom, but at a table over a few beers. When Corkill was a student at ETH Zurich, working in robotics and computer vision, when he hit the wall that every AI engineer eventually faces: the data annotation bottleneck.\"Specifically, I&#x27;ve been working in robotics, AI and computer vision for quite a few years now, studied at ETH here in Zurich, and just always was frustrated with data annotation,\" Corkill recalled in a recent interview. \"Always when you needed humans or human data annotation, that&#x27;s kind of when your project was stopped in its tracks, because up until then, you could move it forward by just pushing longer nights. But when you needed the large scale human annotation, you had to go to someone and then wait for a few weeks\".Frustrated by this delay, Corkill and his co-founders realized that the existing labor model for AI was fundamentally broken for a world moving at the speed of modern compute. While compute scales exponentially, the traditional human workforce—bound by manual onboarding, regional hiring, and slow payment cycles—does not. Rapidata was born from the idea that human judgment could be delivered as a globally distributed, near-instantaneous service.Technology: Turning digital footprints into training dataThe core innovation of Rapidata lies in its distribution method. Rather than hiring full-time annotators in specific regions, Rapidata leverages the existing attention economy of the mobile app world. By partnering with third-party apps like Candy Crush or Duolingo, Rapidata offers users a choice: watch a traditional ad or spend a few seconds providing feedback for an AI model.\"The users are asked, &#x27;Hey, would you rather instead of watching ads and having, you know, companies buy your eyeballs like that, would you rather like annotate some data, give feedback?&#x27;\" Corkill explained. According to Corkill, between 50% and 60% of users opt for the feedback task over a traditional video advertisement.This \"crowd intelligence\" approach allows AI teams to tap into a diverse, global demographic at an unprecedented scale.The global network: Rapidata currently reaches between 15 and 20 million people.Massive parallelism: The platform can process 1.5 million human annotations in a single hour.Speed: Feedback cycles that previously took weeks or months are reduced to hours or even minutes.Quality control: The platform builds trust and expertise profiles for respondents over time, ensuring that complex questions are matched with the most relevant human judges.Anonymity: While users are tracked via anonymized IDs to ensure consistency and reliability, Rapidata does not collect personal identities, maintaining privacy while optimizing for data quality.Online RLHF: Moving into the GPUThe most significant technological leap Rapidata is enabling is what Corkill describes as \"online RLHF\". Traditionally, AI is trained in disconnected batches: you train the model, stop, send data to humans, wait weeks for labels, and then resume. This creates a \"circle\" of information that often lacks fresh human input.Rapidata is moving this judgment directly into the training loop. Because their network is so fast, they can integrate via API directly with the GPUs running the model.\"We&#x27;ve always had this idea of reinforcement learning for human feedback... so far, you always had to do it like in batches,\" Corkill said. \"Now, if you go all the way down, we have a few clients now where, because we&#x27;re so fast, we can be directly, basically in the process, like in in the processor on the GPU right, and the GPU calculate some output, and it can immediately request from us in a distributed fashion. &#x27;Oh, I need, I need, I need a human to look at this.&#x27; I get the answer and then apply that loss, which has not been possible so far\".Currently, the platform supports roughly 5,500 humans per minute providing live feedback to models running on thousands of GPUs. This prevents \"reward model hacking,\" where two AI models trick each other in a feedback loop, by grounding the training in actual human nuance.Product: Solving for taste and global contextAs AI moves beyond simple object recognition into generative media, the requirements for data labeling have evolved from objective tagging to subjective \"taste-based\" curation. It is no longer just about \"is this a cat?\" but rather \"is this voice synthesis convincing?\" or \"which of these two summaries feels more professional?\".Lily Clifford, CEO of the voice AI startup Rime, notes that Rapidata has been transformative for testing models in real-world contexts. \"Previously, gathering meaningful feedback meant cobbling together vendors and surveys, segment by segment, or country by country, which didn’t scale,\" Clifford said. Using Rapidata, Rime can reach the right audiences—whether in Sweden, Serbia, or the United States—and see how models perform in real customer workflows in days, not months.\"Most models are factually correct, but I&#x27;m sure you&#x27;re you have received emails that feel, you know, not authentic, right?\" Corkill noted. \"You can smell an AI email, you can smell an AI image or a video, it&#x27;s immediately clear to you... these models still don&#x27;t feel human, and you need human feedback to do that\".The economic and operational shiftFrom an operational standpoint, Rapidata positions itself as an infrastructure layer that eliminates the need for companies to manage their own custom annotation operations. By providing a scalable network, the company is lowering the barrier to entry for AI teams that previously struggled with the cost and complexity of traditional feedback loops.Jared Newman of Canaan Partners, who led the investment, suggests that this infrastructure is essential for the next generation of AI. \"Every serious AI deployment depends on human judgment somewhere in the lifecycle,\" Newman said. \"As models move from expertise-based tasks to taste-based curation, the demand for scalable human feedback will grow dramatically\".A future of human useWhile the current focus is on the model labs of the Bay Area, Corkill sees a future where the AI models themselves become the primary customers of human judgment. He calls this \"human use\".In this vision, a car designer AI wouldn&#x27;t just generate a generic vehicle; it could programmatically call Rapidata to ask 25,000 people in the French market what they think of a specific aesthetic, iterate on that feedback, and refine its design within hours.\"Society is in constant flux,\" Corkill noted, addressing the trend of using AI to simulate human behavior. \"If they simulate a society now, the simulation will be stable for and maybe mirror ours for a few months, but then it completely changes, because society has changed and has developed completely differently\".By creating a distributed, programmatic way to access human brain capacity worldwide, Rapidata is positioning itself as the vital interconnect between silicon and society. With $8.5 million in new funding, the company plans to move aggressively to ensure that as AI scales, the human element is no longer a bottleneck, but a real-time feature.",
          "content": "Despite growing chatter about a future when much human work is automated by AI, one of the ironies of this current tech boom is how stubbornly reliant on human beings it remains, specifically the process of training AI models using reinforcement learning from human feedback (RLHF). At its simplest, RLHF is a tutoring system: after an AI is trained on curated data, it still makes mistakes or sounds robotic. Human contractors are then hired en masse by AI labs to rate and rank a new model&#x27;s outputs while it trains, and the model learns from their ratings, adjusting its behavior to offer higher-rated outputs. This process is all the more important as AI expands to produce multimedia outputs like video, audio, and imagery which may have more nuanced and subjective measures of quality. Historically, this tutoring process has been a massive logistical headache and PR nightmare for AI companies, relying on fragmented networks of foreign contractors and static labeling pools in specific, low-income geographic hubs, cast by the media as low wage — even exploitative. It&#x27;s also inefficient: requiring AI labs wait weeks or months for a single batch of feedback, delaying model progress. Now a new startup has emerged to make the process far more efficient: Rapidata&#x27;s platform effectively \"gamifies\" RLHF by pushing said review tasks around the globe to nearly 20 million users of popular apps, including Duolingo or Candy Crush, in the form of short, opt-in review tasks they can choose to complete in place of watching mobile ads, with data sent back to a commissioning AI lab instantly. As shared with VentureBeat in a press release, this platform allows AI labs to \"iterate on models in near-real-time,\" significantly shortening development timelines compared to traditional methods.CEO and founder Jason Corkill stated in the same release that Rapidata makes \"human judgment available at a global scale and near real time, unlocking a future where AI teams can run constant feedback loops and build systems that evolve every day instead of every release cycle.\"\"Rapidata treats RLHF as high-speed infrastructure rather than a manual labor problem. Today, the company exclusively announced to us at VentureBeat its emergence with an $8.5 million seed round co-led by Canaan Partners and IA Ventures, with participation from Acequia Capital and BlueYard, to scale its unique approach to on-demand human data.The pub conversation that built a human cloudThe genesis of Rapidata was born not in a boardroom, but at a table over a few beers. When Corkill was a student at ETH Zurich, working in robotics and computer vision, when he hit the wall that every AI engineer eventually faces: the data annotation bottleneck.\"Specifically, I&#x27;ve been working in robotics, AI and computer vision for quite a few years now, studied at ETH here in Zurich, and just always was frustrated with data annotation,\" Corkill recalled in a recent interview. \"Always when you needed humans or human data annotation, that&#x27;s kind of when your project was stopped in its tracks, because up until then, you could move it forward by just pushing longer nights. But when you needed the large scale human annotation, you had to go to someone and then wait for a few weeks\".Frustrated by this delay, Corkill and his co-founders realized that the existing labor model for AI was fundamentally broken for a world moving at the speed of modern compute. While compute scales exponentially, the traditional human workforce—bound by manual onboarding, regional hiring, and slow payment cycles—does not. Rapidata was born from the idea that human judgment could be delivered as a globally distributed, near-instantaneous service.Technology: Turning digital footprints into training dataThe core innovation of Rapidata lies in its distribution method. Rather than hiring full-time annotators in specific regions, Rapidata leverages the existing attention economy of the mobile app world. By partnering with third-party apps like Candy Crush or Duolingo, Rapidata offers users a choice: watch a traditional ad or spend a few seconds providing feedback for an AI model.\"The users are asked, &#x27;Hey, would you rather instead of watching ads and having, you know, companies buy your eyeballs like that, would you rather like annotate some data, give feedback?&#x27;\" Corkill explained. According to Corkill, between 50% and 60% of users opt for the feedback task over a traditional video advertisement.This \"crowd intelligence\" approach allows AI teams to tap into a diverse, global demographic at an unprecedented scale.The global network: Rapidata currently reaches between 15 and 20 million people.Massive parallelism: The platform can process 1.5 million human annotations in a single hour.Speed: Feedback cycles that previously took weeks or months are reduced to hours or even minutes.Quality control: The platform builds trust and expertise profiles for respondents over time, ensuring that complex questions are matched with the most relevant human judges.Anonymity: While users are tracked via anonymized IDs to ensure consistency and reliability, Rapidata does not collect personal identities, maintaining privacy while optimizing for data quality.Online RLHF: Moving into the GPUThe most significant technological leap Rapidata is enabling is what Corkill describes as \"online RLHF\". Traditionally, AI is trained in disconnected batches: you train the model, stop, send data to humans, wait weeks for labels, and then resume. This creates a \"circle\" of information that often lacks fresh human input.Rapidata is moving this judgment directly into the training loop. Because their network is so fast, they can integrate via API directly with the GPUs running the model.\"We&#x27;ve always had this idea of reinforcement learning for human feedback... so far, you always had to do it like in batches,\" Corkill said. \"Now, if you go all the way down, we have a few clients now where, because we&#x27;re so fast, we can be directly, basically in the process, like in in the processor on the GPU right, and the GPU calculate some output, and it can immediately request from us in a distributed fashion. &#x27;Oh, I need, I need, I need a human to look at this.&#x27; I get the answer and then apply that loss, which has not been possible so far\".Currently, the platform supports roughly 5,500 humans per minute providing live feedback to models running on thousands of GPUs. This prevents \"reward model hacking,\" where two AI models trick each other in a feedback loop, by grounding the training in actual human nuance.Product: Solving for taste and global contextAs AI moves beyond simple object recognition into generative media, the requirements for data labeling have evolved from objective tagging to subjective \"taste-based\" curation. It is no longer just about \"is this a cat?\" but rather \"is this voice synthesis convincing?\" or \"which of these two summaries feels more professional?\".Lily Clifford, CEO of the voice AI startup Rime, notes that Rapidata has been transformative for testing models in real-world contexts. \"Previously, gathering meaningful feedback meant cobbling together vendors and surveys, segment by segment, or country by country, which didn’t scale,\" Clifford said. Using Rapidata, Rime can reach the right audiences—whether in Sweden, Serbia, or the United States—and see how models perform in real customer workflows in days, not months.\"Most models are factually correct, but I&#x27;m sure you&#x27;re you have received emails that feel, you know, not authentic, right?\" Corkill noted. \"You can smell an AI email, you can smell an AI image or a video, it&#x27;s immediately clear to you... these models still don&#x27;t feel human, and you need human feedback to do that\".The economic and operational shiftFrom an operational standpoint, Rapidata positions itself as an infrastructure layer that eliminates the need for companies to manage their own custom annotation operations. By providing a scalable network, the company is lowering the barrier to entry for AI teams that previously struggled with the cost and complexity of traditional feedback loops.Jared Newman of Canaan Partners, who led the investment, suggests that this infrastructure is essential for the next generation of AI. \"Every serious AI deployment depends on human judgment somewhere in the lifecycle,\" Newman said. \"As models move from expertise-based tasks to taste-based curation, the demand for scalable human feedback will grow dramatically\".A future of human useWhile the current focus is on the model labs of the Bay Area, Corkill sees a future where the AI models themselves become the primary customers of human judgment. He calls this \"human use\".In this vision, a car designer AI wouldn&#x27;t just generate a generic vehicle; it could programmatically call Rapidata to ask 25,000 people in the French market what they think of a specific aesthetic, iterate on that feedback, and refine its design within hours.\"Society is in constant flux,\" Corkill noted, addressing the trend of using AI to simulate human behavior. \"If they simulate a society now, the simulation will be stable for and maybe mirror ours for a few months, but then it completely changes, because society has changed and has developed completely differently\".By creating a distributed, programmatic way to access human brain capacity worldwide, Rapidata is positioning itself as the vital interconnect between silicon and society. With $8.5 million in new funding, the company plans to move aggressively to ensure that as AI scales, the human element is no longer a bottleneck, but a real-time feature.",
          "feed_position": 3,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/6A3hRqADsdiALNRF8aUM8e/09c213e4e98031ecb62ef459a6de8967/r8BFky--_XqHqt4iCIRmm.jpg?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/data/the-last-mile-data-problem-is-stalling-enterprise-agentic-ai-golden",
          "published_at": "Thu, 19 Feb 2026 13:00:00 GMT",
          "title": "The 'last-mile' data problem is stalling enterprise agentic AI — 'golden pipelines' aim to fix it",
          "standfirst": "Traditional ETL tools like dbt or Fivetran prepare data for reporting: structured analytics and dashboards with stable schemas. AI applications need something different: preparing messy, evolving operational data for model inference in real-time. Empromptu calls this distinction \"inference integrity\" versus \"reporting integrity.\" Instead of treating data preparation as a separate discipline, golden pipelines integrate normalization directly into the AI application workflow, collapsing what typically requires 14 days of manual engineering into under an hour, the company says. Empromptu&#x27;s \"golden pipeline\" approach is a way to accelerate data preparation and make sure that data is accurate.The company works primarily with mid-market and enterprise customers in regulated industries where data accuracy and compliance are non-negotiable. Fintech is Empromptu&#x27;s fastest-growing vertical, with additional customers in healthcare and legal tech. The platform is HIPAA compliant and SOC 2 certified.\"Enterprise AI doesn&#x27;t break at the model layer, it breaks when messy data meets real users,\" Shanea Leven, CEO and co-founder of Empromptu told VentureBeat in an exclusive interview. \"Golden pipelines bring data ingestion, preparation and governance directly into the AI application workflow so teams can build systems that actually work in production.\"How golden pipelines workGolden pipelines operate as an automated layer that sits between raw operational data and AI application features. The system handles five core functions. First, it ingests data from any source including files, databases, APIs and unstructured documents. It then processes that data through automated inspection and cleaning, structuring with schema definitions, and labeling and enrichment to fill gaps and classify records. Built-in governance and compliance checks include audit trails, access controls and privacy enforcement.The technical approach combines deterministic preprocessing with AI-assisted normalization. Instead of hard-coding every transformation, the system identifies inconsistencies, infers missing structure and generates classifications based on model context. Every transformation is logged and tied directly to downstream AI evaluation.The evaluation loop is central to how golden pipelines function. If data normalization reduces downstream accuracy, the system catches it through continuous evaluation against production behavior. That feedback coupling between data preparation and model performance distinguishes golden pipelines from traditional ETL tools, according to Leven.Golden pipelines are embedded directly into the Empromptu Builder and run automatically as part of creating an AI application. From the user&#x27;s perspective, teams are building AI features. Under the hood, golden pipelines ensure the data feeding those features is clean, structured, governed and ready for production use.Reporting integrity versus inference integrityLeven positions golden pipelines as solving a fundamentally different problem than traditional ETL tools like dbt, Fivetran or Databricks.\"Dbt and Fivetran are optimized for reporting integrity. Golden pipelines are optimized for inference integrity,\" Leven said. \"Traditional ETL tools are designed to move and transform structured data based on predefined rules. They assume schema stability, known transformations and relatively static logic.\"\"We&#x27;re not replacing dbt or Fivetran, enterprises will continue to use those for warehouse integrity and structured reporting,\" Leven said. \"Golden pipelines sit closer to the AI application layer. They solve the last-mile problem: how do you take real-world, imperfect operational data and make it usable for AI features without months of manual wrangling?\"The trust argument for AI-driven normalization rests on auditability and continuous evaluation. \"It is not unsupervised magic. It is reviewable, auditable and continuously evaluated against production behavior,\" Leven said. \"If normalization reduces downstream accuracy, the evaluation loop catches it. That feedback coupling between data preparation and model performance is something traditional ETL pipelines do not provide.\"Customer deployment: VOW tackles high-stakes event dataThe golden pipeline approach is already having an impact in the real world.Event management platform VOW handles high-profile events for organizations like GLAAD as well as multiple sports organizations. When GLAAD plans an event, data populates across sponsor invites, ticket purchases, tables, seats and more. The process happens quickly and data consistency is non-negotiable.\"Our data is more complex than the average platform,\" Jennifer Brisman, CEO of VOW, told VentureBeat. \"When GLAAD plans an event that data gets populated across sponsor invites, ticket purchases, tables and seats, and more. And it all has to happen very quickly.\"VOW was writing regex scripts manually. When the company decided to build an AI-generated floor plan feature that updated data in near real-time and populated information across the platform, ensuring data accuracy became critical. Golden Pipelines automated the process of extracting data from floor plans that often arrived messy, inconsistent and unstructured, then formatting and sending it without extensive manual effort across the engineering team.VOW initially used Empromptu for AI-generated floor plan analysis that neither Google&#x27;s AI team nor Amazon&#x27;s AI team could solve. The company is now rewriting its entire platform on Empromptu&#x27;s system.What this means for enterprise AI deploymentsGolden pipelines target a specific deployment pattern: organizations building integrated AI applications where data preparation is currently a manual bottleneck between prototype and production. The approach makes less sense for teams that already have mature data engineering organizations with established ETL processes optimized for their specific domains, or for organizations building standalone AI models rather than integrated applications.The decision point is whether data preparation is blocking AI velocity in the organization. If data scientists are preparing datasets for experimentation that engineering teams then rebuild from scratch for production, integrated data prep addresses that gap. If the bottleneck is elsewhere in the AI development lifecycle, it won&#x27;t. The trade-off is platform integration vs tool flexibility. Teams using golden pipelines commit to an integrated approach where data preparation, AI application development and governance happen in a single platform. Organizations that prefer assembling best-of-breed tools for each function will find that approach limiting. The benefit is eliminating handoffs between data prep and application development. The cost is reduced optionality in how those functions are implemented.",
          "content": "Traditional ETL tools like dbt or Fivetran prepare data for reporting: structured analytics and dashboards with stable schemas. AI applications need something different: preparing messy, evolving operational data for model inference in real-time. Empromptu calls this distinction \"inference integrity\" versus \"reporting integrity.\" Instead of treating data preparation as a separate discipline, golden pipelines integrate normalization directly into the AI application workflow, collapsing what typically requires 14 days of manual engineering into under an hour, the company says. Empromptu&#x27;s \"golden pipeline\" approach is a way to accelerate data preparation and make sure that data is accurate.The company works primarily with mid-market and enterprise customers in regulated industries where data accuracy and compliance are non-negotiable. Fintech is Empromptu&#x27;s fastest-growing vertical, with additional customers in healthcare and legal tech. The platform is HIPAA compliant and SOC 2 certified.\"Enterprise AI doesn&#x27;t break at the model layer, it breaks when messy data meets real users,\" Shanea Leven, CEO and co-founder of Empromptu told VentureBeat in an exclusive interview. \"Golden pipelines bring data ingestion, preparation and governance directly into the AI application workflow so teams can build systems that actually work in production.\"How golden pipelines workGolden pipelines operate as an automated layer that sits between raw operational data and AI application features. The system handles five core functions. First, it ingests data from any source including files, databases, APIs and unstructured documents. It then processes that data through automated inspection and cleaning, structuring with schema definitions, and labeling and enrichment to fill gaps and classify records. Built-in governance and compliance checks include audit trails, access controls and privacy enforcement.The technical approach combines deterministic preprocessing with AI-assisted normalization. Instead of hard-coding every transformation, the system identifies inconsistencies, infers missing structure and generates classifications based on model context. Every transformation is logged and tied directly to downstream AI evaluation.The evaluation loop is central to how golden pipelines function. If data normalization reduces downstream accuracy, the system catches it through continuous evaluation against production behavior. That feedback coupling between data preparation and model performance distinguishes golden pipelines from traditional ETL tools, according to Leven.Golden pipelines are embedded directly into the Empromptu Builder and run automatically as part of creating an AI application. From the user&#x27;s perspective, teams are building AI features. Under the hood, golden pipelines ensure the data feeding those features is clean, structured, governed and ready for production use.Reporting integrity versus inference integrityLeven positions golden pipelines as solving a fundamentally different problem than traditional ETL tools like dbt, Fivetran or Databricks.\"Dbt and Fivetran are optimized for reporting integrity. Golden pipelines are optimized for inference integrity,\" Leven said. \"Traditional ETL tools are designed to move and transform structured data based on predefined rules. They assume schema stability, known transformations and relatively static logic.\"\"We&#x27;re not replacing dbt or Fivetran, enterprises will continue to use those for warehouse integrity and structured reporting,\" Leven said. \"Golden pipelines sit closer to the AI application layer. They solve the last-mile problem: how do you take real-world, imperfect operational data and make it usable for AI features without months of manual wrangling?\"The trust argument for AI-driven normalization rests on auditability and continuous evaluation. \"It is not unsupervised magic. It is reviewable, auditable and continuously evaluated against production behavior,\" Leven said. \"If normalization reduces downstream accuracy, the evaluation loop catches it. That feedback coupling between data preparation and model performance is something traditional ETL pipelines do not provide.\"Customer deployment: VOW tackles high-stakes event dataThe golden pipeline approach is already having an impact in the real world.Event management platform VOW handles high-profile events for organizations like GLAAD as well as multiple sports organizations. When GLAAD plans an event, data populates across sponsor invites, ticket purchases, tables, seats and more. The process happens quickly and data consistency is non-negotiable.\"Our data is more complex than the average platform,\" Jennifer Brisman, CEO of VOW, told VentureBeat. \"When GLAAD plans an event that data gets populated across sponsor invites, ticket purchases, tables and seats, and more. And it all has to happen very quickly.\"VOW was writing regex scripts manually. When the company decided to build an AI-generated floor plan feature that updated data in near real-time and populated information across the platform, ensuring data accuracy became critical. Golden Pipelines automated the process of extracting data from floor plans that often arrived messy, inconsistent and unstructured, then formatting and sending it without extensive manual effort across the engineering team.VOW initially used Empromptu for AI-generated floor plan analysis that neither Google&#x27;s AI team nor Amazon&#x27;s AI team could solve. The company is now rewriting its entire platform on Empromptu&#x27;s system.What this means for enterprise AI deploymentsGolden pipelines target a specific deployment pattern: organizations building integrated AI applications where data preparation is currently a manual bottleneck between prototype and production. The approach makes less sense for teams that already have mature data engineering organizations with established ETL processes optimized for their specific domains, or for organizations building standalone AI models rather than integrated applications.The decision point is whether data preparation is blocking AI velocity in the organization. If data scientists are preparing datasets for experimentation that engineering teams then rebuild from scratch for production, integrated data prep addresses that gap. If the bottleneck is elsewhere in the AI development lifecycle, it won&#x27;t. The trade-off is platform integration vs tool flexibility. Teams using golden pipelines commit to an integrated approach where data preparation, AI application development and governance happen in a single platform. Organizations that prefer assembling best-of-breed tools for each function will find that approach limiting. The benefit is eliminating handoffs between data prep and application development. The cost is reduced optionality in how those functions are implemented.",
          "feed_position": 4,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/5egQ46IjwiShQrV06KpeEk/785fd79433bb0a678b4ab1d2fbf88fb3/golden-pipeline-smk1.jpg?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/audio/speakers/best-portable-bluetooth-speakers-133004551.html",
          "published_at": "Thu, 19 Feb 2026 10:00:35 +0000",
          "title": "The 16 best portable Bluetooth speakers for 2026",
          "standfirst": "Portable Bluetooth speakers have become an easy default for listening away from your desk or living room. They’re the kind of tech you grab without thinking, whether you’re heading outside, cleaning the house or packing for a weekend away. The best portable options manage to sound bigger than they look, delivering clear audio without weighing down your bag.Battery life and durability matter just as much as sound quality now. Many modern speakers are built to survive splashes, dust and the occasional drop, while still offering quick pairing and stable connections. Some are designed for solo listening, others are meant to fill a space with music and keep going for hours.We’ve tested a wide mix of portable Bluetooth speakers to see which ones are actually worth carrying around. Whether you want something small and simple or a speaker that can anchor a get-together, these are the models that stood out. Best portable Bluetooth speakers: $50 to $200 Best portable Bluetooth speakers: $200 to $450 Best portable Bluetooth speakers: $450 and higher Factors to consider in a portable Bluetooth speaker Weather-proofing IP ratings (Ingress Protection) are the alphanumeric indicators you often see in a product’s spec sheet that define water and dust resistance. It’s usually a combo of two numbers with the first indicating solid object ingress and the second being water. The former goes from 0 (no protection) to 6 (dustproof). The water-resistance rating goes from 0 (no protection) to 9 (protected against immersion and high pressure jets). When an X is used instead of a number, that means the product wasn’t tested for resistance. If it’s a waterproof speaker, it may have some innate resistance to solids, but there’s no guarantee. IP67 is a common rating these days indicating highly resistant and potentially rugged speakers often featured in audio products like outdoor speakers. These are safe for quick dunks in the pool or tub and should be more than OK in the rain or in the shower. They’re also good options for the beach, playground and other rough environs. Additionally, speakers with ports and a high rating will often include a tight-fitting cover over the charging or auxiliary ports. If you plan on using the ports, that may limit the product's rated ability to fend off the elements. When looking for the best portable Bluetooth speaker, consider the IP rating and also how you plan to use your Bluetooth speaker when making your decision. It may be worth splurging on a better sounding model with a lower IP rating if you’ll mostly be using it indoors, for instance. Battery life The focus of this guide is on the best portable speakers, and while “portable” can be a relative term, these devices are generally for people who are likely to find themselves far from a power outlet. These days, around 12 hours of playtime seems to be the baseline but obviously, the more battery life you can get out of a speaker, the better, especially if you plan to listen to podcasts or music on the go. That said, be careful when looking at battery specs, as they frequently list a maximum runtime (“up to” x amount of hours). This usually means they tested at a low to mid volume. If you like your tunes loud with punchy bass, it can often end up cutting the expected usage time in half or more. Luckily, some manufacturers also list the expected hours of battery life when used at full volume and that transparency is appreciated. Bear in mind, however, that not all of the best Bluetooth speakers use the same charging port. Some support USB-C charging, while others use micro-USB, and some may even come with an adapter for added convenience. Additionally, if your audio system or mini Bluetooth speaker also happens to have Wi-Fi connectivity, they're usually designed for always-on functionality. Unlike normal Bluetooth speakers that go to sleep after a short period without use, these will usually stay awake (to listen for your commands) and slowly run down the battery. If you're out and about, you'll want to remember to turn these speakers off manually when not in use to maximize battery life. Range Bluetooth 5 offers better range and more reliable connectivity than its predecessors, making it a great feature to look for in the best Bluetooth speaker. That said, Bluetooth range can still be tricky. Some companies list their product’s longest possible range, usually outdoors and in an unobstructed line-of-sight test environment. Other companies stick with a 30-foot range on the spec sheet and leave it at that, even though they may be running Bluetooth 4.x or 5.x. That’s likely underselling the speaker's potential, but unpredictable environments can affect range and there’s little point in promising the moon only to get complaints. I’ve seen signal drop issues when crouching down, with my phone in the front pocket of my jeans, and barely 30 feet away from a speaker inside my apartment. I ran into this issue across several devices regardless of their listed Bluetooth connectivity range. If you’re hosting a patio party and duck inside, it’s wise to keep any wireless Bluetooth speakers relatively close by just in case. It’s hard to gauge what aspects of any environment may interfere with a Bluetooth signal. In general, take range specs around 100 feet or more as a perfect-world scenario. Latency This is a minor mention for those out there who use a speaker for their computer output, or as a mini Bluetooth soundbar solution for setups like a monitor and streaming box. It’s annoying to find that your speaker’s latency isn’t low enough to avoid lip sync issues. Luckily, it seems that most speakers these days don’t often have these problems. Only a handful of the few dozen speakers I tried had persistent, noticeable lip-sync issues. Aside from occasional blips, all of our picks worked well in this regard. If you plan to frequently use a speaker for video playback, look for devices with the most recent Bluetooth 5 technology and lower latency codecs like aptX. Also make sure the speaker is close to the source device as distance can be a factor. To avoid the issue altogether, though, consider getting one with a wired auxiliary input. Extra features Some speakers don’t just play music — they bring the party to life with built-in LED light effects and a full-on light show that syncs to your music. If you love a bit of visual flair with your tunes, it’s worth checking out models that offer LED light customization options. Sound quality also plays a huge role in picking the right speaker. The best Bluetooth speaker should deliver a balanced mix of punchy bass, clear highs and strong vocals. Many models also include customizable sound modes that let you tweak the EQ to better suit different genres — whether you’re blasting EDM, listening to a podcast, or just want a more immersive experience that would impress even an audiophile. If aesthetics matter, many models come in a tiny size that makes them extra portable, with plenty of color options to match your personal style. Whether you want a sleek black speaker or a vibrant eye-catching design, there are plenty of choices to fit your vibe. Other portable Bluetooth speakers we tested Sonos Roam While there's a lot to like about the Sonos Roam, there are plenty of other Bluetooth speakers with more features and better battery life. In our review, we gave the Roam a score of 87, praising it for its good sound quality, durable waterproof design and ability to work well within an existing Sonos speaker ecosystem. But the price is just fine at $180, and we found Bluetooth speakers that offer more at lower price points. Plus, the Roam taps out at 10 hours of battery life, and all of our top picks can run for longer than that on a single charge. Monoprice Soundstage3 The Monoprice Soundstage3 offers relatively big sound at a midrange $250 price, with a variety of inputs rarely found on a portable Bluetooth speaker. The boxy, minimalist design is no nonsense, even if it's more of a less-rugged, bookshelf-styled homebody. While the speaker puts out crisp highs alongside booming lows, we found the bass can overpower the rest of the output, so it's not for everyone. And after using the speaker for many months, we also found the low-slung, poorly labeled button panel along the top can be a bit annoying to use. If you want a speaker for road trips, favor mids and highs, and plan on using physical buttons for volume control and input selections, there are better options out there. JBL Boombox 3 Fans of JBL’s bluetooth speaker sound profile who want to crank up the volume, but also want a rugged and portable option, may enjoy the JBL Boombox 3. It’s a decent grab-and-go speaker with a very loud output, although it's not as good as some of the loud-speaker styled options for long-throw sound and big outdoor areas. However, the price for this speaker line remains prohibitively expensive compared to other options with big sound that cover a bit more ground. If the JBL brand is your thing and you like the rugged, portable form factor, we recommend looking for discounts, or shopping around and exploring the available options including the (less portable) JBL PartyBox series. Soundcore Motion X500 Soundcore speakers have generally been good and often reasonably priced. The Motion X500 loosely falls into that category. It has a tall, metallic lunchbox vibe with a fixed handle and pumps out a respectable 40 watts of crisp, clear sound for its size. It can get pretty loud and serves up a good dose of bass, although its primarily a front-facing speaker. There’s LDAC hi-res audio support for Android users, but the main selling point on this is spatial audio. This is done through an EQ change and the activation of a small, up-firing driver. There’s a slight benefit from this if you’re up close and directly in front of it, but it’s not a total game changer for your listening experience. The original pre-order price of $130 made it a decent option in terms of bang for your buck. But it went up to $170 at launch, making it less appealing even if it’s still a good middle-of-the-road option if you want small-ish, clear and loud. If you can find one on sale for the lower price, it’s definitely worth considering. There’s also the larger and louder X600 ($200) if the overall concept is working for you. Portable Bluetooth speaker FAQs How does a Bluetooth speaker work? Bluetooth technology lets devices connect and exchange data over short distances using ultra high frequency (UHF) radio waves. It’s the frequency range that’s carved out for industrial, scientific and medical purposes, called the 2.4GHz ISM spectrum band. This range is available worldwide, making it easy for companies to use with devices for global markets. Bluetooth speakers include this tech, which lets them communicate with source devices like smartphones, tablets or computers in order to exchange data. The two devices pair by sharing a unique code and will work within the proscribed range for the device and Bluetooth version. Ever since Bluetooth 4.0 was released over a decade ago, new iterations usually improve on range, use less power and offer expanded connectivity with features like multipoint (allowing more than one device to be connected at the same time, for instance). Who should buy a Portable Bluetooth speaker? If you want to play music while you’re out-and-about on something other than headphones, a portable Bluetooth speaker is probably what you want. There’s a broad range of devices for all types of circumstances. Many adventurous people will want a relatively lightweight portable that’s rugged enough to handle the elements while also packing enough charge to play for hours on end. Others may simply need a speaker they can move around the house or use in the backyard. In this case, you can choose larger less rugged models that may offer better sound. This article originally appeared on Engadget at https://www.engadget.com/audio/speakers/best-portable-bluetooth-speakers-133004551.html?src=rss",
          "content": "Portable Bluetooth speakers have become an easy default for listening away from your desk or living room. They’re the kind of tech you grab without thinking, whether you’re heading outside, cleaning the house or packing for a weekend away. The best portable options manage to sound bigger than they look, delivering clear audio without weighing down your bag.Battery life and durability matter just as much as sound quality now. Many modern speakers are built to survive splashes, dust and the occasional drop, while still offering quick pairing and stable connections. Some are designed for solo listening, others are meant to fill a space with music and keep going for hours.We’ve tested a wide mix of portable Bluetooth speakers to see which ones are actually worth carrying around. Whether you want something small and simple or a speaker that can anchor a get-together, these are the models that stood out. Best portable Bluetooth speakers: $50 to $200 Best portable Bluetooth speakers: $200 to $450 Best portable Bluetooth speakers: $450 and higher Factors to consider in a portable Bluetooth speaker Weather-proofing IP ratings (Ingress Protection) are the alphanumeric indicators you often see in a product’s spec sheet that define water and dust resistance. It’s usually a combo of two numbers with the first indicating solid object ingress and the second being water. The former goes from 0 (no protection) to 6 (dustproof). The water-resistance rating goes from 0 (no protection) to 9 (protected against immersion and high pressure jets). When an X is used instead of a number, that means the product wasn’t tested for resistance. If it’s a waterproof speaker, it may have some innate resistance to solids, but there’s no guarantee. IP67 is a common rating these days indicating highly resistant and potentially rugged speakers often featured in audio products like outdoor speakers. These are safe for quick dunks in the pool or tub and should be more than OK in the rain or in the shower. They’re also good options for the beach, playground and other rough environs. Additionally, speakers with ports and a high rating will often include a tight-fitting cover over the charging or auxiliary ports. If you plan on using the ports, that may limit the product's rated ability to fend off the elements. When looking for the best portable Bluetooth speaker, consider the IP rating and also how you plan to use your Bluetooth speaker when making your decision. It may be worth splurging on a better sounding model with a lower IP rating if you’ll mostly be using it indoors, for instance. Battery life The focus of this guide is on the best portable speakers, and while “portable” can be a relative term, these devices are generally for people who are likely to find themselves far from a power outlet. These days, around 12 hours of playtime seems to be the baseline but obviously, the more battery life you can get out of a speaker, the better, especially if you plan to listen to podcasts or music on the go. That said, be careful when looking at battery specs, as they frequently list a maximum runtime (“up to” x amount of hours). This usually means they tested at a low to mid volume. If you like your tunes loud with punchy bass, it can often end up cutting the expected usage time in half or more. Luckily, some manufacturers also list the expected hours of battery life when used at full volume and that transparency is appreciated. Bear in mind, however, that not all of the best Bluetooth speakers use the same charging port. Some support USB-C charging, while others use micro-USB, and some may even come with an adapter for added convenience. Additionally, if your audio system or mini Bluetooth speaker also happens to have Wi-Fi connectivity, they're usually designed for always-on functionality. Unlike normal Bluetooth speakers that go to sleep after a short period without use, these will usually stay awake (to listen for your commands) and slowly run down the battery. If you're out and about, you'll want to remember to turn these speakers off manually when not in use to maximize battery life. Range Bluetooth 5 offers better range and more reliable connectivity than its predecessors, making it a great feature to look for in the best Bluetooth speaker. That said, Bluetooth range can still be tricky. Some companies list their product’s longest possible range, usually outdoors and in an unobstructed line-of-sight test environment. Other companies stick with a 30-foot range on the spec sheet and leave it at that, even though they may be running Bluetooth 4.x or 5.x. That’s likely underselling the speaker's potential, but unpredictable environments can affect range and there’s little point in promising the moon only to get complaints. I’ve seen signal drop issues when crouching down, with my phone in the front pocket of my jeans, and barely 30 feet away from a speaker inside my apartment. I ran into this issue across several devices regardless of their listed Bluetooth connectivity range. If you’re hosting a patio party and duck inside, it’s wise to keep any wireless Bluetooth speakers relatively close by just in case. It’s hard to gauge what aspects of any environment may interfere with a Bluetooth signal. In general, take range specs around 100 feet or more as a perfect-world scenario. Latency This is a minor mention for those out there who use a speaker for their computer output, or as a mini Bluetooth soundbar solution for setups like a monitor and streaming box. It’s annoying to find that your speaker’s latency isn’t low enough to avoid lip sync issues. Luckily, it seems that most speakers these days don’t often have these problems. Only a handful of the few dozen speakers I tried had persistent, noticeable lip-sync issues. Aside from occasional blips, all of our picks worked well in this regard. If you plan to frequently use a speaker for video playback, look for devices with the most recent Bluetooth 5 technology and lower latency codecs like aptX. Also make sure the speaker is close to the source device as distance can be a factor. To avoid the issue altogether, though, consider getting one with a wired auxiliary input. Extra features Some speakers don’t just play music — they bring the party to life with built-in LED light effects and a full-on light show that syncs to your music. If you love a bit of visual flair with your tunes, it’s worth checking out models that offer LED light customization options. Sound quality also plays a huge role in picking the right speaker. The best Bluetooth speaker should deliver a balanced mix of punchy bass, clear highs and strong vocals. Many models also include customizable sound modes that let you tweak the EQ to better suit different genres — whether you’re blasting EDM, listening to a podcast, or just want a more immersive experience that would impress even an audiophile. If aesthetics matter, many models come in a tiny size that makes them extra portable, with plenty of color options to match your personal style. Whether you want a sleek black speaker or a vibrant eye-catching design, there are plenty of choices to fit your vibe. Other portable Bluetooth speakers we tested Sonos Roam While there's a lot to like about the Sonos Roam, there are plenty of other Bluetooth speakers with more features and better battery life. In our review, we gave the Roam a score of 87, praising it for its good sound quality, durable waterproof design and ability to work well within an existing Sonos speaker ecosystem. But the price is just fine at $180, and we found Bluetooth speakers that offer more at lower price points. Plus, the Roam taps out at 10 hours of battery life, and all of our top picks can run for longer than that on a single charge. Monoprice Soundstage3 The Monoprice Soundstage3 offers relatively big sound at a midrange $250 price, with a variety of inputs rarely found on a portable Bluetooth speaker. The boxy, minimalist design is no nonsense, even if it's more of a less-rugged, bookshelf-styled homebody. While the speaker puts out crisp highs alongside booming lows, we found the bass can overpower the rest of the output, so it's not for everyone. And after using the speaker for many months, we also found the low-slung, poorly labeled button panel along the top can be a bit annoying to use. If you want a speaker for road trips, favor mids and highs, and plan on using physical buttons for volume control and input selections, there are better options out there. JBL Boombox 3 Fans of JBL’s bluetooth speaker sound profile who want to crank up the volume, but also want a rugged and portable option, may enjoy the JBL Boombox 3. It’s a decent grab-and-go speaker with a very loud output, although it's not as good as some of the loud-speaker styled options for long-throw sound and big outdoor areas. However, the price for this speaker line remains prohibitively expensive compared to other options with big sound that cover a bit more ground. If the JBL brand is your thing and you like the rugged, portable form factor, we recommend looking for discounts, or shopping around and exploring the available options including the (less portable) JBL PartyBox series. Soundcore Motion X500 Soundcore speakers have generally been good and often reasonably priced. The Motion X500 loosely falls into that category. It has a tall, metallic lunchbox vibe with a fixed handle and pumps out a respectable 40 watts of crisp, clear sound for its size. It can get pretty loud and serves up a good dose of bass, although its primarily a front-facing speaker. There’s LDAC hi-res audio support for Android users, but the main selling point on this is spatial audio. This is done through an EQ change and the activation of a small, up-firing driver. There’s a slight benefit from this if you’re up close and directly in front of it, but it’s not a total game changer for your listening experience. The original pre-order price of $130 made it a decent option in terms of bang for your buck. But it went up to $170 at launch, making it less appealing even if it’s still a good middle-of-the-road option if you want small-ish, clear and loud. If you can find one on sale for the lower price, it’s definitely worth considering. There’s also the larger and louder X600 ($200) if the overall concept is working for you. Portable Bluetooth speaker FAQs How does a Bluetooth speaker work? Bluetooth technology lets devices connect and exchange data over short distances using ultra high frequency (UHF) radio waves. It’s the frequency range that’s carved out for industrial, scientific and medical purposes, called the 2.4GHz ISM spectrum band. This range is available worldwide, making it easy for companies to use with devices for global markets. Bluetooth speakers include this tech, which lets them communicate with source devices like smartphones, tablets or computers in order to exchange data. The two devices pair by sharing a unique code and will work within the proscribed range for the device and Bluetooth version. Ever since Bluetooth 4.0 was released over a decade ago, new iterations usually improve on range, use less power and offer expanded connectivity with features like multipoint (allowing more than one device to be connected at the same time, for instance). Who should buy a Portable Bluetooth speaker? If you want to play music while you’re out-and-about on something other than headphones, a portable Bluetooth speaker is probably what you want. There’s a broad range of devices for all types of circumstances. Many adventurous people will want a relatively lightweight portable that’s rugged enough to handle the elements while also packing enough charge to play for hours on end. Others may simply need a speaker they can move around the house or use in the backyard. In this case, you can choose larger less rugged models that may offer better sound. This article originally appeared on Engadget at https://www.engadget.com/audio/speakers/best-portable-bluetooth-speakers-133004551.html?src=rss",
          "feed_position": 17
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/new-agent-framework-matches-human-engineered-ai-systems-and-adds-zero",
          "published_at": "Wed, 18 Feb 2026 22:00:00 GMT",
          "title": "New agent framework matches human-engineered AI systems — and adds zero inference cost to deploy",
          "standfirst": "Agents built on top of today&#x27;s models often break with simple changes — a new library, a workflow modification — and require a human engineer to fix it. That&#x27;s one of the most persistent challenges in deploying AI for the enterprise: creating agents that can adapt to dynamic environments without constant hand-holding. While today&#x27;s models are powerful, they are largely static.To address this, researchers at the University of California, Santa Barbara have developed Group-Evolving Agents (GEA), a new framework that enables groups of AI agents to evolve together, sharing experiences and reusing their innovations to autonomously improve over time.In experiments on complex coding and software engineering tasks, GEA substantially outperformed existing self-improving frameworks. Perhaps most notably for enterprise decision-makers, the system autonomously evolved agents that matched or exceeded the performance of frameworks painstakingly designed by human experts.The limitations of &#x27;lone wolf&#x27; evolutionMost existing agentic AI systems rely on fixed architectures designed by engineers. These systems often struggle to move beyond the capability boundaries imposed by their initial designs. To solve this, researchers have long sought to create self-evolving agents that can autonomously modify their own code and structure to overcome their initial limits. This capability is essential for handling open-ended environments where the agent must continuously explore new solutions.However, current approaches to self-evolution have a major structural flaw. As the researchers note in their paper, most systems are inspired by biological evolution and are designed around \"individual-centric\" processes. These methods typically use a tree-structured approach: a single \"parent\" agent is selected to produce offspring, creating distinct evolutionary branches that remain strictly isolated from one another.This isolation creates a silo effect. An agent in one branch cannot access the data, tools, or workflows discovered by an agent in a parallel branch. If a specific lineage fails to be selected for the next generation, any valuable discovery made by that agent, such as a novel debugging tool or a more efficient testing workflow, dies out with it.In their paper, the researchers question the necessity of adhering to this biological metaphor. \"AI agents are not biological individuals,\" they argue. \"Why should their evolution remain constrained by biological paradigms?\"The collective intelligence of Group-Evolving AgentsGEA shifts the paradigm by treating a group of agents, rather than an individual, as the fundamental unit of evolution.The process begins by selecting a group of parent agents from an existing archive. To ensure a healthy mix of stability and innovation, GEA selects these agents based on a combined score of performance (competence in solving tasks) and novelty (how distinct their capabilities are from others).Unlike traditional systems where an agent only learns from its direct parent, GEA creates a shared pool of collective experience. This pool contains the evolutionary traces from all members of the parent group, including code modifications, successful solutions to tasks, and tool invocation histories. Every agent in the group gains access to this collective history, allowing them to learn from the breakthroughs and mistakes of their peers.A “Reflection Module,” powered by a large language model, analyzes this collective history to identify group-wide patterns. For instance, if one agent discovers a high-performing debugging tool while another perfects a testing workflow, the system extracts both insights. Based on this analysis, the system generates high-level \"evolution directives\" that guide the creation of the child group. This ensures the next generation possesses the combined strengths of all their parents, rather than just the traits of a single lineage.However, this hive-mind approach works best when success is objective, such as in coding tasks. \"For less deterministic domains (e.g., creative generation), evaluation signals are weaker,\" Zhaotian Weng and Xin Eric Wang, co-authors of the paper, told VentureBeat in written comments. \"Blindly sharing outputs and experiences may introduce low-quality experiences that act as noise. This suggests the need for stronger experience filtering mechanisms\" for subjective tasks.GEA in actionThe researchers tested GEA against the current state-of-the-art self-evolving baseline, the Darwin Godel Machine (DGM), on two rigorous benchmarks. The results demonstrated a massive leap in capability without increasing the number of agents used.This collaborative approach also makes the system more robust against failure. In their experiments, the researchers intentionally broke agents by manually injecting bugs into their implementations. GEA was able to repair these critical bugs in an average of 1.4 iterations, while the baseline took 5 iterations. The system effectively leverages the \"healthy\" members of the group to diagnose and patch the compromised ones.On SWE-bench Verified, a benchmark consisting of real GitHub issues including bugs and feature requests, GEA achieved a 71.0% success rate, compared to the baseline&#x27;s 56.7%. This translates to a significant boost in autonomous engineering throughput, meaning the agents are far more capable of handling real-world software maintenance. Similarly, on Polyglot, which tests code generation across diverse programming languages, GEA achieved 88.3% against the baseline&#x27;s 68.3%, indicating high adaptability to different tech stacks.For enterprise R&D teams, the most critical finding is that GEA allows AI to design itself as effectively as human engineers. On SWE-bench, GEA’s 71.0% success rate effectively matches the performance of OpenHands, the top human-designed open-source framework. On Polyglot, GEA significantly outperformed Aider, a popular coding assistant, which achieved 52.0%. This suggests that organizations may eventually reduce their reliance on large teams of prompt engineers to tweak agent frameworks, as the agents can meta-learn these optimizations autonomously.This efficiency extends to cost management. \"GEA is explicitly a two-stage system: (1) agent evolution, then (2) inference/deployment,\" the researchers said. \"After evolution, you deploy a single evolved agent... so enterprise inference cost is essentially unchanged versus a standard single-agent setup.\"The success of GEA stems largely from its ability to consolidate improvements. The researchers tracked specific innovations invented by the agents during the evolutionary process. In the baseline approach, valuable tools often appeared in isolated branches but failed to propagate because those specific lineages ended. In GEA, the shared experience model ensured these tools were adopted by the best-performing agents. The top GEA agent integrated traits from 17 unique ancestors (representing 28% of the population) whereas the best baseline agent integrated traits from only 9. In effect, GEA creates a \"super-employee\" that possesses the combined best practices of the entire group.\"A GEA-inspired workflow in production would allow agents to first attempt a few independent fixes when failures occur,\" the researchers explained regarding this self-healing capability. \"A reflection agent (typically powered by a strong foundation model) can then summarize the outcomes... and guide a more comprehensive system update.\"Furthermore, the improvements discovered by GEA are not tied to a specific underlying model. Agents evolved using one model, such as Claude, maintained their performance gains even when the underlying engine was swapped to another model family, such as GPT-5.1 or GPT-o3-mini. This transferability offers enterprises the flexibility to switch model providers without losing the custom architectural optimizations their agents have learned.For industries with strict compliance requirements, the idea of self-modifying code might sound risky. To address this, the authors said: \"We expect enterprise deployments to include non-evolvable guardrails, such as sandboxed execution, policy constraints, and verification layers.\"While the researchers plan to release the official code soon, developers can already begin implementing the GEA architecture conceptually on top of existing agent frameworks. The system requires three key additions to a standard agent stack: an “experience archive” to store evolutionary traces, a “reflection module” to analyze group patterns, and an “updating module” that allows the agent to modify its own code based on those insights.Looking ahead, the framework could democratize advanced agent development. \"One promising direction is hybrid evolution pipelines,\" the researchers said, \"where smaller models explore early to accumulate diverse experiences, and stronger models later guide evolution using those experiences.\"",
          "content": "Agents built on top of today&#x27;s models often break with simple changes — a new library, a workflow modification — and require a human engineer to fix it. That&#x27;s one of the most persistent challenges in deploying AI for the enterprise: creating agents that can adapt to dynamic environments without constant hand-holding. While today&#x27;s models are powerful, they are largely static.To address this, researchers at the University of California, Santa Barbara have developed Group-Evolving Agents (GEA), a new framework that enables groups of AI agents to evolve together, sharing experiences and reusing their innovations to autonomously improve over time.In experiments on complex coding and software engineering tasks, GEA substantially outperformed existing self-improving frameworks. Perhaps most notably for enterprise decision-makers, the system autonomously evolved agents that matched or exceeded the performance of frameworks painstakingly designed by human experts.The limitations of &#x27;lone wolf&#x27; evolutionMost existing agentic AI systems rely on fixed architectures designed by engineers. These systems often struggle to move beyond the capability boundaries imposed by their initial designs. To solve this, researchers have long sought to create self-evolving agents that can autonomously modify their own code and structure to overcome their initial limits. This capability is essential for handling open-ended environments where the agent must continuously explore new solutions.However, current approaches to self-evolution have a major structural flaw. As the researchers note in their paper, most systems are inspired by biological evolution and are designed around \"individual-centric\" processes. These methods typically use a tree-structured approach: a single \"parent\" agent is selected to produce offspring, creating distinct evolutionary branches that remain strictly isolated from one another.This isolation creates a silo effect. An agent in one branch cannot access the data, tools, or workflows discovered by an agent in a parallel branch. If a specific lineage fails to be selected for the next generation, any valuable discovery made by that agent, such as a novel debugging tool or a more efficient testing workflow, dies out with it.In their paper, the researchers question the necessity of adhering to this biological metaphor. \"AI agents are not biological individuals,\" they argue. \"Why should their evolution remain constrained by biological paradigms?\"The collective intelligence of Group-Evolving AgentsGEA shifts the paradigm by treating a group of agents, rather than an individual, as the fundamental unit of evolution.The process begins by selecting a group of parent agents from an existing archive. To ensure a healthy mix of stability and innovation, GEA selects these agents based on a combined score of performance (competence in solving tasks) and novelty (how distinct their capabilities are from others).Unlike traditional systems where an agent only learns from its direct parent, GEA creates a shared pool of collective experience. This pool contains the evolutionary traces from all members of the parent group, including code modifications, successful solutions to tasks, and tool invocation histories. Every agent in the group gains access to this collective history, allowing them to learn from the breakthroughs and mistakes of their peers.A “Reflection Module,” powered by a large language model, analyzes this collective history to identify group-wide patterns. For instance, if one agent discovers a high-performing debugging tool while another perfects a testing workflow, the system extracts both insights. Based on this analysis, the system generates high-level \"evolution directives\" that guide the creation of the child group. This ensures the next generation possesses the combined strengths of all their parents, rather than just the traits of a single lineage.However, this hive-mind approach works best when success is objective, such as in coding tasks. \"For less deterministic domains (e.g., creative generation), evaluation signals are weaker,\" Zhaotian Weng and Xin Eric Wang, co-authors of the paper, told VentureBeat in written comments. \"Blindly sharing outputs and experiences may introduce low-quality experiences that act as noise. This suggests the need for stronger experience filtering mechanisms\" for subjective tasks.GEA in actionThe researchers tested GEA against the current state-of-the-art self-evolving baseline, the Darwin Godel Machine (DGM), on two rigorous benchmarks. The results demonstrated a massive leap in capability without increasing the number of agents used.This collaborative approach also makes the system more robust against failure. In their experiments, the researchers intentionally broke agents by manually injecting bugs into their implementations. GEA was able to repair these critical bugs in an average of 1.4 iterations, while the baseline took 5 iterations. The system effectively leverages the \"healthy\" members of the group to diagnose and patch the compromised ones.On SWE-bench Verified, a benchmark consisting of real GitHub issues including bugs and feature requests, GEA achieved a 71.0% success rate, compared to the baseline&#x27;s 56.7%. This translates to a significant boost in autonomous engineering throughput, meaning the agents are far more capable of handling real-world software maintenance. Similarly, on Polyglot, which tests code generation across diverse programming languages, GEA achieved 88.3% against the baseline&#x27;s 68.3%, indicating high adaptability to different tech stacks.For enterprise R&D teams, the most critical finding is that GEA allows AI to design itself as effectively as human engineers. On SWE-bench, GEA’s 71.0% success rate effectively matches the performance of OpenHands, the top human-designed open-source framework. On Polyglot, GEA significantly outperformed Aider, a popular coding assistant, which achieved 52.0%. This suggests that organizations may eventually reduce their reliance on large teams of prompt engineers to tweak agent frameworks, as the agents can meta-learn these optimizations autonomously.This efficiency extends to cost management. \"GEA is explicitly a two-stage system: (1) agent evolution, then (2) inference/deployment,\" the researchers said. \"After evolution, you deploy a single evolved agent... so enterprise inference cost is essentially unchanged versus a standard single-agent setup.\"The success of GEA stems largely from its ability to consolidate improvements. The researchers tracked specific innovations invented by the agents during the evolutionary process. In the baseline approach, valuable tools often appeared in isolated branches but failed to propagate because those specific lineages ended. In GEA, the shared experience model ensured these tools were adopted by the best-performing agents. The top GEA agent integrated traits from 17 unique ancestors (representing 28% of the population) whereas the best baseline agent integrated traits from only 9. In effect, GEA creates a \"super-employee\" that possesses the combined best practices of the entire group.\"A GEA-inspired workflow in production would allow agents to first attempt a few independent fixes when failures occur,\" the researchers explained regarding this self-healing capability. \"A reflection agent (typically powered by a strong foundation model) can then summarize the outcomes... and guide a more comprehensive system update.\"Furthermore, the improvements discovered by GEA are not tied to a specific underlying model. Agents evolved using one model, such as Claude, maintained their performance gains even when the underlying engine was swapped to another model family, such as GPT-5.1 or GPT-o3-mini. This transferability offers enterprises the flexibility to switch model providers without losing the custom architectural optimizations their agents have learned.For industries with strict compliance requirements, the idea of self-modifying code might sound risky. To address this, the authors said: \"We expect enterprise deployments to include non-evolvable guardrails, such as sandboxed execution, policy constraints, and verification layers.\"While the researchers plan to release the official code soon, developers can already begin implementing the GEA architecture conceptually on top of existing agent frameworks. The system requires three key additions to a standard agent stack: an “experience archive” to store evolutionary traces, a “reflection module” to analyze group patterns, and an “updating module” that allows the agent to modify its own code based on those insights.Looking ahead, the framework could democratize advanced agent development. \"One promising direction is hybrid evolution pipelines,\" the researchers said, \"where smaller models explore early to accumulate diverse experiences, and stronger models later guide evolution using those experiences.\"",
          "feed_position": 5,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/2Izl318JbInekR2BSYLBaq/4eddc806d26f5ee7d3567dece9c185ce/Self-evolving_agents.jpg?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/the-best-vpn-deals-up-to-87-percent-off-protonvpn-surfshark-expressvpn-nordvpn-and-more-120056484.html",
          "published_at": "Wed, 18 Feb 2026 18:59:17 +0000",
          "title": "The best VPN deals: Up to 87 percent off ProtonVPN, Surfshark, ExpressVPN, NordVPN and more",
          "standfirst": "The Winter Olympics have been a blast so far, and there are still four days left. It's the perfect time to get ahold of a virtual private network (VPN) and check out how the games are broadcast in other countries— all while improving your cybersecurity. By connecting to a VPN every time you get online, you can keep your activity hidden from your ISP and anyone to whom it may sell that data, while streaming sports and TV from across the globe. We strongly recommend using a VPN, but shopping for one takes some care. If you jump on the very first deal you see, you might get stuck with a substandard app. It's also easy to end up paying more than you meant to, since otherwise respectable VPNs sometimes frame their prices in misleading ways, with advertised deals not always as available as they seem to be. Even with all those conditions, there are some great bargains on the table. Many of the best VPNs — including our top pick, Proton VPN — have deals that save you anywhere from 70 to 87 percent on annual subscriptions. Most of the Valentine's Day sales have ended, but there are still plenty of chances to save money. Best VPN deals ExpressVPN Basic — $68.40 for a two-year subscription with four months free (81 percent off): This is one of the best VPNs, especially for new users, who will find its apps and website headache-free on all platforms. In tests for my ExpressVPN review, it dropped my download speeds by less than 7 percent and successfully changed my virtual location 14 out of 15 times. In short, it's an all-around excellent service that only suffers from being a little overpriced — which is why I'm so excited whenever I find it offering a decent deal. This discount, which gets you 28 months of ExpressVPN service, represents a 81 percent savings. Be aware, though, that it'll renew at the $99.95 per year price. ExpressVPN Advanced — $88.00 for a two-year subscription with four months free (77 percent off): ExpressVPN recently split its pricing into multiple tiers, but they all still come with similar discounts for going long. In addition to top-tier VPN service, advanced users get two additional simultaneous connections (for a total of 12), the ExpressVPN Keys password manager, advanced ad and tracker blocking, ID protection features and a 50 percent discount on an AirCove router. As above, note that it renews at $119.95 annually. NordVPN Basic — $81.36 for a two-year subscription (70 percent off): NordVPN gets the most important parts of a VPN right. It's fast, it doesn't leak any of your data and it's great at changing your virtual location. I noted in my NordVPN review that it always connects quickly and includes a support page that makes it easy to get live help. NordVPN includes a lot of cool features, like servers that instantly connect you to Tor. This deal gives you 70 percent off the two-year plan, but note that it renews at $139.08 per year. NordVPN Plus — $93.36 for a two-year subscription (74 percent off): NordVPN has taken 74 percent off its Plus subscription. For only a little more, you get a powerful ad and tracker blocker that can also catch malware downloads, plus access to the NordPass password manager. A Plus plan also adds a data breach scanner that checks the dark web for your sensitive information. When this plan renews, you'll be paying $179.88 per year. Surfshark Starter — $53.73 for a two-year subscription with three months free (87 percent off): This is the \"basic\" level of Surfshark, but it includes the entire VPN; everything on Surfshark One is an extra perk. With this subscription, you'll get some of the most envelope-pushing features in the VPN world right now. Surfshark can rotate your IP constantly to help you evade detection — it even lets you choose your own entry and exit nodes for a double-hop connection. That all comes with a near-invisible impact on download speeds. With this year-round deal, you can save 87 percent on 27 months of Surfshark. Surfshark One — $61.83 for a two-year subscription with three months free (87 percent off): A VPN is great, but it's not enough to protect your data all on its own. Surfshark One adds several apps that boost your security beyond just VPN service, including Surfshark Antivirus (scans devices and downloads for malware) and Surfshark Alert (alerts you whenever your sensitive information shows up in a data breach), plus Surfshark Search and Alternative ID from the tier below. This extra-low deal gives you 88 percent off all those features. If you bump up to Surfshark One+, you'll also get data removal through Incogni, but the price jumps enough that it's not quite worthwhile in my eyes. CyberGhost — $56.94 for a two-year subscription with four months free (84 percent off): CyberGhost has some of the best automation you'll see on any VPN. With its Smart Rules system, you can determine how its apps respond to different types of Wi-Fi networks, with exceptions for specific networks you know by name. Typically, you can set it to auto-connect, disconnect or send you a message asking what to do. CyberGhost's other best feature is its streaming servers — I've found both better video quality and more consistent unblocking when I use them on streaming sites. Currently, you can get 28 months of CyberGhost for 79 percent off the usual price, but it'll renew at $56.94 per year. hide.me — $69.99 for a two-year subscription with four months free (75 percent off): Hide.me is an excellent free VPN — in fact, it's my favorite on the market, even with EventVPN and the free version of Proton VPN as competition. If you do want to upgrade to its paid plan, though, the two-year subscription offers great savings. Hide.me works well as a no-frills beginner VPN, with apps and a server network it should frankly be charging more for. It also comes with a guarantee that it'll renew at exactly the same length and pricing. Windscribe — $69 for a one-year subscription (32 percent off): It's not nearly as steep a discount as some of the others on this list, but Windscribe was cheap to begin with, so 32 percent off its monthly price is a bigger savings than it might seem. As I just covered in a detailed Windscribe review, it's worth upgrading from the free service to get full access to Windscribe's all-real server network (and remove the free plan's data cap). Private Internet Access — $79 for a three-year subscription with four months free (83 percent off): With this deal, you can get 40 months of Private Internet Access (PIA) for a little bit under $2 per month — an 83 percent discount on its monthly price. You can also get a shorter one-year subscription for $40 ($3.33 per month). Despite being so cheap, PIA has plenty of features, coming with its own DNS servers, a built-in ad blocker and automation powers to rival CyberGhost. However, internet speeds can fluctuate while you're connected. What makes a good VPN deal Practically every VPN heavily discounts its long-term subscriptions year-round, with even sharper discounts around occasions like the holidays. The only noteworthy exception is Mullvad, the Costco hot dog of VPNs (that's a compliment, to be clear). When there's constantly a huge discount going on, it can be hard to tell when you're actually getting a good deal. The best way to squeeze out more savings is to look for seasonal deals, student discounts or exclusive sales like Proton VPN's coupon for Engadget readers. One trick VPNs often use is to add extra months onto an introductory deal, pushing the average monthly price even lower. When it comes time to renew, you usually can't get these extra months again. You often can't even renew for the same basic period of time — for example, you may only be able to renew a two-year subscription for one year. If you're planning to hold onto a VPN indefinitely, check the fine print to see how much it will cost per month after the first renewal, and ensure that fits into your budget. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/the-best-vpn-deals-up-to-87-percent-off-protonvpn-surfshark-expressvpn-nordvpn-and-more-120056484.html?src=rss",
          "content": "The Winter Olympics have been a blast so far, and there are still four days left. It's the perfect time to get ahold of a virtual private network (VPN) and check out how the games are broadcast in other countries— all while improving your cybersecurity. By connecting to a VPN every time you get online, you can keep your activity hidden from your ISP and anyone to whom it may sell that data, while streaming sports and TV from across the globe. We strongly recommend using a VPN, but shopping for one takes some care. If you jump on the very first deal you see, you might get stuck with a substandard app. It's also easy to end up paying more than you meant to, since otherwise respectable VPNs sometimes frame their prices in misleading ways, with advertised deals not always as available as they seem to be. Even with all those conditions, there are some great bargains on the table. Many of the best VPNs — including our top pick, Proton VPN — have deals that save you anywhere from 70 to 87 percent on annual subscriptions. Most of the Valentine's Day sales have ended, but there are still plenty of chances to save money. Best VPN deals ExpressVPN Basic — $68.40 for a two-year subscription with four months free (81 percent off): This is one of the best VPNs, especially for new users, who will find its apps and website headache-free on all platforms. In tests for my ExpressVPN review, it dropped my download speeds by less than 7 percent and successfully changed my virtual location 14 out of 15 times. In short, it's an all-around excellent service that only suffers from being a little overpriced — which is why I'm so excited whenever I find it offering a decent deal. This discount, which gets you 28 months of ExpressVPN service, represents a 81 percent savings. Be aware, though, that it'll renew at the $99.95 per year price. ExpressVPN Advanced — $88.00 for a two-year subscription with four months free (77 percent off): ExpressVPN recently split its pricing into multiple tiers, but they all still come with similar discounts for going long. In addition to top-tier VPN service, advanced users get two additional simultaneous connections (for a total of 12), the ExpressVPN Keys password manager, advanced ad and tracker blocking, ID protection features and a 50 percent discount on an AirCove router. As above, note that it renews at $119.95 annually. NordVPN Basic — $81.36 for a two-year subscription (70 percent off): NordVPN gets the most important parts of a VPN right. It's fast, it doesn't leak any of your data and it's great at changing your virtual location. I noted in my NordVPN review that it always connects quickly and includes a support page that makes it easy to get live help. NordVPN includes a lot of cool features, like servers that instantly connect you to Tor. This deal gives you 70 percent off the two-year plan, but note that it renews at $139.08 per year. NordVPN Plus — $93.36 for a two-year subscription (74 percent off): NordVPN has taken 74 percent off its Plus subscription. For only a little more, you get a powerful ad and tracker blocker that can also catch malware downloads, plus access to the NordPass password manager. A Plus plan also adds a data breach scanner that checks the dark web for your sensitive information. When this plan renews, you'll be paying $179.88 per year. Surfshark Starter — $53.73 for a two-year subscription with three months free (87 percent off): This is the \"basic\" level of Surfshark, but it includes the entire VPN; everything on Surfshark One is an extra perk. With this subscription, you'll get some of the most envelope-pushing features in the VPN world right now. Surfshark can rotate your IP constantly to help you evade detection — it even lets you choose your own entry and exit nodes for a double-hop connection. That all comes with a near-invisible impact on download speeds. With this year-round deal, you can save 87 percent on 27 months of Surfshark. Surfshark One — $61.83 for a two-year subscription with three months free (87 percent off): A VPN is great, but it's not enough to protect your data all on its own. Surfshark One adds several apps that boost your security beyond just VPN service, including Surfshark Antivirus (scans devices and downloads for malware) and Surfshark Alert (alerts you whenever your sensitive information shows up in a data breach), plus Surfshark Search and Alternative ID from the tier below. This extra-low deal gives you 88 percent off all those features. If you bump up to Surfshark One+, you'll also get data removal through Incogni, but the price jumps enough that it's not quite worthwhile in my eyes. CyberGhost — $56.94 for a two-year subscription with four months free (84 percent off): CyberGhost has some of the best automation you'll see on any VPN. With its Smart Rules system, you can determine how its apps respond to different types of Wi-Fi networks, with exceptions for specific networks you know by name. Typically, you can set it to auto-connect, disconnect or send you a message asking what to do. CyberGhost's other best feature is its streaming servers — I've found both better video quality and more consistent unblocking when I use them on streaming sites. Currently, you can get 28 months of CyberGhost for 79 percent off the usual price, but it'll renew at $56.94 per year. hide.me — $69.99 for a two-year subscription with four months free (75 percent off): Hide.me is an excellent free VPN — in fact, it's my favorite on the market, even with EventVPN and the free version of Proton VPN as competition. If you do want to upgrade to its paid plan, though, the two-year subscription offers great savings. Hide.me works well as a no-frills beginner VPN, with apps and a server network it should frankly be charging more for. It also comes with a guarantee that it'll renew at exactly the same length and pricing. Windscribe — $69 for a one-year subscription (32 percent off): It's not nearly as steep a discount as some of the others on this list, but Windscribe was cheap to begin with, so 32 percent off its monthly price is a bigger savings than it might seem. As I just covered in a detailed Windscribe review, it's worth upgrading from the free service to get full access to Windscribe's all-real server network (and remove the free plan's data cap). Private Internet Access — $79 for a three-year subscription with four months free (83 percent off): With this deal, you can get 40 months of Private Internet Access (PIA) for a little bit under $2 per month — an 83 percent discount on its monthly price. You can also get a shorter one-year subscription for $40 ($3.33 per month). Despite being so cheap, PIA has plenty of features, coming with its own DNS servers, a built-in ad blocker and automation powers to rival CyberGhost. However, internet speeds can fluctuate while you're connected. What makes a good VPN deal Practically every VPN heavily discounts its long-term subscriptions year-round, with even sharper discounts around occasions like the holidays. The only noteworthy exception is Mullvad, the Costco hot dog of VPNs (that's a compliment, to be clear). When there's constantly a huge discount going on, it can be hard to tell when you're actually getting a good deal. The best way to squeeze out more savings is to look for seasonal deals, student discounts or exclusive sales like Proton VPN's coupon for Engadget readers. One trick VPNs often use is to add extra months onto an introductory deal, pushing the average monthly price even lower. When it comes time to renew, you usually can't get these extra months again. You often can't even renew for the same basic period of time — for example, you may only be able to renew a two-year subscription for one year. If you're planning to hold onto a VPN indefinitely, check the fine print to see how much it will cost per month after the first renewal, and ensure that fits into your budget. Follow @EngadgetDeals on X for the latest tech deals and buying advice.This article originally appeared on Engadget at https://www.engadget.com/deals/the-best-vpn-deals-up-to-87-percent-off-protonvpn-surfshark-expressvpn-nordvpn-and-more-120056484.html?src=rss",
          "feed_position": 22
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/technology/alibabas-qwen-3-5-397b-a17-beats-its-larger-trillion-parameter-model-at-a",
          "published_at": "Wed, 18 Feb 2026 18:44:00 GMT",
          "title": "Alibaba's Qwen 3.5 397B-A17 beats its larger trillion-parameter model — at a fraction of the cost",
          "standfirst": "Alibaba dropped Qwen3.5 earlier this week, timed to coincide with the Lunar New Year, and the headline numbers alone are enough to make enterprise AI buyers stop and pay attention.The new flagship open-weight model — Qwen3.5-397B-A17B — packs 397 billion total parameters but activates only 17 billion per token. It is claiming benchmark wins against Alibaba&#x27;s own previous flagship, Qwen3-Max, a model the company itself has acknowledged exceeded one trillion parameters. The release marks a meaningful moment in enterprise AI procurement. For IT leaders evaluating AI infrastructure for 2026, Qwen 3.5 presents a different kind of argument: that the model you can actually run, own, and control can now trade blows with the models you have to rent.A New Architecture Built for Speed at ScaleThe engineering story underneath Qwen3.5 starts with its ancestry. The model is a direct successor to last September&#x27;s experimental Qwen3-Next, an ultra-sparse MoE model that was previewed but widely regarded as half-trained. Qwen3.5 takes that architectural direction and scales it aggressively, jumping from 128 experts in the previous Qwen3 MoE models to 512 experts in the new release.The practical implication of this and a better attention mechanism is dramatically lower inference latency. Because only 17 billion of those 397 billion parameters are active for any given forward pass, the compute footprint is far closer to a 17B dense model than a 400B one — while the model can draw on the full depth of its expert pool for specialized reasoning.These speed gains are substantial. At 256K context lengths, Qwen 3.5 decodes 19 times faster than Qwen3-Max and 7.2 times faster than Qwen 3&#x27;s 235B-A22B model. Alibaba is also claiming the model is 60% cheaper to run than its predecessor and eight times more capable of handling large concurrent workloads, figures that matter enormously to any team paying attention to inference bills. It&#x27;s also about 1/18th the cost of Google&#x27;s Gemini 3 Pro.Two other architectural decisions compound these gains:Qwen3.5 adopts multi-token prediction — an approach pioneered in several proprietary models — which accelerates pre-training convergence and increases throughput. It also inherits the attention system from Qwen3-Next released last year, designed specifically to reduce memory pressure at very long context lengths. The result is a model that can comfortably operate within a 256K context window in the open-weight version, and up to 1 million tokens in the hosted Qwen3.5-Plus variant on Alibaba Cloud Model Studio.Native Multimodal, Not Bolted OnFor years, Alibaba took the standard industry approach: build a language model, then attach a vision encoder to create a separate VL variant. Qwen3.5 abandons that pattern entirely. The model is trained from scratch on text, images, and video simultaneously, meaning visual reasoning is woven into the model&#x27;s core representations rather than grafted on.This matters in practice. Natively multimodal models tend to outperform their adapter-based counterparts on tasks that require tight text-image reasoning — think analyzing a technical diagram alongside its documentation, processing UI screenshots for agentic tasks, or extracting structured data from complex visual layouts. On MathVista, the model scores 90.3; on MMMU, 85.0. It trails Gemini 3 on several vision-specific benchmarks but surpasses Claude Opus 4.5 on multimodal tasks and posts competitive numbers against GPT-5.2, all while carrying a fraction of the parameter count.Qwen3.5&#x27;s benchmark performance against larger proprietary models is the number that will drive enterprise conversations. On the evaluations Alibaba has published, the 397B-A17B model outperforms Qwen3-Max — a model with over a trillion parameters — across multiple reasoning and coding tasks. It also claims competitive results against GPT-5.2, Claude Opus 4.5, and Gemini 3 Pro on general reasoning and coding benchmarks.Language Coverage and Tokenizer EfficiencyOne underappreciated detail in the Qwen3.5 release is its expanded multilingual reach. The model&#x27;s vocabulary has grown to 250k tokens, up from 150k in prior Qwen generations and now comparable to Google&#x27;s ~256K tokenizer. Language support expands from 119 languages in Qwen 3 to 201 languages and dialects.The tokenizer upgrade has direct cost implications for global deployments. Larger vocabularies encode non-Latin scripts — Arabic, Thai, Korean, Japanese, Hindi, and others — more efficiently, reducing token counts by 15–40% depending on the language. For IT organizations running AI at scale across multilingual user bases, this is not an academic detail. It translates directly to lower inference costs and faster response times.Agentic Capabilities and the OpenClaw IntegrationAlibaba is positioning Qwen3.5 explicitly as an agentic model — one designed not just to respond to queries but to take multi-step autonomous action on behalf of users and systems. The company has open-sourced Qwen Code, a command-line interface that lets developers delegate complex coding tasks to the model in natural language, roughly analogous to Anthropic&#x27;s Claude Code.The release also highlights compatibility with OpenClaw, the open-source agentic framework that has surged in developer adoption this year. With 15,000 distinct reinforcement learning training environments used to sharpen the model&#x27;s reasoning and task execution, the Qwen team has made a deliberate bet on RL-based training to improve practical agentic performance — a trend consistent with what MiniMax demonstrated with M2.5.The Qwen3.5-Plus hosted variant also enables adaptive inference modes: a fast mode for latency-sensitive applications, a thinking mode that enables extended chain-of-thought reasoning for complex tasks, and an auto (adaptive) mode that selects dynamically. That flexibility matters for enterprise deployments where the same model may need to serve both real-time customer interactions and deep analytical workflows.Deployment Realities: What IT Teams Actually Need to KnowRunning Qwen3.5’s open-weights in-house requires serious hardware. While a quantized version demands approximately 256GB of RAM, and realistically 512GB for comfortable headroom. This is not a model for a workstation or a modest on-prem server. What it is suitable for is a GPU node — a configuration that many enterprises already operate for inference workloads, and one that now offers a compelling alternative to API-dependent deployments.All open-weight Qwen 3.5 models are released under the Apache 2.0 license. This is a meaningful distinction from models with custom or restricted licenses: Apache 2.0 allows commercial use, modification, and redistribution without royalties, with no meaningful strings attached. For legal and procurement teams evaluating open models, that clean licensing posture simplifies the conversation considerably.What Comes NextAlibaba has confirmed this is the first release in the Qwen3.5 family, not the complete rollout. Based on the pattern from Qwen3 — which featured models down to 600 million parameters — the industry expects smaller dense distilled models and additional MoE configurations to follow over the next several weeks and months. The Qwen3-Next 80B model from last September was widely considered undertrained, suggesting a 3.5 variant at that scale is a likely near-term release.For IT decision-makers, the trajectory is clear. Alibaba has demonstrated that open-weight models at the frontier are no longer a compromise. Qwen3.5 is a genuine procurement option for teams that want frontier-class reasoning, native multimodal capabilities, and a 1M token context window — without locking into a proprietary API. The next question is not whether this family of models is capable enough. It is whether your infrastructure and team are ready to take advantage of it.Qwen 3.5 is available now on Hugging Face under the model ID Qwen/Qwen3.5-397B-A17B. The hosted Qwen3.5-Plus variant is available via Alibaba Cloud Model Studio. Qwen Chat at chat.qwen.ai offers free public access for evaluation.",
          "content": "Alibaba dropped Qwen3.5 earlier this week, timed to coincide with the Lunar New Year, and the headline numbers alone are enough to make enterprise AI buyers stop and pay attention.The new flagship open-weight model — Qwen3.5-397B-A17B — packs 397 billion total parameters but activates only 17 billion per token. It is claiming benchmark wins against Alibaba&#x27;s own previous flagship, Qwen3-Max, a model the company itself has acknowledged exceeded one trillion parameters. The release marks a meaningful moment in enterprise AI procurement. For IT leaders evaluating AI infrastructure for 2026, Qwen 3.5 presents a different kind of argument: that the model you can actually run, own, and control can now trade blows with the models you have to rent.A New Architecture Built for Speed at ScaleThe engineering story underneath Qwen3.5 starts with its ancestry. The model is a direct successor to last September&#x27;s experimental Qwen3-Next, an ultra-sparse MoE model that was previewed but widely regarded as half-trained. Qwen3.5 takes that architectural direction and scales it aggressively, jumping from 128 experts in the previous Qwen3 MoE models to 512 experts in the new release.The practical implication of this and a better attention mechanism is dramatically lower inference latency. Because only 17 billion of those 397 billion parameters are active for any given forward pass, the compute footprint is far closer to a 17B dense model than a 400B one — while the model can draw on the full depth of its expert pool for specialized reasoning.These speed gains are substantial. At 256K context lengths, Qwen 3.5 decodes 19 times faster than Qwen3-Max and 7.2 times faster than Qwen 3&#x27;s 235B-A22B model. Alibaba is also claiming the model is 60% cheaper to run than its predecessor and eight times more capable of handling large concurrent workloads, figures that matter enormously to any team paying attention to inference bills. It&#x27;s also about 1/18th the cost of Google&#x27;s Gemini 3 Pro.Two other architectural decisions compound these gains:Qwen3.5 adopts multi-token prediction — an approach pioneered in several proprietary models — which accelerates pre-training convergence and increases throughput. It also inherits the attention system from Qwen3-Next released last year, designed specifically to reduce memory pressure at very long context lengths. The result is a model that can comfortably operate within a 256K context window in the open-weight version, and up to 1 million tokens in the hosted Qwen3.5-Plus variant on Alibaba Cloud Model Studio.Native Multimodal, Not Bolted OnFor years, Alibaba took the standard industry approach: build a language model, then attach a vision encoder to create a separate VL variant. Qwen3.5 abandons that pattern entirely. The model is trained from scratch on text, images, and video simultaneously, meaning visual reasoning is woven into the model&#x27;s core representations rather than grafted on.This matters in practice. Natively multimodal models tend to outperform their adapter-based counterparts on tasks that require tight text-image reasoning — think analyzing a technical diagram alongside its documentation, processing UI screenshots for agentic tasks, or extracting structured data from complex visual layouts. On MathVista, the model scores 90.3; on MMMU, 85.0. It trails Gemini 3 on several vision-specific benchmarks but surpasses Claude Opus 4.5 on multimodal tasks and posts competitive numbers against GPT-5.2, all while carrying a fraction of the parameter count.Qwen3.5&#x27;s benchmark performance against larger proprietary models is the number that will drive enterprise conversations. On the evaluations Alibaba has published, the 397B-A17B model outperforms Qwen3-Max — a model with over a trillion parameters — across multiple reasoning and coding tasks. It also claims competitive results against GPT-5.2, Claude Opus 4.5, and Gemini 3 Pro on general reasoning and coding benchmarks.Language Coverage and Tokenizer EfficiencyOne underappreciated detail in the Qwen3.5 release is its expanded multilingual reach. The model&#x27;s vocabulary has grown to 250k tokens, up from 150k in prior Qwen generations and now comparable to Google&#x27;s ~256K tokenizer. Language support expands from 119 languages in Qwen 3 to 201 languages and dialects.The tokenizer upgrade has direct cost implications for global deployments. Larger vocabularies encode non-Latin scripts — Arabic, Thai, Korean, Japanese, Hindi, and others — more efficiently, reducing token counts by 15–40% depending on the language. For IT organizations running AI at scale across multilingual user bases, this is not an academic detail. It translates directly to lower inference costs and faster response times.Agentic Capabilities and the OpenClaw IntegrationAlibaba is positioning Qwen3.5 explicitly as an agentic model — one designed not just to respond to queries but to take multi-step autonomous action on behalf of users and systems. The company has open-sourced Qwen Code, a command-line interface that lets developers delegate complex coding tasks to the model in natural language, roughly analogous to Anthropic&#x27;s Claude Code.The release also highlights compatibility with OpenClaw, the open-source agentic framework that has surged in developer adoption this year. With 15,000 distinct reinforcement learning training environments used to sharpen the model&#x27;s reasoning and task execution, the Qwen team has made a deliberate bet on RL-based training to improve practical agentic performance — a trend consistent with what MiniMax demonstrated with M2.5.The Qwen3.5-Plus hosted variant also enables adaptive inference modes: a fast mode for latency-sensitive applications, a thinking mode that enables extended chain-of-thought reasoning for complex tasks, and an auto (adaptive) mode that selects dynamically. That flexibility matters for enterprise deployments where the same model may need to serve both real-time customer interactions and deep analytical workflows.Deployment Realities: What IT Teams Actually Need to KnowRunning Qwen3.5’s open-weights in-house requires serious hardware. While a quantized version demands approximately 256GB of RAM, and realistically 512GB for comfortable headroom. This is not a model for a workstation or a modest on-prem server. What it is suitable for is a GPU node — a configuration that many enterprises already operate for inference workloads, and one that now offers a compelling alternative to API-dependent deployments.All open-weight Qwen 3.5 models are released under the Apache 2.0 license. This is a meaningful distinction from models with custom or restricted licenses: Apache 2.0 allows commercial use, modification, and redistribution without royalties, with no meaningful strings attached. For legal and procurement teams evaluating open models, that clean licensing posture simplifies the conversation considerably.What Comes NextAlibaba has confirmed this is the first release in the Qwen3.5 family, not the complete rollout. Based on the pattern from Qwen3 — which featured models down to 600 million parameters — the industry expects smaller dense distilled models and additional MoE configurations to follow over the next several weeks and months. The Qwen3-Next 80B model from last September was widely considered undertrained, suggesting a 3.5 variant at that scale is a likely near-term release.For IT decision-makers, the trajectory is clear. Alibaba has demonstrated that open-weight models at the frontier are no longer a compromise. Qwen3.5 is a genuine procurement option for teams that want frontier-class reasoning, native multimodal capabilities, and a 1M token context window — without locking into a proprietary API. The next question is not whether this family of models is capable enough. It is whether your infrastructure and team are ready to take advantage of it.Qwen 3.5 is available now on Hugging Face under the model ID Qwen/Qwen3.5-397B-A17B. The hosted Qwen3.5-Plus variant is available via Alibaba Cloud Model Studio. Qwen Chat at chat.qwen.ai offers free public access for evaluation.",
          "feed_position": 6,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/7KLUCxdexYBxBe7M2ZwlYA/d4fa942fad8cccbccda18459bb6d406b/Gemini_Generated_Image_rmmft9rmmft9rmmf.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/smartphones/google-pixel-10a-vs-pixel-9a-whats-changed-and-which-one-should-you-buy-150000786.html",
          "published_at": "Wed, 18 Feb 2026 15:00:00 +0000",
          "title": "Google Pixel 10a vs. Pixel 9a: What's changed and which one should you buy?",
          "standfirst": "Now that pre-orders are open for the Google Pixel 10a, it’s time to see how it stacks up against last year’s Pixel 9a. At first glance, the two phones look very similar, and that’s not a bad thing. Google hasn’t tried to reinvent its budget-friendly formula this year, sticking to the same compact design, clean software experience and camera-first approach that made the 9a such a good value.Both phones share a lot in common, including 120Hz OLED displays, Google’s Tensor G4 chip, strong computational photography and seven years of OS and security updates. The actual differences are more incremental, including a moderately brighter, tougher display, improved Extreme Battery Saver longevity, slightly faster wireless charging and the addition of Satellite SOS. Importantly, Google is keeping the starting price the same as before, with both phones coming in at $499.On paper, the Pixel 10a doesn’t dramatically rethink what an affordable Pixel should be, but it does offer meaningful upgrades for the same price. While we wait for a review unit to evaluate the Pixel 10a's day-to-day performance, here's a quick comparison of the spec sheets of the two devices to see what the new model brings.Pixel 10a vs Pixel 9a: Design and displayThere’s very little separating these two on performance. Both the Pixel 9a and Pixel 10a run Google’s Tensor G4 chip with 8GB of RAM and the same storage options, so day-to-day speed should feel virtually identical. The Pixel 10a ships with Android 16 out of the box, though the 9a can be updated to the same version.Off the bat, the Pixel 10a doesn’t look dramatically different from the Pixel 9a, and that appears to be intentional. Google is sticking with the same compact, no-frills approach from the last few A-series Pixels, so you’re still getting a 6.3-inch OLED panel with a smooth 60–120Hz refresh rate and a clean, understated aesthetic. The meaningful changes show up once you dig into the display specs. The Pixel 10a upgrades the cover glass from Corning Gorilla Glass 3 to Gorilla Glass 7i, which should offer better durability against drops and scratches over time. Brightness also gets a noticeable bump. The 9a topped out at 1,800 nits for HDR content and 2,700 nits at peak, while the 10a pushes that to 2,000 nits for HDR and up to 3,000 nits at peak brightness. In practice, that should make the Pixel 10a easier to read outdoors and a bit punchier when watching HDR video.Contrast is improved as well. The Pixel 10a’s panel is rated at a contrast ratio of more than 2,000,000:1, doubling the already respectable figure on the Pixel 9a. That won’t radically change how the phone looks day to day, but it should translate to deeper blacks and slightly more depth in darker scenes, especially when streaming video or browsing photos at night.Pixel 10a vs Pixel 9a: CamerasOn paper, the Pixel 10a’s camera hardware looks very familiar. Like the Pixel 9a, it uses a 48-megapixel main camera paired with a 13MP ultra-wide, and there’s no dedicated telephoto lens. Image quality, color science and low-light performance should therefore be similar between the two.Where the Pixel 10a pulls ahead is in software features. Google has added a few camera tools that aren’t available on the Pixel 9a, even though the underlying hardware hasn’t changed much. One of those is Camera Coach, which debuted on last year’s Pixel 10 series and offers on-screen tips to help you frame shots better or adjust how you’re holding the phone. The Pixel 10a also gains Macro Focus, allowing you to get much closer to small subjects like plants or textures. In our Pixel 9a review, we found the phone could capture solid close-up detail, but locking focus could be finicky at times, so a more dedicated macro mode should make those shots easier to nail.Finally, there’s Auto Best Take, which automatically picks the best expressions from a burst of photos and combines them into a single image. The feature debuted on Google’s Pixel 10 lineup last year, and it’s especially handy for group shots where someone always seems to blink at the wrong moment. By bringing it to the 10a, Google is extending one of its more genuinely practical AI camera tricks to a cheaper phone.Battery life and chargingBoth the Pixel 9a and Pixel 10a use a 5,100mAh battery and support the same 23W wired charging speeds. Where the Pixel 10a does pull ahead slightly is wireless charging. The Pixel 9a tops out at 7.5W, while the Pixel 10a supports wireless charging at up to 10W when used with Qi-certified Extended Power Profile (EPP) chargers, which are designed to deliver faster wireless power than basic Qi pads. The difference isn’t dramatic, but the Pixel 10a should charge a bit quicker on a compatible wireless stand when you’re in a pinch.You’ll also get some extra hours in dire situations. When you activate Extreme Battery Saver, the Pixel 9a is rated for up to 100 hours, while the Pixel 10a extends that to up to 120 hours. The Pixel 10a gets Satellite SOSThe biggest safety-related upgrade on the Pixel 10a is the addition of Satellite SOS. Because it uses a newer modem compared to the Pixel 9a’s Exynos Modem 5300, it is capable of tapping satellite networks when necessary. This allows the phone to contact emergency services when you’re outside of cellular or Wi-Fi coverage, which can be genuinely useful if you spend time hiking, traveling or driving in remote areas.If you already own a Pixel 9a, there doesn’t appear to be a huge reason to upgrade. Day-to-day performance may feel almost identical, since both phones use the same Tensor G4 chip, the same amount of RAM and very similar camera hardware.That said, the Pixel 10a does make a stronger case for first-time buyers or anyone upgrading from an older Pixel. The biggest differentiator, though, is Satellite SOS — it’s the one feature the Pixel 9a simply can’t match due to hardware limitations. At the same $499 starting price, the Pixel 10a is, on paper, the better long-term buy if you’re choosing between the two today. Google Pixel 10a vs. Google Pixel 9a: Specs at a glanceSpecGoogle Pixel 10aGoogle Pixel 9aPrice$499$499ProcessorGoogle Tensor G4, Titan M2 coprocessorGoogle Tensor G4, Titan M2 coprocessorDisplay6.3-inch Actua display, 1080 x 2424 pOLED at 422.2 PPI, Gorilla Glass 7i6.3-inch Actua display, 1080 x 2424 pOLED at 422.2 PPI, Corning Gorilla Glass 3RAM8GB8GBStorage128GB, 256GB128GB, 256GBBattery5,100mAh5,100mAhWireless chargingUp to 10WUp to 7.5WRear camera48MP wide, 13MP ultrawide, Super Res Zoom up to 8x48MP wide, 13MP ultrawide, Super Res Zoom up to 8xFront camera13MP selfie cam13MP selfie camSIMDual SIM (single nano SIM, eSIM)Dual SIM (single nano SIM, eSIM)ConnectivityWi-Fi 6E, Bluetooth v6, NFCWi-Fi 6E, Bluetooth v5.3, NFCOSLaunch with Android 16Launch with Android 15This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/google-pixel-10a-vs-pixel-9a-whats-changed-and-which-one-should-you-buy-150000786.html?src=rss",
          "content": "Now that pre-orders are open for the Google Pixel 10a, it’s time to see how it stacks up against last year’s Pixel 9a. At first glance, the two phones look very similar, and that’s not a bad thing. Google hasn’t tried to reinvent its budget-friendly formula this year, sticking to the same compact design, clean software experience and camera-first approach that made the 9a such a good value.Both phones share a lot in common, including 120Hz OLED displays, Google’s Tensor G4 chip, strong computational photography and seven years of OS and security updates. The actual differences are more incremental, including a moderately brighter, tougher display, improved Extreme Battery Saver longevity, slightly faster wireless charging and the addition of Satellite SOS. Importantly, Google is keeping the starting price the same as before, with both phones coming in at $499.On paper, the Pixel 10a doesn’t dramatically rethink what an affordable Pixel should be, but it does offer meaningful upgrades for the same price. While we wait for a review unit to evaluate the Pixel 10a's day-to-day performance, here's a quick comparison of the spec sheets of the two devices to see what the new model brings.Pixel 10a vs Pixel 9a: Design and displayThere’s very little separating these two on performance. Both the Pixel 9a and Pixel 10a run Google’s Tensor G4 chip with 8GB of RAM and the same storage options, so day-to-day speed should feel virtually identical. The Pixel 10a ships with Android 16 out of the box, though the 9a can be updated to the same version.Off the bat, the Pixel 10a doesn’t look dramatically different from the Pixel 9a, and that appears to be intentional. Google is sticking with the same compact, no-frills approach from the last few A-series Pixels, so you’re still getting a 6.3-inch OLED panel with a smooth 60–120Hz refresh rate and a clean, understated aesthetic. The meaningful changes show up once you dig into the display specs. The Pixel 10a upgrades the cover glass from Corning Gorilla Glass 3 to Gorilla Glass 7i, which should offer better durability against drops and scratches over time. Brightness also gets a noticeable bump. The 9a topped out at 1,800 nits for HDR content and 2,700 nits at peak, while the 10a pushes that to 2,000 nits for HDR and up to 3,000 nits at peak brightness. In practice, that should make the Pixel 10a easier to read outdoors and a bit punchier when watching HDR video.Contrast is improved as well. The Pixel 10a’s panel is rated at a contrast ratio of more than 2,000,000:1, doubling the already respectable figure on the Pixel 9a. That won’t radically change how the phone looks day to day, but it should translate to deeper blacks and slightly more depth in darker scenes, especially when streaming video or browsing photos at night.Pixel 10a vs Pixel 9a: CamerasOn paper, the Pixel 10a’s camera hardware looks very familiar. Like the Pixel 9a, it uses a 48-megapixel main camera paired with a 13MP ultra-wide, and there’s no dedicated telephoto lens. Image quality, color science and low-light performance should therefore be similar between the two.Where the Pixel 10a pulls ahead is in software features. Google has added a few camera tools that aren’t available on the Pixel 9a, even though the underlying hardware hasn’t changed much. One of those is Camera Coach, which debuted on last year’s Pixel 10 series and offers on-screen tips to help you frame shots better or adjust how you’re holding the phone. The Pixel 10a also gains Macro Focus, allowing you to get much closer to small subjects like plants or textures. In our Pixel 9a review, we found the phone could capture solid close-up detail, but locking focus could be finicky at times, so a more dedicated macro mode should make those shots easier to nail.Finally, there’s Auto Best Take, which automatically picks the best expressions from a burst of photos and combines them into a single image. The feature debuted on Google’s Pixel 10 lineup last year, and it’s especially handy for group shots where someone always seems to blink at the wrong moment. By bringing it to the 10a, Google is extending one of its more genuinely practical AI camera tricks to a cheaper phone.Battery life and chargingBoth the Pixel 9a and Pixel 10a use a 5,100mAh battery and support the same 23W wired charging speeds. Where the Pixel 10a does pull ahead slightly is wireless charging. The Pixel 9a tops out at 7.5W, while the Pixel 10a supports wireless charging at up to 10W when used with Qi-certified Extended Power Profile (EPP) chargers, which are designed to deliver faster wireless power than basic Qi pads. The difference isn’t dramatic, but the Pixel 10a should charge a bit quicker on a compatible wireless stand when you’re in a pinch.You’ll also get some extra hours in dire situations. When you activate Extreme Battery Saver, the Pixel 9a is rated for up to 100 hours, while the Pixel 10a extends that to up to 120 hours. The Pixel 10a gets Satellite SOSThe biggest safety-related upgrade on the Pixel 10a is the addition of Satellite SOS. Because it uses a newer modem compared to the Pixel 9a’s Exynos Modem 5300, it is capable of tapping satellite networks when necessary. This allows the phone to contact emergency services when you’re outside of cellular or Wi-Fi coverage, which can be genuinely useful if you spend time hiking, traveling or driving in remote areas.If you already own a Pixel 9a, there doesn’t appear to be a huge reason to upgrade. Day-to-day performance may feel almost identical, since both phones use the same Tensor G4 chip, the same amount of RAM and very similar camera hardware.That said, the Pixel 10a does make a stronger case for first-time buyers or anyone upgrading from an older Pixel. The biggest differentiator, though, is Satellite SOS — it’s the one feature the Pixel 9a simply can’t match due to hardware limitations. At the same $499 starting price, the Pixel 10a is, on paper, the better long-term buy if you’re choosing between the two today. Google Pixel 10a vs. Google Pixel 9a: Specs at a glanceSpecGoogle Pixel 10aGoogle Pixel 9aPrice$499$499ProcessorGoogle Tensor G4, Titan M2 coprocessorGoogle Tensor G4, Titan M2 coprocessorDisplay6.3-inch Actua display, 1080 x 2424 pOLED at 422.2 PPI, Gorilla Glass 7i6.3-inch Actua display, 1080 x 2424 pOLED at 422.2 PPI, Corning Gorilla Glass 3RAM8GB8GBStorage128GB, 256GB128GB, 256GBBattery5,100mAh5,100mAhWireless chargingUp to 10WUp to 7.5WRear camera48MP wide, 13MP ultrawide, Super Res Zoom up to 8x48MP wide, 13MP ultrawide, Super Res Zoom up to 8xFront camera13MP selfie cam13MP selfie camSIMDual SIM (single nano SIM, eSIM)Dual SIM (single nano SIM, eSIM)ConnectivityWi-Fi 6E, Bluetooth v6, NFCWi-Fi 6E, Bluetooth v5.3, NFCOSLaunch with Android 16Launch with Android 15This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/google-pixel-10a-vs-pixel-9a-whats-changed-and-which-one-should-you-buy-150000786.html?src=rss",
          "feed_position": 26
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/smartphones/googles-500-pixel-10a-smartphone-arrives-on-march-5-150000489.html",
          "published_at": "Wed, 18 Feb 2026 15:00:00 +0000",
          "title": "Google's $500 Pixel 10a smartphone arrives on March 5",
          "standfirst": "Google debuted the Pixel 10a phone today. Pre-orders are open now and the smartphone will be available starting March 5. Although it's the new 2026 addition to the A series lineup, the Pixel 10a invites many comparisons with last year's Pixel 9a. For starters, the price is identical at $499. Design-wise, not much as changed. The back of the phone can lay flat, which has become a hallmark of the Pixel A collection, rather than wobbling around on a bulky camera housing. The screen is still 6.3 inches with an Actua display. The phone's insides are also the same; the 10a comes with the same Tensor G4 chip and 8GB of RAM as its predecessor, and buyers have the option to upgrade to either 128GB or 256GB of storage. The phone has an IP68 rating for dust and water resistance and its display uses Corning Gorilla Glass 7i. One of the few areas where the 10a is getting a marked upgrade is on its battery. This version claims more than 30 hours of battery life, or up to 120 under the Extra Battery Saver mode. The 10a also brings the welcome addition of proper fast charging, where a compatible charger can get the device to 50 percent battery in about 30 minutes. This addresses one of the few complaints we had about the 9a. For the photo buffs, the Pixel 10a has a 48MP main camera and a 13MP ultrawide lens; again unchanged from the specs in the 9a. AI is also present in the new model's photography suite, with the addition of the Camera Coach resource for the first time on the A series lineup. Camera Coach uses Gemini AI models to read the scene and offer tips on getting the desired shot. The 10a also has the Auto Best Take feature for getting everyone's best side in a group shot and the Add Me tool that lets you insert yourself into a photo after the fact. This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/googles-500-pixel-10a-smartphone-arrives-on-march-5-150000489.html?src=rss",
          "content": "Google debuted the Pixel 10a phone today. Pre-orders are open now and the smartphone will be available starting March 5. Although it's the new 2026 addition to the A series lineup, the Pixel 10a invites many comparisons with last year's Pixel 9a. For starters, the price is identical at $499. Design-wise, not much as changed. The back of the phone can lay flat, which has become a hallmark of the Pixel A collection, rather than wobbling around on a bulky camera housing. The screen is still 6.3 inches with an Actua display. The phone's insides are also the same; the 10a comes with the same Tensor G4 chip and 8GB of RAM as its predecessor, and buyers have the option to upgrade to either 128GB or 256GB of storage. The phone has an IP68 rating for dust and water resistance and its display uses Corning Gorilla Glass 7i. One of the few areas where the 10a is getting a marked upgrade is on its battery. This version claims more than 30 hours of battery life, or up to 120 under the Extra Battery Saver mode. The 10a also brings the welcome addition of proper fast charging, where a compatible charger can get the device to 50 percent battery in about 30 minutes. This addresses one of the few complaints we had about the 9a. For the photo buffs, the Pixel 10a has a 48MP main camera and a 13MP ultrawide lens; again unchanged from the specs in the 9a. AI is also present in the new model's photography suite, with the addition of the Camera Coach resource for the first time on the A series lineup. Camera Coach uses Gemini AI models to read the scene and offer tips on getting the desired shot. The 10a also has the Auto Best Take feature for getting everyone's best side in a group shot and the Add Me tool that lets you insert yourself into a photo after the fact. This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/googles-500-pixel-10a-smartphone-arrives-on-march-5-150000489.html?src=rss",
          "feed_position": 27
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/smartphones/pixel-10a-hands-on-google-locks-down-the-midrange-phone-game-150000513.html",
          "published_at": "Wed, 18 Feb 2026 15:00:00 +0000",
          "title": "Pixel 10a hands-on: Google locks down the midrange phone game",
          "standfirst": "Google's A-series phones have offered some of the best value among midrange handsets for years, and after checking out the new Pixel 10a, I don't see that trend stopping anytime soon.Let's start with the specs. Starting at just $499, you get a vivid 6.3-inch OLED screen with a 120Hz refresh rate and 3,000 nits of peak brightness, 8GB of RAM and either 128GB or 256GB of onboard storage. The phone also features a durable aluminum frame along with a stronger Corning Gorilla Glass 7i panel in front and a composite plastic back with a lovely matte finish. As a nod towards sustainability, Google says the P10a's chassis is made from 100 percent recycled material, while the rear panel comes in at 81 percent. And just like its predecessor, you still get an IP68 rating for dust and water resistance and the same battery capacity (5,100mAh) — except now it charges even faster, both wired (30 watts, up from 23) and wirelessly (10 watts, up from 5).While lavender is the new hero color for the Pixel 10a, berry is the hue I'd pick. Sam Rutherford for EngadgetThe one place where the Pixel 10a might come up a touch short is that unlike its more expensive siblings, it features an older Tensor G4 processor instead of the Tensor G5 chip used on the main Pixel 10 line. Google says the decision to go with an older SoC is due to budget constraints. While it might not be the first choice for gamers or power users, I've never really had an issue with the day-to-day performance of Google's recent homegrown silicon.However, even with a one-year-old chip, Google found a way to port over three flagship features to the Pixel A series for the first time. Camera Coach uses AI to help you compose and come up with more interesting shots. Meanwhile, Auto Best Take is designed to ensure that everyone in a group shot ends up with their finest expression. Finally, Satellite SOS allows you to call for help during emergencies, even when you don't have proper cell service. Satellite SOS support is one of three new features coming to the Google's A-series phones for the first time. Sam Rutherford for EngadgetAs for its cameras, the P10a looks to be using the same sensors as before, including a 48MP main camera, a 13MP ultra-wide and a 13MP selfie shooter in front. That might be a bummer for some, but considering that the Pixel 9a offered by far the best image quality of any phone in its price bracket, I'm not that bothered. Also, it's quite likely that if Google had opted for new hardware, it may have pushed the phone above $500. After seeing the positive response to the barely-there camera bump on its predecessor, Google leaned in and made the Pixel 10a’s rear camera module completely flat, and it’s my favorite thing about the phone. There's no hump or protrusions to speak of, and when combined with the rest of the phone's design, it results in a really sleek, minimalist look. Plus, after almost a decade of big and bulky camera warts on the back of phones, it's just nice seeing the Pixel 10a go the opposite direction. I really appreciate how Google double downed on feedback regarding the Pixel 9a's tiny camera bump (left) by making the Pixel 10a's camera (right) completely flat. Sam Rutherford for EngadgetOn the flipside, my biggest complaint about the P10a is that Google didn't include Pixelsnap support (aka magnetic Qi2 compatibility). It's another feature that got cut due to cost and it's a real bummer because after introducing it on last year's main Pixel 10 line, I was hoping that it would become a standard inclusion on all Google phones going forward. Thankfully, when I asked about the lack of Pixelsnap support, Google representatives were able to confirm that there will be third-party accessory makers such as Casefinite, Dbrand and Spigen that will offer cases with built-in magnetic rings, so anyone hoping to attach magnetic peripherals will still have an avenue to do so. The Pixel 10a's charging speeds have been improved to 30 watts for wired and 10 watts wirelessly. Sam Rutherford for EngadgetRegardless, for Android phone owners who are in the market for a simple, no-nonsense upgrade that covers all the basics without breaking the bank, the Pixel 10a is looking like another top contender. The Pixel 10a is available for pre-order today in lavender, berry, fog and obsidian with official sales slated for March 5. This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/pixel-10a-hands-on-google-locks-down-the-midrange-phone-game-150000513.html?src=rss",
          "content": "Google's A-series phones have offered some of the best value among midrange handsets for years, and after checking out the new Pixel 10a, I don't see that trend stopping anytime soon.Let's start with the specs. Starting at just $499, you get a vivid 6.3-inch OLED screen with a 120Hz refresh rate and 3,000 nits of peak brightness, 8GB of RAM and either 128GB or 256GB of onboard storage. The phone also features a durable aluminum frame along with a stronger Corning Gorilla Glass 7i panel in front and a composite plastic back with a lovely matte finish. As a nod towards sustainability, Google says the P10a's chassis is made from 100 percent recycled material, while the rear panel comes in at 81 percent. And just like its predecessor, you still get an IP68 rating for dust and water resistance and the same battery capacity (5,100mAh) — except now it charges even faster, both wired (30 watts, up from 23) and wirelessly (10 watts, up from 5).While lavender is the new hero color for the Pixel 10a, berry is the hue I'd pick. Sam Rutherford for EngadgetThe one place where the Pixel 10a might come up a touch short is that unlike its more expensive siblings, it features an older Tensor G4 processor instead of the Tensor G5 chip used on the main Pixel 10 line. Google says the decision to go with an older SoC is due to budget constraints. While it might not be the first choice for gamers or power users, I've never really had an issue with the day-to-day performance of Google's recent homegrown silicon.However, even with a one-year-old chip, Google found a way to port over three flagship features to the Pixel A series for the first time. Camera Coach uses AI to help you compose and come up with more interesting shots. Meanwhile, Auto Best Take is designed to ensure that everyone in a group shot ends up with their finest expression. Finally, Satellite SOS allows you to call for help during emergencies, even when you don't have proper cell service. Satellite SOS support is one of three new features coming to the Google's A-series phones for the first time. Sam Rutherford for EngadgetAs for its cameras, the P10a looks to be using the same sensors as before, including a 48MP main camera, a 13MP ultra-wide and a 13MP selfie shooter in front. That might be a bummer for some, but considering that the Pixel 9a offered by far the best image quality of any phone in its price bracket, I'm not that bothered. Also, it's quite likely that if Google had opted for new hardware, it may have pushed the phone above $500. After seeing the positive response to the barely-there camera bump on its predecessor, Google leaned in and made the Pixel 10a’s rear camera module completely flat, and it’s my favorite thing about the phone. There's no hump or protrusions to speak of, and when combined with the rest of the phone's design, it results in a really sleek, minimalist look. Plus, after almost a decade of big and bulky camera warts on the back of phones, it's just nice seeing the Pixel 10a go the opposite direction. I really appreciate how Google double downed on feedback regarding the Pixel 9a's tiny camera bump (left) by making the Pixel 10a's camera (right) completely flat. Sam Rutherford for EngadgetOn the flipside, my biggest complaint about the P10a is that Google didn't include Pixelsnap support (aka magnetic Qi2 compatibility). It's another feature that got cut due to cost and it's a real bummer because after introducing it on last year's main Pixel 10 line, I was hoping that it would become a standard inclusion on all Google phones going forward. Thankfully, when I asked about the lack of Pixelsnap support, Google representatives were able to confirm that there will be third-party accessory makers such as Casefinite, Dbrand and Spigen that will offer cases with built-in magnetic rings, so anyone hoping to attach magnetic peripherals will still have an avenue to do so. The Pixel 10a's charging speeds have been improved to 30 watts for wired and 10 watts wirelessly. Sam Rutherford for EngadgetRegardless, for Android phone owners who are in the market for a simple, no-nonsense upgrade that covers all the basics without breaking the bank, the Pixel 10a is looking like another top contender. The Pixel 10a is available for pre-order today in lavender, berry, fog and obsidian with official sales slated for March 5. This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/pixel-10a-hands-on-google-locks-down-the-midrange-phone-game-150000513.html?src=rss",
          "feed_position": 28,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/pixel-10a-colors.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/nordvpn-deal-get-two-years-of-the-complete-plan-for-70-percent-off-123000517.html",
          "published_at": "Wed, 18 Feb 2026 14:05:00 +0000",
          "title": "NordVPN deal: Get two years of the Complete plan for 70 percent off",
          "standfirst": "NordVPN is offering a significant discount on its two-year plans, with 70 percent off its Complete tier and up to 74 percent off overall. For the Complete tier, the deal brings the total cost down to $130 for 24 months. NordVPN regularly appears on Engadget’s list of the best VPN services thanks to its wide server network, strong security tools and consistent performance across devices. NordVPN’s latest promotion puts one of its most comprehensive plans at a price that undercuts many competing premium VPN subscriptions. The Complete tier includes full access to NordVPN’s core VPN service, which encrypts internet traffic and masks a user’s IP address to help protect online activity on public Wi-Fi networks and at home. Subscribers can use the service on multiple devices, including phones, tablets, laptops and smart TVs, with apps available for major operating systems. It also includes access to NordPass (more on that below), an ad blocker and 1TB of cloud storage. You’ll find similar discounts on all of NordVPN’s other plans: Basic, Plus and Prime. Beyond the basics, NordVPN offers features like threat protection to help block malicious websites and trackers, as well as specialty servers designed for added privacy or faster performance in specific scenarios. In our NordVPN review, the service was praised for its evolving feature set and overall reliability, even as the VPN market becomes increasingly competitive. Engadget regularly tracks VPN pricing trends and this offer compares favorably with other current promotions. It also appears alongside NordVPN deals featured in Engadget’s ongoing roundup of the best VPN discounts available right now, which compares offers from multiple major providers. Those looking for additional security tools may also want to note that NordVPN’s Complete plan bundles in extra services beyond the VPN itself. One of those is NordPass, the company’s password management app. NordPass is also discounted as part of a separate promotion, if you’re primarily looking for a password manager rather than a VPN. The Premium tier is currently 50 percent off, bringing the price down to $36 for two years. NordPass Premium adds features such as cross-device password syncing, secure password sharing and breach monitoring, which alerts users if stored credentials appear in known data leaks. Both offers are available for a limited time, though Nord has not specified an end date for the promotion. If you’re still unsure whether NordVPN is right for you, it offers a 30-day money-back guarantee, so you can change your mind and get a full refund. This article originally appeared on Engadget at https://www.engadget.com/deals/nordvpn-deal-get-two-years-of-the-complete-plan-for-70-percent-off-123000517.html?src=rss",
          "content": "NordVPN is offering a significant discount on its two-year plans, with 70 percent off its Complete tier and up to 74 percent off overall. For the Complete tier, the deal brings the total cost down to $130 for 24 months. NordVPN regularly appears on Engadget’s list of the best VPN services thanks to its wide server network, strong security tools and consistent performance across devices. NordVPN’s latest promotion puts one of its most comprehensive plans at a price that undercuts many competing premium VPN subscriptions. The Complete tier includes full access to NordVPN’s core VPN service, which encrypts internet traffic and masks a user’s IP address to help protect online activity on public Wi-Fi networks and at home. Subscribers can use the service on multiple devices, including phones, tablets, laptops and smart TVs, with apps available for major operating systems. It also includes access to NordPass (more on that below), an ad blocker and 1TB of cloud storage. You’ll find similar discounts on all of NordVPN’s other plans: Basic, Plus and Prime. Beyond the basics, NordVPN offers features like threat protection to help block malicious websites and trackers, as well as specialty servers designed for added privacy or faster performance in specific scenarios. In our NordVPN review, the service was praised for its evolving feature set and overall reliability, even as the VPN market becomes increasingly competitive. Engadget regularly tracks VPN pricing trends and this offer compares favorably with other current promotions. It also appears alongside NordVPN deals featured in Engadget’s ongoing roundup of the best VPN discounts available right now, which compares offers from multiple major providers. Those looking for additional security tools may also want to note that NordVPN’s Complete plan bundles in extra services beyond the VPN itself. One of those is NordPass, the company’s password management app. NordPass is also discounted as part of a separate promotion, if you’re primarily looking for a password manager rather than a VPN. The Premium tier is currently 50 percent off, bringing the price down to $36 for two years. NordPass Premium adds features such as cross-device password syncing, secure password sharing and breach monitoring, which alerts users if stored credentials appear in known data leaks. Both offers are available for a limited time, though Nord has not specified an end date for the promotion. If you’re still unsure whether NordVPN is right for you, it offers a 30-day money-back guarantee, so you can change your mind and get a full refund. This article originally appeared on Engadget at https://www.engadget.com/deals/nordvpn-deal-get-two-years-of-the-complete-plan-for-70-percent-off-123000517.html?src=rss",
          "feed_position": 30
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/deals/new-users-can-get-one-year-of-access-to-monarch-money-for-50-percent-off-120000143.html",
          "published_at": "Wed, 18 Feb 2026 13:25:17 +0000",
          "title": "New users can get one year of access to Monarch Money for 50 percent off",
          "standfirst": "A good budgeting app can make it much easier to see where your money is actually going, and one of our top picks is 50 percent off right now. Monarch Money is running a deal for new users that cuts the price of its annual plan in half. With the code MONARCHVIP, you’ll pay $50 for one year of access instead of the usual $100. We’ve recommended Monarch before for its deep customization options and robust financial planning tools. It supports unlimited account connections, investment tracking and shared budgets, making it a solid option if you want a detailed look at your finances or plan alongside a partner. It also features prominently in our roundup of the best budgeting apps, where it stood out for its depth and flexibility. Monarch Money is the kind of budgeting app that can feel a little overwhelming at first, especially when you’re setting up categories, rules and recurring transactions. There’s a bit of a learning curve, and some of the finer details are easier to manage on the web than in the mobile app. But once you’re past that initial setup, it starts to make a lot more sense and becomes a powerful tool for keeping tabs on your finances. Where Monarch Money really shines is in the level of detail it offers. It’s built for people who want a clear, structured view of their money, not just a running list of transactions. In the budgeting section, you can see budgets versus actual spending by category, along with forecasts by month or by year. Recurring expenses can also be defined using more than just merchant names, which helps keep things accurate with less manual cleanup. Beyond day-to-day budgeting, Monarch does a good job of showing the bigger picture. It includes visual reports and charts that make it easier to spot trends over time, plus tools for tracking net worth, investments and financial goals. Monarch can even factor in non-cash assets like your home or vehicle, pulling in estimates automatically so they appear alongside your accounts. All of that depth won’t be for everyone, but if you’re willing to spend a little time getting set up, Monarch Money offers a lot of control and insight. With the current deal bringing the price down to $50 for a full year, it’s a solid opportunity to try one of our favorite budgeting apps at a discount of 50 percent off and see if it fits how you like to manage your money. This article originally appeared on Engadget at https://www.engadget.com/deals/new-users-can-get-one-year-of-access-to-monarch-money-for-50-percent-off-120000143.html?src=rss",
          "content": "A good budgeting app can make it much easier to see where your money is actually going, and one of our top picks is 50 percent off right now. Monarch Money is running a deal for new users that cuts the price of its annual plan in half. With the code MONARCHVIP, you’ll pay $50 for one year of access instead of the usual $100. We’ve recommended Monarch before for its deep customization options and robust financial planning tools. It supports unlimited account connections, investment tracking and shared budgets, making it a solid option if you want a detailed look at your finances or plan alongside a partner. It also features prominently in our roundup of the best budgeting apps, where it stood out for its depth and flexibility. Monarch Money is the kind of budgeting app that can feel a little overwhelming at first, especially when you’re setting up categories, rules and recurring transactions. There’s a bit of a learning curve, and some of the finer details are easier to manage on the web than in the mobile app. But once you’re past that initial setup, it starts to make a lot more sense and becomes a powerful tool for keeping tabs on your finances. Where Monarch Money really shines is in the level of detail it offers. It’s built for people who want a clear, structured view of their money, not just a running list of transactions. In the budgeting section, you can see budgets versus actual spending by category, along with forecasts by month or by year. Recurring expenses can also be defined using more than just merchant names, which helps keep things accurate with less manual cleanup. Beyond day-to-day budgeting, Monarch does a good job of showing the bigger picture. It includes visual reports and charts that make it easier to spot trends over time, plus tools for tracking net worth, investments and financial goals. Monarch can even factor in non-cash assets like your home or vehicle, pulling in estimates automatically so they appear alongside your accounts. All of that depth won’t be for everyone, but if you’re willing to spend a little time getting set up, Monarch Money offers a lot of control and insight. With the current deal bringing the price down to $50 for a full year, it’s a solid opportunity to try one of our favorite budgeting apps at a discount of 50 percent off and see if it fits how you like to manage your money. This article originally appeared on Engadget at https://www.engadget.com/deals/new-users-can-get-one-year-of-access-to-monarch-money-for-50-percent-off-120000143.html?src=rss",
          "feed_position": 31
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/audio/headphones/best-wireless-workout-headphones-191517835.html",
          "published_at": "Wed, 18 Feb 2026 10:01:27 +0000",
          "title": "The best wireless workout headphones for 2026",
          "standfirst": "Whether you’re lifting, running or squeezing in a quick session between errands, the last thing you want is a cable getting in the way or earbuds that won’t stay put. The best wireless headphones make it easier to focus on your workout, but not every pair is built to handle sweat, motion and long sessions.Fitness-focused headphones put different demands on design and performance. Secure fit, water resistance and dependable battery life matter just as much as sound quality, especially if you plan to use them outside the gym as well. Some are tuned for awareness during outdoor runs, while others aim to block distractions during intense training.We’ve tested a wide range of wireless headphones and wireless earbuds that are suited for exercise, narrowing the list down to options that hold up during workouts and still work well for everyday listening. Below, you’ll find our top picks, along with guidance to help you choose the right pair for how you train. Best workout headphones for 2026 Others wireless workout headphones we tested Apple AirPods Pro 3 When it comes to running and working out, the edge that the AirPods Pro 3 have over the Pro 2, or even the top picks on our list, is built-in heart rate monitoring. That means you could go out with just your Pro 3 earbuds and your iPhone and still get heart rate information for your entire training session. But otherwise, the Pro 3 buds are just as capable as the Pro 2 when it comes to exercise. Some may prefer the soft-touch finish on our top picks to the AirPods' slick texture. Beats Powerbeats Pro 2 The Powerbeats Pro 2 are a good alternative to the Beats Fit Pro if you’re a stickler for a hook design. However, they cost $50 more than the Powerbeats Fit, and the main added advantage here is built-in heart rate sensors. Anker Soundcore AeroFit Pro The Soundcore AeroFit Pro is Anker’s version of the Shokz OpenFit, but I found the fit to be less secure and not as comfortable. The actual earbuds on the AeroFit Pro are noticeably bulkier than those on the OpenFit and that caused them to shift and move much more during exercise. They never fell off of my ears completely, but I spent more time adjusting them than I did enjoying them. JBL Endurance Peak 3 The most noteworthy thing about the Endurance Peak 3 is that they have the same IP68 rating as the Jabra Elite 8 Active, except they only cost $100. But, while you get the same protection here, you’ll have to sacrifice in other areas. The Endurance Peak 3 didn’t blow me away when it came to sound quality or comfort (its hook is more rigid than those on my favorite similarly designed buds) and their charging case is massive compared to most competitors. What to look for in workout headphones Design Before diving in, it’s worth mentioning that this guide focuses on wireless earbuds. While you could wear over-ear or on-ear headphones during a workout, most of the best headphones available now do not have the same level of durability. Water and dust resistance, particularly the former, is important for any audio gear you plan on sweating with or taking outdoors, and that’s more prevalent in the wireless earbuds world. Most earbuds have one of three designs: in-ear, in-ear with hook or open-ear. The first two are the most popular. In-ears are arguably the most common, while those with hooks promise better security and fit since they have an appendage that curls around the top of your ear. Open-ear designs don’t stick into your ear canal, but rather sit just outside of it. This makes it easier to hear the world around you while also listening to audio, and could be more comfortable for those who don’t like the intrusiveness of in-ear buds. Water resistance and dust protection Even if a pair of headphones for working out aren’t marketed specifically as exercise headphones, a sturdy, water-resistant design will, by default, make them suitable for exercise. To avoid repetition, here’s a quick primer on durability, or ingression protection (IP) ratings. The first digit you’ll see after the “IP” refers to protection from dust and other potential intrusions, measured on a scale from 1 to 6. The second refers to water resistance or even waterproofing, in the best cases. The ratings for water resistance are ranked on a scale of 1 to 9; higher numbers mean more protection, while the letter “X” means the device is not rated for protection in that regard. All of the earbuds we tested for this guide have at least an IPX4 rating, which means there’s no dust protection, but the buds can withstand splashes from any direction and are sweat resistant, but probably shouldn't be submerged. For a detailed breakdown of all the possible permutations, check out this guide published by a supplier called The Enclosure Company. Active noise cancellation and transparency mode Active noise cancellation (ANC) is becoming standard on wireless earbuds, at least those above a certain price point. If you’re looking for a pair of buds that can be your workout companion and serve you outside of the gym, too, noise cancelation is a good feature to have. It makes the buds more versatile, allowing you to block out the dull roar of your home or office so you can focus, or give you some solitude during a busy commute. But an earbud’s ability to block out the world goes hand-in-hand with its ability to open things back up should you need it. Many ANC earbuds also support some sort of “transparency mode,” or various levels of noise reduction. This is important for running headphones because exercising outdoors, alongside busy streets, can be dangerous. You probably don’t want to be totally oblivious to what’s going on around you when you’re running outside; adjusting noise cancelation levels to increase your awareness will help with that. Stronger noise cancelation might be more appealing to those doing more indoor training if they want to block out the dull roar of a gym or the guy exaggeratingly lifting weights next to you. Battery life All of the Bluetooth earbuds we tested have a battery life of six to eight hours. In general, that’s what you can expect from this space, with a few outliers that can get up to 15 hours of life on a charge. Even the low end of the spectrum should be good enough for most athletes and gym junkies, but it’ll be handy to keep the buds’ charging case on you if you think you’ll get close to using up all their juice during a single session. You’ll get an average of 20 to 28 extra hours of battery out of most charging cases and all of the earbuds we tested had holders that provided at least an extra 15 hours. This will dictate how often you actually have to charge the device — as in physically connect the case with earbuds inside to a charging cable, or set it on a wireless charger to power up. How we test workout headphones In testing wireless workout headphones, I wear them during every bit of exercise I do — be it a casual walk around the block, a brisk morning run or a challenging weight-lifting session. I’m looking for comfort arguably most of all, because you should never be fussing with your earbuds when you should be focusing on working out. In the same vein, I’m cognizant of if they get loose during fast movements or slippery when I’m sweating. I also use the earbuds when not exercising to take calls and listen to music throughout the day. Many people will want just one pair of earbuds that they can use while exercising and just doing everyday things, so I evaluate each pair on their ability to be comfortable and provide a good listening experience in multiple different activities. While I am also evaluating sound quality, I’m admittedly not an audio expert. My colleague Billy Steele holds that title at Engadget, and you’ll find much more detailed information about audio quality for some of our top picks in his reviews and buying guides. With these headphones for working out, however, I will make note of related issues if they stood out (i.e. if a pair of earbuds had noticeably strong bass out of the box, weak highs, etc). Most of the wireless workout headphones we tested work with companion apps that have adjustable EQ settings, so you’ll be able to tweak sound profiles to your liking in most cases.This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/best-wireless-workout-headphones-191517835.html?src=rss",
          "content": "Whether you’re lifting, running or squeezing in a quick session between errands, the last thing you want is a cable getting in the way or earbuds that won’t stay put. The best wireless headphones make it easier to focus on your workout, but not every pair is built to handle sweat, motion and long sessions.Fitness-focused headphones put different demands on design and performance. Secure fit, water resistance and dependable battery life matter just as much as sound quality, especially if you plan to use them outside the gym as well. Some are tuned for awareness during outdoor runs, while others aim to block distractions during intense training.We’ve tested a wide range of wireless headphones and wireless earbuds that are suited for exercise, narrowing the list down to options that hold up during workouts and still work well for everyday listening. Below, you’ll find our top picks, along with guidance to help you choose the right pair for how you train. Best workout headphones for 2026 Others wireless workout headphones we tested Apple AirPods Pro 3 When it comes to running and working out, the edge that the AirPods Pro 3 have over the Pro 2, or even the top picks on our list, is built-in heart rate monitoring. That means you could go out with just your Pro 3 earbuds and your iPhone and still get heart rate information for your entire training session. But otherwise, the Pro 3 buds are just as capable as the Pro 2 when it comes to exercise. Some may prefer the soft-touch finish on our top picks to the AirPods' slick texture. Beats Powerbeats Pro 2 The Powerbeats Pro 2 are a good alternative to the Beats Fit Pro if you’re a stickler for a hook design. However, they cost $50 more than the Powerbeats Fit, and the main added advantage here is built-in heart rate sensors. Anker Soundcore AeroFit Pro The Soundcore AeroFit Pro is Anker’s version of the Shokz OpenFit, but I found the fit to be less secure and not as comfortable. The actual earbuds on the AeroFit Pro are noticeably bulkier than those on the OpenFit and that caused them to shift and move much more during exercise. They never fell off of my ears completely, but I spent more time adjusting them than I did enjoying them. JBL Endurance Peak 3 The most noteworthy thing about the Endurance Peak 3 is that they have the same IP68 rating as the Jabra Elite 8 Active, except they only cost $100. But, while you get the same protection here, you’ll have to sacrifice in other areas. The Endurance Peak 3 didn’t blow me away when it came to sound quality or comfort (its hook is more rigid than those on my favorite similarly designed buds) and their charging case is massive compared to most competitors. What to look for in workout headphones Design Before diving in, it’s worth mentioning that this guide focuses on wireless earbuds. While you could wear over-ear or on-ear headphones during a workout, most of the best headphones available now do not have the same level of durability. Water and dust resistance, particularly the former, is important for any audio gear you plan on sweating with or taking outdoors, and that’s more prevalent in the wireless earbuds world. Most earbuds have one of three designs: in-ear, in-ear with hook or open-ear. The first two are the most popular. In-ears are arguably the most common, while those with hooks promise better security and fit since they have an appendage that curls around the top of your ear. Open-ear designs don’t stick into your ear canal, but rather sit just outside of it. This makes it easier to hear the world around you while also listening to audio, and could be more comfortable for those who don’t like the intrusiveness of in-ear buds. Water resistance and dust protection Even if a pair of headphones for working out aren’t marketed specifically as exercise headphones, a sturdy, water-resistant design will, by default, make them suitable for exercise. To avoid repetition, here’s a quick primer on durability, or ingression protection (IP) ratings. The first digit you’ll see after the “IP” refers to protection from dust and other potential intrusions, measured on a scale from 1 to 6. The second refers to water resistance or even waterproofing, in the best cases. The ratings for water resistance are ranked on a scale of 1 to 9; higher numbers mean more protection, while the letter “X” means the device is not rated for protection in that regard. All of the earbuds we tested for this guide have at least an IPX4 rating, which means there’s no dust protection, but the buds can withstand splashes from any direction and are sweat resistant, but probably shouldn't be submerged. For a detailed breakdown of all the possible permutations, check out this guide published by a supplier called The Enclosure Company. Active noise cancellation and transparency mode Active noise cancellation (ANC) is becoming standard on wireless earbuds, at least those above a certain price point. If you’re looking for a pair of buds that can be your workout companion and serve you outside of the gym, too, noise cancelation is a good feature to have. It makes the buds more versatile, allowing you to block out the dull roar of your home or office so you can focus, or give you some solitude during a busy commute. But an earbud’s ability to block out the world goes hand-in-hand with its ability to open things back up should you need it. Many ANC earbuds also support some sort of “transparency mode,” or various levels of noise reduction. This is important for running headphones because exercising outdoors, alongside busy streets, can be dangerous. You probably don’t want to be totally oblivious to what’s going on around you when you’re running outside; adjusting noise cancelation levels to increase your awareness will help with that. Stronger noise cancelation might be more appealing to those doing more indoor training if they want to block out the dull roar of a gym or the guy exaggeratingly lifting weights next to you. Battery life All of the Bluetooth earbuds we tested have a battery life of six to eight hours. In general, that’s what you can expect from this space, with a few outliers that can get up to 15 hours of life on a charge. Even the low end of the spectrum should be good enough for most athletes and gym junkies, but it’ll be handy to keep the buds’ charging case on you if you think you’ll get close to using up all their juice during a single session. You’ll get an average of 20 to 28 extra hours of battery out of most charging cases and all of the earbuds we tested had holders that provided at least an extra 15 hours. This will dictate how often you actually have to charge the device — as in physically connect the case with earbuds inside to a charging cable, or set it on a wireless charger to power up. How we test workout headphones In testing wireless workout headphones, I wear them during every bit of exercise I do — be it a casual walk around the block, a brisk morning run or a challenging weight-lifting session. I’m looking for comfort arguably most of all, because you should never be fussing with your earbuds when you should be focusing on working out. In the same vein, I’m cognizant of if they get loose during fast movements or slippery when I’m sweating. I also use the earbuds when not exercising to take calls and listen to music throughout the day. Many people will want just one pair of earbuds that they can use while exercising and just doing everyday things, so I evaluate each pair on their ability to be comfortable and provide a good listening experience in multiple different activities. While I am also evaluating sound quality, I’m admittedly not an audio expert. My colleague Billy Steele holds that title at Engadget, and you’ll find much more detailed information about audio quality for some of our top picks in his reviews and buying guides. With these headphones for working out, however, I will make note of related issues if they stood out (i.e. if a pair of earbuds had noticeably strong bass out of the box, weak highs, etc). Most of the wireless workout headphones we tested work with companion apps that have adjustable EQ settings, so you’ll be able to tweak sound profiles to your liking in most cases.This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/best-wireless-workout-headphones-191517835.html?src=rss",
          "feed_position": 35
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/cameras/best-drone-120046775.html",
          "published_at": "Wed, 18 Feb 2026 08:01:26 +0000",
          "title": "The best drone for 2026",
          "standfirst": "Drones are no longer just niche toys for enthusiasts. Today’s models are compact, increasingly affordable and capable of capturing sharp aerial photos and video with minimal effort. Whether you’re curious about flying for the first time or looking to upgrade to a more advanced camera drone, the options available in 2026 are broader and more approachable than ever.Entry-level drones now offer features like GPS-assisted flight, return-to-home safety systems and automated shooting modes that take much of the stress out of learning to fly. Step up to more advanced models and you’ll find foldable designs that travel easily, longer flight times and stabilized 4K video that holds up well beyond social media clips.We’ve tested a range of drones to identify the best options across different skill levels and budgets. Whether your priority is learning the basics, capturing polished aerial footage or packing light for travel, these picks highlight the drones that offer the best balance of performance, reliability and ease of use. Best drones for 2026 What to look for in a drone Camera features For this guide, we're looking only at drones that are basically flying cameras, so you want the best video and photo features possible. Bigger devices like DJI’s Mavic 3 Pro or Air 3S carry relatively large sensors, offering superior camera quality for nighttime cityscapes or other low-light scenes. Smaller models like the Mini 4 Pro and HoverAir X1 Max use smaller camera sensors, so they aren’t as good in dim light. Field of view and minimum aperture are also important, with most drones typically having a wide-angle focal length, though a few others like the HoverAir X1 Max carry an ultrawide lens. Some models have multiple cameras including a wide and a zoom. As for aperture, lower numbers are better and allow for shooting in dim light. Most DJI models are solid in this regard, while the HoverAir models don’t perform as well. Video resolution and slow-mo are also essential camera capabilities. Most drones these days can shoot at 4K with a frame rate of at least 30 fps, though some offer 6K or even 8K at up to 30 fps. Higher-end models can shoot 4K at up to 120 fps, allowing you to slow down the action dramatically to create a cinematic look. Other noteworthy features include log or HDR video that supports higher dynamic range, particularly in bright and sunny conditions. Finally, the camera’s gimbal and stabilization are important factors to keep your footage looking as smooth as possible. Some drones have gimbals that can rotate the camera 90 degrees to give social media creators the maximum resolution for vertical formats. Drone features: Speed, range, safety, battery life and obstacle detection By and large, there are two types of camera drones to consider. The first are standard drones (usually with open propellers but not always) designed to fly outside and take scenic shots. Often there’s nothing to stop the props from striking skin or objects, so they can’t really be used indoors or around people. Some models like the DJI Neo and Flip have prop guards that better protect bystanders and property, as well as the drone itself. Then there's first-person-view (FPV) camera drones, which often have propeller guards and are meant to be used both indoors or outside to capture exciting footage. Standard models don’t need to go particularly fast as they’re mainly used to shoot fun videos for social media, but FPV drones need to move at high speeds to create excitement. Because of that speed, they’re also better in breezy conditions thanks to stronger wind resistance, and they can fight gusts and return home more quickly. Acrobatic abilities (often promoted by the manufacturer in ads or packaging) are also important for FPV drones, as it allows the user to perform tricks and zip around obstacles. Battery life is another important factor. The best drones boast a battery endurance of up to 45 minutes, while FPV drones like the Avata 2 can only fly for about half that time as they tend to be heavier and carry smaller batteries to reduce weight. As a general rule, a single battery isn’t enough for any serious shooting so you’d do well to buy your drone in a kit with a few batteries and a charger. As for range, DJI tends to dominate in this area, with its latest models able to maintain a video signal at a distance up to 20km (12.4 miles). HoverAir’s models are weaker with the top-end X1 Max model limited to just 1km (0.6 miles) when using the optional beacon system. DJI also offers multiple ways to control its drones including headsets, joystick-type controllers, motion detection controllers and smartphones. The best drones have sensors to detect obstacles in all directions. Others are limited to only avoiding obstructions coming at them from the front and some only rely on the main camera to prevent crashes. Finally, if you want to have your drone follow you around automatically, you’ll need it to be able to track you around when you’re vlogging, riding a bike or skiing, while also avoiding obstacles. Smooth takeoff and return-to-home features are especially valuable here for both beginners and experienced drone pilots as well. Best drone FAQs What are the rules for owning a drone? Anyone can buy any drone, but once purchased, all drones between 250g and 25 kg must be registered with the FAA and marked with the FAA registration number. Recreational pilots with drones over 249g must pass the recreational UAS safety \"TRUST\" exam and carry proof of TRUST completion when flying a drone. Commercial pilots must obtain a Remote Pilot Certificate from the FAA. You must be aware of and avoid any areas with airspace restrictions, particularly around airports. Are drones safe to fly in the city? In general, it is not legal to fly a drone within city limits over populations, as a crash from a high altitude could injure or kill someone. However, they can be flown over adjacent, non-populated areas in many cases. Here is a guide to where: https://uavcoach.com/where-to-fly-drone/ What is the average flight time of a drone? Most drones can fly for around 20-30 minutes, though some advanced models like DJI's Mavic 4 can fly up to 40 minutes or more.This article originally appeared on Engadget at https://www.engadget.com/cameras/best-drone-120046775.html?src=rss",
          "content": "Drones are no longer just niche toys for enthusiasts. Today’s models are compact, increasingly affordable and capable of capturing sharp aerial photos and video with minimal effort. Whether you’re curious about flying for the first time or looking to upgrade to a more advanced camera drone, the options available in 2026 are broader and more approachable than ever.Entry-level drones now offer features like GPS-assisted flight, return-to-home safety systems and automated shooting modes that take much of the stress out of learning to fly. Step up to more advanced models and you’ll find foldable designs that travel easily, longer flight times and stabilized 4K video that holds up well beyond social media clips.We’ve tested a range of drones to identify the best options across different skill levels and budgets. Whether your priority is learning the basics, capturing polished aerial footage or packing light for travel, these picks highlight the drones that offer the best balance of performance, reliability and ease of use. Best drones for 2026 What to look for in a drone Camera features For this guide, we're looking only at drones that are basically flying cameras, so you want the best video and photo features possible. Bigger devices like DJI’s Mavic 3 Pro or Air 3S carry relatively large sensors, offering superior camera quality for nighttime cityscapes or other low-light scenes. Smaller models like the Mini 4 Pro and HoverAir X1 Max use smaller camera sensors, so they aren’t as good in dim light. Field of view and minimum aperture are also important, with most drones typically having a wide-angle focal length, though a few others like the HoverAir X1 Max carry an ultrawide lens. Some models have multiple cameras including a wide and a zoom. As for aperture, lower numbers are better and allow for shooting in dim light. Most DJI models are solid in this regard, while the HoverAir models don’t perform as well. Video resolution and slow-mo are also essential camera capabilities. Most drones these days can shoot at 4K with a frame rate of at least 30 fps, though some offer 6K or even 8K at up to 30 fps. Higher-end models can shoot 4K at up to 120 fps, allowing you to slow down the action dramatically to create a cinematic look. Other noteworthy features include log or HDR video that supports higher dynamic range, particularly in bright and sunny conditions. Finally, the camera’s gimbal and stabilization are important factors to keep your footage looking as smooth as possible. Some drones have gimbals that can rotate the camera 90 degrees to give social media creators the maximum resolution for vertical formats. Drone features: Speed, range, safety, battery life and obstacle detection By and large, there are two types of camera drones to consider. The first are standard drones (usually with open propellers but not always) designed to fly outside and take scenic shots. Often there’s nothing to stop the props from striking skin or objects, so they can’t really be used indoors or around people. Some models like the DJI Neo and Flip have prop guards that better protect bystanders and property, as well as the drone itself. Then there's first-person-view (FPV) camera drones, which often have propeller guards and are meant to be used both indoors or outside to capture exciting footage. Standard models don’t need to go particularly fast as they’re mainly used to shoot fun videos for social media, but FPV drones need to move at high speeds to create excitement. Because of that speed, they’re also better in breezy conditions thanks to stronger wind resistance, and they can fight gusts and return home more quickly. Acrobatic abilities (often promoted by the manufacturer in ads or packaging) are also important for FPV drones, as it allows the user to perform tricks and zip around obstacles. Battery life is another important factor. The best drones boast a battery endurance of up to 45 minutes, while FPV drones like the Avata 2 can only fly for about half that time as they tend to be heavier and carry smaller batteries to reduce weight. As a general rule, a single battery isn’t enough for any serious shooting so you’d do well to buy your drone in a kit with a few batteries and a charger. As for range, DJI tends to dominate in this area, with its latest models able to maintain a video signal at a distance up to 20km (12.4 miles). HoverAir’s models are weaker with the top-end X1 Max model limited to just 1km (0.6 miles) when using the optional beacon system. DJI also offers multiple ways to control its drones including headsets, joystick-type controllers, motion detection controllers and smartphones. The best drones have sensors to detect obstacles in all directions. Others are limited to only avoiding obstructions coming at them from the front and some only rely on the main camera to prevent crashes. Finally, if you want to have your drone follow you around automatically, you’ll need it to be able to track you around when you’re vlogging, riding a bike or skiing, while also avoiding obstacles. Smooth takeoff and return-to-home features are especially valuable here for both beginners and experienced drone pilots as well. Best drone FAQs What are the rules for owning a drone? Anyone can buy any drone, but once purchased, all drones between 250g and 25 kg must be registered with the FAA and marked with the FAA registration number. Recreational pilots with drones over 249g must pass the recreational UAS safety \"TRUST\" exam and carry proof of TRUST completion when flying a drone. Commercial pilots must obtain a Remote Pilot Certificate from the FAA. You must be aware of and avoid any areas with airspace restrictions, particularly around airports. Are drones safe to fly in the city? In general, it is not legal to fly a drone within city limits over populations, as a crash from a high altitude could injure or kill someone. However, they can be flown over adjacent, non-populated areas in many cases. Here is a guide to where: https://uavcoach.com/where-to-fly-drone/ What is the average flight time of a drone? Most drones can fly for around 20-30 minutes, though some advanced models like DJI's Mavic 4 can fly up to 40 minutes or more.This article originally appeared on Engadget at https://www.engadget.com/cameras/best-drone-120046775.html?src=rss",
          "feed_position": 36
        }
      ],
      "featured_image": "https://images.ctfassets.net/jdtwqhzvc2n1/3QN1ZUexlvrsauz6g2NrrK/42bc7a43c49aab36315e98993de78af1/ClKBtgX7u8IrQZI9CACCZ.jpg?w=300&q=30",
      "popularity_score": 2019.0427825
    },
    {
      "id": "cluster_14",
      "coverage": 2,
      "updated_at": "Thu, 19 Feb 2026 16:56:10 -0500",
      "title": "Sony shuts down Bluepoint Games, the PlayStation subsidiary behind remakes of older games like Demon's Souls and Uncharted; ~70 employees will lose their jobs (Jason Schreier/Bloomberg)",
      "neutral_headline": "Sony is closing the studio behind the Demon&#8217;s Souls and...",
      "bullet_summary": [
        "Reported by TechMeme, The Verge"
      ],
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/260219/p41#a260219p41",
          "published_at": "Thu, 19 Feb 2026 16:56:10 -0500",
          "title": "Sony shuts down Bluepoint Games, the PlayStation subsidiary behind remakes of older games like Demon's Souls and Uncharted; ~70 employees will lose their jobs (Jason Schreier/Bloomberg)",
          "standfirst": "Jason Schreier / Bloomberg: Sony shuts down Bluepoint Games, the PlayStation subsidiary behind remakes of older games like Demon's Souls and Uncharted; ~70 employees will lose their jobs &mdash; The PlayStation subsidiary previously made remakes of games like 'Demon's Souls' &mdash; Sony Group Corp. is shutting down Bluepoint Games &hellip;",
          "content": "Jason Schreier / Bloomberg: Sony shuts down Bluepoint Games, the PlayStation subsidiary behind remakes of older games like Demon's Souls and Uncharted; ~70 employees will lose their jobs &mdash; The PlayStation subsidiary previously made remakes of games like 'Demon's Souls' &mdash; Sony Group Corp. is shutting down Bluepoint Games &hellip;",
          "feed_position": 2,
          "image_url": "http://www.techmeme.com/260219/i41.jpg"
        },
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/games/881578/sony-close-bluepoint-games-studio-remaster-remake-demons-souls-shadow-colossus-god-of-war",
          "published_at": "2026-02-19T14:02:17-05:00",
          "title": "Sony is closing the studio behind the Demon&#8217;s Souls and Shadow of the Colossus remakes",
          "standfirst": "Sony is shutting down Bluepoint Games, the PlayStation studio behind well-received remakes of games like Shadow of the Colossus and Demon's Souls, according to Bloomberg. The change was made \"following a recent business review,\" a spokesperson told the publication. About 70 staffers will be cut, and the studio will shut down in March. \"Bluepoint Games [&#8230;]",
          "content": "Sony is shutting down Bluepoint Games, the PlayStation studio behind well-received remakes of games like Shadow of the Colossus and Demon's Souls, according to Bloomberg. The change was made \"following a recent business review,\" a spokesperson told the publication. About 70 staffers will be cut, and the studio will shut down in March. \"Bluepoint Games is an incredibly talented team and their technical expertise has delivered exceptional experiences for the PlayStation community,\" a spokesperson told Bloomberg. \"We thank them for their passion, creativity and craftmanship.\" Sony didn't immediately reply to a request for comment. Sony acquir … Read the full story at The Verge.",
          "feed_position": 6
        }
      ],
      "featured_image": "http://www.techmeme.com/260219/i41.jpg",
      "popularity_score": 2018.5455602777777
    },
    {
      "id": "cluster_19",
      "coverage": 2,
      "updated_at": "Thu, 19 Feb 2026 16:15:01 -0500",
      "title": "Docs: DHS has signed a five-year, $1B blanket purchase agreement with Palantir, allowing agencies like ICE to skip the competitive bidding process (Makena Kelly/Wired)",
      "neutral_headline": "DHS Opens a Billion-Dollar Tab With Palantir",
      "bullet_summary": [
        "Reported by TechMeme, Wired Tech"
      ],
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/260219/p39#a260219p39",
          "published_at": "Thu, 19 Feb 2026 16:15:01 -0500",
          "title": "Docs: DHS has signed a five-year, $1B blanket purchase agreement with Palantir, allowing agencies like ICE to skip the competitive bidding process (Makena Kelly/Wired)",
          "standfirst": "Makena Kelly / Wired: Docs: DHS has signed a five-year, $1B blanket purchase agreement with Palantir, allowing agencies like ICE to skip the competitive bidding process &mdash; &ldquo;If you are interested in helping shape and deliver the next chapter of Palantir's work across DHS, please reach out,&rdquo; a Palantir executive wrote &hellip;",
          "content": "Makena Kelly / Wired: Docs: DHS has signed a five-year, $1B blanket purchase agreement with Palantir, allowing agencies like ICE to skip the competitive bidding process &mdash; &ldquo;If you are interested in helping shape and deliver the next chapter of Palantir's work across DHS, please reach out,&rdquo; a Palantir executive wrote &hellip;",
          "feed_position": 4,
          "image_url": "http://www.techmeme.com/260219/i39.jpg"
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/department-homeland-security-ice-billion-dollar-agreement-palantir/",
          "published_at": "Thu, 19 Feb 2026 17:00:07 +0000",
          "title": "DHS Opens a Billion-Dollar Tab With Palantir",
          "standfirst": "“If you are interested in helping shape and deliver the next chapter of Palantir’s work across DHS, please reach out,” a Palantir executive wrote to employees about the massive purchasing agreement.",
          "content": "“If you are interested in helping shape and deliver the next chapter of Palantir’s work across DHS, please reach out,” a Palantir executive wrote to employees about the massive purchasing agreement.",
          "feed_position": 7,
          "image_url": "https://media.wired.com/photos/699724a480ce473f0f3a40c2/master/pass/biz-palantir-dhs-2228106302.jpg"
        }
      ],
      "featured_image": "http://www.techmeme.com/260219/i39.jpg",
      "popularity_score": 2017.8597269444444
    },
    {
      "id": "cluster_29",
      "coverage": 2,
      "updated_at": "Thu, 19 Feb 2026 15:15:01 -0500",
      "title": "Workers describe a deteriorating culture at Jack Dorsey's Block as morale plunges amid rolling layoffs and a push to use AI tools to improve productivity (Reece Rogers/Wired)",
      "neutral_headline": "Inside the Rolling Layoffs at Jack Dorsey’s Block",
      "bullet_summary": [
        "Reported by TechMeme, Wired Tech"
      ],
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/260219/p37#a260219p37",
          "published_at": "Thu, 19 Feb 2026 15:15:01 -0500",
          "title": "Workers describe a deteriorating culture at Jack Dorsey's Block as morale plunges amid rolling layoffs and a push to use AI tools to improve productivity (Reece Rogers/Wired)",
          "standfirst": "Reece Rogers / Wired: Workers describe a deteriorating culture at Jack Dorsey's Block as morale plunges amid rolling layoffs and a push to use AI tools to improve productivity &mdash; Workers describe a deteriorating culture at Block, the company behind Square and Cash App, where layoffs continue and employees are expected to use AI tools daily.",
          "content": "Reece Rogers / Wired: Workers describe a deteriorating culture at Jack Dorsey's Block as morale plunges amid rolling layoffs and a push to use AI tools to improve productivity &mdash; Workers describe a deteriorating culture at Block, the company behind Square and Cash App, where layoffs continue and employees are expected to use AI tools daily.",
          "feed_position": 6,
          "image_url": "http://www.techmeme.com/260219/i37.jpg"
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/inside-rolling-layoffs-jack-dorsey-block/",
          "published_at": "Thu, 19 Feb 2026 19:53:11 +0000",
          "title": "Inside the Rolling Layoffs at Jack Dorsey’s Block",
          "standfirst": "Workers describe a deteriorating culture at Block, the company behind Square and Cash App, where layoffs continue and employees are expected to use AI tools daily.",
          "content": "Workers describe a deteriorating culture at Block, the company behind Square and Cash App, where layoffs continue and employees are expected to use AI tools daily.",
          "feed_position": 3,
          "image_url": "https://media.wired.com/photos/698d1d449536f5a1f6e94f7b/master/pass/Block-Workers-Call-Performance-Driven-Layoffs-a-Smokescreen-Business-1470988103.jpg"
        }
      ],
      "featured_image": "http://www.techmeme.com/260219/i37.jpg",
      "popularity_score": 2016.8597269444444
    },
    {
      "id": "cluster_47",
      "coverage": 2,
      "updated_at": "Thu, 19 Feb 2026 13:50:02 -0500",
      "title": "Reddit is testing an AI search feature that takes community recommendations and shows matching products from its advertisers in the results (Aisha Malik/TechCrunch)",
      "neutral_headline": "Reddit is testing a new AI search feature for shopping",
      "bullet_summary": [
        "Reported by TechMeme, TechCrunch"
      ],
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/260219/p34#a260219p34",
          "published_at": "Thu, 19 Feb 2026 13:50:02 -0500",
          "title": "Reddit is testing an AI search feature that takes community recommendations and shows matching products from its advertisers in the results (Aisha Malik/TechCrunch)",
          "standfirst": "Aisha Malik / TechCrunch: Reddit is testing an AI search feature that takes community recommendations and shows matching products from its advertisers in the results &mdash; Reddit announced on Thursday that it's testing a new AI search tool that takes community recommendations and matches them with products &hellip;",
          "content": "Aisha Malik / TechCrunch: Reddit is testing an AI search feature that takes community recommendations and shows matching products from its advertisers in the results &mdash; Reddit announced on Thursday that it's testing a new AI search tool that takes community recommendations and matches them with products &hellip;",
          "feed_position": 9,
          "image_url": "http://www.techmeme.com/260219/i34.jpg"
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2026/02/19/reddit-is-testing-a-new-ai-search-feature-for-shopping/",
          "published_at": "Thu, 19 Feb 2026 18:22:51 +0000",
          "title": "Reddit is testing a new AI search feature for shopping",
          "standfirst": "A small group of users in the U.S. will start to see search results that include interactive product carousels with pricing, images, and direct where-to-buy links.",
          "content": "A small group of users in the U.S. will start to see search results that include interactive product carousels with pricing, images, and direct where-to-buy links.",
          "feed_position": 12
        }
      ],
      "featured_image": "http://www.techmeme.com/260219/i34.jpg",
      "popularity_score": 2015.4433380555556
    },
    {
      "id": "cluster_64",
      "coverage": 2,
      "updated_at": "Thu, 19 Feb 2026 11:55:20 -0500",
      "title": "Inside the \"gay tech mafia\" that mixes social and professional lives, as investors, entrepreneurs, and executives detail gay influence in Silicon Valley (Zoë Bernard/Wired)",
      "neutral_headline": "Inside the Gay Tech Mafia",
      "bullet_summary": [
        "Reported by TechMeme, Wired Tech"
      ],
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/260219/p31#a260219p31",
          "published_at": "Thu, 19 Feb 2026 11:55:20 -0500",
          "title": "Inside the \"gay tech mafia\" that mixes social and professional lives, as investors, entrepreneurs, and executives detail gay influence in Silicon Valley (Zoë Bernard/Wired)",
          "standfirst": "Zo&euml; Bernard / Wired: Inside the &ldquo;gay tech mafia&rdquo; that mixes social and professional lives, as investors, entrepreneurs, and executives detail gay influence in Silicon Valley &mdash; Gay men have long been rumored to run Silicon Valley. WIRED investigates. &mdash; No one can say exactly when, or if, gay men started running Silicon Valley.",
          "content": "Zo&euml; Bernard / Wired: Inside the &ldquo;gay tech mafia&rdquo; that mixes social and professional lives, as investors, entrepreneurs, and executives detail gay influence in Silicon Valley &mdash; Gay men have long been rumored to run Silicon Valley. WIRED investigates. &mdash; No one can say exactly when, or if, gay men started running Silicon Valley.",
          "feed_position": 12,
          "image_url": "http://www.techmeme.com/260219/i31.jpg"
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/inside-the-gay-tech-mafia/",
          "published_at": "Thu, 19 Feb 2026 11:00:00 +0000",
          "title": "Inside the Gay Tech Mafia",
          "standfirst": "Gay men have long been rumored to run Silicon Valley. WIRED investigates.",
          "content": "Gay men have long been rumored to run Silicon Valley. WIRED investigates.",
          "feed_position": 13,
          "image_url": "https://media.wired.com/photos/6994f134872c5ae7a0fede7e/master/pass/Spot_Salesforce%20Beefcake.jpg"
        }
      ],
      "featured_image": "http://www.techmeme.com/260219/i31.jpg",
      "popularity_score": 2013.531671388889
    },
    {
      "id": "cluster_6",
      "coverage": 1,
      "updated_at": "Thu, 19 Feb 2026 22:44:25 +0000",
      "title": "Lawsuit: ChatGPT told student he was \"meant for greatness\"—then came psychosis",
      "neutral_headline": "Lawsuit: ChatGPT told student he was \"meant for greatness\"—then came psychosis",
      "bullet_summary": [
        "Reported by Ars Technica Main"
      ],
      "items": [
        {
          "source": "Ars Technica Main",
          "url": "https://arstechnica.com/tech-policy/2026/02/before-psychosis-chatgpt-told-man-he-was-an-oracle-new-lawsuit-alleges/",
          "published_at": "Thu, 19 Feb 2026 22:44:25 +0000",
          "title": "Lawsuit: ChatGPT told student he was \"meant for greatness\"—then came psychosis",
          "standfirst": "\"AI Injury Attorneys\" target the chatbot design itself.",
          "content": "A Georgia college student named Darian DeCruise has sued OpenAI, alleging that a recently deprecated version of ChatGPT “convinced him that he was an oracle” and “pushed him into psychosis.” This case, which was first reported by ALM, marks the 11th such known lawsuit to be filed against OpenAI that involves mental health breakdowns allegedly caused by the chatbot. Other incidents have ranged from highly questionable medical and health advice to a man who took his own life, apparently after similarly sycophantic conversations with ChatGPT. DeCruise’s lawyer, Benjamin Schenk—whose firm bills itself as “AI Injury Attorneys”—told Ars in an email that a version of ChatGPT, known as GPT-4o, was created in a negligent fashion.Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2023/02/chatgpt-logo-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2023/02/chatgpt-logo-1024x648.jpg",
      "popularity_score": 367.34972694444446
    },
    {
      "id": "cluster_13",
      "coverage": 1,
      "updated_at": "Thu, 19 Feb 2026 21:59:10 +0000",
      "title": "NASA chief classifies Starliner flight as \"Type A\" mishap, says agency made mistakes",
      "neutral_headline": "NASA chief classifies Starliner flight as \"Type A\" mishap, says agency made mistakes",
      "bullet_summary": [
        "\"The most troubling failure revealed by this investigation is not hardware",
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2026/02/nasa-chief-classifies-starliner-flight-as-type-a-mishap-says-agency-made-mistakes/",
          "published_at": "Thu, 19 Feb 2026 21:59:10 +0000",
          "title": "NASA chief classifies Starliner flight as \"Type A\" mishap, says agency made mistakes",
          "standfirst": "\"The most troubling failure revealed by this investigation is not hardware.\"",
          "content": "NASA on Thursday announced it has formally classified the 2024 crewed flight of the Starliner spacecraft as a \"Type A\" mishap, an acknowledgement that the test flight was a serious failure. As part of the announcement, NASA Administrator Jared Isaacman sent an agency-wide letter that recognized the shortcomings of both Starliner's developer, Boeing, as well as the space agency itself. Starliner flew under the auspices of NASA's Commercial Crew Program, in which the agency procures astronaut transportation services to the International Space Station. \"We are taking ownership of our shortcomings,\" Isaacman said.Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2024/09/GettyImages-2156180680-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2024/09/GettyImages-2156180680-1152x648.jpg",
      "popularity_score": 351.5955602777778
    },
    {
      "id": "cluster_16",
      "coverage": 1,
      "updated_at": "Thu, 19 Feb 2026 21:30:02 +0000",
      "title": "Rubik’s WOWCube adds complexity, possibility by reinventing the puzzle cube",
      "neutral_headline": "Rubik’s WOWCube adds complexity, possibility by reinventing the puzzle cube",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/02/rubiks-wowcube-adds-complexity-possibility-by-reinventing-the-puzzle-cube/",
          "published_at": "Thu, 19 Feb 2026 21:30:02 +0000",
          "title": "Rubik’s WOWCube adds complexity, possibility by reinventing the puzzle cube",
          "standfirst": "Technology is a double-edged sword in the $399 Rubik's Cube-inspired toy.",
          "content": "There’s something special about the gadget that \"just works.\" Technology can open opportunities for those devices but also complicate and weigh down products that have done just fine without things like sensors and software. So when a product like the beloved Rubik’s Cube gets stuffed with wires, processors, and rechargeable batteries, there’s demand for it to be not just on par with the original—but markedly better. The Cubios Rubik’s WOWCube successfully breathes fresh life into the classic puzzle, but it’s also an example of when too much technology can cannibalize a gadget’s main appeal.Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/lead-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/lead-1152x648.jpg",
      "popularity_score": 341.11000472222224
    },
    {
      "id": "cluster_30",
      "coverage": 1,
      "updated_at": "Thu, 19 Feb 2026 20:04:09 +0000",
      "title": "Diablo II’s new Warlock is a great excuse to revisit a classic game",
      "neutral_headline": "Diablo II’s new Warlock is a great excuse to revisit a classic game",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2026/02/diablo-iis-new-warlock-is-a-great-excuse-to-revisit-a-classic-game/",
          "published_at": "Thu, 19 Feb 2026 20:04:09 +0000",
          "title": "Diablo II’s new Warlock is a great excuse to revisit a classic game",
          "standfirst": "New skill tree paths offer a fun twist on some generally familiar mechanics.",
          "content": "Diablo II is one of those storied classic PC games that's pretty much always fun to come back to—so much so that some players have put thousands of hours into the game over more than two decades. Across all those years, though, the game itself has barely changed, becoming something of a familiar, comfortable blanket of hellfire for longtime players. That makes last week's introduction of a new playable Warlock class in Diablo II Resurrected’s new \"Reign of the Warlock\" DLC a pretty big deal. And after playing through a few Acts with the Warlock over the recent holiday weekend, I found the new option to be a great excuse to come back to a game that's overdue for a shot in the arm. War-locked in How your Warlock build goes depends heavily on which of the three main upgrade branches you choose to go down. Of these, I found the Eldritch branch had been the most interesting and fun to explore. That's in large part because of a new skill that lets you levitate a powerful two-handed weapon in front of you while still holding a strong shield in your hands. It seems like a small change, but my relief was palpable in this playthrough as I was able to avoid these kinds of tough choices between defense and offense as I juggled my inventory.Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/warlocksigil.png"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/warlocksigil.png",
      "popularity_score": 335.6786158333333
    },
    {
      "id": "cluster_40",
      "coverage": 1,
      "updated_at": "Thu, 19 Feb 2026 19:38:08 +0000",
      "title": "From chickens to humans, animals think \"bouba\" sounds round",
      "neutral_headline": "From chickens to humans, animals think \"bouba\" sounds round",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/02/newly-hatched-chickens-form-the-same-sound-association-we-do/",
          "published_at": "Thu, 19 Feb 2026 19:38:08 +0000",
          "title": "From chickens to humans, animals think \"bouba\" sounds round",
          "standfirst": "There seems to be a deep-seated association between sounds and shapes.",
          "content": "Does \"bouba\" sound round to you? How about \"maluma\"? Neither are real words, but we've known for decades that people who hear them tend to associate them with round objects. There have been plenty of ideas put forward about why that would be the case, and most of them have turned out to be wrong. Now, in perhaps the weirdest bit of evidence to date, researchers have found that even newly hatched chickens seem to associate \"bouba\" with round shapes. The initial finding dates all the way back to 1947, when someone discovered that people associated some word-like sounds with rounded shapes, and others with spiky ones. In the years since, that association got formalized as the bouba/kiki effect, received a fair bit of experimental attention, and ended up with an extensive Wikipedia entry. One of the initial ideas to explain it was similarity to actual words (either phonetically or via the characters used to spell them), but then studies with speakers of different languages and alphabets showed that it is likely a general human tendency. The association also showed up in infants as young as 4 months old, well before they master speaking or spelling. Attempts to find the bouba/kiki effects in other primates, however, came up empty. That led to some speculation that it might be evidence of a strictly human processing ability that underlies our capacity to learn sophisticated languages.Read full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-104303509-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-104303509-1152x648.jpg",
      "popularity_score": 319.24500472222223
    },
    {
      "id": "cluster_51",
      "coverage": 1,
      "updated_at": "Thu, 19 Feb 2026 18:22:29 +0000",
      "title": "F1: Preseason tests show how different 2026 will be",
      "neutral_headline": "F1: Preseason tests show how different 2026 will be",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2026/02/f1-preseason-tests-shows-how-different-2026-will-be/",
          "published_at": "Thu, 19 Feb 2026 18:22:29 +0000",
          "title": "F1: Preseason tests show how different 2026 will be",
          "standfirst": "Everyone's trying to get mileage as F1 undergoes huge technical changes.",
          "content": "It's just two weeks until F1 gets underway in Australia, and teams are currently in Bahrain, midway through their third and final preseason test. The 2026 season promises to be wildly different from those of the past few years, with all-new cars, engines, hybrid systems, and sustainable fuels entering the mix and shaking up the established order. You shouldn't read too much into times from preseason testing. The cars don't have to conform to the in-season rules as teams test new components or fit-test rigs; for example, glowing brake discs could once again be seen on some cars that weren't running wheel covers at an earlier test, something we're unlikely to see during actual races. You also don't know how much fuel—and therefore extra weight—anyone is carrying. In the past, some teams have even made headlines by running too light to set more competitive lap times in an effort to impress potential sponsors. And as the name explains, it's a test, so drivers will be following run plans devised with their engineers to learn specific things about their new cars. Or as one Internet wag once put it, the times mean as much as \"a bacon briefcase.\"Read full article Comments",
          "feed_position": 4,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-2260744865-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-2260744865-1152x648.jpg",
      "popularity_score": 312.9841713888889
    },
    {
      "id": "cluster_56",
      "coverage": 1,
      "updated_at": "Thu, 19 Feb 2026 17:42:14 +0000",
      "title": "Google announces Gemini 3.1 Pro, says it's better at complex problem-solving",
      "neutral_headline": "Google announces Gemini 3.1 Pro, says it's better at complex problem-solving",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/google/2026/02/google-announces-gemini-3-1-pro-says-its-better-at-complex-problem-solving/",
          "published_at": "Thu, 19 Feb 2026 17:42:14 +0000",
          "title": "Google announces Gemini 3.1 Pro, says it's better at complex problem-solving",
          "standfirst": "Google says 3.1 Pro is ready for \"your hardest challenges.\"",
          "content": "Another day, another Google AI model. Google has really been pumping out new AI tools lately, having just released Gemini 3 in November. Today, it's bumping the flagship model to version 3.1. The new Gemini 3.1 Pro is rolling out (in preview) for developers and consumers today with the promise of better problem-solving and reasoning capabilities. Google announced improvements to its Deep Think tool last week, and apparently, the \"core intelligence\" behind that update was Gemini 3.1 Pro. As usual, Google's latest model announcement comes with a plethora of benchmarks that show mostly modest improvements. In the popular Humanity's Last Exam, which tests advanced domain-specific knowledge, Gemini 3.1 Pro scored a record 44.4 percent. Gemini 3 Pro managed 37.5 percent, while OpenAI's GPT 5.2 got 34.5 percent. Credit: Google Read full article Comments",
          "feed_position": 5,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/gemini-3.1_pro-1152x648.png"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/gemini-3.1_pro-1152x648.png",
      "popularity_score": 309.31333805555556
    },
    {
      "id": "cluster_86",
      "coverage": 1,
      "updated_at": "Thu, 19 Feb 2026 14:11:55 +0000",
      "title": "OpenClaw security fears lead Meta, other AI firms to restrict its use",
      "neutral_headline": "OpenClaw security fears lead Meta, other AI firms to restrict its use",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2026/02/openclaw-security-fears-lead-meta-other-ai-firms-to-restrict-its-use/",
          "published_at": "Thu, 19 Feb 2026 14:11:55 +0000",
          "title": "OpenClaw security fears lead Meta, other AI firms to restrict its use",
          "standfirst": "The viral agentic AI tool is known for being highly capable but also wildly unpredictable.",
          "content": "Last month, Jason Grad issued a late-night warning to the 20 employees at his tech startup. “You've likely seen Clawdbot trending on X/LinkedIn. While cool, it is currently unvetted and high-risk for our environment,\" he wrote in a Slack message with a red siren emoji. “Please keep Clawdbot off all company hardware and away from work-linked accounts.” Grad isn’t the only tech executive who has raised concerns to staff about the experimental agentic AI tool, which was briefly known as MoltBot and is now named OpenClaw. A Meta executive says he recently told his team to keep OpenClaw off their regular work laptops or risk losing their jobs. The executive told reporters he believes the software is unpredictable and could lead to a privacy breach if used in otherwise secure environments. He spoke on the condition of anonymity to speak frankly. Peter Steinberger, OpenClaw’s solo founder, launched it as a free, open source tool last November. But its popularity surged last month as other coders contributed features and began sharing their experiences using it on social media. Last week, Steinberger joined ChatGPT developer OpenAI, which says it will keep OpenClaw open source and support it through a foundation.Read full article Comments",
          "feed_position": 7,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/bluecrayfish-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/bluecrayfish-1152x648.jpg",
      "popularity_score": 298.80806027777777
    },
    {
      "id": "cluster_69",
      "coverage": 1,
      "updated_at": "Thu, 19 Feb 2026 16:26:34 +0000",
      "title": "Zero grip, maximum fun: A practical guide to getting into amateur ice racing",
      "neutral_headline": "Zero grip, maximum fun: A practical guide to getting into amateur ice racing",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2026/02/zero-grip-maximum-fun-a-practical-guide-to-getting-into-amateur-ice-racing/",
          "published_at": "Thu, 19 Feb 2026 16:26:34 +0000",
          "title": "Zero grip, maximum fun: A practical guide to getting into amateur ice racing",
          "standfirst": "Where we're racing, we don't need roads.",
          "content": "In Formula One, grip is everything. The world's best engineers devote their careers to designing cars that maximize downforce and grip to squeeze every bit of performance out of a set of four humble tires. These cars punish their drivers by slinging them at six Gs through corners and offer similar levels of abuse in braking. It's all wildly impressive, but I've long maintained that those drivers are not the ones having the most fun. When it comes to sheer enjoyment, grip is highly overrated, and if you want proof of that, you need to try ice racing. Should you be lucky enough to live somewhere that gets cold enough consistently enough, all you need is a good set of tires and a car that's willing and able. That, of course, and a desire to spend more time driving sideways than straight. I've been ice racing for well over 20 years now, and I'm here to tell you that there's no greater thrill on four wheels than sliding through a corner a few inches astern of a hard-charging competitor.Read full article Comments",
          "feed_position": 6,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/2026-Ice-Racing-005-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/2026-Ice-Racing-005-1152x648.jpg",
      "popularity_score": 286.05222694444444
    },
    {
      "id": "cluster_88",
      "coverage": 1,
      "updated_at": "Thu, 19 Feb 2026 13:32:52 +0000",
      "title": "Rare gifted word-learner dogs like to share their toys",
      "neutral_headline": "Rare gifted word-learner dogs like to share their toys",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/02/rare-gifted-word-learner-dogs-like-to-share-their-toys/",
          "published_at": "Thu, 19 Feb 2026 13:32:52 +0000",
          "title": "Rare gifted word-learner dogs like to share their toys",
          "standfirst": "\"It raises the possibility that social motivation plays a role in why some dogs end up learning object names.\"",
          "content": "We love hearing about the latest findings coming out of an Eötvös Loránd University (ELU) research group focused on gifted word learner (GWL) dogs—if only for the pictures of adorable doggoes playing with their toys. Just last month, we learned that such dogs can learn the labels for new toys just by overhearing their owners talking about those toys. The group is back with yet another new paper, published in the journal Animal Cognition, presenting evidence that GWL dogs have a preference for novel toys and like to share them with their owners. That social interaction seems to be the key to the unique cognitive abilities of these rare dogs. As previously reported, ELU co-author Claudia Fugazza has been studying canine behavior and cognition for several years as part of the Genius Dog Challenge. For instance, the group’s 2022 study discovered that dogs store key sensory features about their toys—notably what they look like and how they smell—and recall those features when searching for the named toy. Prior studies had suggested that dogs typically rely on vision, or a combination of sight and smell, to locate target objects. GWL dogs can also identify objects based on verbal labels. Last fall, Fugazza’s group discovered that certain dogs can not only memorize the names of objects like their favorite toys, but also extend those labels to entirely new objects with a similar function, regardless of whether or not they are similar in appearance. It’s a cognitively advanced ability known as “label extension,” and for animals to acquire it usually involves years of intensive training in captivity. But the dogs in this new study developed the ability to classify their toys by function with no formal training, merely by playing naturally with their owners. It’s akin to a person calling a hammer and a rock by the same name, or a child understanding that “cup” can describe a mug, a glass, or a tumbler because they serve the same function.Read full article Comments",
          "feed_position": 8,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/09/doggo5-1152x648-1771357654.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/09/doggo5-1152x648-1771357654.jpg",
      "popularity_score": 263.15722694444446
    },
    {
      "id": "cluster_109",
      "coverage": 1,
      "updated_at": "Wed, 18 Feb 2026 20:58:34 +0000",
      "title": "Verizon acknowledges \"pain\" of new unlock policy, suggests change is coming",
      "neutral_headline": "Verizon acknowledges \"pain\" of new unlock policy, suggests change is coming",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/02/verizon-might-drop-its-annoying-35-day-wait-for-unlocking-paid-off-phones/",
          "published_at": "Wed, 18 Feb 2026 20:58:34 +0000",
          "title": "Verizon acknowledges \"pain\" of new unlock policy, suggests change is coming",
          "standfirst": "Report: Verizon's goal is \"immediate unlock for all payment methods really soon.\"",
          "content": "Following our report last week that Verizon is forcing people to wait 35 days for phone unlocks after paying off device installment plans, Verizon is apparently trying to eliminate the inconvenient delay. But Verizon hasn't confirmed the plan to Ars, and a Verizon statement published by Android Authority yesterday did not provide any timeline for implementing the change. As a refresher, an update to Verizon’s device unlocking policy for postpaid customers imposed a 35-day waiting period when a customer pays off the remaining balance of a device installment plan online, in the Verizon app, or with a Verizon gift card. There's also a 35-day waiting period after paying off an installment plan over the phone or at a Verizon Authorized Retailer. Saying restrictions are needed to counter fraud, Verizon will only unlock a phone immediately when someone pays off their device-plan balance at a Verizon corporate store or when someone pays off an installment plan on schedule via automatic payments. If you're partway into one of Verizon’s 36-month device installment plans and pay off the remaining balance early, but without making a trip to a Verizon corporate store, you'd have to wait 35 days for an unlock that would allow you to switch the phone to a different carrier's network.Read full article Comments",
          "feed_position": 9,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2021/05/getty-verizon-1152x648-1747846769.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2021/05/getty-verizon-1152x648-1747846769.jpg",
      "popularity_score": 258
    },
    {
      "id": "cluster_126",
      "coverage": 1,
      "updated_at": "Wed, 18 Feb 2026 16:00:11 +0000",
      "title": "Record scratch—Google's Lyria 3 AI music model is coming to Gemini today",
      "neutral_headline": "Record scratch—Google's Lyria 3 AI music model is coming to Gemini today",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/google/2026/02/gemini-can-now-generate-ai-music-for-you-no-lyrics-required/",
          "published_at": "Wed, 18 Feb 2026 16:00:11 +0000",
          "title": "Record scratch—Google's Lyria 3 AI music model is coming to Gemini today",
          "standfirst": "With a simple prompt, you can generate 30 seconds of something like music.",
          "content": "The American poet Henry Wadsworth Longfellow called music \"the universal language of mankind.\" Is that still true when the so-called music is being generated by a probabilistic robot instead of a human? We're about to find out. Google has announced its latest Lyria 3 AI model is being deployed in the Gemini app, vastly expanding access to AI music generation. Google DeepMind has been tinkering with Lyria for a while now, offering limited access in developer-oriented products like Vertex AI. Lyria 3 is more capable than previous versions, and it's also quicker to use. Just select the new \"Create music\" option in the Gemini app or web UI to get started. You can describe what you want and even upload an image to help the robot get the right vibe. And in a few seconds, you get music (or something like it). In case there was any uncertainty about whether Lyria tracks still counted as a human artistic endeavor, worry not! Unlike past versions of the model, you don't even have to provide lyrics in your prompt. You can be vague with your request, and the model will create suitable lyrics for the 30-second song. Although with that limit, \"jingle\" might be more accurate.Read full article Comments",
          "feed_position": 15,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/Lyria_Hero-Image-1152x648.png"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/Lyria_Hero-Image-1152x648.png",
      "popularity_score": 160
    },
    {
      "id": "cluster_135",
      "coverage": 1,
      "updated_at": "Wed, 18 Feb 2026 14:24:36 +0000",
      "title": "X-rays reveal kingfisher feather structure in unprecedented detail",
      "neutral_headline": "X-rays reveal kingfisher feather structure in unprecedented detail",
      "bullet_summary": [
        "Synchrotron radiation imaging revealed a porous, almost sponge-like nanostructure to create bright hues",
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/02/what-the-chinese-art-of-tian-tsui-has-to-do-with-kingfishers/",
          "published_at": "Wed, 18 Feb 2026 14:24:36 +0000",
          "title": "X-rays reveal kingfisher feather structure in unprecedented detail",
          "standfirst": "Synchrotron radiation imaging revealed a porous, almost sponge-like nanostructure to create bright hues",
          "content": "In Qing dynasty China, artisans augmented decorative pieces by incorporating iridescent kingfisher feathers—a technique known as tian-tsui. Scientists at Northwestern University's Center for Scientific Studies in the Arts have used high-energy X-ray imaging to achieve unprecedented nanoscale resolution of the unique structure of those feathers, presenting their findings at the annual meeting of the American Association for the Advancement of Science. As previously reported, nature is the ultimate nanofabricator. The bright iridescent colors in butterfly wings, soap bubbles, opals, or beetle shells don’t come from any pigment molecules but from how they are structured—naturally occurring photonic crystals. In nature, scales of chitin (a polysaccharide common to insects), for example, are arranged like roof tiles. Essentially, they form a diffraction grating, except photonic crystals only produce specific colors, or wavelengths, of light, while a diffraction grating will produce the entire spectrum, much like a prism. In the case of kingfisher feathers, the color is due to the microscopic ridges that cover the parallel rows of keratin strands that grow along the central shaft. Also known as photonic band-gap materials, photonic crystals are “tunable,” which means they are precisely ordered to block certain wavelengths of light while letting others through. Alter the structure by changing the size of the tiles, and the crystals become sensitive to a different wavelength. They are used in optical communications as waveguides and switches, as well as in filters, lasers, mirrors, and various anti-reflection stealth devices.Read full article Comments",
          "feed_position": 17,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/kingfisher4-1152x648-1771269456.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/kingfisher4-1152x648-1771269456.jpg",
      "popularity_score": 154
    },
    {
      "id": "cluster_116",
      "coverage": 1,
      "updated_at": "Wed, 18 Feb 2026 19:28:26 +0000",
      "title": "5 changes to know about in Apple's latest iOS, macOS, and iPadOS betas",
      "neutral_headline": "5 changes to know about in Apple's latest iOS, macOS, and iPadOS betas",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/02/5-changes-to-know-about-in-apples-latest-ios-macos-and-ipados-betas/",
          "published_at": "Wed, 18 Feb 2026 19:28:26 +0000",
          "title": "5 changes to know about in Apple's latest iOS, macOS, and iPadOS betas",
          "standfirst": "The 26.3 updates were mostly invisible; these changes are more significant.",
          "content": "This week, Apple released the first developer betas for iOS 26.4, iPadOS 26.4, macOS 26.4, and its other operating systems. On Tuesday, it followed those up with public beta versions of the same updates. Usually released around the midpoint between one major iOS release and the next, the *.4 updates to its operating system usually include a significant batch of new features and other refinements, and if the first beta is any indication, this year's releases uphold that tradition. A new \"Playlist Playground\" feature will let Apple Music subscribers generate playlists with text prompts, and native support for video podcasts is coming to the Podcasts app. The Creator Studio version of the Freeform drawing and collaboration app is also available in the 26.4 updates, allowing subscribers to access stock images from Apple's Content Hub and to insert AI-generated images.Read full article Comments",
          "feed_position": 12,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/Apple-WWDC25-iOS-26-hero-250609-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/Apple-WWDC25-iOS-26-hero-250609-1152x648.jpg",
      "popularity_score": 150
    },
    {
      "id": "cluster_119",
      "coverage": 1,
      "updated_at": "Wed, 18 Feb 2026 19:01:55 +0000",
      "title": "Microsoft's new 10,000-year data storage medium: glass",
      "neutral_headline": "Microsoft's new 10,000-year data storage medium: glass",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/02/microsofts-new-10000-year-data-storage-medium-glass/",
          "published_at": "Wed, 18 Feb 2026 19:01:55 +0000",
          "title": "Microsoft's new 10,000-year data storage medium: glass",
          "standfirst": "Femtosecond lasers etch data into a very stable medium.",
          "content": "Archival storage poses lots of challenges. We want media that is extremely dense and stable for centuries or more, and, ideally, doesn't consume any energy when not being accessed. Lots of ideas have floated around—even DNA has been considered—but one of the simplest is to cut the data into glass. Many forms of glass are very physically and chemically stable, and it's relatively easy to create features in it. There's been a lot of preliminary work demonstrating different aspects of a glass-based storage system. But in Wednesday's issue of Nature, Microsoft Research announced Project Silica, a working demonstration of a system that can read and write data into small slabs of glass with a density of over a Gigabit per cubic millimeter. Writing on glass We tend to think of glass as fragile, prone to shattering, and capable of flowing downward over centuries, although the last claim is a myth. Glass is a category of material, and a variety of chemicals can form glasses. With the right starting chemical, it's possible to make a glass that is, as the researchers put it, \"thermally and chemically stable and is resistant to moisture ingress, temperature fluctuations and electromagnetic interference.\" While it would still need to be handled in a way to minimize damage, glass provides the sort of stability we'd want for long-term storage.Read full article Comments",
          "feed_position": 13,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/Silica_Figure_2-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/Silica_Figure_2-1152x648.jpg",
      "popularity_score": 145
    },
    {
      "id": "cluster_131",
      "coverage": 1,
      "updated_at": "Wed, 18 Feb 2026 15:00:34 +0000",
      "title": "Google's Pixel 10a arrives on March 5 for $499 with specs and design of yesteryear",
      "neutral_headline": "Google's Pixel 10a arrives on March 5 for $499 with specs and design of yesteryear",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/02/googles-pixel-10a-arrives-on-march-5-for-499-with-specs-and-design-of-yesteryear/",
          "published_at": "Wed, 18 Feb 2026 15:00:34 +0000",
          "title": "Google's Pixel 10a arrives on March 5 for $499 with specs and design of yesteryear",
          "standfirst": "Google's new budget phone is here, but don't expect a big upgrade.",
          "content": "It's that time of year—a new budget Pixel phone is about to hit virtual shelves. The Pixel 10a will be available on March 5, and pre-orders go live today. The 9a will still be on sale for a while, but the 10a will be headlining Google's store. However, you might not notice unless you keep up with the Pixel numbering scheme. This year's A-series Pixel is virtually identical to last year's, both inside and out. Last year's Pixel 9a was a notable departure from the older design language, but Google made few changes for 2026. We liked that the Pixel 9a emphasized battery capacity and moved to a flat camera bump, and this time, it's really flat. Google says the camera now sits totally flush with the back panel. This is probably the only change you'll be able to identify visually. Specs at a glance: Google Pixel 9a vs. Pixel 10a Phone Pixel 9a Pixel 10a SoC Google Tensor G4 Google Tensor G4 Memory 8GB 8GB Storage 128GB, 256GB 128GB, 256GB Display 1080×2424 6.3\" pOLED, 60–120 Hz, Gorilla Glass 3, 2700 nits (peak) 1080×2424 6.3\" pOLED, 60–120 Hz, Gorilla Glass 7i, 3000 nits (peak) Cameras 48 MP primary, f/1.7, OIS; 13 MP ultrawide, f/2.2; 13 MP selfie, f/2.2 48 MP primary, f/1.7, OIS; 13 MP ultrawide, f/2.2; 13 MP selfie, f/2.2 Software Android 15 (at launch), 7 years of OS updates Android 16, 7 years of OS updates Battery 5,100 mAh, 23 W wired charging, 7.5 W wireless charging 5,100 mAh, 30 W wired charging, 10 W wireless charging Connectivity Wi-Fi 6e, NFC, Bluetooth 5.3, sub-6 GHz 5G, USB-C 3.2 Wi-Fi 6e, NFC, Bluetooth 6.0, sub-6 GHz 5G, USB-C 3.2 Measurements 154.7×73.3×8.9 mm; 185 g 153.9×73×9 mm; 183 g Google also says the new Pixel will have a slightly upgraded screen. The resolution, size, and refresh rate are unchanged, but peak brightness has been bumped from 2,700 nits to 3,000 nits (the same as the base model Pixel 10). Plus, the cover glass has finally moved beyond Gorilla Glass 3 to Gorilla Glass 7i, which supposedly has improved scratch and drop protection.Read full article Comments",
          "feed_position": 16,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/Pixel-10a-lifestyle-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/Pixel-10a-lifestyle-1152x648.jpg",
      "popularity_score": 145
    },
    {
      "id": "cluster_111",
      "coverage": 1,
      "updated_at": "Wed, 18 Feb 2026 20:22:03 +0000",
      "title": "Chevy Bolt, BMW i3, or something else? At $10K, you have lots of EV options",
      "neutral_headline": "Chevy Bolt, BMW i3, or something else? At $10K, you have lots of EV options",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2026/02/chevy-bolt-bmw-i3-or-something-else-at-10k-you-have-lots-of-ev-options/",
          "published_at": "Wed, 18 Feb 2026 20:22:03 +0000",
          "title": "Chevy Bolt, BMW i3, or something else? At $10K, you have lots of EV options",
          "standfirst": "Two of Ars' favorite electric vehicles are now available for not very much money.",
          "content": "2026 is looking like a pretty good year for affordable electric vehicles. There's a new Nissan Leaf that starts at a hair under $30,000 (as long as you ignore the destination charge). We'll soon drive the reborn Chevrolet Bolt—with a new lithium iron phosphate battery, it also has a price tag starting with a two (again, ignoring the destination charge). And the closer you get to $40,000, the more your options expand: the Hyundai Ioniq 5, Chevy Equinox EV, Toyota bZ, Tesla Model 3, Ford Mustang Mach-E, and Subaru Solterra all fall within that price bracket, and some of those are pretty good cars. But what if you only want to spend a fraction of that? Well, you won't be buying anything new, but then neither do three-quarters of American car buyers, and there's nothing wrong with that. A few weeks ago, we looked at what passes for the used EV bargain basement—ones that cost $5,000 or less. As long as you're OK with limited range and slow charging, going electric on a shoestring is possible. But if you're prepared to spend twice that, it turns out you've got plenty of options. As before, we stress that you should have a reliable place to charge an EV if you're going to buy one, which means at home at night or at work during the day. At this price range, you're unlikely to find something that DC fast charges quickly, and relying on public AC charging sounds stressful. You'll probably find a car with some battery degradation, but for the vast majority of models that use active battery cooling, this should be minimal; about 2 percent a year appears to be the average.Read full article Comments",
          "feed_position": 10,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/electric-piggy-bank-10k-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/electric-piggy-bank-10k-1152x648.jpg",
      "popularity_score": 139
    },
    {
      "id": "cluster_112",
      "coverage": 1,
      "updated_at": "Wed, 18 Feb 2026 19:48:06 +0000",
      "title": "Lawsuit: EPA revoking greenhouse gas finding risks “thousands of avoidable deaths”",
      "neutral_headline": "Lawsuit: EPA revoking greenhouse gas finding risks “thousands of avoidable deaths”",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/02/lawsuit-epa-revoking-greenhouse-gas-finding-risks-thousands-of-avoidable-deaths/",
          "published_at": "Wed, 18 Feb 2026 19:48:06 +0000",
          "title": "Lawsuit: EPA revoking greenhouse gas finding risks “thousands of avoidable deaths”",
          "standfirst": "EPA sued for abandoning its mission to protect public health.",
          "content": "In a lawsuit filed Wednesday, the Environmental Protection Agency was accused of abandoning its mission to protect public health after repealing an \"endangerment finding\" that has served as the basis for federal climate change regulations for 17 years. The lawsuit came from more than a dozen environmental and health groups, including the American Public Health Association, the American Lung Association, the Center for Biological Diversity (CBD), the Clean Air Council, the Environmental Defense Fund (EDF), the Natural Resources Defense Council (NRDC), the Sierra Club, and the Union of Concerned Scientists. The groups have asked the US Court of Appeals for the District of Columbia Circuit to review the EPA decision, which also eliminated requirements controlling greenhouse gas emissions in new cars and trucks. Urging a return to the status quo, the groups argued that the Trump administration is anti-science and illegally moving to benefit the fossil fuel industry, despite a mountain of evidence demonstrating the deadly consequences of unchecked pollution and climate change-induced floods, droughts, wildfires, and hurricanes.Read full article Comments",
          "feed_position": 11,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-1324589360-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-1324589360-1152x648.jpg",
      "popularity_score": 139
    },
    {
      "id": "cluster_123",
      "coverage": 1,
      "updated_at": "Wed, 18 Feb 2026 17:08:18 +0000",
      "title": "FDA reverses surprise rejection of Moderna's mRNA flu vaccine",
      "neutral_headline": "FDA reverses surprise rejection of Moderna's mRNA flu vaccine",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2026/02/fda-does-u-turn-will-review-modernas-mrna-flu-shot-after-shocking-rejection/",
          "published_at": "Wed, 18 Feb 2026 17:08:18 +0000",
          "title": "FDA reverses surprise rejection of Moderna's mRNA flu vaccine",
          "standfirst": "Trump admin's vaccine chief overruled FDA scientists to initially reject the shot.",
          "content": "The Food and Drug Administration has reversed its shocking refusal to consider Moderna's mRNA flu vaccine for approval. The refusal was revealed last week in a sharply worded press release from Moderna. Subsequent reporting found that the decision was made by political appointee Vinay Prasad, the Trump administration's top vaccine regulator, who overruled a team of agency scientists and a top career official in rejecting Moderna's application. In an announcement Wednesday morning, Moderna said the FDA has now agreed to review its vaccine after the company held a formal (Type A) meeting with the FDA and proposed a change to the regulatory pathways used in the application.Read full article Comments",
          "feed_position": 14,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2017/02/GettyImages-496532228-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2017/02/GettyImages-496532228-1024x648.jpg",
      "popularity_score": 139
    },
    {
      "id": "cluster_136",
      "coverage": 1,
      "updated_at": "Wed, 18 Feb 2026 14:14:06 +0000",
      "title": "Inside the DHS forum where ICE agents trash talk one another",
      "neutral_headline": "Inside the DHS forum where ICE agents trash talk one another",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/02/inside-the-dhs-forum-where-ice-agents-trash-talk-one-another/",
          "published_at": "Wed, 18 Feb 2026 14:14:06 +0000",
          "title": "Inside the DHS forum where ICE agents trash talk one another",
          "standfirst": "Forum members have discussed their discomfort with mass deportation efforts.",
          "content": "Every day, people log into an online forum for current and former Homeland Security Investigations (HSI) officers to share their thoughts on the news of the day and complain about their colleagues in Immigration and Customs Enforcement (ICE). “ERO is too busy dressing up as Black Ops Commandos with Tactical body armor, drop down thigh rigs, balaclavas, multiple M4 magazines, and Punisher patches, to do an Admin arrest of a non criminal, non-violent EWI that weighs 90 pounds and is 5 foot 2, inside a secure Federal building where everyone has been screened for weapons,” wrote one user in July 2025. (ERO stands for Enforcement and Removal Operations; along with HSI, it’s one of the two major divisions of ICE, and is responsible for detaining and deporting immigrants.) The forum describes itself as a space for current and prospective HSI agents, “designed for the seasoned HSI Special Agent as well as applicants for entry level Special Agent positions.” HSI is the division within ICE whose agents are normally responsible for investigating crimes like drug smuggling, terrorism, and human trafficking.Read full article Comments",
          "feed_position": 18,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/hsi-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/hsi-1152x648.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_142",
      "coverage": 1,
      "updated_at": "Wed, 18 Feb 2026 12:00:37 +0000",
      "title": "Hallucinogen DMT an effective antidepressant in small clinical trial",
      "neutral_headline": "Hallucinogen DMT an effective antidepressant in small clinical trial",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2026/02/hallucinogen-dmt-an-effective-antidepressant-in-small-clinical-trial/",
          "published_at": "Wed, 18 Feb 2026 12:00:37 +0000",
          "title": "Hallucinogen DMT an effective antidepressant in small clinical trial",
          "standfirst": "Effectiveness appears to correlate with self-described mystical experience.",
          "content": "Over the last few years, evidence has piled up that psychedelic drugs can provide relatively rapid relief from the symptoms of clinical depression. The drugs seemingly work by boosting the brain's ability to remodel connections among neurons and incorporate new experiences. While we have a good picture of which proteins are responsible for the drug's hallucinogenic effects, we're still figuring out how those pathways plug into the brain's ability to change itself. Those lingering uncertainties aren't standing in the way of people trying to develop potentially life-altering treatments. One of the big challenges is probably the hallucinations themselves, which can potentially incapacitate someone for hours after a treatment. But researchers have now described a study showing that the shortest-acting psychedelic, DMT, appears to be just as effective as the rest. Fast-acting DMT, or dimethyltryptamine, is probably best known as a key component of ayahuasca, a liquid made from a combination of two or more plants. The mixture is important because the body produces an enzyme that rapidly digests DMT, blocking its effects. The additional plants contain a chemical that inhibits this enzyme, providing a longer-lasting experience.Read full article Comments",
          "feed_position": 19,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-1322471137-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-1322471137-1152x648.jpg",
      "popularity_score": 133
    }
  ]
}