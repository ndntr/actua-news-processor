{
  "updated_at": "2026-02-25T11:35:47.287Z",
  "clusters": [
    {
      "id": "cluster_33",
      "coverage": 2,
      "updated_at": "Wed, 25 Feb 2026 02:37:00 GMT",
      "title": "Anthropic just released a mobile version of Claude Code called Remote Control",
      "neutral_headline": "Anthropic just released a mobile version of Claude Code called Remote Control",
      "bullet_summary": [
        "\"It wasn&#x27;t a failure of effort, it was a failure of approach, and it&#x27;s something we heard directly from our customers,\" Jensen said",
        "\"In 2025 Claude transformed how developers work, and in 2026 it will do the same for knowledge work,\" Jensen said",
        "\"That framing is central to understanding what Anthropic announced on Tuesday",
        "\"We&#x27;ve heard loud and clear from enterprises — you want Claude to work the way that your company works, not just Claude for legal, but Cowork for legal at your company,\" he said"
      ],
      "items": [
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/anthropic-just-released-a-mobile-version-of-claude-code-called-remote",
          "published_at": "Wed, 25 Feb 2026 02:37:00 GMT",
          "title": "Anthropic just released a mobile version of Claude Code called Remote Control",
          "standfirst": "Claude Code has become increasingly popular in the first year since its launch, and especially in recent months, as developers and non-technical users alike flock to AI unicorn Anthropic&#x27;s hit coding agent to create full applications and websites in days, on their own, that would&#x27;ve taken months and technical teams without. It&#x27;s not a stretch to say it helped spur the \"vibe coding\" boom — using plain English instead of programming languages to write software.But it&#x27;s all been restricted to the desktop Claude Code apps and Terminal command-line interfaces and integrated development environments (IDEs) — until today. Now, Anthropic has added a new mode, Remote Control, that lets users issue commands to Claude Code from their iPhone and Android smartphones — starting with subscribers to Anthropic&#x27;s Claude Max ($100-$200 USD monthly) subscription tier.Anthropic posted on X saying Remote Control will also make its way to Claude Pro ($20 USD monthly) subscribers in the future.The mobile command centerAnnounced earlier today by Claude Code Product Manager Noah Zweben, Remote Control is a synchronization layer that bridges local CLI environments with the Claude mobile app and web interface. The feature allows developers to initiate a complex task in their terminal and maintain full control of it from a phone or tablet, effectively decoupling the AI agent from the physical workstation.Currently, Remote Control is available as a Research Preview for subscribers on the Claude Max tier. While access for Claude Pro ($20/month) users is expected shortly, the feature remains a high-end tool for power users and is notably absent from Team or Enterprise plans during this initial phase. To access the feature, users must follow this guide and update to Claude version 2.1.52 and execute the command claude remote-control or use the in-session slash command /rc. Once active, the terminal displays a QR code that, when scanned, opens a responsive, synchronized session in the Claude mobile app.Less screen time, more IRL time: philosophy of flowThe messaging behind the release centers on the preservation of a developer&#x27;s \"flow state.\" In his announcement, Zweben framed the update as a lifestyle upgrade rather than just a technical one, encouraging users to \"take a walk, see the sun, walk your dog without losing your flow.\"This \"Remote Control\" is not a cloud-based replacement for local development, but a portal into it. According to official documentation, the core value is that \"Claude keeps running on your machine, and you can control the session from the Claude app.\" This ensures that local context—filesystem access, environment variables, and Model Context Protocol (MCP)servers—remains active and reachable even if the user is miles away from their desk.Architecture, security, and setupClaude Code Remote Control functions as a secure bridge between your local terminal and Anthropic’s cloud interface, which provides the Anthropic AI models, Opus 4.6 and Sonnet 4.6, that power Claude Code.When you run the command, your desktop machine initiates an outbound connection to Anthropic’s API for serving the models — meaning you aren&#x27;t opening any \"inbound\" ports or exposing your computer to the open web. Instead, your local machine polls the API for instructions. When you visit the session URL or use the Claude app, you are essentially using those devices as a \"remote window\" to view and command the process still running on your computer. Your files and MCP servers never leave your machine; only the chat messages and tool results flow through the encrypted bridge.To get started, ensure you are on a Pro or Max plan and have authenticated your CLI using the /login command. Simply navigate to your project directory and run claude remote-control to initialize the session. The terminal will then generate a unique session URL and a QR code (toggleable via the spacebar) for your mobile device. Once you open that link on your phone, tablet, or another browser, the two surfaces stay in perfect sync—allowing you to start a task at your desk and continue it from the couch while maintaining full access to your local filesystem and project configuration.From brittle community hacks to official solutionPrior to this official release, the developer community went to great lengths to \"hack\" mobile access into their terminal-based workflows. Power users frequently relied on a patchwork of third-party tools like Tailscale for secure tunneling, Termius or Termux for mobile SSH access, and Tmux for session persistence.Some developers even built complex custom WebSocket bridges just to get a responsive mobile UI for their local Claude sessions. These unofficial solutions, while functional, were often brittle and prone to timeout issues. Remote Control replaces these workarounds with a native streaming connection that requires no port forwarding or complex VPN configurations. It also includes automatic reconnection logic: if a user’s laptop sleeps or the network drops, the session remains alive in the background and reconnects as soon as the host machine is back online.The $2.5 billion-dollar agentThe launch of Remote Control serves as an \"escalation of force\" in what has become a dominant business for Anthropic. As of February 2026, Claude Code has hit a $2.5 billion annualized run rate — a figure that has more than doubled since the start of the year alone.Claude Code is currently experiencing its \"ChatGPT moment,\" surging to 29 million daily installs within Visual Studio Code. Its efficiency is no longer theoretical; recent analysis suggests that 4% of all public GitHub commits worldwide are now authored by Claude Code. By extending this power to mobile, Anthropic is further entrenching its lead in the \"agentic\" coding space, moving beyond simple autocomplete to a world where the AI acts as an autonomous collaborator.Future outlook: vibe coding everywhereThe move toward mobile terminal control signals a broader shift in the software market. We are entering an era where AI tools are writing roughly 41% of all code. For developers, this translates to a migration from \"line-by-line\" typing to \"strategic oversight.\"This trend is likely to accelerate as mobile-tethered agents become the norm. The barrier between \"idea\" and \"production\" is collapsing, enabling a single developer to manage complex systems that previously required entire DevOps teams. This shift has already rattled the broader tech market; shares of major cybersecurity firms like CrowdStrike and Datadog fell as much as 11% following the launch of Claude Code&#x27;s automated security scanning features.As Claude Code moves from the desk to the pocket, the definition of a \"software engineer\" is being rewritten. In the coming year, the industry may see a surge in \"one-person unicorns\"—startups built and maintained almost entirely via mobile agentic commands—marking the end of the manual coding era as we knew it.",
          "content": "Claude Code has become increasingly popular in the first year since its launch, and especially in recent months, as developers and non-technical users alike flock to AI unicorn Anthropic&#x27;s hit coding agent to create full applications and websites in days, on their own, that would&#x27;ve taken months and technical teams without. It&#x27;s not a stretch to say it helped spur the \"vibe coding\" boom — using plain English instead of programming languages to write software.But it&#x27;s all been restricted to the desktop Claude Code apps and Terminal command-line interfaces and integrated development environments (IDEs) — until today. Now, Anthropic has added a new mode, Remote Control, that lets users issue commands to Claude Code from their iPhone and Android smartphones — starting with subscribers to Anthropic&#x27;s Claude Max ($100-$200 USD monthly) subscription tier.Anthropic posted on X saying Remote Control will also make its way to Claude Pro ($20 USD monthly) subscribers in the future.The mobile command centerAnnounced earlier today by Claude Code Product Manager Noah Zweben, Remote Control is a synchronization layer that bridges local CLI environments with the Claude mobile app and web interface. The feature allows developers to initiate a complex task in their terminal and maintain full control of it from a phone or tablet, effectively decoupling the AI agent from the physical workstation.Currently, Remote Control is available as a Research Preview for subscribers on the Claude Max tier. While access for Claude Pro ($20/month) users is expected shortly, the feature remains a high-end tool for power users and is notably absent from Team or Enterprise plans during this initial phase. To access the feature, users must follow this guide and update to Claude version 2.1.52 and execute the command claude remote-control or use the in-session slash command /rc. Once active, the terminal displays a QR code that, when scanned, opens a responsive, synchronized session in the Claude mobile app.Less screen time, more IRL time: philosophy of flowThe messaging behind the release centers on the preservation of a developer&#x27;s \"flow state.\" In his announcement, Zweben framed the update as a lifestyle upgrade rather than just a technical one, encouraging users to \"take a walk, see the sun, walk your dog without losing your flow.\"This \"Remote Control\" is not a cloud-based replacement for local development, but a portal into it. According to official documentation, the core value is that \"Claude keeps running on your machine, and you can control the session from the Claude app.\" This ensures that local context—filesystem access, environment variables, and Model Context Protocol (MCP)servers—remains active and reachable even if the user is miles away from their desk.Architecture, security, and setupClaude Code Remote Control functions as a secure bridge between your local terminal and Anthropic’s cloud interface, which provides the Anthropic AI models, Opus 4.6 and Sonnet 4.6, that power Claude Code.When you run the command, your desktop machine initiates an outbound connection to Anthropic’s API for serving the models — meaning you aren&#x27;t opening any \"inbound\" ports or exposing your computer to the open web. Instead, your local machine polls the API for instructions. When you visit the session URL or use the Claude app, you are essentially using those devices as a \"remote window\" to view and command the process still running on your computer. Your files and MCP servers never leave your machine; only the chat messages and tool results flow through the encrypted bridge.To get started, ensure you are on a Pro or Max plan and have authenticated your CLI using the /login command. Simply navigate to your project directory and run claude remote-control to initialize the session. The terminal will then generate a unique session URL and a QR code (toggleable via the spacebar) for your mobile device. Once you open that link on your phone, tablet, or another browser, the two surfaces stay in perfect sync—allowing you to start a task at your desk and continue it from the couch while maintaining full access to your local filesystem and project configuration.From brittle community hacks to official solutionPrior to this official release, the developer community went to great lengths to \"hack\" mobile access into their terminal-based workflows. Power users frequently relied on a patchwork of third-party tools like Tailscale for secure tunneling, Termius or Termux for mobile SSH access, and Tmux for session persistence.Some developers even built complex custom WebSocket bridges just to get a responsive mobile UI for their local Claude sessions. These unofficial solutions, while functional, were often brittle and prone to timeout issues. Remote Control replaces these workarounds with a native streaming connection that requires no port forwarding or complex VPN configurations. It also includes automatic reconnection logic: if a user’s laptop sleeps or the network drops, the session remains alive in the background and reconnects as soon as the host machine is back online.The $2.5 billion-dollar agentThe launch of Remote Control serves as an \"escalation of force\" in what has become a dominant business for Anthropic. As of February 2026, Claude Code has hit a $2.5 billion annualized run rate — a figure that has more than doubled since the start of the year alone.Claude Code is currently experiencing its \"ChatGPT moment,\" surging to 29 million daily installs within Visual Studio Code. Its efficiency is no longer theoretical; recent analysis suggests that 4% of all public GitHub commits worldwide are now authored by Claude Code. By extending this power to mobile, Anthropic is further entrenching its lead in the \"agentic\" coding space, moving beyond simple autocomplete to a world where the AI acts as an autonomous collaborator.Future outlook: vibe coding everywhereThe move toward mobile terminal control signals a broader shift in the software market. We are entering an era where AI tools are writing roughly 41% of all code. For developers, this translates to a migration from \"line-by-line\" typing to \"strategic oversight.\"This trend is likely to accelerate as mobile-tethered agents become the norm. The barrier between \"idea\" and \"production\" is collapsing, enabling a single developer to manage complex systems that previously required entire DevOps teams. This shift has already rattled the broader tech market; shares of major cybersecurity firms like CrowdStrike and Datadog fell as much as 11% following the launch of Claude Code&#x27;s automated security scanning features.As Claude Code moves from the desk to the pocket, the definition of a \"software engineer\" is being rewritten. In the coming year, the industry may see a surge in \"one-person unicorns\"—startups built and maintained almost entirely via mobile agentic commands—marking the end of the manual coding era as we knew it.",
          "feed_position": 0,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/6RPhHUoUFspa6koUR32kvV/c51a10eb9600c128e13637793ca370ed/Gemini_Generated_Image_7ldhz77ldhz77ldh.png?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/anthropic-says-claude-code-transformed-programming-now-claude-cowork-is",
          "published_at": "Wed, 25 Feb 2026 00:40:00 GMT",
          "title": "Anthropic says Claude Code transformed programming. Now Claude Cowork is coming for the rest of the enterprise.",
          "standfirst": "Anthropic opened its virtual \"Briefing: Enterprise Agents\" event on Tuesday with a provocation. Kate Jensen, the company&#x27;s head of Americas, told viewers that the hype around enterprise AI agents in 2025 \"turned out to be mostly premature,\" with many pilots failing to reach production. \"It wasn&#x27;t a failure of effort, it was a failure of approach, and it&#x27;s something we heard directly from our customers,\" Jensen said.The implicit promise: Anthropic has figured out the right approach, and it starts with the playbook that made Claude Code one of the most consequential developer tools of the past year. \"In 2025 Claude transformed how developers work, and in 2026 it will do the same for knowledge work,\" Jensen said. \"The magic behind Claude Code is simple. When you can delegate hard challenges, you can focus on the work that actually matters. Cowork brings that same power to knowledge workers.\"That framing is central to understanding what Anthropic announced on Tuesday. The company rolled out a sweeping set of enterprise capabilities for Claude Cowork, the AI productivity platform it first released in research preview in January. Scott White, head of product for Claude Enterprise, described the ambition plainly during the keynote: \"Cowork makes it possible for Claude to deliver polished, near final work. It goes beyond drafts and suggestions — actual completed projects and deliverables.\"The product updates are dense but consequential. Enterprise administrators can now build private plugin marketplaces tailored to their organizations, connecting to private GitHub repositories as plugin sources and controlling which plugins employees can access. Anthropic introduced new prebuilt plugin templates spanning HR, design, engineering, operations, financial analysis, investment banking, equity research, private equity, and wealth management. The company also shipped new MCP connectors for Google Drive, Google Calendar, Gmail, DocuSign, Apollo, Clay, Outreach, SimilarWeb, MSCI, LegalZoom, FactSet, WordPress, and Harvey — dramatically extending Claude&#x27;s reach into the software ecosystem that enterprises already use. And Claude can now pass context seamlessly between Cowork, Excel, and PowerPoint, including across multiple files, without requiring users to restart when switching applications.White emphasized that the system is designed to feel native to each organization rather than generic. \"We&#x27;ve heard loud and clear from enterprises — you want Claude to work the way that your company works, not just Claude for legal, but Cowork for legal at your company,\" he said. \"That&#x27;s exactly what today&#x27;s launches deliver.\"Real-world results from Spotify, Novo Nordisk, and Salesforce hint at what&#x27;s comingTo ground the product announcements in measurable outcomes, Anthropic showcased three enterprise deployments that illustrate both the scale and the variety of impact the company claims Claude can deliver.At Spotify, engineers had long struggled with code migrations — the slow, manual work of updating and modernizing code across thousands of services. Jensen explained that after integrating Claude directly into the system Spotify&#x27;s engineers use daily, \"any engineer can kick off a large-scale migration just by describing what they need in plain English.\" The company reports up to a 90% reduction in engineering time, over 650 AI-generated code changes shipped per month, and roughly half of all Spotify updates now flowing through the system.At Novo Nordisk, the pharmaceutical giant built an AI-powered platform called NovoScribe with Claude as its intelligence layer, targeting the grueling process of producing regulatory documentation for new medicines. Staff writers had previously averaged just over two reports per year. After deploying Claude, Jensen said, \"documentation creation went from 10 plus weeks to 10 minutes. That&#x27;s a 95% reduction in resources for verification checks. Medicines are reaching patients faster.\" Jensen also noted that Novo Nordisk used Claude Code to build the platform itself, enabling contributions from non-engineers — their digitalization strategy director, who holds a PhD in molecular biology rather than engineering, now prototypes features using natural language. \"A team of 11 is operating like a team many times its size,\" Jensen said.Salesforce, meanwhile, uses Claude models to help power AI in Slack, reporting a 96% satisfaction rate for tools like its Slack bot and saving customers an estimated 97 minutes per week through summarization and recap features. The partnership reflects Anthropic&#x27;s broader ecosystem strategy: Jensen described the companies featured at the event as \"Claude partners and domain experts with the data and trusted relationships that make Claude work in the real world.\"Enterprise leaders reveal the messy reality behind AI transformationPerhaps the most illuminating segment of the event was a panel discussion featuring executives from Thomson Reuters, the New York Stock Exchange, and Epic, who provided candid assessments of AI&#x27;s enterprise reality that went well beyond the polished case studies.Sridhar Masam, CTO of the New York Stock Exchange, described his organization as \"rewiring our engineering process\" with Claude Code and building internal AI agents using the Claude Agent SDK that can take instructions from a Jira ticket all the way to a committed piece of code. But he also identified fundamental shifts in how leaders must think. \"The accountability is shifting,\" he said. \"Traditionally, we are so used to building deterministic platforms. You write code requirements and build. And now, with AI being probabilistic, the accountability doesn&#x27;t end when the project goes live, but on a daily basis, monitoring the behavior and outcomes.\" He described a new paradigm beyond \"buy versus build\" — what he called \"assembly,\" the practice of combining multiple models, multiple vendors, platforms, data, and internal capabilities into solutions. And he noted that highly regulated industries must shift \"from risk avoidance to risk calibration,\" because simply avoiding AI is no longer a competitive option.Steve Haske from Thomson Reuters, whose Co-Counsel product has reached a million users, was frank about the gap between what the technology can do and what organizations are ready for. \"The tools are in many senses ahead of the change management,\" he said. \"A general counsel&#x27;s office, a law firm, a tax and accounting firm, an audit firm, need to rewire the processes to be able to take advantage of the benefits that the tools provide. And I think it&#x27;s 18 months away before that sort of change management catches up with the standard of the tool.\" He also stressed an \"ironclad guarantee\" to Co-Counsel customers that \"their input will not be part of our AI output,\" and urged enterprise leaders to be \"feverish\" about protecting institutional intellectual property.Seth Hain from Epic — the healthcare technology company behind MyChart — offered a finding that may foreshadow where enterprise AI adoption is truly heading. \"Over half of our use of Claude Code is by non-developer roles across the company,\" Hain said, describing how support and implementation staff had adopted the tool in ways the company never anticipated. Hain also described a deliberate trust-building strategy: Epic&#x27;s first AI capability was a medical record summarization that included links to the underlying source material, giving clinicians the ability to verify and build confidence before the company introduced more autonomous agent capabilities.A year of Claude Code and MCP adoption explains why this moment feels differentTuesday&#x27;s announcements cannot be understood in isolation. They are essentially the culmination of a year in which Anthropic transformed itself from a research-focused AI lab into a company with genuine enterprise distribution and developer ecosystem gravity.The trajectory began with Claude Code, which Jensen noted had taken coding use cases \"from assisting on tiny tasks to AI writing 90 or sometimes even 100% of the code, with enterprises shipping in weeks what once took many quarters.\" But the deeper structural shift was the adoption of MCP — the Model Context Protocol — which has become the connective tissue allowing Claude to reach into and act upon data across an organization&#x27;s entire technology stack. Where previous AI tools were constrained to the information users manually fed them, MCP-connected Claude can pull context from Slack threads, Google Drive documents, CRM records, and financial systems simultaneously. This is what makes the plugin architecture announced Tuesday fundamentally different from earlier chatbot-style enterprise AI: it turns Claude into a reasoning layer that sits across an organization&#x27;s existing infrastructure rather than alongside it.The implications for the broader AI industry are profound. Anthropic is effectively building a platform play — private plugin marketplaces, portable file-based plugins, and an expanding library of MCP connectors — that echoes the ecosystem strategies of earlier platform giants like Salesforce and Microsoft. The difference is velocity: Anthropic is compressing into months the kind of ecosystem development that previously took years. The company&#x27;s willingness to ship sector-specific plugin templates for investment banking, equity research, and wealth management alongside general-purpose tools signals that it sees no bright line between platform and application, between enabling partners and competing with them.This strategic ambiguity is precisely what has spooked Wall Street. IBM shares suffered their worst single-day loss since October 2000 — down nearly 13.2% — on Monday after Anthropic published a blog post about using Claude Code to modernize COBOL, the decades-old programming language that runs on IBM&#x27;s mainframe systems. Enterprise software stocks had already been under heavy pressure since the initial Cowork announcement on January 30, with companies like ServiceNow, Salesforce, Snowflake, Intuit, and Thomson Reuters all experiencing steep declines. Cybersecurity companies tumbled after the company unveiled Claude Code Security on February 20.Yet Tuesday&#x27;s event triggered a partial reversal that revealed something important about how markets are processing AI disruption. Companies named as Anthropic partners and integration targets — Salesforce, DocuSign, LegalZoom, Thomson Reuters, FactSet — all rallied, some sharply. Thomson Reuters surged more than 11%. The market appears to be drawing a new distinction: companies integrated into Anthropic&#x27;s ecosystem may benefit, while those standing outside it face existential risk.Anthropic&#x27;s own economist warns that AI&#x27;s impact will be uneven — and fastPeter McCrory, Anthropic&#x27;s head of economics, presented data from the Anthropic Economic Index that offered a sober counterweight to the event&#x27;s product optimism. Using privacy-preserving methods to analyze how people and businesses use Claude, McCrory&#x27;s team has tracked AI&#x27;s diffusion across more than 150 countries and every US state.The headline finding is striking: a year ago, roughly a third of all US jobs had at least a quarter of their associated tasks appearing in Claude usage data. That figure has now risen to approximately one in every two jobs. \"The scope of impact is broadening out throughout the economy as the tools and as the technology becomes more capable,\" McCrory said. He characterized AI as a \"general purpose technology\" in the economic sense — meaning virtually no facet of the economy will be unaffected.McCrory drew a critical distinction between automation, where Claude simply executes a task, and augmentation, where it collaborates with a human on more complex work. When businesses embed Claude through the API, he noted, \"we see overwhelmingly Claude is being embedded in automated ways\" — a pattern consistent with how transformative technologies have historically diffused through the economy.On the question of job displacement, McCrory was measured but direct. He noted that \"roles that typically require more years of schooling have the largest productivity or efficiency gains,\" suggesting a dynamic economists call skill-biased technical change. He expressed concern about \"jobs that are pure implementation\" — citing data entry workers and technical writers as examples where Claude is already being used for tasks central to those occupations. But he emphasized that no evidence of widespread labor displacement has materialized yet, and pointed to forthcoming research that would introduce methodology for monitoring whether highly exposed workers are beginning to experience it.His advice to enterprise leaders cut to the heart of the organizational challenge. \"It might not just be about fundamental capabilities of the model,\" McCrory said. \"Do you have the right sort of data ecosystem, data infrastructure to provide the right information at the right time?\" If the knowledge Claude needs to execute a sophisticated task exists only in a coworker&#x27;s head, he argued, \"that&#x27;s not a technical problem, per se. That&#x27;s an organizational problem.\"The question every enterprise leader is now asking — and why no one has the answer yetJensen described a concept Anthropic calls \"the thinking divide\" — the growing gap between organizations that embed AI across employees, processes, and products simultaneously, and those that treat it as a point solution. The companies on the right side of that divide, she argued, will compound their advantage over time. Those on the wrong side \"will find themselves falling further and further behind.\"Whether Anthropic ultimately functions as the rising tide that lifts the enterprise software ecosystem or the wave that swamps it remains genuinely uncertain. The same event that triggered a rally in shares of Anthropic&#x27;s named partners has also accelerated a broader reckoning for legacy software companies that cannot yet articulate how they fit into an AI-native world. McCrory, the economist, counseled humility. \"Capabilities are moving very, very quickly,\" he said. \"It might represent an innovation in the method of innovation. So it&#x27;s not just making us better at the things that we do — it&#x27;s helping us discover new ways to do things.\"Thomson Reuters&#x27; Haske perhaps put it most practically. \"As leaders, we all have to get personally involved and personally invested in using the tools,\" he said. \"We&#x27;ve got to move fast. This environment is changing quickly. We cannot afford to get left behind.\"A Fortune 10 CIO recently told Jensen that enterprises would need to fit a decade of innovation into the next few years. The CIO smiled and said: \"We&#x27;re going to do it in one with you.\" Whether that confidence proves prescient or premature, one thing is clear from Tuesday&#x27;s event — the window for figuring it out is closing faster than most boardrooms realize.",
          "content": "Anthropic opened its virtual \"Briefing: Enterprise Agents\" event on Tuesday with a provocation. Kate Jensen, the company&#x27;s head of Americas, told viewers that the hype around enterprise AI agents in 2025 \"turned out to be mostly premature,\" with many pilots failing to reach production. \"It wasn&#x27;t a failure of effort, it was a failure of approach, and it&#x27;s something we heard directly from our customers,\" Jensen said.The implicit promise: Anthropic has figured out the right approach, and it starts with the playbook that made Claude Code one of the most consequential developer tools of the past year. \"In 2025 Claude transformed how developers work, and in 2026 it will do the same for knowledge work,\" Jensen said. \"The magic behind Claude Code is simple. When you can delegate hard challenges, you can focus on the work that actually matters. Cowork brings that same power to knowledge workers.\"That framing is central to understanding what Anthropic announced on Tuesday. The company rolled out a sweeping set of enterprise capabilities for Claude Cowork, the AI productivity platform it first released in research preview in January. Scott White, head of product for Claude Enterprise, described the ambition plainly during the keynote: \"Cowork makes it possible for Claude to deliver polished, near final work. It goes beyond drafts and suggestions — actual completed projects and deliverables.\"The product updates are dense but consequential. Enterprise administrators can now build private plugin marketplaces tailored to their organizations, connecting to private GitHub repositories as plugin sources and controlling which plugins employees can access. Anthropic introduced new prebuilt plugin templates spanning HR, design, engineering, operations, financial analysis, investment banking, equity research, private equity, and wealth management. The company also shipped new MCP connectors for Google Drive, Google Calendar, Gmail, DocuSign, Apollo, Clay, Outreach, SimilarWeb, MSCI, LegalZoom, FactSet, WordPress, and Harvey — dramatically extending Claude&#x27;s reach into the software ecosystem that enterprises already use. And Claude can now pass context seamlessly between Cowork, Excel, and PowerPoint, including across multiple files, without requiring users to restart when switching applications.White emphasized that the system is designed to feel native to each organization rather than generic. \"We&#x27;ve heard loud and clear from enterprises — you want Claude to work the way that your company works, not just Claude for legal, but Cowork for legal at your company,\" he said. \"That&#x27;s exactly what today&#x27;s launches deliver.\"Real-world results from Spotify, Novo Nordisk, and Salesforce hint at what&#x27;s comingTo ground the product announcements in measurable outcomes, Anthropic showcased three enterprise deployments that illustrate both the scale and the variety of impact the company claims Claude can deliver.At Spotify, engineers had long struggled with code migrations — the slow, manual work of updating and modernizing code across thousands of services. Jensen explained that after integrating Claude directly into the system Spotify&#x27;s engineers use daily, \"any engineer can kick off a large-scale migration just by describing what they need in plain English.\" The company reports up to a 90% reduction in engineering time, over 650 AI-generated code changes shipped per month, and roughly half of all Spotify updates now flowing through the system.At Novo Nordisk, the pharmaceutical giant built an AI-powered platform called NovoScribe with Claude as its intelligence layer, targeting the grueling process of producing regulatory documentation for new medicines. Staff writers had previously averaged just over two reports per year. After deploying Claude, Jensen said, \"documentation creation went from 10 plus weeks to 10 minutes. That&#x27;s a 95% reduction in resources for verification checks. Medicines are reaching patients faster.\" Jensen also noted that Novo Nordisk used Claude Code to build the platform itself, enabling contributions from non-engineers — their digitalization strategy director, who holds a PhD in molecular biology rather than engineering, now prototypes features using natural language. \"A team of 11 is operating like a team many times its size,\" Jensen said.Salesforce, meanwhile, uses Claude models to help power AI in Slack, reporting a 96% satisfaction rate for tools like its Slack bot and saving customers an estimated 97 minutes per week through summarization and recap features. The partnership reflects Anthropic&#x27;s broader ecosystem strategy: Jensen described the companies featured at the event as \"Claude partners and domain experts with the data and trusted relationships that make Claude work in the real world.\"Enterprise leaders reveal the messy reality behind AI transformationPerhaps the most illuminating segment of the event was a panel discussion featuring executives from Thomson Reuters, the New York Stock Exchange, and Epic, who provided candid assessments of AI&#x27;s enterprise reality that went well beyond the polished case studies.Sridhar Masam, CTO of the New York Stock Exchange, described his organization as \"rewiring our engineering process\" with Claude Code and building internal AI agents using the Claude Agent SDK that can take instructions from a Jira ticket all the way to a committed piece of code. But he also identified fundamental shifts in how leaders must think. \"The accountability is shifting,\" he said. \"Traditionally, we are so used to building deterministic platforms. You write code requirements and build. And now, with AI being probabilistic, the accountability doesn&#x27;t end when the project goes live, but on a daily basis, monitoring the behavior and outcomes.\" He described a new paradigm beyond \"buy versus build\" — what he called \"assembly,\" the practice of combining multiple models, multiple vendors, platforms, data, and internal capabilities into solutions. And he noted that highly regulated industries must shift \"from risk avoidance to risk calibration,\" because simply avoiding AI is no longer a competitive option.Steve Haske from Thomson Reuters, whose Co-Counsel product has reached a million users, was frank about the gap between what the technology can do and what organizations are ready for. \"The tools are in many senses ahead of the change management,\" he said. \"A general counsel&#x27;s office, a law firm, a tax and accounting firm, an audit firm, need to rewire the processes to be able to take advantage of the benefits that the tools provide. And I think it&#x27;s 18 months away before that sort of change management catches up with the standard of the tool.\" He also stressed an \"ironclad guarantee\" to Co-Counsel customers that \"their input will not be part of our AI output,\" and urged enterprise leaders to be \"feverish\" about protecting institutional intellectual property.Seth Hain from Epic — the healthcare technology company behind MyChart — offered a finding that may foreshadow where enterprise AI adoption is truly heading. \"Over half of our use of Claude Code is by non-developer roles across the company,\" Hain said, describing how support and implementation staff had adopted the tool in ways the company never anticipated. Hain also described a deliberate trust-building strategy: Epic&#x27;s first AI capability was a medical record summarization that included links to the underlying source material, giving clinicians the ability to verify and build confidence before the company introduced more autonomous agent capabilities.A year of Claude Code and MCP adoption explains why this moment feels differentTuesday&#x27;s announcements cannot be understood in isolation. They are essentially the culmination of a year in which Anthropic transformed itself from a research-focused AI lab into a company with genuine enterprise distribution and developer ecosystem gravity.The trajectory began with Claude Code, which Jensen noted had taken coding use cases \"from assisting on tiny tasks to AI writing 90 or sometimes even 100% of the code, with enterprises shipping in weeks what once took many quarters.\" But the deeper structural shift was the adoption of MCP — the Model Context Protocol — which has become the connective tissue allowing Claude to reach into and act upon data across an organization&#x27;s entire technology stack. Where previous AI tools were constrained to the information users manually fed them, MCP-connected Claude can pull context from Slack threads, Google Drive documents, CRM records, and financial systems simultaneously. This is what makes the plugin architecture announced Tuesday fundamentally different from earlier chatbot-style enterprise AI: it turns Claude into a reasoning layer that sits across an organization&#x27;s existing infrastructure rather than alongside it.The implications for the broader AI industry are profound. Anthropic is effectively building a platform play — private plugin marketplaces, portable file-based plugins, and an expanding library of MCP connectors — that echoes the ecosystem strategies of earlier platform giants like Salesforce and Microsoft. The difference is velocity: Anthropic is compressing into months the kind of ecosystem development that previously took years. The company&#x27;s willingness to ship sector-specific plugin templates for investment banking, equity research, and wealth management alongside general-purpose tools signals that it sees no bright line between platform and application, between enabling partners and competing with them.This strategic ambiguity is precisely what has spooked Wall Street. IBM shares suffered their worst single-day loss since October 2000 — down nearly 13.2% — on Monday after Anthropic published a blog post about using Claude Code to modernize COBOL, the decades-old programming language that runs on IBM&#x27;s mainframe systems. Enterprise software stocks had already been under heavy pressure since the initial Cowork announcement on January 30, with companies like ServiceNow, Salesforce, Snowflake, Intuit, and Thomson Reuters all experiencing steep declines. Cybersecurity companies tumbled after the company unveiled Claude Code Security on February 20.Yet Tuesday&#x27;s event triggered a partial reversal that revealed something important about how markets are processing AI disruption. Companies named as Anthropic partners and integration targets — Salesforce, DocuSign, LegalZoom, Thomson Reuters, FactSet — all rallied, some sharply. Thomson Reuters surged more than 11%. The market appears to be drawing a new distinction: companies integrated into Anthropic&#x27;s ecosystem may benefit, while those standing outside it face existential risk.Anthropic&#x27;s own economist warns that AI&#x27;s impact will be uneven — and fastPeter McCrory, Anthropic&#x27;s head of economics, presented data from the Anthropic Economic Index that offered a sober counterweight to the event&#x27;s product optimism. Using privacy-preserving methods to analyze how people and businesses use Claude, McCrory&#x27;s team has tracked AI&#x27;s diffusion across more than 150 countries and every US state.The headline finding is striking: a year ago, roughly a third of all US jobs had at least a quarter of their associated tasks appearing in Claude usage data. That figure has now risen to approximately one in every two jobs. \"The scope of impact is broadening out throughout the economy as the tools and as the technology becomes more capable,\" McCrory said. He characterized AI as a \"general purpose technology\" in the economic sense — meaning virtually no facet of the economy will be unaffected.McCrory drew a critical distinction between automation, where Claude simply executes a task, and augmentation, where it collaborates with a human on more complex work. When businesses embed Claude through the API, he noted, \"we see overwhelmingly Claude is being embedded in automated ways\" — a pattern consistent with how transformative technologies have historically diffused through the economy.On the question of job displacement, McCrory was measured but direct. He noted that \"roles that typically require more years of schooling have the largest productivity or efficiency gains,\" suggesting a dynamic economists call skill-biased technical change. He expressed concern about \"jobs that are pure implementation\" — citing data entry workers and technical writers as examples where Claude is already being used for tasks central to those occupations. But he emphasized that no evidence of widespread labor displacement has materialized yet, and pointed to forthcoming research that would introduce methodology for monitoring whether highly exposed workers are beginning to experience it.His advice to enterprise leaders cut to the heart of the organizational challenge. \"It might not just be about fundamental capabilities of the model,\" McCrory said. \"Do you have the right sort of data ecosystem, data infrastructure to provide the right information at the right time?\" If the knowledge Claude needs to execute a sophisticated task exists only in a coworker&#x27;s head, he argued, \"that&#x27;s not a technical problem, per se. That&#x27;s an organizational problem.\"The question every enterprise leader is now asking — and why no one has the answer yetJensen described a concept Anthropic calls \"the thinking divide\" — the growing gap between organizations that embed AI across employees, processes, and products simultaneously, and those that treat it as a point solution. The companies on the right side of that divide, she argued, will compound their advantage over time. Those on the wrong side \"will find themselves falling further and further behind.\"Whether Anthropic ultimately functions as the rising tide that lifts the enterprise software ecosystem or the wave that swamps it remains genuinely uncertain. The same event that triggered a rally in shares of Anthropic&#x27;s named partners has also accelerated a broader reckoning for legacy software companies that cannot yet articulate how they fit into an AI-native world. McCrory, the economist, counseled humility. \"Capabilities are moving very, very quickly,\" he said. \"It might represent an innovation in the method of innovation. So it&#x27;s not just making us better at the things that we do — it&#x27;s helping us discover new ways to do things.\"Thomson Reuters&#x27; Haske perhaps put it most practically. \"As leaders, we all have to get personally involved and personally invested in using the tools,\" he said. \"We&#x27;ve got to move fast. This environment is changing quickly. We cannot afford to get left behind.\"A Fortune 10 CIO recently told Jensen that enterprises would need to fit a decade of innovation into the next few years. The CIO smiled and said: \"We&#x27;re going to do it in one with you.\" Whether that confidence proves prescient or premature, one thing is clear from Tuesday&#x27;s event — the window for figuring it out is closing faster than most boardrooms realize.",
          "feed_position": 1,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/4Go7ccNVAocm7JfJv7mITS/06d5aee9b462e58c0c16348e6762866f/nuneybits_Vector_art_of_a_burnt_orange_tidal_wave_crashing_over_8c717943-4488-4e3e-a47f-c35dbac7fc46.webp?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/technology/the-era-of-human-web-search-is-over-nimble-launches-agentic-search-platform",
          "published_at": "Tue, 24 Feb 2026 22:47:00 GMT",
          "title": "The era of human web search is over: Nimble launches Agentic Search Platform for enterprises boasting 99% accuracy",
          "standfirst": "Web Search has already been disrupted by AI — just take a look at how readily Google is presenting users with AI Overviews (summaries of search results) at the top of their results pages, how Bing early on integrated OpenAI&#x27;s GPT models, and how Perplexity continues to build on its own AI-driven web search platform and browsers. Nimble announced the launch of its Agentic Search Platform, a system designed to transform the public web into trusted, decision-grade data for AI systems and business workflows. The launch is supported by $47 million in Series B financing led by Norwest, with participation from Databricks Ventures and others, bringing the company&#x27;s total funding to $75 million.The initiative addresses a fundamental bottleneck in the current AI era: while large language models (LLMs) are becoming more sophisticated, they often reason over incomplete or unverifiable external information. Nimble’s platform aims to eliminate this \"guesswork gap\" by providing a governed data layer that searches, navigates, and validates live internet data in real time.In an exclusive interview with VentureBeat, Nimble co-founder and CEO Uri Knorovich reflected on the early skepticism regarding his vision of a machine-centric internet. \"Whenever we started this company, and the first time I went to investors, I told them the web is built for humans, but machines are going to be the first citizens of the web,\" Knorovich recalled. He noted that while initial reactions labeled him as \"too visionary,\" the current reality of AI adoption has validated his thesis.Technology: Coordinated multi-agent architectureThe core of Nimble’s solution is a proprietary distributed architecture that orchestrates specialized agents to perform tasks traditionally handled by human researchers or brittle web scrapers. According to the company&#x27;s infrastructure documentation, the process is broken down into five distinct layers:Headless browser and browsing agents: These layers manage the initial interaction with a target domain, navigating complex site structures as a human would.Parsing agents: These agents interpret the page content, identifying relevant data elements across various formats.Data processing agents: This layer aggregates, filters, and cleans noisy internet data to produce specific, structured answers.Validation agents: The final step involves verifying the results to ensure accuracy and completeness before delivery.Unlike standard search engines designed for consumer link-clicking, this architecture uses multimodal and reasoning capabilities from frontier models—including those from OpenAI, Anthropic, and Meta—to control real browsers. This allows Nimble to navigate dynamic layouts and cross-check results, producing auditable data outputs rather than simple text summaries.A new paradigm: &#x27;The web is built for humans, but machines are the first citizens&#x27;Knorovich points out that the scale of AI interaction with the web is fundamentally different from human behavior. \"We, as humans, search for maybe three or five options before we making decisions... but every day, Nimble perform more than 3.2 million interactions in the web,\" he explained. This sheer volume of billions of monthly searches represents a programmatic shift that requires a new type of infrastructure.The bottleneck for enterprises today, according to Knorovich, isn&#x27;t the intelligence of the models, but the quality of the data they can access. \"Agents are the headlines, and accurate and reliable web search is the bottleneck,\" he stated.Nimble vs. consumer search: Precision over speedKnorovich explicitly differentiates Nimble from general-purpose tools like Google or consumer AI search assistants. While Google has built a search experience for consumers that is optimized for speed and finding a local restaurant, enterprises require high-scale, high-accuracy results to make multi-million dollar decisions.\"General purpose web search tool are great to have a general answers, such as who is the wife Leo missing,\" Knorovich remarked during the interview. \"But enterprises need deep, granular data, and they need to have the ability to control the search filters, to control the regulation, to control what is a trusted source\". Unlike consumer AI modes that may summarize a Reddit post or high-level news, Nimble provides \"street-level\" information that can be stored directly in an enterprise system of record.Product: Bridging the no-code and developer divideThe Agentic Search Platform is delivered through two primary interfaces designed for enterprise scalability:Web search agents: A no-code AI workflow builder that enables business teams to describe the data they need and receive structured data streams without writing a line of code.Web tools SDK: A suite of APIs for builders to search, extract, and crawl the web directly from their code. This includes specialized tools like the /crawl API for mapping entire domains and the /map API for creating domain trees.The platform is built to deliver data with greater than 99% accuracy — meaning fewer than 1% inaccurate or hallucinated data for the total contents of each search result returned — and a latency of 1-2 milliseconds per request. It integrates natively with major data environments, allowing users to stream clean data directly into Databricks, Snowflake, S3, or Microsoft Fabric.During the interview, Knorovich emphasized that Nimble is designed to be model-agnostic, working seamlessly with state-of-the-art models from OpenAI, Anthropic, and Google&#x27;s Gemini. This flexibility allows companies to use Nimble alongside their existing tech stack, whether they are running models in the cloud or on-premise for high-security environments like healthcare or banking.Case studies: Accuracy in actionKnorovich provided several real-world examples of how this \"street-level\" data impacts professional workflows. For instance, a real estate broker looking to expand into a new territory doesn&#x27;t need a high-level summary from a general-purpose AI. \"If you want to know what&#x27;s happening in the commercial real estate in Atlanta... you&#x27;re not looking for search that&#x27;s optimized for the millisecond,\" Knorovich explained. \"You&#x27;re looking for street-level, neighborhood-level information... data that you can actually see on a table or download to Excel\".Another use case involves major financial institutions utilizing Nimble for \"know your customer\" (KYC) processes. By deploying an autonomous search agent, banks can cross-reference multiple public reports, criminal records, and address verifications to build a complete profile of a client before they even enter the building. The goal, Knorovich noted, is to provide the \"external truth\" that exists outside an organization&#x27;s internal firewalls.Enterprise licensing and complianceNimble differentiates itself from legacy scraping tools through a rigorous focus on governance and trust. The platform is \"compliant-by-design,\" holding certifications for SOC2 Type II, GDPR, CCPA, and HIPAA.Pricing is structured to support both experimental startups and high-scale enterprise operations, aligned with the volume and depth of data retrieved. \"Pricing should be aligned with the value that the user is getting... therefore, we are pricing by the amount of searches that you&#x27;re running,\" Knorovich said.Search and answer APIs: Standard search inputs cost $1 per 1,000, while the \"Answer\" function—which provides reasoning based on search results—costs $4 per 1,000.Managed services: For larger organizations, managed tiers start at $2,000 per month (Startup) and scale to $15,000 per month (Professional) for unlimited agents and priority support.Proxy access: A network of over 1 million residential proxies is available starting at $7.50 per GBCommunity and user reactionsThe transition to agentic search has already been operationalized by several Fortune 500 companies and AI-native startups:Julie Averill, former CIO at Lululemon, stated that pricing intelligence which once took weeks to review can now be responded to in minutes by putting control in the hands of an agent.Itamar Fridman, CEO and Co-founder of Qodo, noted that the platform’s scalability was \"crucial in developing more robust and reliable AI systems\" by feeding LLMs with high-quality data.Dennis Irorere, Data Engineer at TripAdvisor, highlighted that the platform simplifies the extraction of structured data from complex sources, which he described as \"transformative\" for his role.Grips Intelligence reported scaling to over 45,000 e-commerce sites using Nimble’s Web API to deliver real-time pricing and product data.Alta utilizes the platform to power millions of AI-driven go-to-market workflows daily, reporting 3–4× deeper context and >99% reliabilitySeries B to accelerate multi-agent web search and data governanceThe $47 million Series B funding announced alongside the platform will be used to accelerate research in multi-agent web search and further develop the governed data layer. The round saw participation from a wide ecosystem of investors, including Target Global, Square Peg, Hetz Ventures, Slow Ventures, R-Squared Ventures, J-Ventures, and InvestInData.Andrew Ferguson, VP of Databricks Ventures, noted that Nimble complements their Data Intelligence Platform by providing a \"real-time web data layer\" that extends workflows beyond internal sources. This strategic investment signals a shift in the industry toward prioritizing \"external truth\" to ground mission-critical AI applications.For Knorovich, the future of the web belongs to programmatic interaction. \"Programmatic web search is where we are building towards,\" he concluded. By moving away from legacy data vendors and brittle scrapers, Nimble aims to provide the real-time structure needed for AI to act with confidence in the real world.",
          "content": "Web Search has already been disrupted by AI — just take a look at how readily Google is presenting users with AI Overviews (summaries of search results) at the top of their results pages, how Bing early on integrated OpenAI&#x27;s GPT models, and how Perplexity continues to build on its own AI-driven web search platform and browsers. Nimble announced the launch of its Agentic Search Platform, a system designed to transform the public web into trusted, decision-grade data for AI systems and business workflows. The launch is supported by $47 million in Series B financing led by Norwest, with participation from Databricks Ventures and others, bringing the company&#x27;s total funding to $75 million.The initiative addresses a fundamental bottleneck in the current AI era: while large language models (LLMs) are becoming more sophisticated, they often reason over incomplete or unverifiable external information. Nimble’s platform aims to eliminate this \"guesswork gap\" by providing a governed data layer that searches, navigates, and validates live internet data in real time.In an exclusive interview with VentureBeat, Nimble co-founder and CEO Uri Knorovich reflected on the early skepticism regarding his vision of a machine-centric internet. \"Whenever we started this company, and the first time I went to investors, I told them the web is built for humans, but machines are going to be the first citizens of the web,\" Knorovich recalled. He noted that while initial reactions labeled him as \"too visionary,\" the current reality of AI adoption has validated his thesis.Technology: Coordinated multi-agent architectureThe core of Nimble’s solution is a proprietary distributed architecture that orchestrates specialized agents to perform tasks traditionally handled by human researchers or brittle web scrapers. According to the company&#x27;s infrastructure documentation, the process is broken down into five distinct layers:Headless browser and browsing agents: These layers manage the initial interaction with a target domain, navigating complex site structures as a human would.Parsing agents: These agents interpret the page content, identifying relevant data elements across various formats.Data processing agents: This layer aggregates, filters, and cleans noisy internet data to produce specific, structured answers.Validation agents: The final step involves verifying the results to ensure accuracy and completeness before delivery.Unlike standard search engines designed for consumer link-clicking, this architecture uses multimodal and reasoning capabilities from frontier models—including those from OpenAI, Anthropic, and Meta—to control real browsers. This allows Nimble to navigate dynamic layouts and cross-check results, producing auditable data outputs rather than simple text summaries.A new paradigm: &#x27;The web is built for humans, but machines are the first citizens&#x27;Knorovich points out that the scale of AI interaction with the web is fundamentally different from human behavior. \"We, as humans, search for maybe three or five options before we making decisions... but every day, Nimble perform more than 3.2 million interactions in the web,\" he explained. This sheer volume of billions of monthly searches represents a programmatic shift that requires a new type of infrastructure.The bottleneck for enterprises today, according to Knorovich, isn&#x27;t the intelligence of the models, but the quality of the data they can access. \"Agents are the headlines, and accurate and reliable web search is the bottleneck,\" he stated.Nimble vs. consumer search: Precision over speedKnorovich explicitly differentiates Nimble from general-purpose tools like Google or consumer AI search assistants. While Google has built a search experience for consumers that is optimized for speed and finding a local restaurant, enterprises require high-scale, high-accuracy results to make multi-million dollar decisions.\"General purpose web search tool are great to have a general answers, such as who is the wife Leo missing,\" Knorovich remarked during the interview. \"But enterprises need deep, granular data, and they need to have the ability to control the search filters, to control the regulation, to control what is a trusted source\". Unlike consumer AI modes that may summarize a Reddit post or high-level news, Nimble provides \"street-level\" information that can be stored directly in an enterprise system of record.Product: Bridging the no-code and developer divideThe Agentic Search Platform is delivered through two primary interfaces designed for enterprise scalability:Web search agents: A no-code AI workflow builder that enables business teams to describe the data they need and receive structured data streams without writing a line of code.Web tools SDK: A suite of APIs for builders to search, extract, and crawl the web directly from their code. This includes specialized tools like the /crawl API for mapping entire domains and the /map API for creating domain trees.The platform is built to deliver data with greater than 99% accuracy — meaning fewer than 1% inaccurate or hallucinated data for the total contents of each search result returned — and a latency of 1-2 milliseconds per request. It integrates natively with major data environments, allowing users to stream clean data directly into Databricks, Snowflake, S3, or Microsoft Fabric.During the interview, Knorovich emphasized that Nimble is designed to be model-agnostic, working seamlessly with state-of-the-art models from OpenAI, Anthropic, and Google&#x27;s Gemini. This flexibility allows companies to use Nimble alongside their existing tech stack, whether they are running models in the cloud or on-premise for high-security environments like healthcare or banking.Case studies: Accuracy in actionKnorovich provided several real-world examples of how this \"street-level\" data impacts professional workflows. For instance, a real estate broker looking to expand into a new territory doesn&#x27;t need a high-level summary from a general-purpose AI. \"If you want to know what&#x27;s happening in the commercial real estate in Atlanta... you&#x27;re not looking for search that&#x27;s optimized for the millisecond,\" Knorovich explained. \"You&#x27;re looking for street-level, neighborhood-level information... data that you can actually see on a table or download to Excel\".Another use case involves major financial institutions utilizing Nimble for \"know your customer\" (KYC) processes. By deploying an autonomous search agent, banks can cross-reference multiple public reports, criminal records, and address verifications to build a complete profile of a client before they even enter the building. The goal, Knorovich noted, is to provide the \"external truth\" that exists outside an organization&#x27;s internal firewalls.Enterprise licensing and complianceNimble differentiates itself from legacy scraping tools through a rigorous focus on governance and trust. The platform is \"compliant-by-design,\" holding certifications for SOC2 Type II, GDPR, CCPA, and HIPAA.Pricing is structured to support both experimental startups and high-scale enterprise operations, aligned with the volume and depth of data retrieved. \"Pricing should be aligned with the value that the user is getting... therefore, we are pricing by the amount of searches that you&#x27;re running,\" Knorovich said.Search and answer APIs: Standard search inputs cost $1 per 1,000, while the \"Answer\" function—which provides reasoning based on search results—costs $4 per 1,000.Managed services: For larger organizations, managed tiers start at $2,000 per month (Startup) and scale to $15,000 per month (Professional) for unlimited agents and priority support.Proxy access: A network of over 1 million residential proxies is available starting at $7.50 per GBCommunity and user reactionsThe transition to agentic search has already been operationalized by several Fortune 500 companies and AI-native startups:Julie Averill, former CIO at Lululemon, stated that pricing intelligence which once took weeks to review can now be responded to in minutes by putting control in the hands of an agent.Itamar Fridman, CEO and Co-founder of Qodo, noted that the platform’s scalability was \"crucial in developing more robust and reliable AI systems\" by feeding LLMs with high-quality data.Dennis Irorere, Data Engineer at TripAdvisor, highlighted that the platform simplifies the extraction of structured data from complex sources, which he described as \"transformative\" for his role.Grips Intelligence reported scaling to over 45,000 e-commerce sites using Nimble’s Web API to deliver real-time pricing and product data.Alta utilizes the platform to power millions of AI-driven go-to-market workflows daily, reporting 3–4× deeper context and >99% reliabilitySeries B to accelerate multi-agent web search and data governanceThe $47 million Series B funding announced alongside the platform will be used to accelerate research in multi-agent web search and further develop the governed data layer. The round saw participation from a wide ecosystem of investors, including Target Global, Square Peg, Hetz Ventures, Slow Ventures, R-Squared Ventures, J-Ventures, and InvestInData.Andrew Ferguson, VP of Databricks Ventures, noted that Nimble complements their Data Intelligence Platform by providing a \"real-time web data layer\" that extends workflows beyond internal sources. This strategic investment signals a shift in the industry toward prioritizing \"external truth\" to ground mission-critical AI applications.For Knorovich, the future of the web belongs to programmatic interaction. \"Programmatic web search is where we are building towards,\" he concluded. By moving away from legacy data vendors and brittle scrapers, Nimble aims to provide the real-time structure needed for AI to act with confidence in the real world.",
          "feed_position": 2,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/3o6l2UtvJR37cFjPT1ym9N/a39fd40138caaa58bc91479e9b4a42e9/QS4VRiXDpntQnkiIa4eHW_Evg9gSvJ.jpg?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/technology/ibms-usd40b-stock-wipeout-is-built-on-a-misconception-translating-cobol-isnt",
          "published_at": "Tue, 24 Feb 2026 22:00:00 GMT",
          "title": "IBM's $40B stock wipeout is built on a misconception: Translating COBOL isn't the same as modernizing it",
          "standfirst": "On Tuesday, Anthropic published tools that let Claude read, analyze and translate legacy COBOL into modern languages like Java and Python. By the end of the trading day, investors had wiped roughly $40 billion from IBM&#x27;s market cap — the company&#x27;s biggest single-day drop in 25 years — pricing the announcement as an existential threat to IBM&#x27;s mainframe business.The reaction was swift. It was also built on a fundamental misreading of why enterprises run mainframes in the first place.IBM&#x27;s COBOL is 66 years old. It was designed in 1959, runs on IBM mainframes, and continues to power transaction processing systems with an estimated 250 billion lines of COBOL in active production, according to the Open Mainframe Project.The engineers who wrote it are retiring; the ones replacing them largely cannot read it. For decades, that skills gap has been one of enterprise IT&#x27;s most expensive unsolved problems — and one IBM has been working to fix with AI since at least 2023, when it launched watsonx Code Assistant for Z to help migrate COBOL to modern Java.Claude Code, Anthropic says, can now analyze entire codebases, map hidden dependencies, and generate working translations of code that most engineers today cannot read. For enterprises running COBOL on distributed platforms — Windows, Linux and other non-mainframe environments — that capability is genuinely useful and increasingly practical.The actual barrier was never technical\"Modernizing COBOL has been a technically solved problem for a while,\" Matt Brasier, analyst at Gartner, told VentureBeat. \"The real problem is that the costs of modernization are high and the ROI is low.\"Amazon and Google have been offering AI-powered COBOL migration tools for years. AWS Transform and a comparable Google Cloud Platform service both targeted the same problem: reducing friction for customers looking to move mainframe workloads to the cloud.\"This is basically one more source of competition,\" Raj Joshi, senior vice president at Moody&#x27;s Ratings, told VentureBeat. \"IBM has always lived in a very competitive domain. On the margin, this thing is basically negative, no question about that. There&#x27;s one more powerful competitor. But IBM has coexisted with these threats.\"Steve McDowell, chief analyst at NAND Research, cuts to the structural argument: \"Applications don&#x27;t run on mainframes because they&#x27;re written in COBOL,\" he said. \"They run on mainframes because mainframes deliver a class of determinism, scalable compute and reliability that general purpose servers can&#x27;t match.\"The issue runs deeper than market positioning. \"GenAI tools are helpful, but their non-deterministic nature means the resulting code is not consistent — the same operation will be implemented in different ways in different parts of the code,\" Brasier said. \"Leading tools combine deterministic and non-deterministic approaches. None of this solves the ROI problem, though.\"What COBOL translation leaves unsolved\"Translating COBOL is the easy part,\" IBM communications director Steven Tomasco told VentureBeat. \"The real work is data architecture redesign, runtime replacement, transaction processing integrity, and hardware-accelerated performance built over decades of tight software and hardware coupling. That is the problem IBM has spent decades learning to solve, and AI is the most powerful tool we have ever had to do it.\"According to IBM, Royal Bank of Canada, the National Organization for Social Insurance and ANZ Bank have all used watsonx Code Assistant for Z to accelerate modernization of COBOL code without moving off IBM Z.That does not mean Anthropic has no competitive foothold. For enterprises running COBOL outside the mainframe — on distributed systems, Windows and Linux environments — Claude Code enters a space where IBM&#x27;s vertical integration is less of an advantage. \"IBM understands mainframe technology at a level that others can&#x27;t match. If I&#x27;m only looking at COBOL, I&#x27;m using IBM&#x27;s watsonx,\" McDowell said. \"Anthropic, however, has a broader footprint within a lot of development teams, where a single vendor makes it worthwhile.\"What enterprise buyers should actually doSenior data and infrastructure engineers will spend the next few weeks fielding questions from executives who saw the headlines and assumed the hard problem just got solved. It did not. \"It&#x27;s COBOL, but there are numerous applications tied to it,\" Joshi said. \"It&#x27;s not like you transform millions of lines and somehow you are ready to go to cloud. It&#x27;s a massive risk assessment, dependencies and all those things.\"The more useful question for buyers is whether this week&#x27;s noise creates an opening. Braiser thinks it does. \"They should use the resulting board-level and shareholder discussions to review postponed modernization initiatives and see if any of them now have ROI,\" Brasier said.McDowell was blunt on the competitive question. \"Will Anthropic take business from IBM&#x27;s tool? Yes, of course,\" he said. \"But I&#x27;d be surprised if that tool was making significant revenue for IBM.\"Chirag Mehta, analyst at Constellation Research, cautioned that IT leaders should not react emotionally or rewrite strategy overnight. \"Treat this as a reason to run a small, bounded pilot to measure outcomes, not as a reason to rip and replace vendors,\" Mehta told VentureBeat. Mehta suggests that enterprises pick one well-scoped application slice or workflow with clear inputs and outputs, and evaluate approaches apples-to-apples: quality of dependency mapping, quality of recovered business logic documentation, test coverage and equivalence checks, performance and reliability regressions.In Mehta&#x27;s view, the bigger reminder is that modernization is more than converting code. The hard parts are extracting institutional knowledge, reworking processes and controls, change management, and containing operational risk in systems that cannot break. AI can compress the “analysis and translation” work, but it does not eliminate the governance and accountability burden.\"The teams that win will treat AI as an accelerator inside a disciplined modernization program, with measurable checkpoints and risk guardrails, not as a magic conversion button,\" Mehta said.",
          "content": "On Tuesday, Anthropic published tools that let Claude read, analyze and translate legacy COBOL into modern languages like Java and Python. By the end of the trading day, investors had wiped roughly $40 billion from IBM&#x27;s market cap — the company&#x27;s biggest single-day drop in 25 years — pricing the announcement as an existential threat to IBM&#x27;s mainframe business.The reaction was swift. It was also built on a fundamental misreading of why enterprises run mainframes in the first place.IBM&#x27;s COBOL is 66 years old. It was designed in 1959, runs on IBM mainframes, and continues to power transaction processing systems with an estimated 250 billion lines of COBOL in active production, according to the Open Mainframe Project.The engineers who wrote it are retiring; the ones replacing them largely cannot read it. For decades, that skills gap has been one of enterprise IT&#x27;s most expensive unsolved problems — and one IBM has been working to fix with AI since at least 2023, when it launched watsonx Code Assistant for Z to help migrate COBOL to modern Java.Claude Code, Anthropic says, can now analyze entire codebases, map hidden dependencies, and generate working translations of code that most engineers today cannot read. For enterprises running COBOL on distributed platforms — Windows, Linux and other non-mainframe environments — that capability is genuinely useful and increasingly practical.The actual barrier was never technical\"Modernizing COBOL has been a technically solved problem for a while,\" Matt Brasier, analyst at Gartner, told VentureBeat. \"The real problem is that the costs of modernization are high and the ROI is low.\"Amazon and Google have been offering AI-powered COBOL migration tools for years. AWS Transform and a comparable Google Cloud Platform service both targeted the same problem: reducing friction for customers looking to move mainframe workloads to the cloud.\"This is basically one more source of competition,\" Raj Joshi, senior vice president at Moody&#x27;s Ratings, told VentureBeat. \"IBM has always lived in a very competitive domain. On the margin, this thing is basically negative, no question about that. There&#x27;s one more powerful competitor. But IBM has coexisted with these threats.\"Steve McDowell, chief analyst at NAND Research, cuts to the structural argument: \"Applications don&#x27;t run on mainframes because they&#x27;re written in COBOL,\" he said. \"They run on mainframes because mainframes deliver a class of determinism, scalable compute and reliability that general purpose servers can&#x27;t match.\"The issue runs deeper than market positioning. \"GenAI tools are helpful, but their non-deterministic nature means the resulting code is not consistent — the same operation will be implemented in different ways in different parts of the code,\" Brasier said. \"Leading tools combine deterministic and non-deterministic approaches. None of this solves the ROI problem, though.\"What COBOL translation leaves unsolved\"Translating COBOL is the easy part,\" IBM communications director Steven Tomasco told VentureBeat. \"The real work is data architecture redesign, runtime replacement, transaction processing integrity, and hardware-accelerated performance built over decades of tight software and hardware coupling. That is the problem IBM has spent decades learning to solve, and AI is the most powerful tool we have ever had to do it.\"According to IBM, Royal Bank of Canada, the National Organization for Social Insurance and ANZ Bank have all used watsonx Code Assistant for Z to accelerate modernization of COBOL code without moving off IBM Z.That does not mean Anthropic has no competitive foothold. For enterprises running COBOL outside the mainframe — on distributed systems, Windows and Linux environments — Claude Code enters a space where IBM&#x27;s vertical integration is less of an advantage. \"IBM understands mainframe technology at a level that others can&#x27;t match. If I&#x27;m only looking at COBOL, I&#x27;m using IBM&#x27;s watsonx,\" McDowell said. \"Anthropic, however, has a broader footprint within a lot of development teams, where a single vendor makes it worthwhile.\"What enterprise buyers should actually doSenior data and infrastructure engineers will spend the next few weeks fielding questions from executives who saw the headlines and assumed the hard problem just got solved. It did not. \"It&#x27;s COBOL, but there are numerous applications tied to it,\" Joshi said. \"It&#x27;s not like you transform millions of lines and somehow you are ready to go to cloud. It&#x27;s a massive risk assessment, dependencies and all those things.\"The more useful question for buyers is whether this week&#x27;s noise creates an opening. Braiser thinks it does. \"They should use the resulting board-level and shareholder discussions to review postponed modernization initiatives and see if any of them now have ROI,\" Brasier said.McDowell was blunt on the competitive question. \"Will Anthropic take business from IBM&#x27;s tool? Yes, of course,\" he said. \"But I&#x27;d be surprised if that tool was making significant revenue for IBM.\"Chirag Mehta, analyst at Constellation Research, cautioned that IT leaders should not react emotionally or rewrite strategy overnight. \"Treat this as a reason to run a small, bounded pilot to measure outcomes, not as a reason to rip and replace vendors,\" Mehta told VentureBeat. Mehta suggests that enterprises pick one well-scoped application slice or workflow with clear inputs and outputs, and evaluate approaches apples-to-apples: quality of dependency mapping, quality of recovered business logic documentation, test coverage and equivalence checks, performance and reliability regressions.In Mehta&#x27;s view, the bigger reminder is that modernization is more than converting code. The hard parts are extracting institutional knowledge, reworking processes and controls, change management, and containing operational risk in systems that cannot break. AI can compress the “analysis and translation” work, but it does not eliminate the governance and accountability burden.\"The teams that win will treat AI as an accelerator inside a disciplined modernization program, with measurable checkpoints and risk guardrails, not as a magic conversion button,\" Mehta said.",
          "feed_position": 3,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/4Qj7GhG4v8CA6gtk59bDeh/190132c73d9aad5ecc01ba41b990666c/IBM_and_Anthropic_wrestling_with_the_COBOL-smk1.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/smartphones/iphone-fold-rumors-everything-we-know-right-now-including-the-leaked-design-upgrades-price-and-more-130000733.html",
          "published_at": "Tue, 24 Feb 2026 18:16:43 +0000",
          "title": "iPhone Fold rumors: Everything we know right now, including the leaked design, upgrades, price and more",
          "standfirst": "Apple still hasn’t revealed a foldable iPhone, but the steady drip of leaks suggests the project is moving closer to reality. Over the past few months, analysts and supply-chain watchers have continued to fill in key details, with most reports still pointing to a launch sometime in the second half of 2026. While Apple hasn’t confirmed anything publicly, the overall picture is starting to look more consistent.As always, plans for unreleased Apple hardware can change at any time. Features may shift, timelines can slip and some prototypes may never ship. Even so, recent reporting gives us the clearest sense yet of how Apple’s first foldable could take shape and where it might fit in the broader iPhone lineup.Below, we’ve rounded up the most credible rumors so far, and we’ll keep this guide updated as new details emerge.When could the iPhone Fold launch?Rumors of a foldable iPhone date back as far as 2017, but more recent reporting suggests Apple has finally locked onto a realistic window. Most sources now point to fall 2026, likely alongside the iPhone 18 lineup, with some supply-chain hints suggesting mass production could begin in mid-2026 if development stays on track.Mark Gurman has gone back and forth on timing, initially suggesting Apple could launch “as early as 2026,” before later writing that the device would ship at the end of 2026 and sell primarily in 2027. Analyst Ming-Chi Kuo has also repeatedly cited the second half of 2026 as Apple’s target.Some reports still claim the project could slip into 2027 if Apple runs into manufacturing or durability issues, particularly around the hinge or display. Given Apple’s history of delaying products that it feels aren’t ready, that remains a real possibility.What will the iPhone Fold look like?Current consensus suggests Apple has settled on a book-style foldable design, similar to Samsung’s Galaxy Z Fold series, rather than a clamshell flip phone.When unfolded, the iPhone Fold is expected to resemble a small tablet like the iPad mini (8.3 inches). Based on the rumor mill, though, the iPhone Fold may be a touch smaller, with an internal display measuring around 7.7 to 7.8 inches. When closed, it should function like a conventional smartphone, with an outer display in the 5.5-inch range.CAD leaks and alleged case-maker molds suggest the device may be shorter and wider than a standard iPhone when folded, creating a squarer footprint that better matches the aspect ratio of the inner display. Several reports have also pointed to the iPhone Air as a potential preview of Apple’s foldable design work, with its unusually thin chassis widely interpreted as a look at what one half of a future foldable iPhone could resemble.If that theory holds, it could help explain the Fold’s rumored dimensions. Thickness is expected to land around 4.5 to 4.8mm when unfolded, according to analyst Ming-Chi Kuo, putting it in a similar range to the iPhone Air, and roughly 9 to 9.5mm when folded, depending on the final hinge design and internal layering.iPhone 17 Pro, iPhone AirEngadgetDisplay and the crease questionThe display is arguably the biggest challenge for any foldable phone, and it’s an area where Apple appears to have invested years of development.Multiple reports say Apple will rely on Samsung Display as its primary supplier. At CES 2026, Samsung showcased a new crease-less foldable OLED panel, which several sources — including Bloomberg — suggested could be the same technology Apple plans to use.According to these reports, the panel combines a flexible OLED with a laser-drilled metal support plate that disperses stress when folding. The goal is a display with a nearly invisible crease, something Apple reportedly considers essential before entering the foldable market.If Apple does use this panel, it would mark a notable improvement over current foldables, which still show visible creasing under certain lighting conditions.Cameras and biometricsCamera rumors suggest Apple is planning a four-camera setup. That may include:Two rear cameras (main and ultra-wide, both rumored at 48MP)One punch-hole camera on the outer displayOne under-display camera on the inner screenSeveral sources claim Apple will avoid Face ID entirely on the iPhone Fold. Instead, it’s expected to rely on Touch ID built into the power button, similar to recent iPad models. This would allow Apple to keep both displays free of notches or Dynamic Island cutouts.Under-display camera technology has historically produced lower image quality, but a rumored 24MP sensor would be a significant step up compared to existing foldables, which typically use much lower-resolution sensors.iPhone Fold’s hinge and materialsThe hinge is another area where Apple may diverge from competitors. Multiple reports claim Apple will use Liquidmetal, which is a long-standing trade name for a metallic glass alloy the company has previously used in smaller components. While often referred to as “liquid metal” or “Liquid Metal” in reports, Liquidmetal is the branding Apple has historically associated with the material.Liquidmetal is said to be stronger and more resistant to deformation than titanium, while remaining relatively lightweight. If accurate, this could help improve long-term durability and reduce wear on the foldable display.Leaks from Jon Prosser also reference a metal plate beneath the display that works in tandem with the hinge to minimize creasing — a claim that aligns with reporting from Korean and Chinese supply-chain sources.Battery and other components Battery life is another potential differentiator. According to Ming-Chi Kuo and multiple Asian supply-chain reports, Apple is testing high-density battery cells in the 5,000 to 5,800mAh range.That would make it the largest battery ever used in an iPhone, and competitive with (or larger than) batteries in current Android foldables. The device is also expected to use a future A-series chip and Apple’s in-house modem, with some reports pointing specifically to a next-generation C2 modem as part of Apple’s broader push to reduce reliance on Qualcomm.PriceNone of this will come cheap, that’s for certain. Nearly every report agrees that the iPhone Fold will be Apple’s most expensive iPhone ever.Estimates currently place the price between $2,000 and $2,500 in the US. Bloomberg has said the price will be “at least $2,000,” while other analysts have narrowed the likely range to around $2,100 and $2,300. That positions the iPhone Fold well above the iPhone Pro Max and closer to Apple’s high-end Macs and iPads.Despite years of rumors, there’s still plenty that remains unclear. Apple hasn’t confirmed the name “iPhone Fold,” final dimensions, software features or how iOS would adapt to a folding form factor. Durability, repairability and long-term reliability are also open questions. For now, the safest assumption is that Apple is taking its time and that many of these details could still change before launch. This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/iphone-fold-rumors-everything-we-know-right-now-including-the-leaked-design-upgrades-price-and-more-130000733.html?src=rss",
          "content": "Apple still hasn’t revealed a foldable iPhone, but the steady drip of leaks suggests the project is moving closer to reality. Over the past few months, analysts and supply-chain watchers have continued to fill in key details, with most reports still pointing to a launch sometime in the second half of 2026. While Apple hasn’t confirmed anything publicly, the overall picture is starting to look more consistent.As always, plans for unreleased Apple hardware can change at any time. Features may shift, timelines can slip and some prototypes may never ship. Even so, recent reporting gives us the clearest sense yet of how Apple’s first foldable could take shape and where it might fit in the broader iPhone lineup.Below, we’ve rounded up the most credible rumors so far, and we’ll keep this guide updated as new details emerge.When could the iPhone Fold launch?Rumors of a foldable iPhone date back as far as 2017, but more recent reporting suggests Apple has finally locked onto a realistic window. Most sources now point to fall 2026, likely alongside the iPhone 18 lineup, with some supply-chain hints suggesting mass production could begin in mid-2026 if development stays on track.Mark Gurman has gone back and forth on timing, initially suggesting Apple could launch “as early as 2026,” before later writing that the device would ship at the end of 2026 and sell primarily in 2027. Analyst Ming-Chi Kuo has also repeatedly cited the second half of 2026 as Apple’s target.Some reports still claim the project could slip into 2027 if Apple runs into manufacturing or durability issues, particularly around the hinge or display. Given Apple’s history of delaying products that it feels aren’t ready, that remains a real possibility.What will the iPhone Fold look like?Current consensus suggests Apple has settled on a book-style foldable design, similar to Samsung’s Galaxy Z Fold series, rather than a clamshell flip phone.When unfolded, the iPhone Fold is expected to resemble a small tablet like the iPad mini (8.3 inches). Based on the rumor mill, though, the iPhone Fold may be a touch smaller, with an internal display measuring around 7.7 to 7.8 inches. When closed, it should function like a conventional smartphone, with an outer display in the 5.5-inch range.CAD leaks and alleged case-maker molds suggest the device may be shorter and wider than a standard iPhone when folded, creating a squarer footprint that better matches the aspect ratio of the inner display. Several reports have also pointed to the iPhone Air as a potential preview of Apple’s foldable design work, with its unusually thin chassis widely interpreted as a look at what one half of a future foldable iPhone could resemble.If that theory holds, it could help explain the Fold’s rumored dimensions. Thickness is expected to land around 4.5 to 4.8mm when unfolded, according to analyst Ming-Chi Kuo, putting it in a similar range to the iPhone Air, and roughly 9 to 9.5mm when folded, depending on the final hinge design and internal layering.iPhone 17 Pro, iPhone AirEngadgetDisplay and the crease questionThe display is arguably the biggest challenge for any foldable phone, and it’s an area where Apple appears to have invested years of development.Multiple reports say Apple will rely on Samsung Display as its primary supplier. At CES 2026, Samsung showcased a new crease-less foldable OLED panel, which several sources — including Bloomberg — suggested could be the same technology Apple plans to use.According to these reports, the panel combines a flexible OLED with a laser-drilled metal support plate that disperses stress when folding. The goal is a display with a nearly invisible crease, something Apple reportedly considers essential before entering the foldable market.If Apple does use this panel, it would mark a notable improvement over current foldables, which still show visible creasing under certain lighting conditions.Cameras and biometricsCamera rumors suggest Apple is planning a four-camera setup. That may include:Two rear cameras (main and ultra-wide, both rumored at 48MP)One punch-hole camera on the outer displayOne under-display camera on the inner screenSeveral sources claim Apple will avoid Face ID entirely on the iPhone Fold. Instead, it’s expected to rely on Touch ID built into the power button, similar to recent iPad models. This would allow Apple to keep both displays free of notches or Dynamic Island cutouts.Under-display camera technology has historically produced lower image quality, but a rumored 24MP sensor would be a significant step up compared to existing foldables, which typically use much lower-resolution sensors.iPhone Fold’s hinge and materialsThe hinge is another area where Apple may diverge from competitors. Multiple reports claim Apple will use Liquidmetal, which is a long-standing trade name for a metallic glass alloy the company has previously used in smaller components. While often referred to as “liquid metal” or “Liquid Metal” in reports, Liquidmetal is the branding Apple has historically associated with the material.Liquidmetal is said to be stronger and more resistant to deformation than titanium, while remaining relatively lightweight. If accurate, this could help improve long-term durability and reduce wear on the foldable display.Leaks from Jon Prosser also reference a metal plate beneath the display that works in tandem with the hinge to minimize creasing — a claim that aligns with reporting from Korean and Chinese supply-chain sources.Battery and other components Battery life is another potential differentiator. According to Ming-Chi Kuo and multiple Asian supply-chain reports, Apple is testing high-density battery cells in the 5,000 to 5,800mAh range.That would make it the largest battery ever used in an iPhone, and competitive with (or larger than) batteries in current Android foldables. The device is also expected to use a future A-series chip and Apple’s in-house modem, with some reports pointing specifically to a next-generation C2 modem as part of Apple’s broader push to reduce reliance on Qualcomm.PriceNone of this will come cheap, that’s for certain. Nearly every report agrees that the iPhone Fold will be Apple’s most expensive iPhone ever.Estimates currently place the price between $2,000 and $2,500 in the US. Bloomberg has said the price will be “at least $2,000,” while other analysts have narrowed the likely range to around $2,100 and $2,300. That positions the iPhone Fold well above the iPhone Pro Max and closer to Apple’s high-end Macs and iPads.Despite years of rumors, there’s still plenty that remains unclear. Apple hasn’t confirmed the name “iPhone Fold,” final dimensions, software features or how iOS would adapt to a folding form factor. Durability, repairability and long-term reliability are also open questions. For now, the safest assumption is that Apple is taking its time and that many of these details could still change before launch. This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/iphone-fold-rumors-everything-we-know-right-now-including-the-leaked-design-upgrades-price-and-more-130000733.html?src=rss",
          "feed_position": 13,
          "image_url": "https://media-mbst-pub-ue1.s3.amazonaws.com/creatr-uploaded-images/2025-09/a476c2e0-9780-11f0-bd4b-d87caa240702"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/smartphones/samsung-galaxy-unpacked-2026-the-galaxy-s26-series-ai-and-other-products-we-might-see-on-february-25-130000135.html",
          "published_at": "Tue, 24 Feb 2026 15:48:57 +0000",
          "title": "Samsung Galaxy Unpacked 2026: The Galaxy S26 series, AI and other products we might see on February 25",
          "standfirst": "Samsung’s 2025 was filled with new foldables, an ultra-thin new form factor and the launch of Google's XR platform. After making some announcements at CES 2026, the company has announced its first Galaxy Unpacked of the year will take place on February 25, where it is expected to introduce the Galaxy S26 lineup. Official invites have been shared, but actual information on what devices are arriving then is still not completely confirmed. But as usual, we know a lot about what’s expected at Unpacked.Engadget will be covering Galaxy Unpacked live from San Francisco tomorrow, and we'll most likely have hands-on coverage of Samsung's new smartphones soon after they're announced. While we wait for the full details, here's everything we expect Samsung will introduce at the first Galaxy Unpacked event of 2026.When is Unpacked 2026 taking place?According to the official invite that Samsung shared on February 10, Unpacked will happen on February 25, 2026 in San Francisco. The keynote will start at 10AM PT (1PM ET) and be livestreamed on Samsung.com, as well as the company’s newsroom and YouTube channel. The announcement on February 10 also said this launch will mark “a new phase in the era of AI as intelligence becomes truly personal and adaptive.” It’s not a lot to go on, since we’ve heard a version of this from various companies over the last few years, but at least we won’t be shocked when we hear more about AI in just about two weeks.Galaxy S26, S26+ and S26 UltraSamsung Galaxy S25 Ultra hands-on photoPhoto by Sam Rutherford/EngadgetSamsung's restrained approach to updating its phones will likely continue with the Galaxy S26. Based on leaked images of the new lineup, the company is not expected to radically reinvent the look of the Galaxy S26, Galaxy S26+ or Galaxy S26 Ultra, and instead will stick with a similar design to what it used on the Galaxy S25. The phones will have a flat front screen and frame, with rounded corners and cameras housed in a vertical pill-shaped plateau on the back. Unlike Apple's move from the iPhone 16 Pro to the iPhone 17 Pro, the biggest difference here will likely be internal components like the screens, chips and camera sensors Samsung uses.Qualcomm's new Snapdragon 8 Elite Gen 5 chip is expected to be in all Samsung Galaxy S26 phones, though Korean news site Yonhap News reports Samsung's relatively new Exynos 2600 chip could be used in some phones in the lineup depending on the region, a strategy Samsung has deployed in the past. Either way the new phones should be more performant than the previous generation, and in the case of the models with the Snapdragon 8 Elite Gen 5, particularly good at on-device AI processing.I have compiled the most accurate comprehensive parameter comparison of Galaxy S25, S25+ and Galaxy S26、 S26+. Which one do you want to buy? pic.twitter.com/aQpoSvYjOz— Ice Universe (@UniverseIce) November 29, 2025One notable difference between the Galaxy S26 and the Galaxy S25 could be the phone's screen. The new phone will reportedly feature a 6.3-inch FHD+ display according to specs shared by leaker Ice Universe, which makes it ever so slightly larger than the 6.2-inch display used on the Galaxy S25. The S26 will also allegedly come with 12GB of RAM, either 256GB or 512GB of storage and a slightly larger 4,300mAh battery. Samsung isn't changing the cameras on the entry-level phone, though: leaks suggest it'll feature the same 50-megapixel main camera, 12-megapixel ultrawide, 10-megapixel 3x telephoto and 12-megapixel selfie camera as the previous generation. Changes appear to be even more minor on the Galaxy S26+. Other than the new Snapdragon chip, the phone will reportedly feature the same 6.7-inch FHD+ screen, 4,900mAh battery, 12GB of RAM and the same camera array used on the base Galaxy S26.The difference between the Galaxy S26 Ultra and Galaxy S25 Ultra is reportedly a bit clearer. According to Android Headlines, the new phone's cameras will be slightly more raised, and stand out thanks to a new metallic finish. Samsung may also switch back to using an aluminum frame on the Galaxy S26 Ultra, after using titanium frames on both the Galaxy S24 and S25 Ultras. Most importantly, to make the phone actually support Qi2 rather than only technically work with the standard when a case is attached, rumors suggest Samsung will remove the S Pen digitizer layer in the phone and adopt a new method for accepting stylus input. It's not clear what that new method will actually be, but it could let the Galaxy S26 Ultra more easily work with Qi2 accessories without losing its stylus.Android Headlines also recently shared what appear to be full image renders of the S26 series, and they generally line up with what has already been rumored, leaked and reported so far. If these pictures are accurate, they give us a clearer look at the camera bump and two color variants of the S26 Ultra.Fans of magnets may continue to be disappointed by Samsung if the latest rumors are accurate. Despite the launch of the Qi 2 wireless charging standard adding support for convenient magnetic alignment years ago, Samsung has yet to bring that feature to its phones. Though the S-series have the higher speed charging rates that the spec enables, Nieuwemobiel.nl is reporting that, due to images it received of cases with magnetic rings, the S26 series likely won’t have built-in magnets. Samsung has made these cases to add the magnetic capability to its S-series in the past, and the existence of the images of these accessories lends weight to the idea that the company will continue this approach.Galaxy Buds 4Galaxy Buds 3 Pro in case.EngadgetSamsung released the Galaxy Buds 3 and 3 Pro in 2024, with a major redesign that brought them much more in line with Apple's AirPods. The Galaxy Buds 4 and Buds 4 Pro Samsung is rumored to be announcing soon won't necessarily change that, though they will feature a more compact case and less angular stems, according to leaked images from the Samsung Tips app.Support for head gestures to accept and decline calls, a feature Apple includes on the AirPods Pro 3 and AirPods 4, is also rumored to work on both versions of the new Galaxy Buds. SamMobile reports the Galaxy Buds 4 and 4 Pro may also ship with a new Ultra Wideband chip that will make them easier to find with Google's Find Hub network.Galaxy Z TrifoldYes, the TriFold has a crease, two in fact. But they still don't ruin the experience. Sam Rutherford for EngadgetSamsung announced the Galaxy Z TriFold in late 2025 without firm details of when the new smartphone-that-folds-into-a-tablet would be available in North America. That info came on January 27, when the company announced the TriFold would be available in the US on January 30, for a whopping $2,900. Considering we’ve already seen the device in person at CES 2026 and people are most likely to have had a chance to look at, if not buy the foldable for themselves by the time Unpacked rolls around, we don’t expect Samsung to spend too much time dwelling on it, if at all.Galaxy S26 EdgeAt just 5.8mm thick, the Samsung Galaxy S25 Edge is one of the thinnest smartphones ever made. Sam Rutherford for EngadgetWhen the Galaxy S25 Edge was announced in 2025, it seemed possible that Samsung could replace its \"Plus\" smartphone with a unique form factor, just like Apple has opted to do with the iPhone Air. There have been conflicting reports on the matter, but it seems like Samsung will not be doing that with the Galaxy S26 Edge.Instead, the smartphone will reportedly remain another option, much like foldables are for customers not swayed by Samsung's traditional smartphones. The Galaxy S26 Edge is rumored to feature a slightly different design than last year's model, according to Android Headlines, with a large rectangular camera plateau that's reminiscent of Google's Pixel phones, and the raised oval Apple used on the iPhone Air. Beyond that, the phone is also expected to be ever so slightly thinner at 5.5mm than the 5.8mm Galaxy S25 Edge.Bixby and other AI featuresSamsung already acts as a first place Google can show off new AI features for Android, but the company is reportedly exploring other AI partnerships, too. In June 2025, Bloomberg reported that Samsung was nearing a deal with Perplexity to integrate its AI-powered search engine across OneUI and its homegrown mobile browser. Perplexity already has a deal with Motorola on its Razr phones, so the only thing that would make a deal with Samsung unusual is the close relationship the company already has with Google.The company also accidentally announced a new version of its Bixby AI assistant, which will likely also be integrated with Perplexity and could serve as an alternative to Google Gemini. Both a new Bixby and a deeper integration with Perplexity seem like natural new software features to show off at Galaxy Unpacked.On February 17, Samsung teased some mobile AI photography features ahead of Unpacked. These expand the S-series’ existing image-editing tools by bringing the ability “to turn a photo from day to night in seconds, restore missing parts of objects in images, capture detailed photos in low light, and seamlessly merge multiple photos into a single, cohesive result.” A lot of these things are already possible in other photo-editing apps or even in the Google Photos app, but we’ll have to wait to see them in action on the S26 phones for more details on whether they’re different or more effective.The company continued to drip feed more teasers in the week leading up to Unpacked 2026, announcing just a few days later that it’s updated its Bixby assistant to be more conversational. Then, over the weekend, it shared that the S26 series will offer third-party AI agents within Galaxy AI, including Perplexity’s offering. It will allow for the devices to respond to the wake phrase “Hey Plex,” which is sure to be popular and not at all confusing to those who already use a similarly named media server and streaming app. Until we find out more at Unpacked 2026, it’s tricky to determine if and how effective these updates will be, so we’ll just have to be patient until we get the phones in our hands. Update, January 27 2026, 11:55AM ET: This story has been updated to reflect the latest news around the Galaxy Z TriFold’s price and availability in the US.Update, January 30 2026, 12:45PM ET: This story has been updated to include the latest leaks on the possible dates for Unpacked 2026.Update, February 02 2026, 11:30AM ET: This story has been updated to include the latest leaks with full image renders of the S26 trio of devices.Update, February 03 2026, 11:00AM ET: This story has been updated to include the latest leaks about the possible lack of magnetic support on the S26 series.Update, February 10 2026, 7:15PM ET: This story has been updated to include the official date of Galaxy Unpacked as Samsung announced it today. The intro was also edited to reflect that detail.Update, February 17 2026, 4:55PM ET: This story has been updated to add Samsung’s teaser about its upcoming mobile AI photography tools. The intro was also edited for timeliness.Update, February 24 2026, 10:45AM ET: This story has been updated to add Samsung’s recent updates about Bixby and Galaxy AI’s integration with Perplexity. The intro was also edited for timeliness.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/samsung-galaxy-unpacked-2026-the-galaxy-s26-series-ai-and-other-products-we-might-see-on-february-25-130000135.html?src=rss",
          "content": "Samsung’s 2025 was filled with new foldables, an ultra-thin new form factor and the launch of Google's XR platform. After making some announcements at CES 2026, the company has announced its first Galaxy Unpacked of the year will take place on February 25, where it is expected to introduce the Galaxy S26 lineup. Official invites have been shared, but actual information on what devices are arriving then is still not completely confirmed. But as usual, we know a lot about what’s expected at Unpacked.Engadget will be covering Galaxy Unpacked live from San Francisco tomorrow, and we'll most likely have hands-on coverage of Samsung's new smartphones soon after they're announced. While we wait for the full details, here's everything we expect Samsung will introduce at the first Galaxy Unpacked event of 2026.When is Unpacked 2026 taking place?According to the official invite that Samsung shared on February 10, Unpacked will happen on February 25, 2026 in San Francisco. The keynote will start at 10AM PT (1PM ET) and be livestreamed on Samsung.com, as well as the company’s newsroom and YouTube channel. The announcement on February 10 also said this launch will mark “a new phase in the era of AI as intelligence becomes truly personal and adaptive.” It’s not a lot to go on, since we’ve heard a version of this from various companies over the last few years, but at least we won’t be shocked when we hear more about AI in just about two weeks.Galaxy S26, S26+ and S26 UltraSamsung Galaxy S25 Ultra hands-on photoPhoto by Sam Rutherford/EngadgetSamsung's restrained approach to updating its phones will likely continue with the Galaxy S26. Based on leaked images of the new lineup, the company is not expected to radically reinvent the look of the Galaxy S26, Galaxy S26+ or Galaxy S26 Ultra, and instead will stick with a similar design to what it used on the Galaxy S25. The phones will have a flat front screen and frame, with rounded corners and cameras housed in a vertical pill-shaped plateau on the back. Unlike Apple's move from the iPhone 16 Pro to the iPhone 17 Pro, the biggest difference here will likely be internal components like the screens, chips and camera sensors Samsung uses.Qualcomm's new Snapdragon 8 Elite Gen 5 chip is expected to be in all Samsung Galaxy S26 phones, though Korean news site Yonhap News reports Samsung's relatively new Exynos 2600 chip could be used in some phones in the lineup depending on the region, a strategy Samsung has deployed in the past. Either way the new phones should be more performant than the previous generation, and in the case of the models with the Snapdragon 8 Elite Gen 5, particularly good at on-device AI processing.I have compiled the most accurate comprehensive parameter comparison of Galaxy S25, S25+ and Galaxy S26、 S26+. Which one do you want to buy? pic.twitter.com/aQpoSvYjOz— Ice Universe (@UniverseIce) November 29, 2025One notable difference between the Galaxy S26 and the Galaxy S25 could be the phone's screen. The new phone will reportedly feature a 6.3-inch FHD+ display according to specs shared by leaker Ice Universe, which makes it ever so slightly larger than the 6.2-inch display used on the Galaxy S25. The S26 will also allegedly come with 12GB of RAM, either 256GB or 512GB of storage and a slightly larger 4,300mAh battery. Samsung isn't changing the cameras on the entry-level phone, though: leaks suggest it'll feature the same 50-megapixel main camera, 12-megapixel ultrawide, 10-megapixel 3x telephoto and 12-megapixel selfie camera as the previous generation. Changes appear to be even more minor on the Galaxy S26+. Other than the new Snapdragon chip, the phone will reportedly feature the same 6.7-inch FHD+ screen, 4,900mAh battery, 12GB of RAM and the same camera array used on the base Galaxy S26.The difference between the Galaxy S26 Ultra and Galaxy S25 Ultra is reportedly a bit clearer. According to Android Headlines, the new phone's cameras will be slightly more raised, and stand out thanks to a new metallic finish. Samsung may also switch back to using an aluminum frame on the Galaxy S26 Ultra, after using titanium frames on both the Galaxy S24 and S25 Ultras. Most importantly, to make the phone actually support Qi2 rather than only technically work with the standard when a case is attached, rumors suggest Samsung will remove the S Pen digitizer layer in the phone and adopt a new method for accepting stylus input. It's not clear what that new method will actually be, but it could let the Galaxy S26 Ultra more easily work with Qi2 accessories without losing its stylus.Android Headlines also recently shared what appear to be full image renders of the S26 series, and they generally line up with what has already been rumored, leaked and reported so far. If these pictures are accurate, they give us a clearer look at the camera bump and two color variants of the S26 Ultra.Fans of magnets may continue to be disappointed by Samsung if the latest rumors are accurate. Despite the launch of the Qi 2 wireless charging standard adding support for convenient magnetic alignment years ago, Samsung has yet to bring that feature to its phones. Though the S-series have the higher speed charging rates that the spec enables, Nieuwemobiel.nl is reporting that, due to images it received of cases with magnetic rings, the S26 series likely won’t have built-in magnets. Samsung has made these cases to add the magnetic capability to its S-series in the past, and the existence of the images of these accessories lends weight to the idea that the company will continue this approach.Galaxy Buds 4Galaxy Buds 3 Pro in case.EngadgetSamsung released the Galaxy Buds 3 and 3 Pro in 2024, with a major redesign that brought them much more in line with Apple's AirPods. The Galaxy Buds 4 and Buds 4 Pro Samsung is rumored to be announcing soon won't necessarily change that, though they will feature a more compact case and less angular stems, according to leaked images from the Samsung Tips app.Support for head gestures to accept and decline calls, a feature Apple includes on the AirPods Pro 3 and AirPods 4, is also rumored to work on both versions of the new Galaxy Buds. SamMobile reports the Galaxy Buds 4 and 4 Pro may also ship with a new Ultra Wideband chip that will make them easier to find with Google's Find Hub network.Galaxy Z TrifoldYes, the TriFold has a crease, two in fact. But they still don't ruin the experience. Sam Rutherford for EngadgetSamsung announced the Galaxy Z TriFold in late 2025 without firm details of when the new smartphone-that-folds-into-a-tablet would be available in North America. That info came on January 27, when the company announced the TriFold would be available in the US on January 30, for a whopping $2,900. Considering we’ve already seen the device in person at CES 2026 and people are most likely to have had a chance to look at, if not buy the foldable for themselves by the time Unpacked rolls around, we don’t expect Samsung to spend too much time dwelling on it, if at all.Galaxy S26 EdgeAt just 5.8mm thick, the Samsung Galaxy S25 Edge is one of the thinnest smartphones ever made. Sam Rutherford for EngadgetWhen the Galaxy S25 Edge was announced in 2025, it seemed possible that Samsung could replace its \"Plus\" smartphone with a unique form factor, just like Apple has opted to do with the iPhone Air. There have been conflicting reports on the matter, but it seems like Samsung will not be doing that with the Galaxy S26 Edge.Instead, the smartphone will reportedly remain another option, much like foldables are for customers not swayed by Samsung's traditional smartphones. The Galaxy S26 Edge is rumored to feature a slightly different design than last year's model, according to Android Headlines, with a large rectangular camera plateau that's reminiscent of Google's Pixel phones, and the raised oval Apple used on the iPhone Air. Beyond that, the phone is also expected to be ever so slightly thinner at 5.5mm than the 5.8mm Galaxy S25 Edge.Bixby and other AI featuresSamsung already acts as a first place Google can show off new AI features for Android, but the company is reportedly exploring other AI partnerships, too. In June 2025, Bloomberg reported that Samsung was nearing a deal with Perplexity to integrate its AI-powered search engine across OneUI and its homegrown mobile browser. Perplexity already has a deal with Motorola on its Razr phones, so the only thing that would make a deal with Samsung unusual is the close relationship the company already has with Google.The company also accidentally announced a new version of its Bixby AI assistant, which will likely also be integrated with Perplexity and could serve as an alternative to Google Gemini. Both a new Bixby and a deeper integration with Perplexity seem like natural new software features to show off at Galaxy Unpacked.On February 17, Samsung teased some mobile AI photography features ahead of Unpacked. These expand the S-series’ existing image-editing tools by bringing the ability “to turn a photo from day to night in seconds, restore missing parts of objects in images, capture detailed photos in low light, and seamlessly merge multiple photos into a single, cohesive result.” A lot of these things are already possible in other photo-editing apps or even in the Google Photos app, but we’ll have to wait to see them in action on the S26 phones for more details on whether they’re different or more effective.The company continued to drip feed more teasers in the week leading up to Unpacked 2026, announcing just a few days later that it’s updated its Bixby assistant to be more conversational. Then, over the weekend, it shared that the S26 series will offer third-party AI agents within Galaxy AI, including Perplexity’s offering. It will allow for the devices to respond to the wake phrase “Hey Plex,” which is sure to be popular and not at all confusing to those who already use a similarly named media server and streaming app. Until we find out more at Unpacked 2026, it’s tricky to determine if and how effective these updates will be, so we’ll just have to be patient until we get the phones in our hands. Update, January 27 2026, 11:55AM ET: This story has been updated to reflect the latest news around the Galaxy Z TriFold’s price and availability in the US.Update, January 30 2026, 12:45PM ET: This story has been updated to include the latest leaks on the possible dates for Unpacked 2026.Update, February 02 2026, 11:30AM ET: This story has been updated to include the latest leaks with full image renders of the S26 trio of devices.Update, February 03 2026, 11:00AM ET: This story has been updated to include the latest leaks about the possible lack of magnetic support on the S26 series.Update, February 10 2026, 7:15PM ET: This story has been updated to include the official date of Galaxy Unpacked as Samsung announced it today. The intro was also edited to reflect that detail.Update, February 17 2026, 4:55PM ET: This story has been updated to add Samsung’s teaser about its upcoming mobile AI photography tools. The intro was also edited for timeliness.Update, February 24 2026, 10:45AM ET: This story has been updated to add Samsung’s recent updates about Bixby and Galaxy AI’s integration with Perplexity. The intro was also edited for timeliness.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/samsung-galaxy-unpacked-2026-the-galaxy-s26-series-ai-and-other-products-we-might-see-on-february-25-130000135.html?src=rss",
          "feed_position": 21,
          "image_url": "https://media-mbst-pub-ue1.s3.amazonaws.com/creatr-uploaded-images/2025-01/59db82d0-d8d0-11ef-babd-deb856accfc5"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/kilo-launches-kiloclaw-allowing-anyone-to-deploy-hosted-openclaw-agents-into",
          "published_at": "Tue, 24 Feb 2026 15:00:00 GMT",
          "title": "Kilo launches KiloClaw, allowing anyone to deploy hosted OpenClaw agents into production in 60 seconds",
          "standfirst": "In the rapidly evolving landscape of artificial intelligence, the distance between a developer’s idea and a functioning agent has historically been measured in hours of configuration, dependency conflicts, and terminal-induced headaches. That friction point changed today. Kilo, the AI infrastructure startup backed by GitLab co-founder Sid Sijbrandij, has announced the general availability of KiloClaw, a fully managed service designed to deploy a production-ready OpenClaw agent in under 60 seconds.By eliminating the “SSH, Docker, and YAML” barriers that have gatekept high-end AI agents, Kilo is betting that the next phase of software development—often called \"vibe coding\"—will be defined not just by the quality of a model, but by the reliability of the infrastructure that hosts it.Technology: Re-engineering the agentic sandboxOpenClaw has emerged as a viral phenomenon, amassing over 161,000 GitHub stars by offering a capability that many proprietary tools lack: the ability to actually perform tasks—controlling browsers, managing files, and connecting to over 50 chat platforms like Telegram and Signal. However, as Kilo co-founder and CEO Scott Breitenother noted in an exclusive interview with VentureBeat, \"OpenClaw itself isn&#x27;t the hard part... getting it running is\".The technical architecture of KiloClaw is a departure from the \"Mac Mini on a desk\" model that many early adopters have relied on. Instead of requiring users to provision their own hardware or Virtual Private Servers (VPS), KiloClaw runs on a multi-tenant Virtual Machine (VM) architecture powered by Fly.io, a Chicago remote-first startup offering a developer-focused public cloud. This setup provides a level of isolation and security that is difficult for individual developers to replicate.\"What we&#x27;re doing is making KiloClaw the safest way to claw,\" Breitenother explained during the interview. \"We have a virtual machine that is a hosted OpenClaw instance, and we&#x27;re handling all that network security, sandboxing, and proxies that an enterprise company would require. We are essentially running multi-tenant, hosted OpenClaw\".To ensure security, KiloClaw utilizes two distinct proxies that sit outside the VM to manage traffic and protect the instance from the open internet. This prevents the common \"user error\" of accidentally exposing an agent’s API keys or leaving a local instance vulnerable to external attacks. \"It&#x27;s going to be better than [a local setup] in every single way,\" Breitenother asserted. \"If you were to set it up yourself, you&#x27;d probably miss a setting and end up with it accidentally on the internet or exposing an API key\".Product: The &#x27;mech suit&#x27; and the 3 am crashA primary pain point for OpenClaw users is the “3 am crash”—the tendency for locally hosted Node.js processes to die silently overnight without health monitoring or auto-restart capabilities. KiloClaw addresses this with built-in process monitoring and a cloud-native \"always on\" state.Unlike standard Kilo Code workflows, which spin up a terminal session only when a developer initiates a command, KiloClaw is persistent. \"KiloClaw is just running and listening,\" said Breitenother. \"It&#x27;s always on, waiting for your WhatsApp message or your Slack message. It has to be always on. That&#x27;s a different paradigm—always-on infrastructure to engage with\".This persistence allows for a suite of \"agentic affordances\" that Kilo calls an \"exoskeleton for the mind\":Scheduled automations: Users can set cron jobs for the agent to perform research, monitor repositories, or generate reports while the human user is offline.Persistent memory: Utilizing a \"Memory Bank\" system, the agent stores context in structured Markdown files within the repository, ensuring it retains the state of a project even if the underlying model is swapped.Cross-platform command: The agent can be triggered from Slack, Telegram, or a terminal, maintaining a unified execution state across all entry points.Breitenother highlighted the shift in the developer’s role during the interview: \"We&#x27;ve actually moved our engineers to be product owners. The time they freed up from writing code, they&#x27;re actually doing much more thinking. They&#x27;re setting the strategy for the product\".The “gateway” advantage: 500+ models, no lock-inA core component of the KiloClaw architecture is its native integration with the Kilo Gateway. While the original OpenClaw was initially tied closely to Anthropic&#x27;s models, KiloClaw allows users to toggle between over 500 different models from providers like OpenAI, Google, and MiniMax, as well as open-weight models like Qwen or GLM.\"Your preferred model today may not be the same—and honestly shouldn&#x27;t be the same—a month and a half from now,\" Breitenother said, emphasizing the speed of the industry. \"You may want different models for different tasks. Maybe you use Opus for something complex, or you switch to a tighter-budget open-weight model for routine work\".This flexibility is supported by Kilo&#x27;s transparent pricing model. The company offers \"zero markup\" on AI tokens, charging users the exact API rates provided by the model vendors. For power users, this is managed through Kilo Pass, a subscription tier that provides bonus credits (e.g., $199/month for $278.60 in credits) to subsidize high-volume agentic work.How to get started with KiloClaw right nowSign in or register: Navigate to the Kilo Code application on the web (desktop) at app.kilo.ai and sign in using your existing account. Kilo supports several authentication methods, including GitHub and Google OAuth.Create your instance: Select the \"Claw\" tab from the side navigation menu to access the KiloClaw dashboard. Click the \"Create Instance\" button to begin provisioning your agent (see image above for where to find it). Choose your model: Select a default AI model to power your agent from the dropdown menu. Users can choose from a wide array of options, including free (for the time being) models like MiniMax.Configure messaging channels (optional): During setup, you can optionally connect your agent to Discord, Telegram, or Slack and communicate with your KiloClaw agent directly over those channels — instead of on the Kilo Code website. But to move faster, you may skip this step and are always able to add these supported bot keys and configure these channels later in the instance settings.Provision and start: Click \"Create and Provision\" to set up your virtual machine. Once the instance is provisioned, click \"Start\" to boot the agent, which typically takes only a few secondVerify and access: Click the \"Open\" button to enter the OpenClaw interface. For security, you will need to click \"Access Code\" to generate a one-time verification token that validates your device for the first time.Begin vibe coding: Once verified, you can begin interacting with your agent directly in the chat interface. The agent will remain running 24/7 on a dedicated virtual machine, listening for commands across all connected platforms.According to Brendan O&#x27;Leary, Developer Relations at Kilo Code and former Developer Evangelist at GitLab, users unsure which model to select should consult PinchBench, an open-source benchmarking tool developed to evaluate models on 23 real-world agentic tasks, such as email sorting and blog post generation.Benchmarking the agentic era: the launch of PinchBench, a new open-source benchmarking suite specifically for Claw tasksTo help developers navigate the choice between 500+ models, Kilo has also released PinchBench, an open-source benchmark specifically for agentic workloads. While traditional benchmarks like MMLU or HumanEval test chat prompts in isolation, PinchBench tests agents on 23 real-world, multi-step tasks such as calendar management and multi-source research.The project was spearheaded by O&#x27;Leary, who noted during a demonstration that the benchmark was \"kind of inspired by... other little kind of fun benches\" like those created by developer YouTuber Theo Browne (@t3dotgg), CEO/Founder of Ping Labs. O&#x27;Leary explained that while existing benchmarks are often highly specialized, he wanted a way to \"benchmark the kind of things that we asked OpenClaw to do\". He has personally run the benchmark \"hundreds and hundreds of times against OpenClaw\" to ensure its accuracy, and taking a page out of Browne&#x27;s book (er, video playbook?), also launched a YouTube series to find out if KiloClaw can handle various tasks, entitled, fittingly, \"Will It Claw?\"To maintain high standards of evaluation for subjective tasks like writing blog posts, O&#x27;Leary designed a system where a high-end \"judge model\"—specifically Claude 4.5 Opus—is used to grade the output of other models. \"We actually have... not the model under test, but always Opus... [judge] the output of each of the models,\" O&#x27;Leary stated, adding that the judge model even provides specific notes on execution quality. The benchmark allows users to view a scatter plot comparing \"Cost to Intelligence,\" identifying which models offer the highest proficiency for the lowest price. This specific visualization is a priority for O&#x27;Leary, who noted it is \"my favorite graph for looking at models... how much do you spend versus how much is the success rate\". For those who prefer to host their own infrastructure, O&#x27;Leary has made the process entirely transparent, providing a \"skill file that people can download\" so they can \"benchmark their own OpenClaw instance\" independently\"We&#x27;re doing this work anyway to know which defaults we should recommend,\" Breitenother added in a separate interview. \"We decided to open source it because the individual developer shouldn&#x27;t have to think about which model is best for the job. We want to give people more and more information\". O&#x27;Leary expanded on this philosophy, describing the benchmark as being \"kind of like the Olympics in a lot of ways,\" where tasks range from \"very objectively graded\" to those requiring a more nuanced assessment.Industry context: Distinguishing from the growing OpenClaw family of offshoots KiloClaw enters a market increasingly crowded with OpenClaw variants. Projects like Nanoclaw have gained traction for being lightweight, while companies like Runlayer have targeted the enterprise \"Virtual Private Server\" niche.However, Kilo distinguishes itself by refusing to \"fork\" the code. \"It’s not a fork, and that’s what’s important,\" Breitenother stated. \"OpenClaw moves so quickly that we are hosting the actual OpenClaw [version]. It is literally OpenClaw on a really well-tuned, well-set-up managed virtual machine\". This ensures that as the core OpenClaw project evolves, KiloClaw users receive updates automatically without manual \"git pull\" operations.This \"open core\" philosophy extends to the licensing. While KiloClaw is a paid hosted service, the underlying Kilo CLI and core extensions remain MIT-licensed. This allows for community auditing—a critical feature for security-conscious enterprises.Conclusion: toward an agentic futureThe launch of KiloClaw marks a strategic move by Kilo to expand its user base beyond \"wonky\" developers to enterprise managers and non-technical professionals. By offering a \"one-click\" path to a production agent, the company is attempting to democratize the \"magical moments\" of AI.According to a release provided to VentureBeat by Kilo ahead of the launch, in the first two weeks, more than 3,500 developers joined the waitlist. These early adopters have been \"really pushing KiloClaw in all kinds of directions,\" using it to automate everything from Discord management to repository maintenance.\"Our mission is to build the best all-in-one AI work platform,\" Breitenother concluded. \"Whether you are a developer, a product manager, or a data engineer, we want all of these personas to experience the magic of the exoskeleton for the mind\".KiloClaw is available now, offering 7 days of free compute for all new users. With thousands of developers already having cleared the waitlist, the era of the managed AI agent appears to have arrived—no Mac Mini required.",
          "content": "In the rapidly evolving landscape of artificial intelligence, the distance between a developer’s idea and a functioning agent has historically been measured in hours of configuration, dependency conflicts, and terminal-induced headaches. That friction point changed today. Kilo, the AI infrastructure startup backed by GitLab co-founder Sid Sijbrandij, has announced the general availability of KiloClaw, a fully managed service designed to deploy a production-ready OpenClaw agent in under 60 seconds.By eliminating the “SSH, Docker, and YAML” barriers that have gatekept high-end AI agents, Kilo is betting that the next phase of software development—often called \"vibe coding\"—will be defined not just by the quality of a model, but by the reliability of the infrastructure that hosts it.Technology: Re-engineering the agentic sandboxOpenClaw has emerged as a viral phenomenon, amassing over 161,000 GitHub stars by offering a capability that many proprietary tools lack: the ability to actually perform tasks—controlling browsers, managing files, and connecting to over 50 chat platforms like Telegram and Signal. However, as Kilo co-founder and CEO Scott Breitenother noted in an exclusive interview with VentureBeat, \"OpenClaw itself isn&#x27;t the hard part... getting it running is\".The technical architecture of KiloClaw is a departure from the \"Mac Mini on a desk\" model that many early adopters have relied on. Instead of requiring users to provision their own hardware or Virtual Private Servers (VPS), KiloClaw runs on a multi-tenant Virtual Machine (VM) architecture powered by Fly.io, a Chicago remote-first startup offering a developer-focused public cloud. This setup provides a level of isolation and security that is difficult for individual developers to replicate.\"What we&#x27;re doing is making KiloClaw the safest way to claw,\" Breitenother explained during the interview. \"We have a virtual machine that is a hosted OpenClaw instance, and we&#x27;re handling all that network security, sandboxing, and proxies that an enterprise company would require. We are essentially running multi-tenant, hosted OpenClaw\".To ensure security, KiloClaw utilizes two distinct proxies that sit outside the VM to manage traffic and protect the instance from the open internet. This prevents the common \"user error\" of accidentally exposing an agent’s API keys or leaving a local instance vulnerable to external attacks. \"It&#x27;s going to be better than [a local setup] in every single way,\" Breitenother asserted. \"If you were to set it up yourself, you&#x27;d probably miss a setting and end up with it accidentally on the internet or exposing an API key\".Product: The &#x27;mech suit&#x27; and the 3 am crashA primary pain point for OpenClaw users is the “3 am crash”—the tendency for locally hosted Node.js processes to die silently overnight without health monitoring or auto-restart capabilities. KiloClaw addresses this with built-in process monitoring and a cloud-native \"always on\" state.Unlike standard Kilo Code workflows, which spin up a terminal session only when a developer initiates a command, KiloClaw is persistent. \"KiloClaw is just running and listening,\" said Breitenother. \"It&#x27;s always on, waiting for your WhatsApp message or your Slack message. It has to be always on. That&#x27;s a different paradigm—always-on infrastructure to engage with\".This persistence allows for a suite of \"agentic affordances\" that Kilo calls an \"exoskeleton for the mind\":Scheduled automations: Users can set cron jobs for the agent to perform research, monitor repositories, or generate reports while the human user is offline.Persistent memory: Utilizing a \"Memory Bank\" system, the agent stores context in structured Markdown files within the repository, ensuring it retains the state of a project even if the underlying model is swapped.Cross-platform command: The agent can be triggered from Slack, Telegram, or a terminal, maintaining a unified execution state across all entry points.Breitenother highlighted the shift in the developer’s role during the interview: \"We&#x27;ve actually moved our engineers to be product owners. The time they freed up from writing code, they&#x27;re actually doing much more thinking. They&#x27;re setting the strategy for the product\".The “gateway” advantage: 500+ models, no lock-inA core component of the KiloClaw architecture is its native integration with the Kilo Gateway. While the original OpenClaw was initially tied closely to Anthropic&#x27;s models, KiloClaw allows users to toggle between over 500 different models from providers like OpenAI, Google, and MiniMax, as well as open-weight models like Qwen or GLM.\"Your preferred model today may not be the same—and honestly shouldn&#x27;t be the same—a month and a half from now,\" Breitenother said, emphasizing the speed of the industry. \"You may want different models for different tasks. Maybe you use Opus for something complex, or you switch to a tighter-budget open-weight model for routine work\".This flexibility is supported by Kilo&#x27;s transparent pricing model. The company offers \"zero markup\" on AI tokens, charging users the exact API rates provided by the model vendors. For power users, this is managed through Kilo Pass, a subscription tier that provides bonus credits (e.g., $199/month for $278.60 in credits) to subsidize high-volume agentic work.How to get started with KiloClaw right nowSign in or register: Navigate to the Kilo Code application on the web (desktop) at app.kilo.ai and sign in using your existing account. Kilo supports several authentication methods, including GitHub and Google OAuth.Create your instance: Select the \"Claw\" tab from the side navigation menu to access the KiloClaw dashboard. Click the \"Create Instance\" button to begin provisioning your agent (see image above for where to find it). Choose your model: Select a default AI model to power your agent from the dropdown menu. Users can choose from a wide array of options, including free (for the time being) models like MiniMax.Configure messaging channels (optional): During setup, you can optionally connect your agent to Discord, Telegram, or Slack and communicate with your KiloClaw agent directly over those channels — instead of on the Kilo Code website. But to move faster, you may skip this step and are always able to add these supported bot keys and configure these channels later in the instance settings.Provision and start: Click \"Create and Provision\" to set up your virtual machine. Once the instance is provisioned, click \"Start\" to boot the agent, which typically takes only a few secondVerify and access: Click the \"Open\" button to enter the OpenClaw interface. For security, you will need to click \"Access Code\" to generate a one-time verification token that validates your device for the first time.Begin vibe coding: Once verified, you can begin interacting with your agent directly in the chat interface. The agent will remain running 24/7 on a dedicated virtual machine, listening for commands across all connected platforms.According to Brendan O&#x27;Leary, Developer Relations at Kilo Code and former Developer Evangelist at GitLab, users unsure which model to select should consult PinchBench, an open-source benchmarking tool developed to evaluate models on 23 real-world agentic tasks, such as email sorting and blog post generation.Benchmarking the agentic era: the launch of PinchBench, a new open-source benchmarking suite specifically for Claw tasksTo help developers navigate the choice between 500+ models, Kilo has also released PinchBench, an open-source benchmark specifically for agentic workloads. While traditional benchmarks like MMLU or HumanEval test chat prompts in isolation, PinchBench tests agents on 23 real-world, multi-step tasks such as calendar management and multi-source research.The project was spearheaded by O&#x27;Leary, who noted during a demonstration that the benchmark was \"kind of inspired by... other little kind of fun benches\" like those created by developer YouTuber Theo Browne (@t3dotgg), CEO/Founder of Ping Labs. O&#x27;Leary explained that while existing benchmarks are often highly specialized, he wanted a way to \"benchmark the kind of things that we asked OpenClaw to do\". He has personally run the benchmark \"hundreds and hundreds of times against OpenClaw\" to ensure its accuracy, and taking a page out of Browne&#x27;s book (er, video playbook?), also launched a YouTube series to find out if KiloClaw can handle various tasks, entitled, fittingly, \"Will It Claw?\"To maintain high standards of evaluation for subjective tasks like writing blog posts, O&#x27;Leary designed a system where a high-end \"judge model\"—specifically Claude 4.5 Opus—is used to grade the output of other models. \"We actually have... not the model under test, but always Opus... [judge] the output of each of the models,\" O&#x27;Leary stated, adding that the judge model even provides specific notes on execution quality. The benchmark allows users to view a scatter plot comparing \"Cost to Intelligence,\" identifying which models offer the highest proficiency for the lowest price. This specific visualization is a priority for O&#x27;Leary, who noted it is \"my favorite graph for looking at models... how much do you spend versus how much is the success rate\". For those who prefer to host their own infrastructure, O&#x27;Leary has made the process entirely transparent, providing a \"skill file that people can download\" so they can \"benchmark their own OpenClaw instance\" independently\"We&#x27;re doing this work anyway to know which defaults we should recommend,\" Breitenother added in a separate interview. \"We decided to open source it because the individual developer shouldn&#x27;t have to think about which model is best for the job. We want to give people more and more information\". O&#x27;Leary expanded on this philosophy, describing the benchmark as being \"kind of like the Olympics in a lot of ways,\" where tasks range from \"very objectively graded\" to those requiring a more nuanced assessment.Industry context: Distinguishing from the growing OpenClaw family of offshoots KiloClaw enters a market increasingly crowded with OpenClaw variants. Projects like Nanoclaw have gained traction for being lightweight, while companies like Runlayer have targeted the enterprise \"Virtual Private Server\" niche.However, Kilo distinguishes itself by refusing to \"fork\" the code. \"It’s not a fork, and that’s what’s important,\" Breitenother stated. \"OpenClaw moves so quickly that we are hosting the actual OpenClaw [version]. It is literally OpenClaw on a really well-tuned, well-set-up managed virtual machine\". This ensures that as the core OpenClaw project evolves, KiloClaw users receive updates automatically without manual \"git pull\" operations.This \"open core\" philosophy extends to the licensing. While KiloClaw is a paid hosted service, the underlying Kilo CLI and core extensions remain MIT-licensed. This allows for community auditing—a critical feature for security-conscious enterprises.Conclusion: toward an agentic futureThe launch of KiloClaw marks a strategic move by Kilo to expand its user base beyond \"wonky\" developers to enterprise managers and non-technical professionals. By offering a \"one-click\" path to a production agent, the company is attempting to democratize the \"magical moments\" of AI.According to a release provided to VentureBeat by Kilo ahead of the launch, in the first two weeks, more than 3,500 developers joined the waitlist. These early adopters have been \"really pushing KiloClaw in all kinds of directions,\" using it to automate everything from Discord management to repository maintenance.\"Our mission is to build the best all-in-one AI work platform,\" Breitenother concluded. \"Whether you are a developer, a product manager, or a data engineer, we want all of these personas to experience the magic of the exoskeleton for the mind\".KiloClaw is available now, offering 7 days of free compute for all new users. With thousands of developers already having cleared the waitlist, the era of the managed AI agent appears to have arrived—no Mac Mini required.",
          "feed_position": 4,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/1QiGGYPYc6tdMLKflF0YdI/17bfba48715e6ef3811d63ae394fb13b/iEcN1uWLBkQLckQpBDapb_9aWch0lT.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/home/kitchen-tech/seattle-ultrasonics-c-200-review-this-is-the-future-of-kitchen-knives-140000051.html",
          "published_at": "Tue, 24 Feb 2026 14:00:00 +0000",
          "title": "Seattle Ultrasonics C-200 review: This is the future of kitchen knives",
          "standfirst": "There’s a type of knife tech often seen in science fiction that revolves around vibrating a blade to increase its sharpness. We’ve seen examples of this in franchises like Star Wars (vibroblades), Evangelion (the prog knife), Dune (pulse-swords) and the Marvel universe (vibranium), but what might surprise you is that the underlying science is sound. By vibrating a cutting tool at high frequencies, not only do you reduce friction, you essentially turn the blade into a saw, as tiny oscillations enhance the inherent sharpness of a blade. However, up until recently, this tech largely only existed in fiction or for large companies that have the money to utilize the tech on an industrial scale. But that's changing in a big way for home cooks this year thanks to Seattle Ultrasonics, which is releasing the world's first ultrasonic chef's knife: the C-200. After chopping, smashing and cooking with it for about a month, I'm convinced that this is the future of kitchen knives. Design From afar, the C-200 looks a lot like a regular 8-inch chef's knife, but with a slightly more contemporary design. It features a three-layer san mai blade made from Japanese AUS-10 steel with a 13-degree edge angle per side (26 degrees total). However, upon closer inspection, you'll notice there are some features that seem a bit out of place on a premium knife. The first is that the C-200 doesn't have a full tang, which is the back end of a blade that ideally extends into the handle to provide added strength and durability. This is usually a major no-no, particularly on a $400 knife. However, when you consider that Seattle Ultrasonics needed somewhere to put its vibration tech, there really isn't any room for it other than inside the knife's grip. You won't be able to feel it, but pressing this button allows the C-200's blade to vibrate 30,000 times per second. Sam Rutherford for Engadget The knife's second quirk is that the back of the plastic handle features small indicator lights on either side, which is obviously a bit weird. Furthermore, the entire gray section can be removed to reveal a small 1,100mAh battery with an onboard USB-C port. Frankly, the presence of a battery in a knife is just kind of funky. But hey, the power to vibrate the knife has to come from somewhere because it definitely isn't being generated by your hands. And while Seattle Ultrasonics doesn't include a charging adapter or cable in the box, I don't mind because the company wisely took cues from the larger gadget industry and went with a power spec that's already widely in use. Honestly, I wish more kitchen tech makers would do the same. However, the knife's biggest oddity is the big orange button on the bottom of its handle. This is what you use to make the blade vibrate, which it does at 33kHz. It's positioned well so that it's easy to press regardless of whether you do a traditional pinch grip or if you're a bit more casual and prefer to hold the knife only using its handle. In the future, I can see this button becoming a touch-sensitive sensor, but for now, it's simple and effective. Here's a small selection of knives I own sorted by weight (from top to bottom) compared to the C200: 6-inch Kyocera ceramic knife (97 grams), MAC molybdenum steel chef's knife (110g), Furtif Evercut titanium carbide chef's knife (190g), Seattle Ultrasonics C-200 (328g), Korin carbon steel cleaver (396g). Sam Rutherford for Engadget The main downside to the C-200's design is that at 328 grams (around 0.75 pounds) it's heavier and bulkier than a typical knife. When compared to other knives I own, which are made from a wide variety of materials including, ceramic, molybdenum steel, carbon steel and even titanium carbide, it weighs more than everything else aside from my big Chinese cleaver (396 grams). And while it fits nicely in my hand, my wife said it takes a bit more effort for her to wield. It's not too much to the point where you don't want to use it. But for quick tasks, sometimes I found myself subconsciously reaching for lighter options like my 6-inch ceramic knife, which weighs just 97 grams. How it works From a user standpoint, putting the C-200 to work couldn't be simpler. Just press the button and let the knife do its thing. The big difference from how knives like this work in sci-fi is that there's no audible hum or detectable vibration when it's on. It's practically silent (well, most of the time, but more on that later), so you have to trust that it's on or check the indicator light on the handle. That said, if you still don't believe anything is happening, you can run the edge of the blade under water or scrape it over some cut citrus, at which point the blade's vibration will atomize nearby liquid into a fine mist. It's a cool party trick that also doubles as a way to amp up a cocktail by adding a faint essence of lemon, lime or anything else you can think of. Pushing the C-200's button is super easy, regardless of what kind of knife grip you prefer. Sam Rutherford for Engadget Inside, the knife relies on PZT-8 piezoelectric ceramic crystals to generate up to 30,000 vibrations per second, which propagate down the blade and make the knife function as if it's sharper than it actually is. This all sounds rather fantastic, so how does it function in the real world? In-use To really put the C-200 through its paces, I cooked over a dozen meals that involved neatly slicing or preparing a wide variety of foods — including Hasselback potatoes, flank steak, pork belly, chives, sushi-grade tuna and all sorts of fruit. After prepping four pounds of pork belly with various knives, the C-200 really showed off how much of a difference its vibration tech makes. Sam Rutherford for Engadget In short, the C-200's effectiveness depends a lot on what you're chopping. For soft things like strawberries or a piece of cake, I didn't notice much of a difference. To make things even more difficult, the knife arrived out of the box with an incredibly fine edge — the kind that makes shearing through a sheet of paper child's play. So even though Seattle Ultrasonics says its knife can reduce cutting effort by up to 50 percent, there's not much gain to be had when slicing foods that could just as easily be cut by a butter knife. However, as I used it more, I found that the C-200 excels at cutting through delicate items like tomatoes, scallions and fish, where using a dull knife often results in bruising the food as you chop. This was most evident when I made poke at home, where Seattle Ultrasonic's knife delivered cleaner, more precise cuts than anything else I own. For me, the C-200's $399 price tag is almost worth it just so I have an an easier time making my one of my all-time favorite dishes (lu rou fan). Sam Rutherford for Engadget When I whipped up some pico de gallo, I distinctly noticed how neatly the C-200 sliced through the skin of a tomato, instead of initially putting a crease in it before cleanly passing through its interior — which often happens when using dull knives. An additional benefit is that because of the vibrations, I found some foods like garlic didn't stick to the side of the blade as much. This made it easier to keep track of how much I chopped while simultaneously reducing the mess from things falling willy-nilly during prep. But perhaps the most obvious demonstration of the knife's prowess was when I diced an onion. When using my other knives or the C-200 without powering it on, I could feel when I tried to cut through thicker, more sturdy layers. But then, at the touch of a button, I was able to slice down with practically no resistance. It's almost shocking because it feels like magic. The C-200 truly excels at cutting denser foods like flank steak. Sadly mine ended up closer to medium than medium rare, but that's not the knife's fault. Sam Rutherford for Engadget The C-200 even has the ability to reduce the importance of certain knife techniques. Anyone who's seen all the posts on r/kitchenconfidential about cutting chives will already know what I'm talking about. As J Kenji Lopez-Alt neatly demonstrated, the ideal way to get crisp, clean slices is to do a subtle forward or back cut instead of simply chopping straight down. But with Seattle Ultrasonics' knife, I've found that it's so sharp you can get away with almost any motion and still get good results. And if you do it the right way, things are even better. Other types of food that makes the C-200 really shine are denser ingredients like meat and potatoes, where you can really feel the added cutting power. Previously, when I had to break down thick cuts of protein, I sometimes wished I owned a serrated electric knife. You know, the kind you break out once a year on Thanksgiving and then it sits and gathers dust for the other 364 days. But the C-200 made that desire a thing of that past, as it quickly and easily worked through flank steak while once again producing neat, uniform slices. Sushi-grade tuna is another food that really shows off how the C-200's increased sharpness is better at preserving the delicate texture of the fish. Sam Rutherford for Engadget My favorite application of the C-200 was when I was doing prep for Taiwanese braised pork (aka 滷肉飯). Despite this being one of my most beloved dishes that I taught myself how to cook because I couldn't easily find it from local restaurants, I don't make it very often because it's a lot of work to cut multiple pounds of pork belly into small lardon-shaped pieces. Here, the knife's vibrations made it so much easier to cut through all those layers of meat, fat and skin. If there's any situation where the C-200 makes it 50 percent easier to slice through something, it's this. It might be hard to tell, but I was able to cut chives a little finer and more neatly with the C-200 (left) than with my other knives. Sam Rutherford for Engadget During my testing, two small issues cropped up. While it was quite rare, the knife would sometimes emit a faint high-pitched whine. When I asked Seattle Ultrasonic's founder Scott Heimendinger about this behavior, he was rather frank, saying that this can occur when water or moisture accumulates in just the right spots on the blade. Furthermore, he said this only happens on a small number of V1 models, which the company is working to fix in the future. Thankfully, I don't mind, but if it bothers you, making the noise go away is as easy as wiping down the knife down with a cloth or paper towel. The C-200s battery can be easily removed for cleaning and charging. Sam Rutherford for Engadget The other complication came while I was working through the multiple pounds of pork belly I mentioned earlier. After 10 to 15 minutes of continuous use, the knife beeped and its indicator light turned red. Turns out the knife had overheated, which was something I had not even considered. This led to higher-than-normal temperatures inside the knife's sealed electronics causing it to shut off. But after just 30 seconds, it returned to form. During later uses, I learned that simply taking my finger off the button between tasks, which happens naturally as you prep anyway, was more than enough to stop that situation from happening ever again. On the flipside, I was happy to discover that despite lacking a full tang, the C-200 can handle fairly rough tasks, including laying the knife on its side to smash garlic or jamming it into an avocado to remove its pit. That said, I would really recommend against doing the latter, because between its inherent sharpness and its vibration tech, this is the first knife I've used that can slice cleanly through an entire avocado with almost no extra effort. Cleaning and care The Seattle Ultrasonics C-200 8-inch chef's knife features an IP65 rating for the whole device, though the front half is actually a bit more resistant thanks to an IP67 rating for its button and bolster. Sam Rutherford for Engadget The last big concern about a knife with built-in electronics is how it handles clean-up. Thankfully, the C-200 features an IP65 rating for dust and water resistance. That means it can withstand rinsing and splashes without issue. And it's actually even tougher than that, because the front of the knife, including its bolster and button, are rated IP67. This means it can take full submersions in water if need be. However, just because you can, doesn't mean you should. Good kitchen protocol says you don't throw knives you care about in the sink and forget them, just like how you wouldn't put one in the dishwasher either. But perhaps the greatest advantage of this tech is that it allows you to go longer between needing to get your knives sharpened, which if you're like most home cooks, is probably never. To be clear, I haven't tested this and in some respects I wish I had been able to test out a dull version of the C-200. That said, science dictates that slice for slice, an ultrasonic knife will simply cut better than an equivalent blade without the extra tech. So if you believe in the adage that a dull knife is more dangerous than a sharp one because you need to apply more force to get the same results, this is another bonus for both safety and convenience. The not-so-optional accessory Seattle Ultrasonics' wireless charging tile makes it incredibly easy to forget that the C-200 needs to be topped up between uses. Sam Rutherford for Engadget I fully admit the need to keep a knife charged up is a major annoyance and something I or anyone else probably doesn't want to do. Thankfully, Seattle Ultrasonics thought of that by including support for wireless charging via the C-200's magnetic tile and it's dead simple to use. Just toss it on the charger when you're not using and it will take care of itself, so you never have to worry about how much of its normal 20-minute runtime it may or may not have left. There are also holes around back so you can easily mount the charger on a wall or shelf. In short, the added convenience the charging tile brings is so valuable that I don't really consider it an optional accessory. If you're getting the C-200, you need to buy this too, which sadly means you're looking at an all-in price of $500 for the bundle instead of just $400 for the knife by itself. Wrap-up As much as I love old-school knives, they'll simply never be as sharp an equivalent blade with this newfound tech. Sam Rutherford for Engadget After using the C-200, I don't think people need to rush out and throw all their old-school knives in the trash. The beauty of an ultrasonic blade like this is that it can handle everything your old cutlery is meant for, but with the touch of a button, it delivers sharpness unlike anything you've experienced before. And while it has some quirks, they're nothing like the kind you typically encounter on first-gen gadgets. Its biggest drawback is that its magnetic charging tile feels like an essential accessory, but it adds extra cost on top of a product that already has a deservedly premium price tag. Even though I'm sure knife makers will continue tweaking blade shapes and alloy mixes from now until the end of time, the addition of ultrasonic vibrations to a chef's knife unlocks a completely new tier of performance. That's because this technology is additive. All it does is enhance what a blade already does best. And when you look at related gadgets in the maker space, I don't think it's a coincidence that there's a similar revolution that resulted in Adam Savage of Mythbusters fame naming a sonic cutter as one of his favorite things of 2025. When viewed that way, it makes me even more confident that the C-200 is the flagbearer for a new breed of kitchen knives. This article originally appeared on Engadget at https://www.engadget.com/home/kitchen-tech/seattle-ultrasonics-c-200-review-this-is-the-future-of-kitchen-knives-140000051.html?src=rss",
          "content": "There’s a type of knife tech often seen in science fiction that revolves around vibrating a blade to increase its sharpness. We’ve seen examples of this in franchises like Star Wars (vibroblades), Evangelion (the prog knife), Dune (pulse-swords) and the Marvel universe (vibranium), but what might surprise you is that the underlying science is sound. By vibrating a cutting tool at high frequencies, not only do you reduce friction, you essentially turn the blade into a saw, as tiny oscillations enhance the inherent sharpness of a blade. However, up until recently, this tech largely only existed in fiction or for large companies that have the money to utilize the tech on an industrial scale. But that's changing in a big way for home cooks this year thanks to Seattle Ultrasonics, which is releasing the world's first ultrasonic chef's knife: the C-200. After chopping, smashing and cooking with it for about a month, I'm convinced that this is the future of kitchen knives. Design From afar, the C-200 looks a lot like a regular 8-inch chef's knife, but with a slightly more contemporary design. It features a three-layer san mai blade made from Japanese AUS-10 steel with a 13-degree edge angle per side (26 degrees total). However, upon closer inspection, you'll notice there are some features that seem a bit out of place on a premium knife. The first is that the C-200 doesn't have a full tang, which is the back end of a blade that ideally extends into the handle to provide added strength and durability. This is usually a major no-no, particularly on a $400 knife. However, when you consider that Seattle Ultrasonics needed somewhere to put its vibration tech, there really isn't any room for it other than inside the knife's grip. You won't be able to feel it, but pressing this button allows the C-200's blade to vibrate 30,000 times per second. Sam Rutherford for Engadget The knife's second quirk is that the back of the plastic handle features small indicator lights on either side, which is obviously a bit weird. Furthermore, the entire gray section can be removed to reveal a small 1,100mAh battery with an onboard USB-C port. Frankly, the presence of a battery in a knife is just kind of funky. But hey, the power to vibrate the knife has to come from somewhere because it definitely isn't being generated by your hands. And while Seattle Ultrasonics doesn't include a charging adapter or cable in the box, I don't mind because the company wisely took cues from the larger gadget industry and went with a power spec that's already widely in use. Honestly, I wish more kitchen tech makers would do the same. However, the knife's biggest oddity is the big orange button on the bottom of its handle. This is what you use to make the blade vibrate, which it does at 33kHz. It's positioned well so that it's easy to press regardless of whether you do a traditional pinch grip or if you're a bit more casual and prefer to hold the knife only using its handle. In the future, I can see this button becoming a touch-sensitive sensor, but for now, it's simple and effective. Here's a small selection of knives I own sorted by weight (from top to bottom) compared to the C200: 6-inch Kyocera ceramic knife (97 grams), MAC molybdenum steel chef's knife (110g), Furtif Evercut titanium carbide chef's knife (190g), Seattle Ultrasonics C-200 (328g), Korin carbon steel cleaver (396g). Sam Rutherford for Engadget The main downside to the C-200's design is that at 328 grams (around 0.75 pounds) it's heavier and bulkier than a typical knife. When compared to other knives I own, which are made from a wide variety of materials including, ceramic, molybdenum steel, carbon steel and even titanium carbide, it weighs more than everything else aside from my big Chinese cleaver (396 grams). And while it fits nicely in my hand, my wife said it takes a bit more effort for her to wield. It's not too much to the point where you don't want to use it. But for quick tasks, sometimes I found myself subconsciously reaching for lighter options like my 6-inch ceramic knife, which weighs just 97 grams. How it works From a user standpoint, putting the C-200 to work couldn't be simpler. Just press the button and let the knife do its thing. The big difference from how knives like this work in sci-fi is that there's no audible hum or detectable vibration when it's on. It's practically silent (well, most of the time, but more on that later), so you have to trust that it's on or check the indicator light on the handle. That said, if you still don't believe anything is happening, you can run the edge of the blade under water or scrape it over some cut citrus, at which point the blade's vibration will atomize nearby liquid into a fine mist. It's a cool party trick that also doubles as a way to amp up a cocktail by adding a faint essence of lemon, lime or anything else you can think of. Pushing the C-200's button is super easy, regardless of what kind of knife grip you prefer. Sam Rutherford for Engadget Inside, the knife relies on PZT-8 piezoelectric ceramic crystals to generate up to 30,000 vibrations per second, which propagate down the blade and make the knife function as if it's sharper than it actually is. This all sounds rather fantastic, so how does it function in the real world? In-use To really put the C-200 through its paces, I cooked over a dozen meals that involved neatly slicing or preparing a wide variety of foods — including Hasselback potatoes, flank steak, pork belly, chives, sushi-grade tuna and all sorts of fruit. After prepping four pounds of pork belly with various knives, the C-200 really showed off how much of a difference its vibration tech makes. Sam Rutherford for Engadget In short, the C-200's effectiveness depends a lot on what you're chopping. For soft things like strawberries or a piece of cake, I didn't notice much of a difference. To make things even more difficult, the knife arrived out of the box with an incredibly fine edge — the kind that makes shearing through a sheet of paper child's play. So even though Seattle Ultrasonics says its knife can reduce cutting effort by up to 50 percent, there's not much gain to be had when slicing foods that could just as easily be cut by a butter knife. However, as I used it more, I found that the C-200 excels at cutting through delicate items like tomatoes, scallions and fish, where using a dull knife often results in bruising the food as you chop. This was most evident when I made poke at home, where Seattle Ultrasonic's knife delivered cleaner, more precise cuts than anything else I own. For me, the C-200's $399 price tag is almost worth it just so I have an an easier time making my one of my all-time favorite dishes (lu rou fan). Sam Rutherford for Engadget When I whipped up some pico de gallo, I distinctly noticed how neatly the C-200 sliced through the skin of a tomato, instead of initially putting a crease in it before cleanly passing through its interior — which often happens when using dull knives. An additional benefit is that because of the vibrations, I found some foods like garlic didn't stick to the side of the blade as much. This made it easier to keep track of how much I chopped while simultaneously reducing the mess from things falling willy-nilly during prep. But perhaps the most obvious demonstration of the knife's prowess was when I diced an onion. When using my other knives or the C-200 without powering it on, I could feel when I tried to cut through thicker, more sturdy layers. But then, at the touch of a button, I was able to slice down with practically no resistance. It's almost shocking because it feels like magic. The C-200 truly excels at cutting denser foods like flank steak. Sadly mine ended up closer to medium than medium rare, but that's not the knife's fault. Sam Rutherford for Engadget The C-200 even has the ability to reduce the importance of certain knife techniques. Anyone who's seen all the posts on r/kitchenconfidential about cutting chives will already know what I'm talking about. As J Kenji Lopez-Alt neatly demonstrated, the ideal way to get crisp, clean slices is to do a subtle forward or back cut instead of simply chopping straight down. But with Seattle Ultrasonics' knife, I've found that it's so sharp you can get away with almost any motion and still get good results. And if you do it the right way, things are even better. Other types of food that makes the C-200 really shine are denser ingredients like meat and potatoes, where you can really feel the added cutting power. Previously, when I had to break down thick cuts of protein, I sometimes wished I owned a serrated electric knife. You know, the kind you break out once a year on Thanksgiving and then it sits and gathers dust for the other 364 days. But the C-200 made that desire a thing of that past, as it quickly and easily worked through flank steak while once again producing neat, uniform slices. Sushi-grade tuna is another food that really shows off how the C-200's increased sharpness is better at preserving the delicate texture of the fish. Sam Rutherford for Engadget My favorite application of the C-200 was when I was doing prep for Taiwanese braised pork (aka 滷肉飯). Despite this being one of my most beloved dishes that I taught myself how to cook because I couldn't easily find it from local restaurants, I don't make it very often because it's a lot of work to cut multiple pounds of pork belly into small lardon-shaped pieces. Here, the knife's vibrations made it so much easier to cut through all those layers of meat, fat and skin. If there's any situation where the C-200 makes it 50 percent easier to slice through something, it's this. It might be hard to tell, but I was able to cut chives a little finer and more neatly with the C-200 (left) than with my other knives. Sam Rutherford for Engadget During my testing, two small issues cropped up. While it was quite rare, the knife would sometimes emit a faint high-pitched whine. When I asked Seattle Ultrasonic's founder Scott Heimendinger about this behavior, he was rather frank, saying that this can occur when water or moisture accumulates in just the right spots on the blade. Furthermore, he said this only happens on a small number of V1 models, which the company is working to fix in the future. Thankfully, I don't mind, but if it bothers you, making the noise go away is as easy as wiping down the knife down with a cloth or paper towel. The C-200s battery can be easily removed for cleaning and charging. Sam Rutherford for Engadget The other complication came while I was working through the multiple pounds of pork belly I mentioned earlier. After 10 to 15 minutes of continuous use, the knife beeped and its indicator light turned red. Turns out the knife had overheated, which was something I had not even considered. This led to higher-than-normal temperatures inside the knife's sealed electronics causing it to shut off. But after just 30 seconds, it returned to form. During later uses, I learned that simply taking my finger off the button between tasks, which happens naturally as you prep anyway, was more than enough to stop that situation from happening ever again. On the flipside, I was happy to discover that despite lacking a full tang, the C-200 can handle fairly rough tasks, including laying the knife on its side to smash garlic or jamming it into an avocado to remove its pit. That said, I would really recommend against doing the latter, because between its inherent sharpness and its vibration tech, this is the first knife I've used that can slice cleanly through an entire avocado with almost no extra effort. Cleaning and care The Seattle Ultrasonics C-200 8-inch chef's knife features an IP65 rating for the whole device, though the front half is actually a bit more resistant thanks to an IP67 rating for its button and bolster. Sam Rutherford for Engadget The last big concern about a knife with built-in electronics is how it handles clean-up. Thankfully, the C-200 features an IP65 rating for dust and water resistance. That means it can withstand rinsing and splashes without issue. And it's actually even tougher than that, because the front of the knife, including its bolster and button, are rated IP67. This means it can take full submersions in water if need be. However, just because you can, doesn't mean you should. Good kitchen protocol says you don't throw knives you care about in the sink and forget them, just like how you wouldn't put one in the dishwasher either. But perhaps the greatest advantage of this tech is that it allows you to go longer between needing to get your knives sharpened, which if you're like most home cooks, is probably never. To be clear, I haven't tested this and in some respects I wish I had been able to test out a dull version of the C-200. That said, science dictates that slice for slice, an ultrasonic knife will simply cut better than an equivalent blade without the extra tech. So if you believe in the adage that a dull knife is more dangerous than a sharp one because you need to apply more force to get the same results, this is another bonus for both safety and convenience. The not-so-optional accessory Seattle Ultrasonics' wireless charging tile makes it incredibly easy to forget that the C-200 needs to be topped up between uses. Sam Rutherford for Engadget I fully admit the need to keep a knife charged up is a major annoyance and something I or anyone else probably doesn't want to do. Thankfully, Seattle Ultrasonics thought of that by including support for wireless charging via the C-200's magnetic tile and it's dead simple to use. Just toss it on the charger when you're not using and it will take care of itself, so you never have to worry about how much of its normal 20-minute runtime it may or may not have left. There are also holes around back so you can easily mount the charger on a wall or shelf. In short, the added convenience the charging tile brings is so valuable that I don't really consider it an optional accessory. If you're getting the C-200, you need to buy this too, which sadly means you're looking at an all-in price of $500 for the bundle instead of just $400 for the knife by itself. Wrap-up As much as I love old-school knives, they'll simply never be as sharp an equivalent blade with this newfound tech. Sam Rutherford for Engadget After using the C-200, I don't think people need to rush out and throw all their old-school knives in the trash. The beauty of an ultrasonic blade like this is that it can handle everything your old cutlery is meant for, but with the touch of a button, it delivers sharpness unlike anything you've experienced before. And while it has some quirks, they're nothing like the kind you typically encounter on first-gen gadgets. Its biggest drawback is that its magnetic charging tile feels like an essential accessory, but it adds extra cost on top of a product that already has a deservedly premium price tag. Even though I'm sure knife makers will continue tweaking blade shapes and alloy mixes from now until the end of time, the addition of ultrasonic vibrations to a chef's knife unlocks a completely new tier of performance. That's because this technology is additive. All it does is enhance what a blade already does best. And when you look at related gadgets in the maker space, I don't think it's a coincidence that there's a similar revolution that resulted in Adam Savage of Mythbusters fame naming a sonic cutter as one of his favorite things of 2025. When viewed that way, it makes me even more confident that the C-200 is the flagbearer for a new breed of kitchen knives. This article originally appeared on Engadget at https://www.engadget.com/home/kitchen-tech/seattle-ultrasonics-c-200-review-this-is-the-future-of-kitchen-knives-140000051.html?src=rss",
          "feed_position": 23,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/c200-button.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/general/the-morning-after-engadget-newsletter-122906428.html",
          "published_at": "Tue, 24 Feb 2026 12:29:12 +0000",
          "title": "The Morning After: What to expect at Samsung’s Galaxy Unpacked event tomorrow",
          "standfirst": "Samsung’s ready to launch its first new devices of 2026, and it’s got a Galaxy Unpacked event in San Francisco to stream everything. The keynote starts at 10AM PT (1PM ET) and will be livestreamed on YouTube. The announcement on February 10 also said this launch will mark “a new phase in the era of AI as intelligence becomes truly personal and adaptive.” What are we expecting? Based on leaked images of the new lineup, the company is not likely to have radically reinvented the look of the Galaxy S26, Galaxy S26+ or Galaxy S26 Ultra, sticking instead with a similar design to the Galaxy S25. We’re expecting Qualcomm’s new Snapdragon 8 Elite Gen 5 chip to be in all Samsung Galaxy S26 phones, though Korean news site Yonhap News reports Samsung’s relatively new Exynos 2600 chip could be in some devices, depending on the region. Despite the launch of the Qi 2 wireless charging standard, which added support for convenient magnetic alignment, Samsung still hasn’t brought the feature to its phones. Rumours suggest the S-series will have the spec’s higher speed wireless charging rates but will lack built-in magnets and have to depend on cases to add MagSafe-style charging and mounting. Honestly? It could be a pretty mild launch event, especially after wowing everyone with the Galaxy TriFold at the start of the year. Are you more interested in foldables than traditional candy bar devices? (If so, get ready for MWC 2026, kicking off next week. We’re expecting a lot of foldables.) — Mat Smith The other big stories (and deals) this morning The creators of Dark Sky have a new weather app Engadget review recap: Sony WF-1000XM6, ASUS Zenbook Duo and more Falcon Northwest FragBox review: A compact gaming rig that does everything right A new Evangelion series is coming Yoko Taro, creator of NieR, will pen it. Gainmax Yes, a truly new Neon Genesis Evangelion series is coming. The announcement came during a 30th-anniversary event in Japan. However, franchise creator Hideaki Anno won’t write the scripts. His replacement will be Yoko Taro, creator of the NieR video game series, who wears a giant spooky moon mask for interviews and game briefings. He’s also a cool guy underneath. Evangelion veteran Kazuya Tsurumaki will be on hand to direct episodes, produced by Studio Khara and Cloverworks. Continue reading. Bungie says ‘no second chances’ if you’re caught cheating in its new game Marathon players found cheating or developing cheats will receive a permaban. In a detailed blog post, Bungie took a very declarative position against those caught trying to cheat: “We are taking a strong stance against cheating and anyone found to be cheating or developing cheats will be permanently banned from playing Marathon forever, no second chances.” The blog post added that an appeals system will be in place. However, Bungie’s anti-cheat standards go beyond punishment. In the blog post, Bungie explained that Marathon’s dedicated servers have full authority on movement, shooting, actions and inventory. Since these key actions rely on the server, it will translate to smoother gunplay for players as well as the prevention of cheats related to teleportation, unlimited ammo or damage manipulation. Continue reading. This is the Nothing Phone 4(a) And it’s coming March 5. Nothing Looks like Nothing. Continue reading.This article originally appeared on Engadget at https://www.engadget.com/general/the-morning-after-engadget-newsletter-122906428.html?src=rss",
          "content": "Samsung’s ready to launch its first new devices of 2026, and it’s got a Galaxy Unpacked event in San Francisco to stream everything. The keynote starts at 10AM PT (1PM ET) and will be livestreamed on YouTube. The announcement on February 10 also said this launch will mark “a new phase in the era of AI as intelligence becomes truly personal and adaptive.” What are we expecting? Based on leaked images of the new lineup, the company is not likely to have radically reinvented the look of the Galaxy S26, Galaxy S26+ or Galaxy S26 Ultra, sticking instead with a similar design to the Galaxy S25. We’re expecting Qualcomm’s new Snapdragon 8 Elite Gen 5 chip to be in all Samsung Galaxy S26 phones, though Korean news site Yonhap News reports Samsung’s relatively new Exynos 2600 chip could be in some devices, depending on the region. Despite the launch of the Qi 2 wireless charging standard, which added support for convenient magnetic alignment, Samsung still hasn’t brought the feature to its phones. Rumours suggest the S-series will have the spec’s higher speed wireless charging rates but will lack built-in magnets and have to depend on cases to add MagSafe-style charging and mounting. Honestly? It could be a pretty mild launch event, especially after wowing everyone with the Galaxy TriFold at the start of the year. Are you more interested in foldables than traditional candy bar devices? (If so, get ready for MWC 2026, kicking off next week. We’re expecting a lot of foldables.) — Mat Smith The other big stories (and deals) this morning The creators of Dark Sky have a new weather app Engadget review recap: Sony WF-1000XM6, ASUS Zenbook Duo and more Falcon Northwest FragBox review: A compact gaming rig that does everything right A new Evangelion series is coming Yoko Taro, creator of NieR, will pen it. Gainmax Yes, a truly new Neon Genesis Evangelion series is coming. The announcement came during a 30th-anniversary event in Japan. However, franchise creator Hideaki Anno won’t write the scripts. His replacement will be Yoko Taro, creator of the NieR video game series, who wears a giant spooky moon mask for interviews and game briefings. He’s also a cool guy underneath. Evangelion veteran Kazuya Tsurumaki will be on hand to direct episodes, produced by Studio Khara and Cloverworks. Continue reading. Bungie says ‘no second chances’ if you’re caught cheating in its new game Marathon players found cheating or developing cheats will receive a permaban. In a detailed blog post, Bungie took a very declarative position against those caught trying to cheat: “We are taking a strong stance against cheating and anyone found to be cheating or developing cheats will be permanently banned from playing Marathon forever, no second chances.” The blog post added that an appeals system will be in place. However, Bungie’s anti-cheat standards go beyond punishment. In the blog post, Bungie explained that Marathon’s dedicated servers have full authority on movement, shooting, actions and inventory. Since these key actions rely on the server, it will translate to smoother gunplay for players as well as the prevention of cheats related to teleportation, unlimited ammo or damage manipulation. Continue reading. This is the Nothing Phone 4(a) And it’s coming March 5. Nothing Looks like Nothing. Continue reading.This article originally appeared on Engadget at https://www.engadget.com/general/the-morning-after-engadget-newsletter-122906428.html?src=rss",
          "feed_position": 26,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2026-02/f80765c0-117b-11f1-aeb3-f144f309e7bf"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/accessories/best-webcams-123047068.html",
          "published_at": "Tue, 24 Feb 2026 10:00:36 +0000",
          "title": "The best webcams for 2026",
          "standfirst": "Whether you’re on back-to-back video meetings, live streaming or just trying to look presentable on a family call, your webcam matters more than most might expect. The cameras built into laptops are fine in a pinch, but they rarely deliver consistent image quality, especially in less-than-ideal lighting. A dedicated webcam can noticeably improve sharpness, color accuracy and overall reliability. There’s no single “best” webcam for everyone, though. Some models are built around higher resolutions, while others focus on smoother video, better low-light performance or stronger onboard microphones. We’ve tested a wide range of options to see which ones are actually worth using day to day. Best webcams for 2026 Factors to consider before buying a webcam Resolution and field of view While some newer computers have 1080p webcams, most built-in cameras have a resolution of 720p, so you’ll want to look for an external webcam that has a higher resolution. FHD webcams will give you better video quality; ideally, you’re looking for something that can handle 1080p at 60fps or 30fps. If you’re considering a cheap 720p webcam, make sure to get one that supports at least 30fps (most will) or, even better, 60fps. However, if your primary concern is better picture quality during video calls, 1080p is the way to go. Some webcams can shoot in 4K, but that’s overkill for most people. Not to mention most video conferencing services like Zoom, Google Meet and Skype don’t even support 4K video. When it comes to streaming, Twitch maxes out at 1080p video, but YouTube added 4K live streaming back in 2016. Ultimately, with 4K webcam shots having such limited use, most people can get by with a solid 1080p camera. Field of view (FOV) controls how much can fit in the frame when you’re recording. Most webcams I tested had a default field of view of around 78 degrees, which captured me and enough of my background to prove that I really need to organize my home office. On cheaper webcams you’ll usually see narrower fields of view (around 60 degrees), and those aren’t necessarily bad. They won’t show as much of your background, but that also means you won’t be able to squeeze as many friends or family members into frame when you’re having Zoom birthday parties. On the flip side, more expensive webcams may let you adjust the field of view to be even wider than average, and some even offer features like digital zoom. Autofocus and other “auto” features Webcams with autofocus will keep the image quality sharp without much work on your part. You should be able to move around, step back and forth, and remain in focus the whole time. Some standalone webcam models let you manually adjust focus, too, if you have specific needs. Devices with fixed focus are less convenient, but they tend to be more affordable. In the same vein is auto framing, a feature that some high-end webcams now offer. Similarly to Apple’s Center Stage feature, the camera automatically adjusts to keep you in the center of the frame even as you move around. This used to be a feature only available on the most premium webcams, but now you can find it on sub-$200 devices. You’ll also see other “auto” features listed in webcam specs, most notably auto light correction. This will adjust the camera’s settings to make up for a dimly lit room. If you don’t have bright lights, or often take calls in places where you can’t control the lighting, this feature will be valuable. Alternatively, you might consider using your mirrorless camera as a high-quality webcam solution, taking all of the benefits and features with you (albeit in a cumbersome package). Microphones Most webcams have built-in microphones that, depending on your setup, might end up being closer to you than your computer’s own mics. Check to see if the model you’re considering has mono or stereo mics, as the latter is better. Some even use noise-reduction technology to keep your voice loud and clear. While audiophiles and streamers will want to invest in a standalone microphone, most others can get by using a webcam’s built-in mic. Design There aren’t a ton of fascinating breakthroughs when it comes to external webcam design. Most are round or rectangular devices that clip onto a monitor or your laptop screen. Some have the ability to swivel or screw onto a tripod stand and others can simply sit on your desk beside your computer. But unless you really like having people stare up your nose, the latter isn’t ideal. We recommend clipping your webcam to your monitor and ensuring that it’s at or slightly above eye level. A few webcams go above and beyond by adding hardware extras like built-in lights and lens covers, too. The former can help you stand out in a dark room, while the latter makes it so hackers can’t view you through your webcam without your knowledge. Price Most external webcams that are just good enough to be a step up from your computer’s built-in camera cost between $60 and $150. If the webcam has the same resolution as the internal one on your laptop, you should look out for other specs like auto light correction, a wider field of view or an extra-long connecting cable that can provide a step-up in quality or ease of use. Spending $150 or more means you might get advanced features that tend to be present in a pro webcam like 4K resolution, vertical and horizontal recording options, stereo mics, customizable video settings and more. But unless you’re spending hours on video calls each day or streaming multiple times each week, you can settle on a budget webcam and safely skip most of those high-end options. How we test webcams We primarily test webcams by putting them through as much real-world use as possible. We examine their design, how flexible they are and how easy they are to reposition, and make note of how heavy they are and if that affects their ability to stay put while sitting on top of a screen. We use each webcam for at least a week straight as our primary camera for all video chats, and we make sure to use the device in different lighting environments to test low-light performance. We also use any built-in microphones as our primary audio inputs on video calls as well. Finally, although most of these webcams are plug-and-play, we test out any proprietary software that’s intended to work with each webcam, tweaking things like field of view, video resolution and effects, and using any special features like Show Mode on Logitech webcams. Others webcams we tested Logitech C920s Pro HD Our previous top pick, the Logitech C920s Pro HD webcam remains a solid option for those with less than $100 to spend and really only need a basic 1080p camera to upgrade their setup, or something affordable to make them look better on those inevitable Zoom calls. It has a 78-degree field of view, decent microphones and handy privacy shutter built in. The Brio 500 took the top spot away from this model thanks to its advanced light correction, auto-framing and Show Mode. Webcam FAQs Should I get a 4K or 1080p webcam? It depends on how you plan to use it. A 1080p webcam is more than enough for most video calls, online classes and casual streaming. The picture looks clear, loads quickly and works well even on slower internet connections. A 4K webcam makes sense if you want sharper detail, especially for content creation, professional streaming or recordings you plan to upload. The extra resolution also helps if you crop or zoom in during a call without losing much quality. Keep in mind that 4K requires more bandwidth and not every platform supports it, so think about whether your setup and audience will benefit before spending more. Georgie Peru contributed to this report.This article originally appeared on Engadget at https://www.engadget.com/computing/accessories/best-webcams-123047068.html?src=rss",
          "content": "Whether you’re on back-to-back video meetings, live streaming or just trying to look presentable on a family call, your webcam matters more than most might expect. The cameras built into laptops are fine in a pinch, but they rarely deliver consistent image quality, especially in less-than-ideal lighting. A dedicated webcam can noticeably improve sharpness, color accuracy and overall reliability. There’s no single “best” webcam for everyone, though. Some models are built around higher resolutions, while others focus on smoother video, better low-light performance or stronger onboard microphones. We’ve tested a wide range of options to see which ones are actually worth using day to day. Best webcams for 2026 Factors to consider before buying a webcam Resolution and field of view While some newer computers have 1080p webcams, most built-in cameras have a resolution of 720p, so you’ll want to look for an external webcam that has a higher resolution. FHD webcams will give you better video quality; ideally, you’re looking for something that can handle 1080p at 60fps or 30fps. If you’re considering a cheap 720p webcam, make sure to get one that supports at least 30fps (most will) or, even better, 60fps. However, if your primary concern is better picture quality during video calls, 1080p is the way to go. Some webcams can shoot in 4K, but that’s overkill for most people. Not to mention most video conferencing services like Zoom, Google Meet and Skype don’t even support 4K video. When it comes to streaming, Twitch maxes out at 1080p video, but YouTube added 4K live streaming back in 2016. Ultimately, with 4K webcam shots having such limited use, most people can get by with a solid 1080p camera. Field of view (FOV) controls how much can fit in the frame when you’re recording. Most webcams I tested had a default field of view of around 78 degrees, which captured me and enough of my background to prove that I really need to organize my home office. On cheaper webcams you’ll usually see narrower fields of view (around 60 degrees), and those aren’t necessarily bad. They won’t show as much of your background, but that also means you won’t be able to squeeze as many friends or family members into frame when you’re having Zoom birthday parties. On the flip side, more expensive webcams may let you adjust the field of view to be even wider than average, and some even offer features like digital zoom. Autofocus and other “auto” features Webcams with autofocus will keep the image quality sharp without much work on your part. You should be able to move around, step back and forth, and remain in focus the whole time. Some standalone webcam models let you manually adjust focus, too, if you have specific needs. Devices with fixed focus are less convenient, but they tend to be more affordable. In the same vein is auto framing, a feature that some high-end webcams now offer. Similarly to Apple’s Center Stage feature, the camera automatically adjusts to keep you in the center of the frame even as you move around. This used to be a feature only available on the most premium webcams, but now you can find it on sub-$200 devices. You’ll also see other “auto” features listed in webcam specs, most notably auto light correction. This will adjust the camera’s settings to make up for a dimly lit room. If you don’t have bright lights, or often take calls in places where you can’t control the lighting, this feature will be valuable. Alternatively, you might consider using your mirrorless camera as a high-quality webcam solution, taking all of the benefits and features with you (albeit in a cumbersome package). Microphones Most webcams have built-in microphones that, depending on your setup, might end up being closer to you than your computer’s own mics. Check to see if the model you’re considering has mono or stereo mics, as the latter is better. Some even use noise-reduction technology to keep your voice loud and clear. While audiophiles and streamers will want to invest in a standalone microphone, most others can get by using a webcam’s built-in mic. Design There aren’t a ton of fascinating breakthroughs when it comes to external webcam design. Most are round or rectangular devices that clip onto a monitor or your laptop screen. Some have the ability to swivel or screw onto a tripod stand and others can simply sit on your desk beside your computer. But unless you really like having people stare up your nose, the latter isn’t ideal. We recommend clipping your webcam to your monitor and ensuring that it’s at or slightly above eye level. A few webcams go above and beyond by adding hardware extras like built-in lights and lens covers, too. The former can help you stand out in a dark room, while the latter makes it so hackers can’t view you through your webcam without your knowledge. Price Most external webcams that are just good enough to be a step up from your computer’s built-in camera cost between $60 and $150. If the webcam has the same resolution as the internal one on your laptop, you should look out for other specs like auto light correction, a wider field of view or an extra-long connecting cable that can provide a step-up in quality or ease of use. Spending $150 or more means you might get advanced features that tend to be present in a pro webcam like 4K resolution, vertical and horizontal recording options, stereo mics, customizable video settings and more. But unless you’re spending hours on video calls each day or streaming multiple times each week, you can settle on a budget webcam and safely skip most of those high-end options. How we test webcams We primarily test webcams by putting them through as much real-world use as possible. We examine their design, how flexible they are and how easy they are to reposition, and make note of how heavy they are and if that affects their ability to stay put while sitting on top of a screen. We use each webcam for at least a week straight as our primary camera for all video chats, and we make sure to use the device in different lighting environments to test low-light performance. We also use any built-in microphones as our primary audio inputs on video calls as well. Finally, although most of these webcams are plug-and-play, we test out any proprietary software that’s intended to work with each webcam, tweaking things like field of view, video resolution and effects, and using any special features like Show Mode on Logitech webcams. Others webcams we tested Logitech C920s Pro HD Our previous top pick, the Logitech C920s Pro HD webcam remains a solid option for those with less than $100 to spend and really only need a basic 1080p camera to upgrade their setup, or something affordable to make them look better on those inevitable Zoom calls. It has a 78-degree field of view, decent microphones and handy privacy shutter built in. The Brio 500 took the top spot away from this model thanks to its advanced light correction, auto-framing and Show Mode. Webcam FAQs Should I get a 4K or 1080p webcam? It depends on how you plan to use it. A 1080p webcam is more than enough for most video calls, online classes and casual streaming. The picture looks clear, loads quickly and works well even on slower internet connections. A 4K webcam makes sense if you want sharper detail, especially for content creation, professional streaming or recordings you plan to upload. The extra resolution also helps if you crop or zoom in during a call without losing much quality. Keep in mind that 4K requires more bandwidth and not every platform supports it, so think about whether your setup and audience will benefit before spending more. Georgie Peru contributed to this report.This article originally appeared on Engadget at https://www.engadget.com/computing/accessories/best-webcams-123047068.html?src=rss",
          "feed_position": 31,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2021-04/02284fb0-a11a-11eb-aafb-70e6f3b5aa36"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/how-smarsh-built-an-ai-front-door-for-regulated-industries-and-drove-59-self",
          "published_at": "Tue, 24 Feb 2026 05:00:00 GMT",
          "title": "How Smarsh built an AI front door for regulated industries — and drove 59% self-service adoption",
          "standfirst": "Presented by Salesforce Smarsh, a global provider of cloud-native, AI-driven solutions that capture, archive, and analyze communications data and intelligence for highly regulated industries, set an ambitious goal: use AI to scale its workforce and increase productivity by 30%. But its customer service team had already identified the real challenge — customers were navigating a maze of products, documentation, and compliance requirements.The solution wasn’t just more automation. It was a single, intelligent entry point into support.\"At the team level we asked ourselves, how can we become a better support organization for our regulated industry customers given that we keep on acquiring companies and have so many products to support?\" says Rohit Khanna, Smarsh chief customer officer. \"How do we harness the knowledge we have internally and present that to these customers in a way that makes our teams more efficient, and customer service more effective?\"In practice, that meant building an intelligent, human-centric “front door” trained on Smarsh’s proprietary knowledge. The system centralizes the support journey, distilling complex AI infrastructure into a simple, practical experience. Customers bypass complex navigation trees and describe what they need in plain language, and the AI directs them to the right solution — reducing the friction of traditional self-service.Archie, the Smarsh AI support agentSmarsh named its AI support agent \"Archie.\" While many AI initiatives stall during the last mile — the difficult transition from a successful pilot to a durable, production-scale operation — Smarsh avoided this by building on a deeply unified platform. The company chose Salesforce’s Agentforce 360 Platform to ensure Archie had the shared context, controlled execution, and orchestration required for an agentic enterprise.By deploying Agentforce rather than a bespoke DIY solution, Smarsh ensures Archie can plan and execute work across systems for smarter self-service and faster resolutions. This approach allows Smarsh to move work forward automatically across data and workflows, achieving greater efficiency without compromising the strict compliance rigor required by their industry. As a result, the company expects to see a 20% increase in its customer self-service success rates, 25% faster issue resolution compared to traditional self-service search and browse methods, and a 30% boost in service representative productivity.The bleeding edge of customer service AIBoth generative and agentic AI are rewriting the customer service playbook, yet the technology’s nascency can create intimidating hurdles. An organization can reap major rewards by moving decisively when launching AI initiatives, but it still requires care, forethought, and the right partnerships, Khanna says. Part of that is careful vendor choice.\"We&#x27;re a Salesforce shop,” he shared. “We use a core set of Salesforce products, including Data 360, Agentforce Service, Agentforce Sales and more, so it was wise to hang our hat on an AI agent provided to us by Salesforce rather than buying something from outside. We know that in the beginning, as new tech comes, it will be challenging, but Salesforce is up to the task and we&#x27;ll evolve together.\"From day one, effective AI has demanded a single non-negotiable prerequisite: clean, secure data. Grounding generative AI in an organization’s verified corporate knowledge and internal data slashes hallucination risk while delivering a significantly better user experience. Smarsh, however, didn’t wait for the industry to catch up. The company anticipated this need nearly half a decade ago, spending years meticulously rationalizing, annotating, and anonymizing its data to prepare for this exact moment. \"A lot of people run into challenges and don’t complete their AI projects because the data’s not ready and it&#x27;s not there,\" Khanna says. \"We started out strong, right out of the gate because our data was already clean and locked down, and today we’re in production with a service agent as we speak.\"Prioritizing data trustGiven Smarsh’s focus on regulatory compliance, Archie was introduced to replace the company’s previous self-service customer support chatbot. Janine Deegan, digital support program manager at Smarsh, worked with the Salesforce admin team on Smarsh&#x27;s Agentforce deployment. \"With Archie, the goal was to move beyond experimentation and make AI genuinely usable in a regulated environment. It wasn’t as simple as just switching on an agent; we had to build a system that gave that raw intelligence the context and control our industry actually requires, which is why we chose Salesforce,” Deegan says. “By connecting our documentation directly to Agentforce, which is backed by the Salesforce Trust Layer, we turned our static data into a live, trusted resource that handles the precision needed for a regulated space.\"Given its criticality, Khanna adds that maintaining pristine, secure documentation and data requires constant vigilance. To guarantee this, Smarsh erased the lines between departments, fusing the documentation team with the AI team. Now the two work in a tight loop: all of the material the document team produces, the AI team checks, verifies, and opens it up to the LLM. AI and regulatory compliance\"We’re in a compliance world. We’re custodians of archival data for all of our financial institutions, and our data is so sacred that we don’t give it away, \" Khanna explains. \"We have to be very cognizant of security and identity as we open up our systems to agentic AI.\"Infosec requirements were a critical consideration for rolling out Agentforce. Smarsh is regularly audited not just by regulatory bodies but also by the banks and financial institutions that have to comply with stringent data protection rules and ask for model risk management, (MRM). \"The safety regulators and banks ask for MRM,\" Khanna says. \"They say, ‘Tell me that all my data is not going to the public because it’s connecting with an LLM. Tell me about the LLM. Tell me about the model you’re using.’ We worked with Salesforce so we could get MRM approval for our customers. And thanks to Salesforce’s knowledge base and documentation, we&#x27;re always able to explain to these regulatory bodies what and why Archie is answering.\" Boosting customer adoptionCustomer buy-in is always a major challenge when it comes to new AI tools, and Archie was no exception. On the initial rollout of the new interface, some customers were confused by the new text box in the center of their screen and didn’t immediately understand how to interact with it.“We learned the hard way that we needed better change management, and to make sure our industry customers understood they could simply ask questions in natural language,” Khanna says.Personalization, they soon realized, was the key to gen AI adoption. \"Once customers had a better understanding of how Archie could be used for more efficient self-service, suddenly our adoption rate went up to 59%,\" he says. \"Personalization was very critical for us. Now we see the uptake, and we hope to see that continue when we roll out Archie to the rest of our products.\"Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "content": "Presented by Salesforce Smarsh, a global provider of cloud-native, AI-driven solutions that capture, archive, and analyze communications data and intelligence for highly regulated industries, set an ambitious goal: use AI to scale its workforce and increase productivity by 30%. But its customer service team had already identified the real challenge — customers were navigating a maze of products, documentation, and compliance requirements.The solution wasn’t just more automation. It was a single, intelligent entry point into support.\"At the team level we asked ourselves, how can we become a better support organization for our regulated industry customers given that we keep on acquiring companies and have so many products to support?\" says Rohit Khanna, Smarsh chief customer officer. \"How do we harness the knowledge we have internally and present that to these customers in a way that makes our teams more efficient, and customer service more effective?\"In practice, that meant building an intelligent, human-centric “front door” trained on Smarsh’s proprietary knowledge. The system centralizes the support journey, distilling complex AI infrastructure into a simple, practical experience. Customers bypass complex navigation trees and describe what they need in plain language, and the AI directs them to the right solution — reducing the friction of traditional self-service.Archie, the Smarsh AI support agentSmarsh named its AI support agent \"Archie.\" While many AI initiatives stall during the last mile — the difficult transition from a successful pilot to a durable, production-scale operation — Smarsh avoided this by building on a deeply unified platform. The company chose Salesforce’s Agentforce 360 Platform to ensure Archie had the shared context, controlled execution, and orchestration required for an agentic enterprise.By deploying Agentforce rather than a bespoke DIY solution, Smarsh ensures Archie can plan and execute work across systems for smarter self-service and faster resolutions. This approach allows Smarsh to move work forward automatically across data and workflows, achieving greater efficiency without compromising the strict compliance rigor required by their industry. As a result, the company expects to see a 20% increase in its customer self-service success rates, 25% faster issue resolution compared to traditional self-service search and browse methods, and a 30% boost in service representative productivity.The bleeding edge of customer service AIBoth generative and agentic AI are rewriting the customer service playbook, yet the technology’s nascency can create intimidating hurdles. An organization can reap major rewards by moving decisively when launching AI initiatives, but it still requires care, forethought, and the right partnerships, Khanna says. Part of that is careful vendor choice.\"We&#x27;re a Salesforce shop,” he shared. “We use a core set of Salesforce products, including Data 360, Agentforce Service, Agentforce Sales and more, so it was wise to hang our hat on an AI agent provided to us by Salesforce rather than buying something from outside. We know that in the beginning, as new tech comes, it will be challenging, but Salesforce is up to the task and we&#x27;ll evolve together.\"From day one, effective AI has demanded a single non-negotiable prerequisite: clean, secure data. Grounding generative AI in an organization’s verified corporate knowledge and internal data slashes hallucination risk while delivering a significantly better user experience. Smarsh, however, didn’t wait for the industry to catch up. The company anticipated this need nearly half a decade ago, spending years meticulously rationalizing, annotating, and anonymizing its data to prepare for this exact moment. \"A lot of people run into challenges and don’t complete their AI projects because the data’s not ready and it&#x27;s not there,\" Khanna says. \"We started out strong, right out of the gate because our data was already clean and locked down, and today we’re in production with a service agent as we speak.\"Prioritizing data trustGiven Smarsh’s focus on regulatory compliance, Archie was introduced to replace the company’s previous self-service customer support chatbot. Janine Deegan, digital support program manager at Smarsh, worked with the Salesforce admin team on Smarsh&#x27;s Agentforce deployment. \"With Archie, the goal was to move beyond experimentation and make AI genuinely usable in a regulated environment. It wasn’t as simple as just switching on an agent; we had to build a system that gave that raw intelligence the context and control our industry actually requires, which is why we chose Salesforce,” Deegan says. “By connecting our documentation directly to Agentforce, which is backed by the Salesforce Trust Layer, we turned our static data into a live, trusted resource that handles the precision needed for a regulated space.\"Given its criticality, Khanna adds that maintaining pristine, secure documentation and data requires constant vigilance. To guarantee this, Smarsh erased the lines between departments, fusing the documentation team with the AI team. Now the two work in a tight loop: all of the material the document team produces, the AI team checks, verifies, and opens it up to the LLM. AI and regulatory compliance\"We’re in a compliance world. We’re custodians of archival data for all of our financial institutions, and our data is so sacred that we don’t give it away, \" Khanna explains. \"We have to be very cognizant of security and identity as we open up our systems to agentic AI.\"Infosec requirements were a critical consideration for rolling out Agentforce. Smarsh is regularly audited not just by regulatory bodies but also by the banks and financial institutions that have to comply with stringent data protection rules and ask for model risk management, (MRM). \"The safety regulators and banks ask for MRM,\" Khanna says. \"They say, ‘Tell me that all my data is not going to the public because it’s connecting with an LLM. Tell me about the LLM. Tell me about the model you’re using.’ We worked with Salesforce so we could get MRM approval for our customers. And thanks to Salesforce’s knowledge base and documentation, we&#x27;re always able to explain to these regulatory bodies what and why Archie is answering.\" Boosting customer adoptionCustomer buy-in is always a major challenge when it comes to new AI tools, and Archie was no exception. On the initial rollout of the new interface, some customers were confused by the new text box in the center of their screen and didn’t immediately understand how to interact with it.“We learned the hard way that we needed better change management, and to make sure our industry customers understood they could simply ask questions in natural language,” Khanna says.Personalization, they soon realized, was the key to gen AI adoption. \"Once customers had a better understanding of how Archie could be used for more efficient self-service, suddenly our adoption rate went up to 59%,\" he says. \"Personalization was very critical for us. Now we see the uptake, and we hope to see that continue when we roll out Archie to the rest of our products.\"Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "feed_position": 5,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/tpGhXZcbNGfxfdbzyArgw/a690a08505d7402f5d7149901398e9bf/AdobeStock_109891076.jpeg?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/google-clamps-down-on-antigravity-malicious-usage-cutting-off-openclaw-users",
          "published_at": "Mon, 23 Feb 2026 23:01:00 GMT",
          "title": "Google clamps down on Antigravity 'malicious usage', cutting off OpenClaw users in sweeping ToS enforcement move",
          "standfirst": "Google caused controversy among some developers this weekend and today, Monday, February 23rd, after restricting their usage of its new Antigravity \"vibe coding\" platform, alleging \"maliciously usage.\" Some users who had been using the open source autonomous AI agent OpenClaw in conjunction with agents built on Antigravity, as well as those who had connected OpenClaw agents to their Gmails, claimed on social media that they lost access to their Google accounts. According to Google, said users had been using Antigravity to access a larger number of Gemini tokens via third-party platforms like OpenClaw, which overwhelmed the system for other Antigravity customers. This move has cut off several users, underscoring the architectural and trust issues that can arise with OpenClaw. The timing of Google’s crackdown is particularly pointed. Just one week ago, on February 15, OpenAI CEO Sam Altman announced that OpenClaw creator Peter Steinberger had joined OpenAI to lead its “next generation of personal agents.” While OpenClaw remains an open-source project under an independent foundation, it is now financially backed and strategically guided by Google’s primary rival. By cutting off OpenClaw’s access to Antigravity, Google isn’t just protecting its server load; it is effectively severing a pipeline that allows an OpenAI-adjacent tool to leverage Google’s most advanced Gemini models.Google DeepMind engineer and former CEO and founder of Windsurf, Varun Mohan, said in an X post that the company noticed “malicious usage” that led to service degradation.“We’ve been seeing a massive increase in malicious usage of the Antigravity backend that has tremendously degraded the quality of service for our users. We needed to find a path to quickly shut off access to these users that are not using the product as intended. We understand that a subset of these users were not aware that this was against our ToS [Terms of Service] and will get a path for them to come back on but we have limited capacity and want to be fair to our actual users,” the post said. A Google DeepMind spokesperson told VentureBeat that the move is not to permanently ban the use of Antigravity to access third-party platforms, but to align its use with the platform’s terms of service. Unsurprisingly, Google’s move has caused a furor among OpenClaw users, including from OpenClaw creator Peter Steinberger, who announced that OpenClaw will remove Google support as a result. Infrastructure and connection uncertaintyOpenClaw emerged as a way for individual users to run shell commands and access local files, fulfilling a major promise of AI agents: efficiently running workflows for users. But, as VentureBeat has frequently pointed out, it can often run into security and guardrail issues. There are companies building ways for enterprise customers to access OpenClaw securely and with a governance layer, though OpenClaw is so new that we should expect more announcements soon.However, Google’s move was not framed as a security issue but rather as one of access and runtime, further showing that there is still significant uncertainty when users want to bring in something like OpenClaw into their workflow. This is not the first time developers and power users of agentic AI found their access curtailed. Last year, Anthropic throttled access to Claude Code after the company claimed some users were abusing the system by running it 24/7. What this does highlight is the disconnect between companies like Google and OpenClaw users. OpenClaw offered many interesting possibilities for creating workflows with agents. However, because it is continually evolving, users may inadvertently run afoul of ToS or rate limits. Mohan said Google is working to bring the banned users back, but whether this means the company will amend its ToS or figure out a secure connection between OpenClaw agents and Antigravity models remains to be seen. For developers, the message is clear: the era of \"bring your own agent\" to a frontier model is ending. Providers are now prioritizing vertically integrated experiences where they can capture 100% of the telemetry and subscription revenue, often at the expense of the open-source interoperability that defined the early days of the LLM boom.Affected usersSeveral users said on both the Y Combinator chat boards and X that they no longer had access to their Google accounts after running OpenClaw instances for certain Google products. Google’s move mirrors a broader industry shift toward \"walled garden\" agent ecosystems. Earlier this year, Anthropic introduced \"client fingerprinting\" to ensure that its Claude Code environment remains the exclusive interface for its models, effectively locking out third-party wrappers like OpenClaw. For developers, the message is clear: the era of \"bring your own agent\" to a frontier model is ending. Providers are now prioritizing vertically integrated experiences where they can capture 100% of the telemetry and subscription revenue, often at the expense of the open-source interoperability that defined the early days of the LLM boom.Some have said they will no longer use Google or Gemini for their projects. Right now, people who still want to keep using Antigravity will need to wait until Google figures out a way for them to use OpenClaw and access Gemini tokens in a manner Google deems “fair.” Google DeepMind reiterated that it had only cut access to Antigravity, not to other Google applications. Conclusion: the enterprise takeawayFor enterprise technical decision-makers, the \"Antigravity Ban\" serves as a definitive case study in the risks of agentic dependency. As the industry moves from chatbots to autonomous agents, the following realities must now dictate strategy:Platform fragility is the new normal: The sudden lockout of $250/month \"Ultra\" users proves that even high-paying enterprise customers have little leverage when a provider decides to change its \"fair use\" definitions. Relying on OAuth-based third-party wrappers for core business logic is now a high-risk gamble.The rise of local-first governance: With OpenClaw moving toward an OpenAI-backed foundation and Google/Anthropic tightening their clouds, enterprises should prioritize agent frameworks that can run \"local-first\" or within VPCs. The \"token loophole\" that OpenClaw exploited is being closed; future agentic scale will require direct, high-cost API contracts rather than subsidized consumer seats.Account portability as a requirement: The fact that users \"lost access to their Google accounts\" underscores the danger of bundling development environments with primary identity providers. Decision-makers should decouple AI development from core corporate identity (SSO) where possible to avoid a single ToS violation paralyzing an entire team&#x27;s communications.Ultimately, the Antigravity incident marks the end of the \"Wild West\" for AI agents. As Google and OpenAI stake their claims, the enterprise must choose between the stability of the walled garden or the complexity (and cost) of truly independent, self-hosted infrastructure.",
          "content": "Google caused controversy among some developers this weekend and today, Monday, February 23rd, after restricting their usage of its new Antigravity \"vibe coding\" platform, alleging \"maliciously usage.\" Some users who had been using the open source autonomous AI agent OpenClaw in conjunction with agents built on Antigravity, as well as those who had connected OpenClaw agents to their Gmails, claimed on social media that they lost access to their Google accounts. According to Google, said users had been using Antigravity to access a larger number of Gemini tokens via third-party platforms like OpenClaw, which overwhelmed the system for other Antigravity customers. This move has cut off several users, underscoring the architectural and trust issues that can arise with OpenClaw. The timing of Google’s crackdown is particularly pointed. Just one week ago, on February 15, OpenAI CEO Sam Altman announced that OpenClaw creator Peter Steinberger had joined OpenAI to lead its “next generation of personal agents.” While OpenClaw remains an open-source project under an independent foundation, it is now financially backed and strategically guided by Google’s primary rival. By cutting off OpenClaw’s access to Antigravity, Google isn’t just protecting its server load; it is effectively severing a pipeline that allows an OpenAI-adjacent tool to leverage Google’s most advanced Gemini models.Google DeepMind engineer and former CEO and founder of Windsurf, Varun Mohan, said in an X post that the company noticed “malicious usage” that led to service degradation.“We’ve been seeing a massive increase in malicious usage of the Antigravity backend that has tremendously degraded the quality of service for our users. We needed to find a path to quickly shut off access to these users that are not using the product as intended. We understand that a subset of these users were not aware that this was against our ToS [Terms of Service] and will get a path for them to come back on but we have limited capacity and want to be fair to our actual users,” the post said. A Google DeepMind spokesperson told VentureBeat that the move is not to permanently ban the use of Antigravity to access third-party platforms, but to align its use with the platform’s terms of service. Unsurprisingly, Google’s move has caused a furor among OpenClaw users, including from OpenClaw creator Peter Steinberger, who announced that OpenClaw will remove Google support as a result. Infrastructure and connection uncertaintyOpenClaw emerged as a way for individual users to run shell commands and access local files, fulfilling a major promise of AI agents: efficiently running workflows for users. But, as VentureBeat has frequently pointed out, it can often run into security and guardrail issues. There are companies building ways for enterprise customers to access OpenClaw securely and with a governance layer, though OpenClaw is so new that we should expect more announcements soon.However, Google’s move was not framed as a security issue but rather as one of access and runtime, further showing that there is still significant uncertainty when users want to bring in something like OpenClaw into their workflow. This is not the first time developers and power users of agentic AI found their access curtailed. Last year, Anthropic throttled access to Claude Code after the company claimed some users were abusing the system by running it 24/7. What this does highlight is the disconnect between companies like Google and OpenClaw users. OpenClaw offered many interesting possibilities for creating workflows with agents. However, because it is continually evolving, users may inadvertently run afoul of ToS or rate limits. Mohan said Google is working to bring the banned users back, but whether this means the company will amend its ToS or figure out a secure connection between OpenClaw agents and Antigravity models remains to be seen. For developers, the message is clear: the era of \"bring your own agent\" to a frontier model is ending. Providers are now prioritizing vertically integrated experiences where they can capture 100% of the telemetry and subscription revenue, often at the expense of the open-source interoperability that defined the early days of the LLM boom.Affected usersSeveral users said on both the Y Combinator chat boards and X that they no longer had access to their Google accounts after running OpenClaw instances for certain Google products. Google’s move mirrors a broader industry shift toward \"walled garden\" agent ecosystems. Earlier this year, Anthropic introduced \"client fingerprinting\" to ensure that its Claude Code environment remains the exclusive interface for its models, effectively locking out third-party wrappers like OpenClaw. For developers, the message is clear: the era of \"bring your own agent\" to a frontier model is ending. Providers are now prioritizing vertically integrated experiences where they can capture 100% of the telemetry and subscription revenue, often at the expense of the open-source interoperability that defined the early days of the LLM boom.Some have said they will no longer use Google or Gemini for their projects. Right now, people who still want to keep using Antigravity will need to wait until Google figures out a way for them to use OpenClaw and access Gemini tokens in a manner Google deems “fair.” Google DeepMind reiterated that it had only cut access to Antigravity, not to other Google applications. Conclusion: the enterprise takeawayFor enterprise technical decision-makers, the \"Antigravity Ban\" serves as a definitive case study in the risks of agentic dependency. As the industry moves from chatbots to autonomous agents, the following realities must now dictate strategy:Platform fragility is the new normal: The sudden lockout of $250/month \"Ultra\" users proves that even high-paying enterprise customers have little leverage when a provider decides to change its \"fair use\" definitions. Relying on OAuth-based third-party wrappers for core business logic is now a high-risk gamble.The rise of local-first governance: With OpenClaw moving toward an OpenAI-backed foundation and Google/Anthropic tightening their clouds, enterprises should prioritize agent frameworks that can run \"local-first\" or within VPCs. The \"token loophole\" that OpenClaw exploited is being closed; future agentic scale will require direct, high-cost API contracts rather than subsidized consumer seats.Account portability as a requirement: The fact that users \"lost access to their Google accounts\" underscores the danger of bundling development environments with primary identity providers. Decision-makers should decouple AI development from core corporate identity (SSO) where possible to avoid a single ToS violation paralyzing an entire team&#x27;s communications.Ultimately, the Antigravity incident marks the end of the \"Wild West\" for AI agents. As Google and OpenAI stake their claims, the enterprise must choose between the stability of the walled garden or the complexity (and cost) of truly independent, self-hosted infrastructure.",
          "feed_position": 6,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/vwGThxYtgeCfHxjn466tk/5630229b22b3017cc1edff8e5021d66a/crimedy7_illustration_of_a_lobster_thats_in_a_cage_--ar_169_-_2081b356-9d2f-480b-9bef-99c11d44bb10_1.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/gaming/bungie-says-no-second-chances-if-youre-caught-cheating-in-marathon-191633998.html",
          "published_at": "Mon, 23 Feb 2026 19:16:33 +0000",
          "title": "Bungie says 'no second chances' if you're caught cheating in Marathon",
          "standfirst": "Bungie isn't taking any prisoners when it comes to cheating on its upcoming extraction shooter, Marathon. In a detailed blog post explaining its anti-cheat measures, Bungie took a very declarative position against those caught trying to gain an unfair advantage. \"We are taking a strong stance against cheating and anyone found to be cheating or developing cheats will be permanently banned from playing Marathon forever, no second chances,\" the blog post read, adding that there will be an appeals system in place. However, Bungie's anti-cheat standards go beyond punishment. In the blog post, Bungie detailed that Marathon's dedicated servers have full authority on movement, shooting, actions, and inventory. Since these key actions rely on the server, it will translate to smoother gunplay for players as well as the prevention of cheats related to teleportation, unlimited ammo or damage manipulation. Bungie is also incorporating a \"Fog of War\" system that limits an individual player's client to see only certain regions of a map, which should prevent wall hacks, ESP cheats or loot revealers. On top of these robust regulations, Bungie is utilizing BattlEye, a kernel-level anticheat that's seen with other popular multiplayer shooters like Fortnite, Rainbow Six Siege and Destiny 2. Bungie added that in the event of disconnecting, you'll be able to reconnect to your run without any hitches. If players can't reconnect due to an issue with the servers, Bungie said it will \"attempt to return the starting gear to all impacted players.\" Marathon isn't out until March 5, but Bungie is doing a preview weekend with the Server Slam event starting February 26. Still, it's obvious that Bungie already wants to get ahead of the competition, since Arc Raiders, another recently released extraction shooter, has been dealing with its own cheating problem. To address the rise in cheating, the game's developer, Embark Studios, implemented a three-strike system, which some players have criticized as too lenient.This article originally appeared on Engadget at https://www.engadget.com/gaming/bungie-says-no-second-chances-if-youre-caught-cheating-in-marathon-191633998.html?src=rss",
          "content": "Bungie isn't taking any prisoners when it comes to cheating on its upcoming extraction shooter, Marathon. In a detailed blog post explaining its anti-cheat measures, Bungie took a very declarative position against those caught trying to gain an unfair advantage. \"We are taking a strong stance against cheating and anyone found to be cheating or developing cheats will be permanently banned from playing Marathon forever, no second chances,\" the blog post read, adding that there will be an appeals system in place. However, Bungie's anti-cheat standards go beyond punishment. In the blog post, Bungie detailed that Marathon's dedicated servers have full authority on movement, shooting, actions, and inventory. Since these key actions rely on the server, it will translate to smoother gunplay for players as well as the prevention of cheats related to teleportation, unlimited ammo or damage manipulation. Bungie is also incorporating a \"Fog of War\" system that limits an individual player's client to see only certain regions of a map, which should prevent wall hacks, ESP cheats or loot revealers. On top of these robust regulations, Bungie is utilizing BattlEye, a kernel-level anticheat that's seen with other popular multiplayer shooters like Fortnite, Rainbow Six Siege and Destiny 2. Bungie added that in the event of disconnecting, you'll be able to reconnect to your run without any hitches. If players can't reconnect due to an issue with the servers, Bungie said it will \"attempt to return the starting gear to all impacted players.\" Marathon isn't out until March 5, but Bungie is doing a preview weekend with the Server Slam event starting February 26. Still, it's obvious that Bungie already wants to get ahead of the competition, since Arc Raiders, another recently released extraction shooter, has been dealing with its own cheating problem. To address the rise in cheating, the game's developer, Embark Studios, implemented a three-strike system, which some players have criticized as too lenient.This article originally appeared on Engadget at https://www.engadget.com/gaming/bungie-says-no-second-chances-if-youre-caught-cheating-in-marathon-191633998.html?src=rss",
          "feed_position": 35
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/falcon-northwest-fragbox-review-a-compact-gaming-rig-that-does-everything-right-130000837.html",
          "published_at": "Mon, 23 Feb 2026 18:51:26 +0000",
          "title": "Falcon Northwest FragBox review: A compact gaming rig that does everything right",
          "standfirst": "Mafia: The Old Country demands to be played on an enormous screen. As much as I love my 32-inch Alienware OLED gaming monitor, it doesn't do justice to Mafia's cinematic vistas of Sicily. But, I also wanted to play that game in its full 4K glory, with none of the compromises of today's game consoles. So why not just shove a tiny gaming desktop under my home theater? Enter the Fragbox, Falcon Northwest's revamped small form factor gaming PC. While it's very expensive, starting at $3,997, it's incredibly powerful and gives you the freedom to easily upgrade the hardware down the line. I know what you're thinking: \"A $4,000 desktop, in this economy?\" That pricing also doesn't include upgrading from the stock NVIDIA's RTX 5070 GPU, as well as adding more RAM and larger SSDs, all of which could drive the price up thousands more. I initially planned to review the FragBox back in early December 2025, before the AI-induced RAMaggedon made memory, storage and other components dramatically more expensive. Falcon Northwest is mainly known as a boutique and high-end system builder, so its wealthier clientele can likely weather the pricing storm. If you're looking for a deal, though, you won't find it here. So what, exactly, is a FragBox? Imagine a typical mid-tower desktop squashed down to a system that's only 10.2-inches tall, 10.5-inches wide and 15.9-inches deep. When Falcon initially debuted the FragBox in 2003, it was notable for being a genuinely small PC that used full-sized parts. That's still a main selling point today: It can still fit in large NVIDIA GPUs, including the beefy RTX 5090, as well as either Intel's latest Core Ultra chips or AMD's Ryzen 9000 CPUs. A huge 280mm radiator sits at the top pulling out hot air, and it also serves as an All-in-One (AIO) liquid cooler for the CPU. At 25 pounds, the FragBox isn't exactly light, but its sturdy metal handle makes it easy to move around. Most mid-tower desktops usually weigh between 20 and 35 pounds, depending on their case material. But they're also much larger and harder to squeeze into tight spaces. The FragBox's relatively squat size makes it easy to shove into a home entertainment center, or just sit on the corner of your desk. If you need a bit more height clearance, you can also remove the handle from the top panel. Just be sure there’s enough room for some airflow — all of that heat has to go somewhere, right? Falcon Northwest FragBox Devindra Hardawar for Engadget Despite its density, the FragBox's elegant design makes it a cinch to access to all of the system's components. Just unscrew the side and top panels and you can easily remove the GPU, RAM, storage and other major components. There are three slots of M.2 SSDs, as well as two locations for 2.5-inch drives and a spot for a large 3.5-inch HDD. The system is bundled with a 1,200W power supply, which should be more than enough to handle future GPUs and CPUs. Ports are plentiful as well: There are two USB-A and one USB-C connections right up front, alongside a headphone jack. On the rear, you've got your typical assortment of mid-tower connections, including four USB-A 2.0 connections, seven USB-A 3 ports, one 20G USB-C 3.2 port, 2.5G Ethernet, HDMI and DisplayPort. Our RTX 5090 review unit also included three DisplayPort jacks and one HDMI connection (which you'll see on most GPUs). Wi-Fi 6E was also built into our unit, but Falcon says that Wi-Fi 7 is now standard with new builds. Falcon Northwest FragBox Devindra Hardawar for Engadget The FragBox, thankfully, lacks the garish LEDs and cheesy thermal glass you find on more ostentatious gaming rigs. Falcon Northwest's aluminum case looks and feels stately, like an old-school luxury car. If you want something flashier, you can shell out an additional $400 for a custom UV printed case or $149 for a UV-printed front panel. Our review unit was equipped with AMD's Ryzen 9950X3D CPU, NVIDIA's RTX 5090, 96GB of DDR5 RAM and a 2TB SSD, which adds up to a whopping $7,995. Five months ago, it would have cost $7,047 —- you can thank the RAM shortage for the price jump. Even before benchmarking or running any games, I expected it to be a beast. In PCMark 10, the FragBox scored a whopping 13,810, which is around 500 points higher than my mid-tower system with the same CPU and GPU. It also scored the highest 3DMark Speedway and Port Royal ray tracing scores I've ever seen. Even more impressive, the FragBox's fans were barely audible under load, and the CPU and GPU sat at a chill 52C and 65C, respectively CPU GeekBench 6 CPU GeekBench 6 GPU Cinebench 2024 Falcon Northwest FragBox 3,445/22,787 390,148 N/A Desktop with AMD Ryzen 9 9950X3D, RTX 5090 3,366/18,950 381,400 134/2,124 Desktop with AMD Ryzen 9 7900X, RTX 5090 2,822/14,216 358,253 113/1,103 Apple Mac Studio M4 Max 4,090/26,394 116,028 190/2066 To get back to my initial point, it ran Mafia: The Old Country in 4K flawlessly, with every graphics setting cranked all the way up. While playing on my 120-inch projector home theater setup, the game reached 62 fps natively, and flipping on DLSS upscaling and frame generation bumped that up to 120 fps. Not that you need a super higher framerate for a slow-paced, mostly cinematic action game. I was just happy to be playing without any compromises — even the PS5 Pro can't reach the same level of graphical fidelity as the monstrously powerful RTX 5090. Falcon Northwest FragBox Devindra Hardawar for Engadget I'm no stranger to big-screen PC gaming, but previously I've had to run a laughably long HDMI cable from my desktop to make it work. I'm just too old for that mess now. And it also doesn't work consistently, especially at higher framerates, thanks to the massive bandwidth required to pump out 4K at high refresh rates. In-home game streaming is also an option, but that's not great when you're blowing games up to an enormous TV or projector screen. It's just too hard to ignore the imperfections of streaming compression. (Admittedly, I need to test newer high-bandwidth options, especially after I was impressed by NVIDIA's GeForce Now upgrade last year.) The FragBox also made it easy to jump into all of my recent Steam titles, including Mewgeneics and Arc Raiders on a big screen. Unfortunately, Windows itself remains a key stumbling block for home theater PC gaming. You'll still need to keep a keyboard and PC around to deal with the initial OS configuration. And even once I enabled Steam's Big Picture mode, which offers excellent controller options, I still occasionally had to deal with Windows Updates and other annoyances. Falcon Northwest FragBox Devindra Hardawar for Engadget Microsoft is currently trying to optimize Windows for gaming handhelds, and it's reportedly doing even more to make a future PC-powered Xbox feel more console-like. For now, though, using a Windows PC in your home theater doesn't feel much different than it did a decade ago. Steam is your savior, Windows is your enemy. Or you could just save thousands of dollars and buy a $500 PlayStation 5 or $700 PS5 Pro, instead. The latter will still get you smooth framerates and a healthy dose of ray tracing, without the annoyance of Windows, keyboards and mice. But if you just want a compact and insanely powerful gaming desktop, and you don't mind spending a premium, it's hard to deny that the FragBox gets everything right. Update 2/23, 1:48PM: Added updated information about Wi-Fi 7, handle removability and pricing.This article originally appeared on Engadget at https://www.engadget.com/computing/falcon-northwest-fragbox-review-a-compact-gaming-rig-that-does-everything-right-130000837.html?src=rss",
          "content": "Mafia: The Old Country demands to be played on an enormous screen. As much as I love my 32-inch Alienware OLED gaming monitor, it doesn't do justice to Mafia's cinematic vistas of Sicily. But, I also wanted to play that game in its full 4K glory, with none of the compromises of today's game consoles. So why not just shove a tiny gaming desktop under my home theater? Enter the Fragbox, Falcon Northwest's revamped small form factor gaming PC. While it's very expensive, starting at $3,997, it's incredibly powerful and gives you the freedom to easily upgrade the hardware down the line. I know what you're thinking: \"A $4,000 desktop, in this economy?\" That pricing also doesn't include upgrading from the stock NVIDIA's RTX 5070 GPU, as well as adding more RAM and larger SSDs, all of which could drive the price up thousands more. I initially planned to review the FragBox back in early December 2025, before the AI-induced RAMaggedon made memory, storage and other components dramatically more expensive. Falcon Northwest is mainly known as a boutique and high-end system builder, so its wealthier clientele can likely weather the pricing storm. If you're looking for a deal, though, you won't find it here. So what, exactly, is a FragBox? Imagine a typical mid-tower desktop squashed down to a system that's only 10.2-inches tall, 10.5-inches wide and 15.9-inches deep. When Falcon initially debuted the FragBox in 2003, it was notable for being a genuinely small PC that used full-sized parts. That's still a main selling point today: It can still fit in large NVIDIA GPUs, including the beefy RTX 5090, as well as either Intel's latest Core Ultra chips or AMD's Ryzen 9000 CPUs. A huge 280mm radiator sits at the top pulling out hot air, and it also serves as an All-in-One (AIO) liquid cooler for the CPU. At 25 pounds, the FragBox isn't exactly light, but its sturdy metal handle makes it easy to move around. Most mid-tower desktops usually weigh between 20 and 35 pounds, depending on their case material. But they're also much larger and harder to squeeze into tight spaces. The FragBox's relatively squat size makes it easy to shove into a home entertainment center, or just sit on the corner of your desk. If you need a bit more height clearance, you can also remove the handle from the top panel. Just be sure there’s enough room for some airflow — all of that heat has to go somewhere, right? Falcon Northwest FragBox Devindra Hardawar for Engadget Despite its density, the FragBox's elegant design makes it a cinch to access to all of the system's components. Just unscrew the side and top panels and you can easily remove the GPU, RAM, storage and other major components. There are three slots of M.2 SSDs, as well as two locations for 2.5-inch drives and a spot for a large 3.5-inch HDD. The system is bundled with a 1,200W power supply, which should be more than enough to handle future GPUs and CPUs. Ports are plentiful as well: There are two USB-A and one USB-C connections right up front, alongside a headphone jack. On the rear, you've got your typical assortment of mid-tower connections, including four USB-A 2.0 connections, seven USB-A 3 ports, one 20G USB-C 3.2 port, 2.5G Ethernet, HDMI and DisplayPort. Our RTX 5090 review unit also included three DisplayPort jacks and one HDMI connection (which you'll see on most GPUs). Wi-Fi 6E was also built into our unit, but Falcon says that Wi-Fi 7 is now standard with new builds. Falcon Northwest FragBox Devindra Hardawar for Engadget The FragBox, thankfully, lacks the garish LEDs and cheesy thermal glass you find on more ostentatious gaming rigs. Falcon Northwest's aluminum case looks and feels stately, like an old-school luxury car. If you want something flashier, you can shell out an additional $400 for a custom UV printed case or $149 for a UV-printed front panel. Our review unit was equipped with AMD's Ryzen 9950X3D CPU, NVIDIA's RTX 5090, 96GB of DDR5 RAM and a 2TB SSD, which adds up to a whopping $7,995. Five months ago, it would have cost $7,047 —- you can thank the RAM shortage for the price jump. Even before benchmarking or running any games, I expected it to be a beast. In PCMark 10, the FragBox scored a whopping 13,810, which is around 500 points higher than my mid-tower system with the same CPU and GPU. It also scored the highest 3DMark Speedway and Port Royal ray tracing scores I've ever seen. Even more impressive, the FragBox's fans were barely audible under load, and the CPU and GPU sat at a chill 52C and 65C, respectively CPU GeekBench 6 CPU GeekBench 6 GPU Cinebench 2024 Falcon Northwest FragBox 3,445/22,787 390,148 N/A Desktop with AMD Ryzen 9 9950X3D, RTX 5090 3,366/18,950 381,400 134/2,124 Desktop with AMD Ryzen 9 7900X, RTX 5090 2,822/14,216 358,253 113/1,103 Apple Mac Studio M4 Max 4,090/26,394 116,028 190/2066 To get back to my initial point, it ran Mafia: The Old Country in 4K flawlessly, with every graphics setting cranked all the way up. While playing on my 120-inch projector home theater setup, the game reached 62 fps natively, and flipping on DLSS upscaling and frame generation bumped that up to 120 fps. Not that you need a super higher framerate for a slow-paced, mostly cinematic action game. I was just happy to be playing without any compromises — even the PS5 Pro can't reach the same level of graphical fidelity as the monstrously powerful RTX 5090. Falcon Northwest FragBox Devindra Hardawar for Engadget I'm no stranger to big-screen PC gaming, but previously I've had to run a laughably long HDMI cable from my desktop to make it work. I'm just too old for that mess now. And it also doesn't work consistently, especially at higher framerates, thanks to the massive bandwidth required to pump out 4K at high refresh rates. In-home game streaming is also an option, but that's not great when you're blowing games up to an enormous TV or projector screen. It's just too hard to ignore the imperfections of streaming compression. (Admittedly, I need to test newer high-bandwidth options, especially after I was impressed by NVIDIA's GeForce Now upgrade last year.) The FragBox also made it easy to jump into all of my recent Steam titles, including Mewgeneics and Arc Raiders on a big screen. Unfortunately, Windows itself remains a key stumbling block for home theater PC gaming. You'll still need to keep a keyboard and PC around to deal with the initial OS configuration. And even once I enabled Steam's Big Picture mode, which offers excellent controller options, I still occasionally had to deal with Windows Updates and other annoyances. Falcon Northwest FragBox Devindra Hardawar for Engadget Microsoft is currently trying to optimize Windows for gaming handhelds, and it's reportedly doing even more to make a future PC-powered Xbox feel more console-like. For now, though, using a Windows PC in your home theater doesn't feel much different than it did a decade ago. Steam is your savior, Windows is your enemy. Or you could just save thousands of dollars and buy a $500 PlayStation 5 or $700 PS5 Pro, instead. The latter will still get you smooth framerates and a healthy dose of ray tracing, without the annoyance of Windows, keyboards and mice. But if you just want a compact and insanely powerful gaming desktop, and you don't mind spending a premium, it's hard to deny that the FragBox gets everything right. Update 2/23, 1:48PM: Added updated information about Wi-Fi 7, handle removability and pricing.This article originally appeared on Engadget at https://www.engadget.com/computing/falcon-northwest-fragbox-review-a-compact-gaming-rig-that-does-everything-right-130000837.html?src=rss",
          "feed_position": 36,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/falcon_northwest_fragbox_2.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/entertainment/tv-movies/a-new-evangelion-series-is-coming-from-studio-khara-and-yoko-taro-creator-of-nier-170916543.html",
          "published_at": "Mon, 23 Feb 2026 17:09:16 +0000",
          "title": "A new Evangelion series is coming from Studio Khara and Yoko Taro, creator of NieR",
          "standfirst": "Anime fans rejoice, as there's a new Neon Genesis Evangelion series on the horizon. This was announced during a 30th anniversary event held in Japan. The bad news? Franchise creator Hideaki Anno won't be writing the scripts. However, his replacement will be Yoko Taro, the guy who created the video game NieR. He also wears a giant and rather unsettling moon mask for some reason. The NieR franchise is known for rich and complex lore, with a story spanning thousands of years that occasionally dips into a parallel universe. Wikimedia Commons Evangelion veteran Kazuya Tsurumaki will be on hand to direct episodes, which is nice for long-time fans. He directed the Rebuild of Evangelion films and the recent Mobile Suit Gundam GQuuuuuuX anime. Composer Keiichi Okabe, from the NieR franchise, is scoring the new show. The new series will be produced by Studio Khara and Cloverworks. While we know a fair bit about who's behind the scenes of the upcoming show, we don't know anything about the plot. We don't know if it's yet another remake of the original story, a sequel or some kind of spin-off like the chibi-inspired Petit Eva: Evangelion@School. There's a trailer, but it's light on details. New \"Neon Genesis Evangelion\" ANIME SERIES NEW TRAILER Written by Yoko Taro Directors: Kazuya Tsurumaki & Toko Yatabe Music: Keiichi Okabe Animation Production: CloverWorks x Khara pic.twitter.com/jnJZ12XSRb— Captain Melvin Seahorse⚘️ (@sshiroux19) February 23, 2026 With Taro on board, it could really go in any direction. It's worth remembering, after all, that NieR is actually a spin-off of a PS2 game called Drakengard. In one of the multiple endings of that game, a final boss is transported from a fantasy realm to modern-day Tokyo. Slaying this beast releases a virus that plagues humankind, which is what eventually leads to the post-apocalyptic setting of NieR. This is sort of like if the events of a Dragon Quest game somehow led to the world of Resident Evil. If there's anyone who can breathe fresh life into the Evangelion franchise, it's Taro. Did I mention he wears a gigantic moon mask? Also, this isn't his first time penning TV scripts. He co-wrote the NieR: Automata anime spinoff.This article originally appeared on Engadget at https://www.engadget.com/entertainment/tv-movies/a-new-evangelion-series-is-coming-from-studio-khara-and-yoko-taro-creator-of-nier-170916543.html?src=rss",
          "content": "Anime fans rejoice, as there's a new Neon Genesis Evangelion series on the horizon. This was announced during a 30th anniversary event held in Japan. The bad news? Franchise creator Hideaki Anno won't be writing the scripts. However, his replacement will be Yoko Taro, the guy who created the video game NieR. He also wears a giant and rather unsettling moon mask for some reason. The NieR franchise is known for rich and complex lore, with a story spanning thousands of years that occasionally dips into a parallel universe. Wikimedia Commons Evangelion veteran Kazuya Tsurumaki will be on hand to direct episodes, which is nice for long-time fans. He directed the Rebuild of Evangelion films and the recent Mobile Suit Gundam GQuuuuuuX anime. Composer Keiichi Okabe, from the NieR franchise, is scoring the new show. The new series will be produced by Studio Khara and Cloverworks. While we know a fair bit about who's behind the scenes of the upcoming show, we don't know anything about the plot. We don't know if it's yet another remake of the original story, a sequel or some kind of spin-off like the chibi-inspired Petit Eva: Evangelion@School. There's a trailer, but it's light on details. New \"Neon Genesis Evangelion\" ANIME SERIES NEW TRAILER Written by Yoko Taro Directors: Kazuya Tsurumaki & Toko Yatabe Music: Keiichi Okabe Animation Production: CloverWorks x Khara pic.twitter.com/jnJZ12XSRb— Captain Melvin Seahorse⚘️ (@sshiroux19) February 23, 2026 With Taro on board, it could really go in any direction. It's worth remembering, after all, that NieR is actually a spin-off of a PS2 game called Drakengard. In one of the multiple endings of that game, a final boss is transported from a fantasy realm to modern-day Tokyo. Slaying this beast releases a virus that plagues humankind, which is what eventually leads to the post-apocalyptic setting of NieR. This is sort of like if the events of a Dragon Quest game somehow led to the world of Resident Evil. If there's anyone who can breathe fresh life into the Evangelion franchise, it's Taro. Did I mention he wears a gigantic moon mask? Also, this isn't his first time penning TV scripts. He co-wrote the NieR: Automata anime spinoff.This article originally appeared on Engadget at https://www.engadget.com/entertainment/tv-movies/a-new-evangelion-series-is-coming-from-studio-khara-and-yoko-taro-creator-of-nier-170916543.html?src=rss",
          "feed_position": 40,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2026-02/45209e00-10d5-11f1-93df-540dd239e30e"
        }
      ],
      "featured_image": "https://images.ctfassets.net/jdtwqhzvc2n1/6RPhHUoUFspa6koUR32kvV/c51a10eb9600c128e13637793ca370ed/Gemini_Generated_Image_7ldhz77ldhz77ldh.png?w=300&q=30",
      "popularity_score": 2011.0201980555555
    },
    {
      "id": "cluster_49",
      "coverage": 2,
      "updated_at": "2026-02-24T19:45:37-05:00",
      "title": "Apple&#8217;s new age verification tools block underage app downloads where required by law",
      "neutral_headline": "Apple&#8217;s new age verification tools block underage app downloads...",
      "bullet_summary": [
        "Reported by The Verge, TechCrunch"
      ],
      "items": [
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/tech/884136/apple-age-verification-assurance-underage-app-downloads",
          "published_at": "2026-02-24T19:45:37-05:00",
          "title": "Apple&#8217;s new age verification tools block underage app downloads where required by law",
          "standfirst": "Apple, like many others, has had to launch age verification features in response to new requirements for age checks in many regions, and on Tuesday, the company announced new details about its tools that developers can use to \"meet their age assurance obligations under upcoming U.S. and regional laws, including in Brazil, Australia, Singapore, Utah, [&#8230;]",
          "content": "Apple, like many others, has had to launch age verification features in response to new requirements for age checks in many regions, and on Tuesday, the company announced new details about its tools that developers can use to \"meet their age assurance obligations under upcoming U.S. and regional laws, including in Brazil, Australia, Singapore, Utah, and Louisiana.\" One of the big updates is that users in Australia, Brazil, and Singapore can't download apps rated 18-plus unless their age has been confirmed through \"reasonable methods,\" which the App Store can confirm automatically. Apple notes that developers may still \"have separate obliga … Read the full story at The Verge.",
          "feed_position": 2
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2026/02/24/apple-rolls-out-age-verification-tools-worldwide-to-comply-with-growing-web-of-child-safety-laws/",
          "published_at": "Tue, 24 Feb 2026 23:21:54 +0000",
          "title": "Apple rolls out age-verification tools worldwide to comply with growing web of child safety laws",
          "standfirst": "Apple complies with new age-assurance laws in the U.S. and abroad, including those that block users from downloading apps aimed at adults.",
          "content": "Apple complies with new age-assurance laws in the U.S. and abroad, including those that block users from downloading apps aimed at adults.",
          "feed_position": 4
        }
      ],
      "popularity_score": 2009.1638091666666
    },
    {
      "id": "cluster_70",
      "coverage": 2,
      "updated_at": "Tue, 24 Feb 2026 20:35:49 +0000",
      "title": "The Pentagon has reportedly given Anthropic until Friday to let it use Claude as it sees fit",
      "neutral_headline": "US AI giant accuses Chinese rivals of mass data theft",
      "bullet_summary": [
        "Defense Secretary Pete Hegseth will reportedly give Anthropic until Friday to drop certain guardrails for military use, as reported by Axios",
        "The outlet also reported that CEO Dario Amodei met with Hegseth yesterday as the Pentagon ratcheted up pressure on the AI company to give in to its demands",
        "The Pentagon is reportedly ramping up conversations with OpenAI and Google about using their models for classified work",
        "com/ai/the-pentagon-has-reportedly-given-anthropic-until-friday-to-let-it-use-claude-as-it-sees-fit-203549467"
      ],
      "items": [
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/the-pentagon-has-reportedly-given-anthropic-until-friday-to-let-it-use-claude-as-it-sees-fit-203549467.html",
          "published_at": "Tue, 24 Feb 2026 20:35:49 +0000",
          "title": "The Pentagon has reportedly given Anthropic until Friday to let it use Claude as it sees fit",
          "standfirst": "Defense Secretary Pete Hegseth will reportedly give Anthropic until Friday to drop certain guardrails for military use, as reported by Axios. The outlet also reported that CEO Dario Amodei met with Hegseth yesterday as the Pentagon ratcheted up pressure on the AI company to give in to its demands. The makers of Claude have reportedly been offered an ultimatum: Either yield to the government's demands to remove limits for certain military applications, or potentially be forced to tailor its AI model to the government's needs under the Defense Production Act. Anthropic, for its part, has said that while it was willing to adopt certain policies for the Pentagon, it would not allow its model to be used for mass surveillance of Americans or for the development of autonomous weapons. Claude is currently the only AI model employed in some of the government's most sensitive work. \"The only reason we're still talking to these people is we need them and we need them now. The problem for these guys is they are that good,\" a defense official told Axios. The Pentagon is reportedly ramping up conversations with OpenAI and Google about using their models for classified work. ChatGPT and Gemini are already approved for unclassified government use. Elon Musk's xAI also recently signed with the DoD to use Grok in classified systems.This article originally appeared on Engadget at https://www.engadget.com/ai/the-pentagon-has-reportedly-given-anthropic-until-friday-to-let-it-use-claude-as-it-sees-fit-203549467.html?src=rss",
          "content": "Defense Secretary Pete Hegseth will reportedly give Anthropic until Friday to drop certain guardrails for military use, as reported by Axios. The outlet also reported that CEO Dario Amodei met with Hegseth yesterday as the Pentagon ratcheted up pressure on the AI company to give in to its demands. The makers of Claude have reportedly been offered an ultimatum: Either yield to the government's demands to remove limits for certain military applications, or potentially be forced to tailor its AI model to the government's needs under the Defense Production Act. Anthropic, for its part, has said that while it was willing to adopt certain policies for the Pentagon, it would not allow its model to be used for mass surveillance of Americans or for the development of autonomous weapons. Claude is currently the only AI model employed in some of the government's most sensitive work. \"The only reason we're still talking to these people is we need them and we need them now. The problem for these guys is they are that good,\" a defense official told Axios. The Pentagon is reportedly ramping up conversations with OpenAI and Google about using their models for classified work. ChatGPT and Gemini are already approved for unclassified government use. Elon Musk's xAI also recently signed with the DoD to use Grok in classified systems.This article originally appeared on Engadget at https://www.engadget.com/ai/the-pentagon-has-reportedly-given-anthropic-until-friday-to-let-it-use-claude-as-it-sees-fit-203549467.html?src=rss",
          "feed_position": 7
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/the-us-military-will-reportedly-use-elon-musks-grok-ai-in-its-classified-systems-110049021.html",
          "published_at": "Tue, 24 Feb 2026 11:00:49 +0000",
          "title": "The US military will reportedly use Elon Musk's Grok AI in its classified systems",
          "standfirst": "The US Department of Defense has reportedly reached a deal to use Elon Musk's Grok in its classified systems, according to Axios. That follows news that the Pentagon is currently in a dispute with another AI company, Anthropic, over limits on its technology for things like mass surveillance. Last year, the White ordered Grok, along with ChatGPT, Gemini and Anthropic's Claude to be approved for government use. Up until now, though, only Anthropic's model has been allowed for the military's most sensitive tasks in intelligence, weapons development and battlefield operations. Claude was reportedly used in the Venezuelan raid in which the US military exfiltrated the country's president, Nicolás Maduro, and his wife. However, the Pentagon demanded that Anthropic make Claude available for \"all lawful purposes\" including mass surveillance and the development of fully autonomous weapons. Anthropic reportedly refused to offer its tech for those things, even with a \"safety stack\" built into that model. xAI, by contrast, agreed to a standard that would allow the DoD to employ its AI for any purpose it deems \"lawful.\" However, the xAI model is not considered by officials to be as cutting-edge or reliable as Anthropic's Claude, and they admit that replacing Claude with Grok would be a challenge. The Pentagon is reportedly also negotiating deals with OpenAI and Gemini, both of which it considers to be on par with Anthropic. xAI had announced a version of Grok for US government agencies in July 2025. Shortly before that, though, the chatbot started spouting fascist propaganda and antisemitic rhetoric while dubbing itself \"MechaHitler.\" All of that followed a public spat between Musk and Trump over the president's spending bill, after which GSA approval of Grok seemed to stall. Earlier this week, Anthropic accused three Chinese AI labs of abusing Claude's AI with \"distillation attacks\" to improve their own models. This article originally appeared on Engadget at https://www.engadget.com/ai/the-us-military-will-reportedly-use-elon-musks-grok-ai-in-its-classified-systems-110049021.html?src=rss",
          "content": "The US Department of Defense has reportedly reached a deal to use Elon Musk's Grok in its classified systems, according to Axios. That follows news that the Pentagon is currently in a dispute with another AI company, Anthropic, over limits on its technology for things like mass surveillance. Last year, the White ordered Grok, along with ChatGPT, Gemini and Anthropic's Claude to be approved for government use. Up until now, though, only Anthropic's model has been allowed for the military's most sensitive tasks in intelligence, weapons development and battlefield operations. Claude was reportedly used in the Venezuelan raid in which the US military exfiltrated the country's president, Nicolás Maduro, and his wife. However, the Pentagon demanded that Anthropic make Claude available for \"all lawful purposes\" including mass surveillance and the development of fully autonomous weapons. Anthropic reportedly refused to offer its tech for those things, even with a \"safety stack\" built into that model. xAI, by contrast, agreed to a standard that would allow the DoD to employ its AI for any purpose it deems \"lawful.\" However, the xAI model is not considered by officials to be as cutting-edge or reliable as Anthropic's Claude, and they admit that replacing Claude with Grok would be a challenge. The Pentagon is reportedly also negotiating deals with OpenAI and Gemini, both of which it considers to be on par with Anthropic. xAI had announced a version of Grok for US government agencies in July 2025. Shortly before that, though, the chatbot started spouting fascist propaganda and antisemitic rhetoric while dubbing itself \"MechaHitler.\" All of that followed a public spat between Musk and Trump over the president's spending bill, after which GSA approval of Grok seemed to stall. Earlier this week, Anthropic accused three Chinese AI labs of abusing Claude's AI with \"distillation attacks\" to improve their own models. This article originally appeared on Engadget at https://www.engadget.com/ai/the-us-military-will-reportedly-use-elon-musks-grok-ai-in-its-classified-systems-110049021.html?src=rss",
          "feed_position": 29
        },
        {
          "source": "Guardian Tech",
          "url": "https://www.theguardian.com/technology/2026/feb/23/us-ai-anthropic-china",
          "published_at": "Mon, 23 Feb 2026 23:15:50 GMT",
          "title": "US AI giant accuses Chinese rivals of mass data theft",
          "standfirst": "Anthropic says three Chinese firms used ‘distillation’ technique to extract information from its Claude chatbotUS artificial intelligence company Anthropic said on Monday it had uncovered campaigns by three Chinese AI firms to illicitly extract capabilities from its Claude chatbot, in what it described as industrial-scale intellectual property theft. OpenAI leveled similar charges last month.Anthropic said DeepSeek, Moonshot AI and MiniMax used a technique known as “distillation” – using outputs from a more powerful AI system to rapidly boost the performance of a less capable one. Continue reading...",
          "content": "Anthropic says three Chinese firms used ‘distillation’ technique to extract information from its Claude chatbotUS artificial intelligence company Anthropic said on Monday it had uncovered campaigns by three Chinese AI firms to illicitly extract capabilities from its Claude chatbot, in what it described as industrial-scale intellectual property theft. OpenAI leveled similar charges last month.Anthropic said DeepSeek, Moonshot AI and MiniMax used a technique known as “distillation” – using outputs from a more powerful AI system to rapidly boost the performance of a less capable one. Continue reading...",
          "feed_position": 4
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/anthropic-accuses-three-chinese-ai-labs-of-abusing-claude-to-improve-their-own-models-205210613.html",
          "published_at": "Mon, 23 Feb 2026 20:52:10 +0000",
          "title": "Anthropic accuses three Chinese AI labs of abusing Claude to improve their own models",
          "standfirst": "Anthropic is issuing a call to action against AI \"distillation attacks,\" after accusing three AI companies of misusing its Claude chatbot. On its website, Anthropic claimed that DeepSeek, Moonshot and MiniMax have been conducting \"industrial-scale campaigns…to illicitly extract Claude’s capabilities to improve their own models.\" Distillation in the AI world refers to when less capable models lean on the responses of more powerful ones to train themselves. While distillation isn't a bad thing across the board, Anthropic said that these types of attacks can be used in a more nefarious way. According to Anthropic, these three Chinese AI firms were responsible for more than \"16 million exchanges with Claude through approximately 24,000 fraudulent accounts.\" From Anthropic's perspective, these competing companies were using Claude as a shortcut to develop more advanced AI models, which could also lead to circumventing certain safeguards. Anthropic said in its post that it was able to link each of these distilling attack campaigns to the specific companies with \"high confidence\" thanks to IP address correlation, metadata requests and infrastructure indicators, along with corroborating with others in the AI industry who have noticed similar behaviors. Early last year, OpenAI made similar claims of rival firms distilling its models and banned suspected accounts in response. As for Anthropic, the company behind Claude said it would upgrade its system to make distillation attacks harder to do and easier to identify. While Anthropic is pointing fingers at these other firms, it's also facing a lawsuit from music publishers who accused the AI company of using illegal copies of songs to train its Claude chatbot.This article originally appeared on Engadget at https://www.engadget.com/ai/anthropic-accuses-three-chinese-ai-labs-of-abusing-claude-to-improve-their-own-models-205210613.html?src=rss",
          "content": "Anthropic is issuing a call to action against AI \"distillation attacks,\" after accusing three AI companies of misusing its Claude chatbot. On its website, Anthropic claimed that DeepSeek, Moonshot and MiniMax have been conducting \"industrial-scale campaigns…to illicitly extract Claude’s capabilities to improve their own models.\" Distillation in the AI world refers to when less capable models lean on the responses of more powerful ones to train themselves. While distillation isn't a bad thing across the board, Anthropic said that these types of attacks can be used in a more nefarious way. According to Anthropic, these three Chinese AI firms were responsible for more than \"16 million exchanges with Claude through approximately 24,000 fraudulent accounts.\" From Anthropic's perspective, these competing companies were using Claude as a shortcut to develop more advanced AI models, which could also lead to circumventing certain safeguards. Anthropic said in its post that it was able to link each of these distilling attack campaigns to the specific companies with \"high confidence\" thanks to IP address correlation, metadata requests and infrastructure indicators, along with corroborating with others in the AI industry who have noticed similar behaviors. Early last year, OpenAI made similar claims of rival firms distilling its models and banned suspected accounts in response. As for Anthropic, the company behind Claude said it would upgrade its system to make distillation attacks harder to do and easier to identify. While Anthropic is pointing fingers at these other firms, it's also facing a lawsuit from music publishers who accused the AI company of using illegal copies of songs to train its Claude chatbot.This article originally appeared on Engadget at https://www.engadget.com/ai/anthropic-accuses-three-chinese-ai-labs-of-abusing-claude-to-improve-their-own-models-205210613.html?src=rss",
          "feed_position": 33
        }
      ],
      "popularity_score": 2005.0004758333334
    },
    {
      "id": "cluster_51",
      "coverage": 1,
      "updated_at": "Wed, 25 Feb 2026 00:05:05 +0000",
      "title": "Boozy chimps fail urine test, confirm hotly debated theory",
      "neutral_headline": "Boozy chimps fail urine test, confirm hotly debated theory",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/02/boozy-chimps-fail-urine-test-confirm-hotly-debated-theory/",
          "published_at": "Wed, 25 Feb 2026 00:05:05 +0000",
          "title": "Boozy chimps fail urine test, confirm hotly debated theory",
          "standfirst": "Spare a thought for the intrepid graduate students who spent last summer in Africa collecting chimp urine.",
          "content": "The urine of chimpanzees contains high levels of alcohol byproduct, most likely because the chimps regularly gorge themselves on fermented fruit, according to a new paper published in the journal Biology Letters. It's the latest evidence in support of a hotly debated theory regarding the evolutionary origins of human fondness for alcohol. As previously reported, in 2014, University of California, Berkeley (UCB) biologist Robert Dudley wrote a book called The Drunken Monkey: Why We Drink and Abuse Alcohol. His controversial “drunken monkey hypothesis” proposed that the human attraction to alcohol goes back about 18 million years, to the origin of the great apes, and that social communication and sharing food evolved to better identify the presence of fruit from a distance. At the time, skeptical scientists insisted that this was unlikely because chimpanzees and other primates just don’t eat fermented fruit or nectar. But reports of primates doing just that have grown over the ensuing two decades. Earlier this year, we reported that researchers had caught wild chimpanzees on camera engaging in what appears to be sharing fermented African breadfruit with measurable alcoholic content. That observational data was the first evidence of the sharing of alcoholic foods among nonhuman great apes in the wild. The authors measured the alcohol content of the fruit with a handy portable breathalyzer and found almost all of the fallen fruit (90 percent) contained some ethanol, with the ripest containing the highest levels—the equivalent of 0.61 percent ABV (alcohol by volume).Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/chimp1-1152x648-1771719191.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/chimp1-1152x648-1771719191.jpg",
      "popularity_score": 361.48825361111113
    },
    {
      "id": "cluster_59",
      "coverage": 1,
      "updated_at": "Tue, 24 Feb 2026 22:52:52 +0000",
      "title": "WBD says Paramount’s new, higher offer could be “superior” to Netflix's",
      "neutral_headline": "WBD says Paramount’s new, higher offer could be “superior” to Netflix's",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/02/paramount-increases-its-warner-bros-discovery-bid-by-1-per-share/",
          "published_at": "Tue, 24 Feb 2026 22:52:52 +0000",
          "title": "WBD says Paramount’s new, higher offer could be “superior” to Netflix's",
          "standfirst": "WBD's board is still reviewing the offer.",
          "content": "Paramount Skydance increased its bid for Warner Bros. Discovery (WBD) from $30 per share to $31 per share, WBD said today. Amid a competing offer from Netflix for WBD’s movie studios and streaming businesses, WBD said that Paramount’s new bid “could reasonably be expected to lead to a ‘Company Superior Proposal.’” Under its revamped offer, Paramount would also pay the $7 billion regulatory termination fee that would arise should a Paramount-WBD merger fail to close due to antitrust regulation. The company owned by David Ellison also said it would pay $0.25 per share for every day the deal doesn’t close, starting on September 30, rather than the previous start date of December 31.Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2215193098-1152x648-1768255617.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2215193098-1152x648-1768255617.jpg",
      "popularity_score": 330.2846425
    },
    {
      "id": "cluster_60",
      "coverage": 1,
      "updated_at": "Tue, 24 Feb 2026 22:40:08 +0000",
      "title": "Following 35% growth, solar has passed hydro on US grid",
      "neutral_headline": "Following 35% growth, solar has passed hydro on US grid",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/02/final-2025-data-is-in-us-energy-use-is-up-as-solar-passes-hydro/",
          "published_at": "Tue, 24 Feb 2026 22:40:08 +0000",
          "title": "Following 35% growth, solar has passed hydro on US grid",
          "standfirst": "Coal makes a bit of a comeback, if only by accident.",
          "content": "On Tuesday, the US Energy Information Administration released full-year data on how the country generated electricity in 2025. It's a bit of a good news/bad news situation. The bad news is that overall demand rose appreciably, and a fair chunk of that was met by additional coal use. On the good side, solar continued its run of astonishing growth, generating 35 percent more power than a year earlier and surpassing hydroelectric power for the first time. Shifting markets Overall, electrical consumption in the US rose by 2.8 percent, or about 121 terawatt-hours. Consumption had been largely flat for several decades, with efficiency and the decline of industry offsetting the effects of population and economic growth. There were plenty of year-to-year changes, however, driven by factors ranging from heating and cooling demand to a global pandemic. Given that history, the growth in demand in 2025 is a bit concerning, but it's not yet a clear signal that the factors that will inevitably drive growth have kicked in. (These factors include things like the switch to heat pumps, the electrification of transportation, and the growth in data centers. While the first two of those involve a more efficient use of energy overall, they involve electricity replacing direct use of fossil fuels, and so will increase demand on the grid.)Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-2255162141-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-2255162141-1152x648.jpg",
      "popularity_score": 320.0724202777778
    },
    {
      "id": "cluster_67",
      "coverage": 1,
      "updated_at": "Tue, 24 Feb 2026 21:15:26 +0000",
      "title": "DJI sues the FCC for “carelessly” restricting its drones",
      "neutral_headline": "DJI sues the FCC for “carelessly” restricting its drones",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/02/dji-sues-the-fcc-for-carelessly-restricting-its-drones/",
          "published_at": "Tue, 24 Feb 2026 21:15:26 +0000",
          "title": "DJI sues the FCC for “carelessly” restricting its drones",
          "standfirst": "DJI lawsuit says company has been \"severely harmed by the FCC’s ruling.\"",
          "content": "DJI, the most popular consumer drone maker, is suing over the Federal Communications Commission (FCC)’s import ban against new, foreign-made drones, which has been in effect since December 23, 2025. On Tuesday, the Shenzhen-headquartered company filed a petition [PDF] with the US Court of Appeals for the Ninth Circuit that seeks to overturn the FCC’s decision to list DJI on its Covered List. The Covered List includes communications equipment and services that are \"deemed to pose an unacceptable risk to the national security of the United States or the security and safety of United States persons,” per the FCC. In its petition dated February 20, 2026, DJI said:Read full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-1436102852-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-1436102852-1152x648.jpg",
      "popularity_score": 308.6607536111111
    },
    {
      "id": "cluster_85",
      "coverage": 1,
      "updated_at": "Tue, 24 Feb 2026 18:46:03 +0000",
      "title": "In a replay of 2019, Apple says a single desktop Mac will be manufactured in the US",
      "neutral_headline": "In a replay of 2019, Apple says a single desktop Mac will be manufactured in the US",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/apple/2026/02/in-a-replay-of-2019-apple-says-a-single-desktop-mac-will-be-manufactured-in-the-us/",
          "published_at": "Tue, 24 Feb 2026 18:46:03 +0000",
          "title": "In a replay of 2019, Apple says a single desktop Mac will be manufactured in the US",
          "standfirst": "Apple is still working to get favorable tariff treatment from the Trump administration.",
          "content": "Apple plans to start manufacturing the Mac mini in the United States later this year, the company announced today, as part of its $600 billion commitment to expand its domestic manufacturing operation. The Macs will be made in a facility in Houston, the same facility Apple uses for \"advanced AI server manufacturing.\" CEO Tim Cook says these AI servers are shipping \"ahead of schedule.\" The facility will also eventually provide \"hands-on training in advanced manufacturing techniques\" for students, Apple employees, \"and American businesses of all sizes.\" Apple and many other US tech companies have announced plans to expand their domestic manufacturing operations, just one element of a multi-prong strategy to secure favorable treatment from a Trump administration that has been happy to threaten Apple and others with steep tariffs to get what it wants. Today's Mac mini announcement is more subtle than the time Tim Cook delivered Trump a signed gold statue, but the goal is likely the same.Read full article Comments",
          "feed_position": 5,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/IMG_2326-1152x648.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/IMG_2326-1152x648.jpeg",
      "popularity_score": 298.1710313888889
    },
    {
      "id": "cluster_75",
      "coverage": 1,
      "updated_at": "Tue, 24 Feb 2026 19:53:15 +0000",
      "title": "UK fines Reddit for not checking user ages aggressively enough",
      "neutral_headline": "UK fines Reddit for not checking user ages aggressively enough",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/02/uk-fines-reddit-for-not-checking-user-ages-aggressively-enough/",
          "published_at": "Tue, 24 Feb 2026 19:53:15 +0000",
          "title": "UK fines Reddit for not checking user ages aggressively enough",
          "standfirst": "UK agency alleges \"Reddit failed to apply any robust age assurance mechanism.\"",
          "content": "A UK regulator today fined Reddit £14.5 million ($19.6 million) for not verifying the ages of users. The UK Information Commissioner's Office (ICO) alleged that the failure to check ages resulted in Reddit illegally using children’s personal information. \"Our investigation found that Reddit failed to apply any robust age assurance mechanism and therefore did not have a lawful basis for processing the personal information of children under the age of 13... These failures meant Reddit was using children’s data unlawfully, potentially exposing them to inappropriate and harmful content,\" an ICO press release said. The ICO findings are based on Reddit's actions prior to its July 2025 rollout of a system that verifies UK users’ ages before letting them view adult content. But the ICO said it is still concerned about Reddit's post-July 2025 system because the company relies on users to declare their ages when opening an account.Read full article Comments",
          "feed_position": 4,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/07/reddit-icon-1152x648-1752522571.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/07/reddit-icon-1152x648-1752522571.jpg",
      "popularity_score": 297.2910313888889
    },
    {
      "id": "cluster_97",
      "coverage": 1,
      "updated_at": "Tue, 24 Feb 2026 17:13:14 +0000",
      "title": "Inside the quixotic team trying to build an entire world in a 20-year-old game",
      "neutral_headline": "Inside the quixotic team trying to build an entire world in a 20-year-old game",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2026/02/inside-the-quixotic-team-trying-to-build-an-entire-world-in-a-20-year-old-game/",
          "published_at": "Tue, 24 Feb 2026 17:13:14 +0000",
          "title": "Inside the quixotic team trying to build an entire world in a 20-year-old game",
          "standfirst": "Stories and lesson learned from an impossibly large community modding project.",
          "content": "Despite being regarded as one of the greatest role-playing games of all time, The Elder Scrolls III: Morrowind disappointed some fans upon its release in 2002 because it didn't match the colossal scope of its predecessor, The Elder Scrolls II: Daggerfall. Almost immediately, fans began modding the remaining parts of the series’ fictional continent, Tamriel, into the game. Over 20 years later, thousands of volunteers have collaborated on the mod projects Tamriel Rebuilt and Project Tamriel, building a space comparable in size to a small country. Such projects often sputter out, but these have endured, thanks in part to a steady stream of small, manageable updates instead of larger, less frequent ones. A tale of (at least two) mods It's true that Daggerfall included an entire continent’s worth of content, but it was mostly composed of procedurally generated liminal space. By contrast, Morrowind contained just a single island—not even the entire province after which the game was named. The difference was that it was handcrafted.Read full article Comments",
          "feed_position": 6,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/Anvil-1152x648-1769206004.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/Anvil-1152x648-1769206004.jpg",
      "popularity_score": 274.62408694444446
    },
    {
      "id": "cluster_99",
      "coverage": 1,
      "updated_at": "Tue, 24 Feb 2026 16:43:27 +0000",
      "title": "50 mpg in a Nissan crossover? Testing the new E-Power hybrid system.",
      "neutral_headline": "50 mpg in a Nissan crossover? Testing the new E-Power hybrid system.",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2026/02/on-the-road-with-nissans-new-e-power-hybrid-coming-to-the-2027-rogue/",
          "published_at": "Tue, 24 Feb 2026 16:43:27 +0000",
          "title": "50 mpg in a Nissan crossover? Testing the new E-Power hybrid system.",
          "standfirst": "Nissan imported some Qashqais from Europe so we could sample the hybrid system.",
          "content": "While Toyota and Honda's showrooms are littered with electrified offerings, Nissan hasn't had much to counter. Globally, Nissan offers a series hybrid system called E-Power, but the company has been reluctant to offer it Stateside. If you ask anyone at the company about it, they'll tell you that while it makes sense in Europe, Japan, and other parts of Asia, it is not optimized for the type of driving we do this side of the pond. Nissan's hybrid offerings in North America have been lackluster at best. There was the Altima that borrowed Toyota's hybrid system from the Camry, and there was the Rogue hybrid that failed to deliver noticeably better fuel economy. And that's really it. That, however, is about to change with the company's third-generation system.Read full article Comments",
          "feed_position": 7,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/IMG_0763-1152x648.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/IMG_0763-1152x648.jpeg",
      "popularity_score": 269.1276980555556
    },
    {
      "id": "cluster_104",
      "coverage": 1,
      "updated_at": "Tue, 24 Feb 2026 15:24:02 +0000",
      "title": "Lamborghini cancels electric Lanzador as supercar buyers reject EVs",
      "neutral_headline": "Lamborghini cancels electric Lanzador as supercar buyers reject EVs",
      "bullet_summary": [
        "Investing heavily in battery EVs would be \"financially irresponsible,\" CEO said",
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2026/02/lamborghini-drops-ev-plan-in-favor-of-future-plug-in-hybrids/",
          "published_at": "Tue, 24 Feb 2026 15:24:02 +0000",
          "title": "Lamborghini cancels electric Lanzador as supercar buyers reject EVs",
          "standfirst": "Investing heavily in battery EVs would be \"financially irresponsible,\" CEO said.",
          "content": "For the last few years, Lamborghini has been in a quandary: What to do about an electric vehicle? Among the supercar brands, Lamborghini has always stood out as favoring drama over lap times. And while electric motors and their instant torque can make a car accelerate very quickly indeed, other than the G-forces, it happens with such little fuss. Working out how to imbue an EV with enough \"wow\" factor to wear the famous bull badge has proved so difficult that the company has thrown in the towel in favor of developing more plug-in hybrids. As part of Volkswagen Group, Lamborghini has access to the EV platforms used by fellow VW Group brands Audi and Porsche, so it's not a question of access to technology. Rather, the company just doesn't think it can sell the cars. As Tim Stevens found out for Ars last year, in this rarefied end of the car market, the customers just aren't interested in EVs. People paying six or even seven figures for a supercar, especially a Lamborghini, are not exercising restraint, and they don't want the car to do that, either. Speaking to the Sunday Times this weekend, Lamborghini CEO Stephan Winkelmann revealed that the Lanzador, an electric SUV under development for the past few years, was canceled in late 2025. \"Investing heavily in full-EV development when the market and customer base are not ready would be an expensive hobby, and financially irresponsible towards shareholders, customers [and] to our employees and their families,\" he told the paper.Read full article Comments",
          "feed_position": 8,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-1610564490-1152x648-1771945747.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-1610564490-1152x648-1771945747.jpg",
      "popularity_score": 259
    },
    {
      "id": "cluster_107",
      "coverage": 1,
      "updated_at": "Tue, 24 Feb 2026 14:10:13 +0000",
      "title": "Meta could end up owning 10% of AMD in new chip deal",
      "neutral_headline": "Meta could end up owning 10% of AMD in new chip deal",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2026/02/meta-could-end-up-owning-of-10-amd-in-new-chip-deal/",
          "published_at": "Tue, 24 Feb 2026 14:10:13 +0000",
          "title": "Meta could end up owning 10% of AMD in new chip deal",
          "standfirst": "AMD will supply 6 gigawatts' worth of chips to buttress Meta's AI efforts.",
          "content": "Meta has struck a multi-billion dollar chip deal with AMD that could lead to the Facebook owner taking a 10 percent stake in the group, sending shares in the US chipmaker surging on Tuesday. The social media giant said it would acquire customized chips with a total capacity of 6 gigawatts from AMD as it races to develop and deploy its AI models. AMD’s chief executive Lisa Su said that “each gigawatt of compute is worth double-digit billions” under the deal.Read full article Comments",
          "feed_position": 9,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2024/07/meta-ai-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2024/07/meta-ai-1152x648.jpg",
      "popularity_score": 243
    },
    {
      "id": "cluster_141",
      "coverage": 1,
      "updated_at": "Mon, 23 Feb 2026 17:45:29 +0000",
      "title": "New Microsoft gaming chief has \"no tolerance for bad AI\"",
      "neutral_headline": "New Microsoft gaming chief has \"no tolerance for bad AI\"",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2026/02/new-microsoft-gaming-chief-has-no-tolerance-for-bad-ai/",
          "published_at": "Mon, 23 Feb 2026 17:45:29 +0000",
          "title": "New Microsoft gaming chief has \"no tolerance for bad AI\"",
          "standfirst": "But Asha Sharma faces scrutiny for lack of gaming experience.",
          "content": "Last week's surprise departure of Phil Spencer from Microsoft led to the promotion of Asha Sharma, who comes to head Microsoft's gaming division after two years as president of the company's CoreAI Product group. Despite that recent history, Sharma says in a new interview that she has \"no tolerance for bad AI\" in game development. Speaking with Variety, Sharma noted that \"AI has long been part of gaming and will continue to be,\" before adding that \"great stories are created by humans.\" The interview comes after Sharma promised in an introductory memo: \"We will not chase short-term efficiency or flood our ecosystem with soulless AI slop. Games are and always will be art, crafted by humans, and created with the most innovative technology provided by us.\" Those statements seem like a clear line in the sand from Sharma against the use of AI tools in Microsoft's first-party game development, at the very least. But what separates \"bad AI\" and \"soulless AI slop\" from \"innovative technology\" that humans can use to create artful games is a matter of some significant debate in the gaming world.Read full article Comments",
          "feed_position": 14,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/sharma-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/sharma-1152x648.jpg",
      "popularity_score": 160
    },
    {
      "id": "cluster_148",
      "coverage": 1,
      "updated_at": "Mon, 23 Feb 2026 15:38:00 +0000",
      "title": "AIs can generate near-verbatim copies of novels from training data",
      "neutral_headline": "AIs can generate near-verbatim copies of novels from training data",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2026/02/ais-can-generate-near-verbatim-copies-of-novels-from-training-data/",
          "published_at": "Mon, 23 Feb 2026 15:38:00 +0000",
          "title": "AIs can generate near-verbatim copies of novels from training data",
          "standfirst": "LLMs memorize more training data than previously thought.",
          "content": "The world’s top AI models can be prompted to generate near-verbatim copies of bestselling novels, raising fresh questions about the industry’s claim that its systems do not store copyrighted works. A series of recent studies has shown that large language models from OpenAI, Google, Meta, Anthropic, and xAI memorize far more of their training data than previously thought. AI and legal experts told the FT this “memorization” ability could have serious ramifications on AI groups’ battle against dozens of copyright lawsuits around the world, as it undermines their core defense that LLMs “learn” from copyrighted works but do not store copies.Read full article Comments",
          "feed_position": 16,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/library-shelves-1152x648-1768598730.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/library-shelves-1152x648-1768598730.jpg",
      "popularity_score": 148
    },
    {
      "id": "cluster_151",
      "coverage": 1,
      "updated_at": "Mon, 23 Feb 2026 13:51:36 +0000",
      "title": "Review: Knight of the Seven Kingdoms brings back that Westeros magic",
      "neutral_headline": "Review: Knight of the Seven Kingdoms brings back that Westeros magic",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/culture/2026/02/review-knight-of-the-seven-kingdoms-brings-back-that-westeros-magic/",
          "published_at": "Mon, 23 Feb 2026 13:51:36 +0000",
          "title": "Review: Knight of the Seven Kingdoms brings back that Westeros magic",
          "standfirst": "Prequel series is just great storytelling, reminding GoT fans why they loved the original so much.",
          "content": "HBO has another critically acclaimed hit with A Knight of the Seven Kingdoms, based on George R.R. Martin’s Tales of Dunk and Egg novellas, and it deserves every bit of the praise heaped upon it. The immensely satisfying first season wrapped with last night's finale, dealing with the tragedy of the penultimate episode and setting the stage for the further adventures of Dunk and Egg. House of the Dragon is a solid series, but Knight of the Seven Kingdoms has reminded staunch GoT fans of everything they loved about the original series in the first place. (Spoilers below, but no major reveals until after the second gallery. We'll give you a heads up when we get there.) A Knight of the Seven Kingdoms adapts the first novella in the series, The Hedge Knight, and is set more than 50 years after the events of House of the Dragon. Dunk (Peter Claffey) is a lowly hedge knight who has just buried his aged mentor, Ser Arlan of Pennytree (Danny Webb). Ser Arlan was perhaps not the kindest of mentors and often stone drunk, but at least he was hung like the proverbial horse—as viewers discovered in a full-frontal moment that instantly went viral. Lacking any good employment options, Dunk decides to enter a local tournament, since he has inherited Ser Arlan's sword, shield, and three horses.Read full article Comments",
          "feed_position": 17,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/dunkTOP-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/dunkTOP-1152x648.jpg",
      "popularity_score": 144
    },
    {
      "id": "cluster_109",
      "coverage": 1,
      "updated_at": "Tue, 24 Feb 2026 14:00:17 +0000",
      "title": "Scientists crack the case of \"screeching\" Scotch tape",
      "neutral_headline": "Scientists crack the case of \"screeching\" Scotch tape",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/02/heres-why-scotch-tape-screeches-when-its-peeled/",
          "published_at": "Tue, 24 Feb 2026 14:00:17 +0000",
          "title": "Scientists crack the case of \"screeching\" Scotch tape",
          "standfirst": "Micro-cracks travel along the peeling tape at supersonic speeds, producing shock waves and sound pulses.",
          "content": "Scotch tape has been a household mainstay for nearly a century, but it still holds some scientific surprises. Researchers have discovered that the screeching sound emitted when one rapidly peels Scotch tape—akin to the screech of fingernails on a chalkboard—is the result of shock waves produced by micro-cracks propagating along the tape at supersonic speeds, according to a new paper published in the journal Physical Review E. It was a 3M engineer named Richard Drew who developed the first transparent sticky tape in 1930. The impetus came from car manufacturing, specifically two-color designs, where the adhesives used were so sticky they often removed the paint when peeled off; the paint then needed to be manually touched up. Drew found a sandpaper adhesive with just the right amount of stickiness and used it to coat a roll of cellophane tape. (Fun fact: Drew also co-invented the snail-style dispenser for the tape with his 3M colleague, John Borden.) The tape was hugely popular during the Great Depression; consumers used it to repair everyday items rather than replace them. That popularity has never waned. Scotch tape has also generated considerable interest among physicists. Back in 1939, scientists noticed that peeling tape could produce light—specifically, a glowing line where the tape end pulls away from the roll. The phenomenon was first recorded in the 17th century and is known as triboluminescence: the generation of light when a material is crushed, ripped, rubbed, or scratched. Diamonds, for instance, sometimes glow blue or red during the cutting process, while ceramics emit yellow-orange light when being cut by abrasive water jets.Read full article Comments",
          "feed_position": 10,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/scotch1-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/scotch1-1152x648.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_133",
      "coverage": 1,
      "updated_at": "Mon, 23 Feb 2026 22:14:28 +0000",
      "title": "Pentagon buyer: We're happy with our launch industry, but payloads are lagging",
      "neutral_headline": "Pentagon buyer: We're happy with our launch industry, but payloads are lagging",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2026/02/pentagon-buyer-were-happy-with-our-launch-industry-but-payloads-are-lagging/",
          "published_at": "Mon, 23 Feb 2026 22:14:28 +0000",
          "title": "Pentagon buyer: We're happy with our launch industry, but payloads are lagging",
          "standfirst": "\"The point is to get missions out the door as fast as possible. Two to three years is too slow.\"",
          "content": "DALLAS—The Space Force officer tasked with overseeing more than $24 billion in research and development spending says the Pentagon is more interested in supporting startups building new space sensors and payloads than adding yet another rocket company to its portfolio. The statement, made at a space finance conference in Dallas last week, was one of several points Maj. Gen. Stephen Purdy wanted to get across to a room full of investors and commercial space executives. The other points on Purdy's agenda were that the Space Force is more interested in high-volume production than spending money to develop the latest technologies, and that the military has, at least for now, lost one of its most important tools for supporting and diversifying the space industrial base.Read full article Comments",
          "feed_position": 11,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/05/GettyImages-1348666509-1152x648-1771883779.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/05/GettyImages-1348666509-1152x648-1771883779.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_134",
      "coverage": 1,
      "updated_at": "Mon, 23 Feb 2026 21:48:44 +0000",
      "title": "Data center builders thought farmers would willingly sell land, learn otherwise",
      "neutral_headline": "Data center builders thought farmers would willingly sell land, learn otherwise",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/02/im-not-for-sale-farmers-refuse-to-take-millions-in-data-center-deals/",
          "published_at": "Mon, 23 Feb 2026 21:48:44 +0000",
          "title": "Data center builders thought farmers would willingly sell land, learn otherwise",
          "standfirst": "Even in a fragile farm economy, million-dollar offers can't sway dedicated farmers.",
          "content": "It seems that tech giants eyeing rural zones for data center development have underestimated how attached American farmers have grown to their lands in the decades they've been nurturing them. Across the country, several farmers have firmly rejected eye-popping offers—sometimes in the tens of millions. These offers dwarf the value of their properties, but farmers have refused to put a price on the lands that they love most. In a report on Monday, The Guardian highlighted a handful of cases nationwide where farmers' refusals have frustrated plans to build data centers in areas long deemed rural.Read full article Comments",
          "feed_position": 12,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-1233733221-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-1233733221-1024x648.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_135",
      "coverage": 1,
      "updated_at": "Mon, 23 Feb 2026 21:16:20 +0000",
      "title": "Panasonic, the former plasma king, will no longer make its own TVs",
      "neutral_headline": "Panasonic, the former plasma king, will no longer make its own TVs",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/02/panasonic-the-former-plasma-king-will-no-longer-make-its-own-tvs/",
          "published_at": "Mon, 23 Feb 2026 21:16:20 +0000",
          "title": "Panasonic, the former plasma king, will no longer make its own TVs",
          "standfirst": "Panasonic was one of the last Japanese companies still manufacturing TVs.",
          "content": "Panasonic, once revered for its plasma TVs, is giving up on making its own TV sets. Today, it announced that Chinese company Skyworth will take over manufacturing, marketing, and selling Panasonic-branded TVs. Skyworth is a Shenzhen-headquartered TV brand. The company claims to be “a top three global provider of the Android TV platform.” In July, research firm Omdia reported that Skyworth was one of the top-five TV brands by sales revenue in Q1 2025; however, Skyworth hasn’t been able to maintain that position regularly. Panasonic made its announcement at a \"launch event,” FlatpanelsHD reported today. During the event, a Panasonic representative reportedly said:Read full article Comments",
          "feed_position": 13,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-56528381-1152x648-1771879994.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-56528381-1152x648-1771879994.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_143",
      "coverage": 1,
      "updated_at": "Mon, 23 Feb 2026 17:00:02 +0000",
      "title": "The 2026 Mazda CX-5, driven: It got bigger; plus, radical tech upgrade",
      "neutral_headline": "The 2026 Mazda CX-5, driven: It got bigger; plus, radical tech upgrade",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/cars/2026/02/the-2026-mazda-cx-5-driven-it-got-bigger-plus-radical-tech-upgrade/",
          "published_at": "Mon, 23 Feb 2026 17:00:02 +0000",
          "title": "The 2026 Mazda CX-5, driven: It got bigger; plus, radical tech upgrade",
          "standfirst": "Starting at $29,990, there's a lot to like about the all-new Mazda, but it's not perfect.",
          "content": "Mazda provided flights from Washington, DC, to San Diego and accommodation so Ars could drive the CX-5. Ars does not accept paid editorial content. ENCINITAS, Calif.—Its sales may have been buoyed of late by the big CX-90 and CX-70 SUVs, but for Mazda, the CX-5 is still where most of the action is. Unlike the similar-sized, similar-priced CX-50, which was designed just for North America, the all-new CX-5 is a global car, and it's also Mazda's standard-bearer for a range of new technologies. Gone is the basic but effective infotainment system, replaced by an all-new Google-based experience as Mazda starts its journey toward software-defined vehicles. There's even an in-house hybrid on the way, albeit not until next year. And it starts at a competitive $29,990. The new CX-5 is bigger than the car it replaces, 4.5 inches (114.5 mm) longer and half an inch (13 mm) wider than before, at 184.6 inches (4,689 mm) long, 73.2 inches (1,859 mm) wide, and 66.7 inches (1,694 mm) tall. Much of that extra space is between the axles—the wheelbase is now 110 inches (2,794 mm) long, which translates to more interior space. From the outside, there's a new light signature, and the way the bodywork curves around the front and wraps down the fenders gives me strong Range Rover vibes, even if I could never adequately capture what I'm talking about with a camera. As ever, Mazda's arresting Soul Red Crystal metallic paint (a $595 option) sparkles, even on a day when the sun remained hidden from view. The last time that Mazda evolved this compact crossover, it did so with a new upmarket interior. Since then, the brand has staked out that space across its model lineup, with cabins that punch well above their price tags. Happily, the company's designers haven't lost much mojo since then, with a restrained approach that looks good across the five different trim levels, each of which is a $2,000 step up from the one that precedes it. But if you're a current CX-5 driver, you'll find much has changed, perhaps not entirely for the better.Read full article Comments",
          "feed_position": 15,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/2026-Mazda-CX-5-1-1152x648-1771861550.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/2026-Mazda-CX-5-1-1152x648-1771861550.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_153",
      "coverage": 1,
      "updated_at": "Mon, 23 Feb 2026 12:00:45 +0000",
      "title": "The first cars bold enough to drive themselves",
      "neutral_headline": "The first cars bold enough to drive themselves",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/features/2026/02/the-first-cars-bold-enough-to-drive-themselves/",
          "published_at": "Mon, 23 Feb 2026 12:00:45 +0000",
          "title": "The first cars bold enough to drive themselves",
          "standfirst": "Quevedo's telekino of 1904 was the first step on the road to autonomous Waymos.",
          "content": "No one knows exactly when the vehicles we drive will finally wrest the steering wheel from us. But the age of the autonomous automobile isn’t some sudden Big Bang. It’s more of a slow crawl, one that started during the Roosevelt administration. And that’s Theodore, not Franklin. And not in America, but in Spain, by someone you’ve probably never heard of. His name was Leonardo Torres Quevedo, a Spanish engineer born in Santa Cruz, Spain, in 1852. Smart? In 1914, he developed a mechanical chess machine that autonomously played against humans. But more than a decade earlier, he pioneered the development of remote-control systems. What he wrought was brilliant, if crude—and certainly ahead of its time. The first wireless control It was called the Telekino, a name drawn from the Greek “tele,” meaning at a distance, and “kino,” meaning movement. Patented in Spain, France, and the United States, it was conceived as a way to prevent airship accidents. The Telekino transmitted wireless signals to a small receiver known as a coherer, which detected electromagnetic waves and transformed them into an electrical current. This current was amplified and sent on to electromagnets that slowly rotated a switch controlling the proper servomotor. Quevedo could issue 19 distinct commands to the systems of an airship without ever touching a control cable.Read full article Comments",
          "feed_position": 18,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/radio-controlled-vintage-cars-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/radio-controlled-vintage-cars-1152x648.jpg",
      "popularity_score": 130
    }
  ]
}