{
  "updated_at": "2026-02-03T07:37:46.094Z",
  "clusters": [
    {
      "id": "cluster_16",
      "coverage": 3,
      "updated_at": "Mon, 02 Feb 2026 19:55:00 -0500",
      "title": "Leaked email: as part of the xAI-SpaceX deal, xAI shares will be converted into 0.1433 shares of SpaceX stock, and employees will have the option to cash out (Wall Street Journal)",
      "neutral_headline": "Elon Musk Is Rolling xAI Into SpaceX—Creating the World’s...",
      "bullet_summary": [
        "Reported by TechMeme, Wired Tech, TechCrunch"
      ],
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/260202/p46#a260202p46",
          "published_at": "Mon, 02 Feb 2026 19:55:00 -0500",
          "title": "Leaked email: as part of the xAI-SpaceX deal, xAI shares will be converted into 0.1433 shares of SpaceX stock, and employees will have the option to cash out (Wall Street Journal)",
          "standfirst": "Wall Street Journal: Leaked email: as part of the xAI-SpaceX deal, xAI shares will be converted into 0.1433 shares of SpaceX stock, and employees will have the option to cash out &mdash; The merger puts Elon Musk's rocket and artificial-intelligence companies under one roof &mdash; Elon Musk said SpaceX acquired xAI &hellip;",
          "content": "Wall Street Journal: Leaked email: as part of the xAI-SpaceX deal, xAI shares will be converted into 0.1433 shares of SpaceX stock, and employees will have the option to cash out &mdash; The merger puts Elon Musk's rocket and artificial-intelligence companies under one roof &mdash; Elon Musk said SpaceX acquired xAI &hellip;",
          "feed_position": 7,
          "image_url": "http://www.techmeme.com/260202/i46.jpg"
        },
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/260202/p44#a260202p44",
          "published_at": "Mon, 02 Feb 2026 19:05:03 -0500",
          "title": "The SpaceX-xAI merger further intermingles Musk's companies, creates the most valuable private company in the world, and provides a financial lifeline to xAI (New York Times)",
          "standfirst": "New York Times: The SpaceX-xAI merger further intermingles Musk's companies, creates the most valuable private company in the world, and provides a financial lifeline to xAI &mdash; SpaceX, the rocket and satellite maker led by Elon Musk, said on Monday it had acquired xAI, the artificial intelligence company controlled by Mr. Musk.",
          "content": "New York Times: The SpaceX-xAI merger further intermingles Musk's companies, creates the most valuable private company in the world, and provides a financial lifeline to xAI &mdash; SpaceX, the rocket and satellite maker led by Elon Musk, said on Monday it had acquired xAI, the artificial intelligence company controlled by Mr. Musk.",
          "feed_position": 9,
          "image_url": "http://www.techmeme.com/260202/i44.jpg"
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/spacex-acquires-xai-elon-musk/",
          "published_at": "Mon, 02 Feb 2026 23:07:19 +0000",
          "title": "Elon Musk Is Rolling xAI Into SpaceX—Creating the World’s Most Valuable Private Company",
          "standfirst": "By fusing SpaceX and xAI—which acquired X last year—Elon Musk tightens his grip over technologies that shape national security, social media, and artificial intelligence.",
          "content": "By fusing SpaceX and xAI—which acquired X last year—Elon Musk tightens his grip over technologies that shape national security, social media, and artificial intelligence.",
          "feed_position": 1,
          "image_url": "https://media.wired.com/photos/69811faf5fea9b4898ac924e/master/pass/SpaceX-Aquires-xAI-Business-2256970109.jpg"
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2026/02/02/elon-musk-spacex-acquires-xai-data-centers-space-merger/",
          "published_at": "Mon, 02 Feb 2026 22:21:57 +0000",
          "title": "Elon Musk&#8217;s SpaceX officially acquires Elon Musk&#8217;s xAI, with plan to build data centers in space",
          "standfirst": "The merger creates the world's most valuable private company and paves the way for Musk to try and prove out the usefulness of space-based data centers.",
          "content": "The merger creates the world's most valuable private company and paves the way for Musk to try and prove out the usefulness of space-based data centers.",
          "feed_position": 2
        }
      ],
      "featured_image": "http://www.techmeme.com/260202/i46.jpg",
      "popularity_score": 3013.287196388889
    },
    {
      "id": "cluster_1",
      "coverage": 2,
      "updated_at": "Tue, 03 Feb 2026 02:25:00 -0500",
      "title": "Nintendo says the Switch 1 sold 155.37M units as of December 31, 2025 since its 2017 launch, topping the DS at 154.02M, becoming its best-selling console ever (Jess Weatherbed/The Verge)",
      "neutral_headline": "The Switch is now Nintendo’s best-selling console of all time",
      "bullet_summary": [
        "Reported by TechMeme, The Verge"
      ],
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/260203/p4#a260203p4",
          "published_at": "Tue, 03 Feb 2026 02:25:00 -0500",
          "title": "Nintendo says the Switch 1 sold 155.37M units as of December 31, 2025 since its 2017 launch, topping the DS at 154.02M, becoming its best-selling console ever (Jess Weatherbed/The Verge)",
          "standfirst": "Jess Weatherbed / The Verge: Nintendo says the Switch 1 sold 155.37M units as of December 31, 2025 since its 2017 launch, topping the DS at 154.02M, becoming its best-selling console ever &mdash; &#65279;The DS has been overthrown, 12 years after it was discontinued. &hellip; The original Switch is officially Nintendo's best-selling console &hellip;",
          "content": "Jess Weatherbed / The Verge: Nintendo says the Switch 1 sold 155.37M units as of December 31, 2025 since its 2017 launch, topping the DS at 154.02M, becoming its best-selling console ever &mdash; &#65279;The DS has been overthrown, 12 years after it was discontinued. &hellip; The original Switch is officially Nintendo's best-selling console &hellip;",
          "feed_position": 0,
          "image_url": "http://www.techmeme.com/260203/i4.jpg"
        },
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/games/872768/nintendo-earnings-switch-best-selling-console-ds",
          "published_at": "2026-02-03T02:05:22-05:00",
          "title": "The Switch is now Nintendo’s best-selling console of all time",
          "standfirst": "The original Switch is officially Nintendo's best-selling console of all time after surpassing the DS handheld in lifetime sales. In its latest earnings release, Nintendo reports that the Nintendo Switch has, as of December 31, 2025, sold 155.37 million units since its launch in 2017, compared to 154.02 million units for the 2004 Nintendo DS. [&#8230;]",
          "content": "The original Switch is officially Nintendo's best-selling console of all time after surpassing the DS handheld in lifetime sales. In its latest earnings release, Nintendo reports that the Nintendo Switch has, as of December 31, 2025, sold 155.37 million units since its launch in 2017, compared to 154.02 million units for the 2004 Nintendo DS. In November, Nintendo reported that the Switch and DS were neck and neck. We expected the holiday sales period would see the Switch surpass the DS, even with Nintendo announcing that primary development would focus on the Switch 2. Nintendo previously said that it would continue to sell the original Sw … Read the full story at The Verge.",
          "feed_position": 0
        }
      ],
      "featured_image": "http://www.techmeme.com/260203/i4.jpg",
      "popularity_score": 2019.7871963888888
    },
    {
      "id": "cluster_30",
      "coverage": 2,
      "updated_at": "Mon, 02 Feb 2026 18:30:01 -0500",
      "title": "Adobe plans to discontinue its 2D animation software Animate on March 1; enterprise customers can receive support until March 2029, and others until March 2027 (Sarah Perez/TechCrunch)",
      "neutral_headline": "Adobe Animate is shutting down next month",
      "bullet_summary": [
        "Reported by TechMeme, The Verge"
      ],
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/260202/p42#a260202p42",
          "published_at": "Mon, 02 Feb 2026 18:30:01 -0500",
          "title": "Adobe plans to discontinue its 2D animation software Animate on March 1; enterprise customers can receive support until March 2029, and others until March 2027 (Sarah Perez/TechCrunch)",
          "standfirst": "Sarah Perez / TechCrunch: Adobe plans to discontinue its 2D animation software Animate on March 1; enterprise customers can receive support until March 2029, and others until March 2027 &mdash; As Adobe ramps up its investments in AI, the company has decided to shut down its 2D animation software, Adobe Animate.",
          "content": "Sarah Perez / TechCrunch: Adobe plans to discontinue its 2D animation software Animate on March 1; enterprise customers can receive support until March 2029, and others until March 2027 &mdash; As Adobe ramps up its investments in AI, the company has decided to shut down its 2D animation software, Adobe Animate.",
          "feed_position": 11,
          "image_url": "http://www.techmeme.com/260202/i42.jpg"
        },
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/news/872731/adobe-animate-app-shutdown-date",
          "published_at": "2026-02-02T17:58:28-05:00",
          "title": "Adobe Animate is shutting down next month",
          "standfirst": "Adobe is pulling the plug on Adobe Animate. In a FAQ posted to Adobe's website, the company says it will stop selling the animation software on March 1st, citing the emergence of new platforms \"that better serve the needs of the users.\" Users have until March 1st, 2027 (or March 1st, 2029 for enterprise customers) [&#8230;]",
          "content": "Adobe is pulling the plug on Adobe Animate. In a FAQ posted to Adobe's website, the company says it will stop selling the animation software on March 1st, citing the emergence of new platforms \"that better serve the needs of the users.\" Users have until March 1st, 2027 (or March 1st, 2029 for enterprise customers) to access and download files from Animate, as they'll no longer be available after this time. The app will be available to download until those deadlines, and Adobe will continue providing support during that period. Adobe Animate's history dates back to 1996, when FutureWave Software launched the vector graphics application, ori … Read the full story at The Verge.",
          "feed_position": 1
        }
      ],
      "featured_image": "http://www.techmeme.com/260202/i42.jpg",
      "popularity_score": 2011.8708075
    },
    {
      "id": "cluster_39",
      "coverage": 2,
      "updated_at": "Mon, 02 Feb 2026 22:16:17 +0000",
      "title": "Elon Musk's SpaceX has acquired his AI company, xAI",
      "neutral_headline": "Elon Musk's SpaceX has acquired his AI company, xAI",
      "bullet_summary": [
        "Elon Musk’s SpaceX has acquired Musk’s xAI, the companies announced",
        "And he recently announced that Tesla was investing $2 billion into xAI"
      ],
      "items": [
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/elon-musks-spacex-has-acquired-his-ai-company-xai-221617040.html",
          "published_at": "Mon, 02 Feb 2026 22:16:17 +0000",
          "title": "Elon Musk's SpaceX has acquired his AI company, xAI",
          "standfirst": "Elon Musk’s SpaceX has acquired Musk’s xAI, the companies announced. The merger will “form the most ambitious, vertically-integrated innovation engine on (and off) Earth, with AI, rockets, space-based internet, direct-to-mobile device communications and the world’s foremost real-time information and free speech platform,” Musk wrote in an update.The AI company that right now is best known for its CSAM-generating chatbot might seem like a strange fit for a rocket company. But SpaceX is key to Musk’s latest scheme to build AI data centers in space. In his update, Musk wrote that “global electricity demand for AI simply cannot be met with terrestrial solutions” and that moving the resource-intensive operations to space is “the only logical solution.” SpaceX just days ago filed an application with the FCC to create an “orbital data center” by launching a million new satellites.Musk also claimed that, eventually, space-based data centers will enable other advancements in space travel. “The capabilities we unlock by making space-based data centers a reality will fund and enable self-growing bases on the Moon, an entire civilization on Mars and ultimately expansion to the Universe.” Notably, it’s not the first time Musk has made lofty claims about Mars. He predicted in 2017 that SpaceX would send crewed missions to Mars by 2024. This also isn’t the first time Musk has acquired one of his own companies. He merged xAI and X last year, which means SpaceX now owns the social network Musk bought in 2022. And he recently announced that Tesla was investing $2 billion into xAI. SpaceX is planning to go public later this year in an initial public offering (IPO) that could value the company at more than $1 trillion, according to Bloomberg, which notes that SpaceX has also “discussed a possible merger with Tesla.”This article originally appeared on Engadget at https://www.engadget.com/ai/elon-musks-spacex-has-acquired-his-ai-company-xai-221617040.html?src=rss",
          "content": "Elon Musk’s SpaceX has acquired Musk’s xAI, the companies announced. The merger will “form the most ambitious, vertically-integrated innovation engine on (and off) Earth, with AI, rockets, space-based internet, direct-to-mobile device communications and the world’s foremost real-time information and free speech platform,” Musk wrote in an update.The AI company that right now is best known for its CSAM-generating chatbot might seem like a strange fit for a rocket company. But SpaceX is key to Musk’s latest scheme to build AI data centers in space. In his update, Musk wrote that “global electricity demand for AI simply cannot be met with terrestrial solutions” and that moving the resource-intensive operations to space is “the only logical solution.” SpaceX just days ago filed an application with the FCC to create an “orbital data center” by launching a million new satellites.Musk also claimed that, eventually, space-based data centers will enable other advancements in space travel. “The capabilities we unlock by making space-based data centers a reality will fund and enable self-growing bases on the Moon, an entire civilization on Mars and ultimately expansion to the Universe.” Notably, it’s not the first time Musk has made lofty claims about Mars. He predicted in 2017 that SpaceX would send crewed missions to Mars by 2024. This also isn’t the first time Musk has acquired one of his own companies. He merged xAI and X last year, which means SpaceX now owns the social network Musk bought in 2022. And he recently announced that Tesla was investing $2 billion into xAI. SpaceX is planning to go public later this year in an initial public offering (IPO) that could value the company at more than $1 trillion, according to Bloomberg, which notes that SpaceX has also “discussed a possible merger with Tesla.”This article originally appeared on Engadget at https://www.engadget.com/ai/elon-musks-spacex-has-acquired-his-ai-company-xai-221617040.html?src=rss",
          "feed_position": 2
        },
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/tech/872619/elon-musk-merges-spacex-with-xai-and-x",
          "published_at": "2026-02-02T16:53:11-05:00",
          "title": "Elon Musk merges SpaceX with xAI (and X)",
          "standfirst": "Elon Musk is merging two of the companies that he leads, SpaceX and xAI (which also owns X), into one. According to an announcement from Musk: SpaceX has acquired xAI to form the most ambitious, vertically-integrated innovation engine on (and off) Earth, with AI, rockets, space-based internet, direct-to-mobile device communications and the world's foremost real-time [&#8230;]",
          "content": "Elon Musk is merging two of the companies that he leads, SpaceX and xAI (which also owns X), into one. According to an announcement from Musk: SpaceX has acquired xAI to form the most ambitious, vertically-integrated innovation engine on (and off) Earth, with AI, rockets, space-based internet, direct-to-mobile device communications and the world's foremost real-time information and free speech platform. This marks not just the next chapter, but the next book in SpaceX and xAI's mission: scaling to make a sentient sun to understand the Universe and extend the light of consciousness to the stars! Current advances in AI are dependent on la … Read the full story at The Verge.",
          "feed_position": 4
        }
      ],
      "popularity_score": 2010.6419186111111
    },
    {
      "id": "cluster_44",
      "coverage": 2,
      "updated_at": "2026-02-02T16:49:22-05:00",
      "title": "Will Elon Musk’s emails with Jeffrey Epstein derail his very important year?",
      "neutral_headline": "Will Elon Musk’s emails with Jeffrey Epstein derail his very important year",
      "bullet_summary": [
        "Reported by The Verge, Wired Tech"
      ],
      "items": [
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/tech/872450/elon-musk-jeffrey-epstein-emails-spacex-ipo-tesla",
          "published_at": "2026-02-02T16:49:22-05:00",
          "title": "Will Elon Musk’s emails with Jeffrey Epstein derail his very important year?",
          "standfirst": "Last week, the Department of Justice released a trove of documents related to its case against Jeffrey Epstein, its largest to date. Amid the millions of files were many mentions of Elon Musk. A search of Musk's name in the department's database results in at least 1,500 hits. Since the release, Musk has been - [&#8230;]",
          "content": "Last week, the Department of Justice released a trove of documents related to its case against Jeffrey Epstein, its largest to date. Amid the millions of files were many mentions of Elon Musk. A search of Musk's name in the department's database results in at least 1,500 hits. Since the release, Musk has been - what else? - posting through it, defending himself and his correspondence with Epstein on his social media platform, X. Musk said he had \"very little correspondence\" with Epstein and \"declined repeated invitations\" to go to Epstein's island, despite emails showing he had been in touch with Epstein in 2012 and 2013, at one point aski … Read the full story at The Verge.",
          "feed_position": 5
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/epstein-files-tech-elites-gates-thiel-musk/",
          "published_at": "Mon, 02 Feb 2026 20:27:22 +0000",
          "title": "The Tech Elites in the Epstein Files",
          "standfirst": "The Department of Justice has released more than 3 million documents and photos related to Jeffrey Epstein. Here’s who shows up from Big Tech the most often—and what the files reveal.",
          "content": "The Department of Justice has released more than 3 million documents and photos related to Jeffrey Epstein. Here’s who shows up from Big Tech the most often—and what the files reveal.",
          "feed_position": 3,
          "image_url": "https://media.wired.com/photos/6980fbe095b9dff81bbd7236/master/pass/biz-epstein-tech-2246882306.jpg"
        }
      ],
      "featured_image": "https://media.wired.com/photos/6980fbe095b9dff81bbd7236/master/pass/biz-epstein-tech-2246882306.jpg",
      "popularity_score": 2010.1933075
    },
    {
      "id": "cluster_51",
      "coverage": 2,
      "updated_at": "2026-02-02T15:43:27-05:00",
      "title": "Notepad++ updates got hijacked for months and could have spied for China",
      "neutral_headline": "Notepad++ updates got hijacked for months and could have spied for China",
      "bullet_summary": [
        "The developer of the popular text editor Notepad++ said hackers associated with the Chinese government hijacked its software update mechanism to deliver tainted software to users for months",
        "Reported by The Verge, TechCrunch"
      ],
      "items": [
        {
          "source": "The Verge",
          "url": "https://www.theverge.com/tech/872462/notepad-plus-plus-server-hijacking",
          "published_at": "2026-02-02T15:43:27-05:00",
          "title": "Notepad++ updates got hijacked for months and could have spied for China",
          "standfirst": "Users of the text and code editor Notepad++ may have unknowingly downloaded a malicious update for the app after its shared hosting servers were hijacked last year. On Monday, the app's developer, Don Ho, posted an update on the attack with more details, including that the hackers were \"likely a Chinese state-sponsored group\" and that [&#8230;]",
          "content": "Users of the text and code editor Notepad++ may have unknowingly downloaded a malicious update for the app after its shared hosting servers were hijacked last year. On Monday, the app's developer, Don Ho, posted an update on the attack with more details, including that the hackers were \"likely a Chinese state-sponsored group\" and that the app's servers were vulnerable for roughly six months from June through December 2nd, 2025. The post explains that the hijacking occurred on the app's unnamed, now-former hosting provider's end, stating that \"Traffic from certain targeted users was selectively redirected to attacker-controlled served malic … Read the full story at The Verge.",
          "feed_position": 6
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2026/02/02/notepad-says-chinese-government-hackers-hijacked-its-software-updates-for-months/",
          "published_at": "Mon, 02 Feb 2026 18:09:34 +0000",
          "title": "Notepad++ says Chinese government hackers hijacked its software updates for months",
          "standfirst": "The developer of the popular text editor Notepad++ said hackers associated with the Chinese government hijacked its software update mechanism to deliver tainted software to users for months.",
          "content": "The developer of the popular text editor Notepad++ said hackers associated with the Chinese government hijacked its software update mechanism to deliver tainted software to users for months.",
          "feed_position": 10
        }
      ],
      "popularity_score": 2009.094696388889
    },
    {
      "id": "cluster_54",
      "coverage": 2,
      "updated_at": "Mon, 02 Feb 2026 20:34:00 GMT",
      "title": "Shared memory is the missing layer in AI orchestration",
      "neutral_headline": "Shared memory is the missing layer in AI orchestration",
      "bullet_summary": [
        "This way, “when you assign a task, you&#x27;re not having to go ahead and re-provide all of the context about how your business works,” Bose said at a recent VB event in San Francisco",
        "”“The person with edit rights can delete those things that are conflicting and make it go back to its correct behavior,” said Bose",
        "”Right now, though, beyond what Asana is doing, there’s no standard protocol around shared knowledge and memory, said Bose",
        "“But because the protocol or standard doesn&#x27;t exist, today it has to be a very custom bespoke conversation,” said Bose"
      ],
      "items": [
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/shared-memory-is-the-missing-layer-in-ai-orchestration",
          "published_at": "Mon, 02 Feb 2026 20:34:00 GMT",
          "title": "Shared memory is the missing layer in AI orchestration",
          "standfirst": "The key to successful AI agents within an enterprise? Shared memory and context. This, according to Asana CPO Arnab Bose, provides detailed history and direct access from the get-go — with guardrail checkpoints and human oversight, of course. This way, “when you assign a task, you&#x27;re not having to go ahead and re-provide all of the context about how your business works,” Bose said at a recent VB event in San Francisco. AI as an active teammate, rather than a passive add-onAsana launched Asana AI Teammates last year with the philosophy that, just like humans, AI agents should be plugged directly into a team or project to create a collaborative system. To further this mission, the project management company has fully integrated with Anthropic’s Claude. Users can choose from 12 pre-built agents — for common use cases like IT ticket deflection — or build their own, then assign them to project teams and immediately provide a historical record of what tasks have already been completed and what is still yet to be resolved. Agents also have access to third-party resources like Microsoft 365 or Google Drive. “When that agent gets created, it&#x27;s not acting on behalf of someone, it manifests itself as a teammate and it gets all of the same sharing permissions, it inherits that,” Bose explained. Everything anyone does — humans and AI included — is documented to allow for “ease of explainability” and a “very transparent and trustworthy system.”But just like human workers, AI agents are kept in check: Critically, workflows incorporate checkpoints, where humans can give feedback and ask the agent to tweak certain elements of a project or adjust research plans. This is documented in what Bose called a “very human-readable way.” Also importantly, the UI provides instructions and knowledge about agent behavior, and approved admins can pause, edit and redirect models in the API when they take actions based on conflicting directions or start acting “in a weird way.”“The person with edit rights can delete those things that are conflicting and make it go back to its correct behavior,” said Bose. “We&#x27;re leaning into that common human-understandable interaction pattern.”Overcoming challenges of authorization, integration But because AI agents are so new, there are still many challenges around security, accessibility and compatibility. Asana users, for instance, must go through an OAuth flow and grant Claude access to Asana via their MCP and other public APIs. But getting all knowledge workers to know that that integration exists — and more importantly, which OAuth grants are OK and which are to be avoided — can be a tall order.Some of the challenges around direct OAuth grants between applications could be centralized by identity providers, Bose noted, or a centralized listing of approved enterprise AI agents with their skill sets, “almost like an active directory or universal directory of agents.”Right now, though, beyond what Asana is doing, there’s no standard protocol around shared knowledge and memory, said Bose. His team has been getting “a lot of interesting inbound asks” from partners who want their agents to operate on the Asana work graph and benefit from shared work.“But because the protocol or standard doesn&#x27;t exist, today it has to be a very custom bespoke conversation,” said Bose. Ultimately, there are three questions the CPO called “extremely interesting” in AI orchestration right now: How do you build, manage and secure an authoritative list of known approved AI agents? How can you enable app-to-app integrations as an IT team without potentially configuring dangerous or harmful agents?Today’s agent-to-agent interactions are very single player. Clouds can independently be connected to Asana or Figma or Slack. How can we finally get to a unified, multi-player outcome?The increased adoption of modern context protocol (MCP) — the open standard introduced by Anthropic that connects AI agents to external systems in a single action, rather than custom integrations for every single pairing — is promising, he noted, and its widespread adoption could open up new and exciting use cases.However, “I think there probably isn&#x27;t a silver bullet standard out there right now,” said Bose.",
          "content": "The key to successful AI agents within an enterprise? Shared memory and context. This, according to Asana CPO Arnab Bose, provides detailed history and direct access from the get-go — with guardrail checkpoints and human oversight, of course. This way, “when you assign a task, you&#x27;re not having to go ahead and re-provide all of the context about how your business works,” Bose said at a recent VB event in San Francisco. AI as an active teammate, rather than a passive add-onAsana launched Asana AI Teammates last year with the philosophy that, just like humans, AI agents should be plugged directly into a team or project to create a collaborative system. To further this mission, the project management company has fully integrated with Anthropic’s Claude. Users can choose from 12 pre-built agents — for common use cases like IT ticket deflection — or build their own, then assign them to project teams and immediately provide a historical record of what tasks have already been completed and what is still yet to be resolved. Agents also have access to third-party resources like Microsoft 365 or Google Drive. “When that agent gets created, it&#x27;s not acting on behalf of someone, it manifests itself as a teammate and it gets all of the same sharing permissions, it inherits that,” Bose explained. Everything anyone does — humans and AI included — is documented to allow for “ease of explainability” and a “very transparent and trustworthy system.”But just like human workers, AI agents are kept in check: Critically, workflows incorporate checkpoints, where humans can give feedback and ask the agent to tweak certain elements of a project or adjust research plans. This is documented in what Bose called a “very human-readable way.” Also importantly, the UI provides instructions and knowledge about agent behavior, and approved admins can pause, edit and redirect models in the API when they take actions based on conflicting directions or start acting “in a weird way.”“The person with edit rights can delete those things that are conflicting and make it go back to its correct behavior,” said Bose. “We&#x27;re leaning into that common human-understandable interaction pattern.”Overcoming challenges of authorization, integration But because AI agents are so new, there are still many challenges around security, accessibility and compatibility. Asana users, for instance, must go through an OAuth flow and grant Claude access to Asana via their MCP and other public APIs. But getting all knowledge workers to know that that integration exists — and more importantly, which OAuth grants are OK and which are to be avoided — can be a tall order.Some of the challenges around direct OAuth grants between applications could be centralized by identity providers, Bose noted, or a centralized listing of approved enterprise AI agents with their skill sets, “almost like an active directory or universal directory of agents.”Right now, though, beyond what Asana is doing, there’s no standard protocol around shared knowledge and memory, said Bose. His team has been getting “a lot of interesting inbound asks” from partners who want their agents to operate on the Asana work graph and benefit from shared work.“But because the protocol or standard doesn&#x27;t exist, today it has to be a very custom bespoke conversation,” said Bose. Ultimately, there are three questions the CPO called “extremely interesting” in AI orchestration right now: How do you build, manage and secure an authoritative list of known approved AI agents? How can you enable app-to-app integrations as an IT team without potentially configuring dangerous or harmful agents?Today’s agent-to-agent interactions are very single player. Clouds can independently be connected to Asana or Figma or Slack. How can we finally get to a unified, multi-player outcome?The increased adoption of modern context protocol (MCP) — the open standard introduced by Anthropic that connects AI agents to external systems in a single action, rather than custom integrations for every single pairing — is promising, he noted, and its widespread adoption could open up new and exciting use cases.However, “I think there probably isn&#x27;t a silver bullet standard out there right now,” said Bose.",
          "feed_position": 0,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/hgdgcVYh6eTScx5sg3xmL/51a2bb25a7e65cb132358db07dcc2315/Connecting_data.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/smartphones/samsung-galaxy-a17-5g-review-a-respectable-and-affordable-android-option-190000154.html",
          "published_at": "Mon, 02 Feb 2026 19:00:00 +0000",
          "title": "Samsung Galaxy A17 5G review: A respectable and affordable Android option",
          "standfirst": "Buying a good budget phone can be a challenge. High-end handsets continue to get more features, but on the other end of the spectrum, there are only so many things you can skimp on before a device becomes too compromised. With the Galaxy A17, Samsung is trying to balance both sides of that equation with something that sports a solid design, a bright screen, decent cameras and respectable battery life for just $200. And despite some flaws, the company has succeeded at making a capable phone that fits into almost every budget. Design and display The Galaxy A17 does a good job of demonstrating how all plastics aren't the same. Despite having a polycarbonate frame and back, the phone never feels cheap. Everything from its buttons to its camera module feels nice and tight. The optical image stabilization system used for its rear shooters rattles, though that’s something even $1,000 flagships suffer from, so it’s not a big deal. Some small concessions for cost savings include a teardrop cutout for its front selfie cam and a small chin beneath its display, but considering its price, they're very forgivable. There's also only a single mono speaker and instead of an in-screen fingerprint sensor, Samsung built one into the power button on its side. Though for some, the latter might actually be a bonus. The Galaxy A17's 6.7-inch OLED display is one of the phone's best components thanks to solid brightness and a 90Hz refresh rate. Sam Rutherford for Engadget Meanwhile, one thing the A17 has that you don't get on high-end handsets anymore is a microSD card slot (that's shared with its SIM tray) for expandable storage. This gives you a cheap way to increase the phone's base 128GB of space and considering how rare this is nowadays, it’s another win for people looking for a truly affordable device. The Galaxy A17's screen is also surprisingly nice for its price, as it sports a 6.7-inch OLED display with up to 800 nits of brightness. Granted, its refresh rate tops out at 90Hz instead of the 120Hz you get on more expensive fare. But once again, considering how much it costs, I'm not complaining. Especially when you remember that base iPhones were still saddled with 60Hz panels as recently as 2024. Performance One area where budget phones often struggle is performance because skimping on RAM or the processor can save manufacturers a lot of money. And while the Galaxy A17 is generally fine considering its price bracket, I really wish Samsung had opted for a slightly newer chip. The phone comes with just 4GB of RAM (though there are slightly pricier versions with more), 128GB of onboard storage and an Exynos 1330 SoC, the latter of which is nearly three years old. The Galaxy A17 comes with three rear cameras, but its really more like two because one of those is a 2MP macro cam. Sam Rutherford for Engadget At first, I was really worried because during the initial setup, the phone was a laggy, stuttery mess. Thankfully, after signing in, giving the phone some time to download updates in the background and making sure all of its apps were up to date, performance improved significantly. To be clear, this thing still isn't a speed demon and when you're multitasking or quickly switching between heavy apps, you may notice some slowdown. I also wish touch input felt a bit more responsive because sometimes when you tap an icon, there's a small delay before anything happens. But thankfully, it's relatively minor, and in most situations, the phone is snappy enough. Cameras The A17 comes with a 13-megapixel selfie camera and three rear shooters, though in practice it's really more like two because one of those is a 2MP macro cam, which doesn't get much use unless you take a lot of up-close photos. That said, the phone takes better pictures than you might expect given its price. In well-lit conditions, both its 50MP main and 5MP ultrawide cams don't give you much to complain about. Images look sharp and sport vivid colors. However, in low-light situations, there's an obvious difference in quality between the A17 and more expensive midrange phones like Pixel 9a. In a shot of some fruit in my dimly lit kitchen, the A17's pic looks soft and features washed-out colors compared to what Google's phone produced. Then, when I went outside and snapped a photo of a car still buried after the recent snowstorm, textures on the slush in the road, along with various highlights and shadows looked worse in the A17's images. So while the phone can hold its own, camera quality is still one of the biggest reasons you might want to consider upgrading to a more expensive handset. Battery life The bottom of the Galaxy A17 features the phone's USB-C port and its single, mono speaker. Sam Rutherford for Engadget For a phone with a 5,000mAh battery and a low-power chip, the Galaxy A17 didn't last quite as long as I expected. On our local video rundown test, it lasted just over 23 hours (23:08), which is decent, but also five hours less than the Pixel 9a (28:04). On the other hand, its wired charging speed of 25 watts is more than enough. Just don't be surprised when you plop it on a wireless charging pad and nothing happens because the phone doesn't support that. Wrap-up If you are hard-capped at $200, the Samsung Galaxy A17 is a surprisingly impressive device. It's got a solid build, decent cameras with a handful of different lenses, respectable battery life and even a built-in microSD card slot for extra storage. You even get six years of OS and security updates, which is significantly longer than almost all of its similarly-priced rivals. And while its performance could be smoother, it's not laggy enough to get truly bothered about on a phone this affordable. Even though the Galaxy A17 is made out of plastic, the phone still doesn't feel cheap. Sam Rutherford for Engadget For those with wiggle room in their gadget allowance, I would seriously consider looking at a version with 8GB of RAM, which is just $30 more. Alternatively, the Pixel 9a remains my favorite Android phone when it comes to value for money and it’s $399 (down from its launch price of $499). But if money is tight, the Galaxy A17 delivers everything you need without blowing up your budget. This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/samsung-galaxy-a17-5g-review-a-respectable-and-affordable-android-option-190000154.html?src=rss",
          "content": "Buying a good budget phone can be a challenge. High-end handsets continue to get more features, but on the other end of the spectrum, there are only so many things you can skimp on before a device becomes too compromised. With the Galaxy A17, Samsung is trying to balance both sides of that equation with something that sports a solid design, a bright screen, decent cameras and respectable battery life for just $200. And despite some flaws, the company has succeeded at making a capable phone that fits into almost every budget. Design and display The Galaxy A17 does a good job of demonstrating how all plastics aren't the same. Despite having a polycarbonate frame and back, the phone never feels cheap. Everything from its buttons to its camera module feels nice and tight. The optical image stabilization system used for its rear shooters rattles, though that’s something even $1,000 flagships suffer from, so it’s not a big deal. Some small concessions for cost savings include a teardrop cutout for its front selfie cam and a small chin beneath its display, but considering its price, they're very forgivable. There's also only a single mono speaker and instead of an in-screen fingerprint sensor, Samsung built one into the power button on its side. Though for some, the latter might actually be a bonus. The Galaxy A17's 6.7-inch OLED display is one of the phone's best components thanks to solid brightness and a 90Hz refresh rate. Sam Rutherford for Engadget Meanwhile, one thing the A17 has that you don't get on high-end handsets anymore is a microSD card slot (that's shared with its SIM tray) for expandable storage. This gives you a cheap way to increase the phone's base 128GB of space and considering how rare this is nowadays, it’s another win for people looking for a truly affordable device. The Galaxy A17's screen is also surprisingly nice for its price, as it sports a 6.7-inch OLED display with up to 800 nits of brightness. Granted, its refresh rate tops out at 90Hz instead of the 120Hz you get on more expensive fare. But once again, considering how much it costs, I'm not complaining. Especially when you remember that base iPhones were still saddled with 60Hz panels as recently as 2024. Performance One area where budget phones often struggle is performance because skimping on RAM or the processor can save manufacturers a lot of money. And while the Galaxy A17 is generally fine considering its price bracket, I really wish Samsung had opted for a slightly newer chip. The phone comes with just 4GB of RAM (though there are slightly pricier versions with more), 128GB of onboard storage and an Exynos 1330 SoC, the latter of which is nearly three years old. The Galaxy A17 comes with three rear cameras, but its really more like two because one of those is a 2MP macro cam. Sam Rutherford for Engadget At first, I was really worried because during the initial setup, the phone was a laggy, stuttery mess. Thankfully, after signing in, giving the phone some time to download updates in the background and making sure all of its apps were up to date, performance improved significantly. To be clear, this thing still isn't a speed demon and when you're multitasking or quickly switching between heavy apps, you may notice some slowdown. I also wish touch input felt a bit more responsive because sometimes when you tap an icon, there's a small delay before anything happens. But thankfully, it's relatively minor, and in most situations, the phone is snappy enough. Cameras The A17 comes with a 13-megapixel selfie camera and three rear shooters, though in practice it's really more like two because one of those is a 2MP macro cam, which doesn't get much use unless you take a lot of up-close photos. That said, the phone takes better pictures than you might expect given its price. In well-lit conditions, both its 50MP main and 5MP ultrawide cams don't give you much to complain about. Images look sharp and sport vivid colors. However, in low-light situations, there's an obvious difference in quality between the A17 and more expensive midrange phones like Pixel 9a. In a shot of some fruit in my dimly lit kitchen, the A17's pic looks soft and features washed-out colors compared to what Google's phone produced. Then, when I went outside and snapped a photo of a car still buried after the recent snowstorm, textures on the slush in the road, along with various highlights and shadows looked worse in the A17's images. So while the phone can hold its own, camera quality is still one of the biggest reasons you might want to consider upgrading to a more expensive handset. Battery life The bottom of the Galaxy A17 features the phone's USB-C port and its single, mono speaker. Sam Rutherford for Engadget For a phone with a 5,000mAh battery and a low-power chip, the Galaxy A17 didn't last quite as long as I expected. On our local video rundown test, it lasted just over 23 hours (23:08), which is decent, but also five hours less than the Pixel 9a (28:04). On the other hand, its wired charging speed of 25 watts is more than enough. Just don't be surprised when you plop it on a wireless charging pad and nothing happens because the phone doesn't support that. Wrap-up If you are hard-capped at $200, the Samsung Galaxy A17 is a surprisingly impressive device. It's got a solid build, decent cameras with a handful of different lenses, respectable battery life and even a built-in microSD card slot for extra storage. You even get six years of OS and security updates, which is significantly longer than almost all of its similarly-priced rivals. And while its performance could be smoother, it's not laggy enough to get truly bothered about on a phone this affordable. Even though the Galaxy A17 is made out of plastic, the phone still doesn't feel cheap. Sam Rutherford for Engadget For those with wiggle room in their gadget allowance, I would seriously consider looking at a version with 8GB of RAM, which is just $30 more. Alternatively, the Pixel 9a remains my favorite Android phone when it comes to value for money and it’s $399 (down from its launch price of $499). But if money is tight, the Galaxy A17 delivers everything you need without blowing up your budget. This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/samsung-galaxy-a17-5g-review-a-respectable-and-affordable-android-option-190000154.html?src=rss",
          "feed_position": 7,
          "image_url": "https://d29szjachogqwa.cloudfront.net/images/user-uploaded/a17-display.jpg"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/ai/openai-brings-its-codex-coding-app-to-mac-with-new-multi-agent-abilities-included-183103262.html",
          "published_at": "Mon, 02 Feb 2026 18:31:03 +0000",
          "title": "OpenAI brings its Codex coding app to Mac, with new multi-agent abilities included",
          "standfirst": "Since last spring, OpenAI has offered Codex. What started life as the company's response to Claude Code is becoming something more sophisticated with the release of a new dedicated macOS app. At its most basic form, Codex is a programming agent capable of writing code for users, but now it can also manage multiple AI assistants that can work together to complete more complex tasks.OpenAI gives an example of how this could work in practice. The company used Codex to create a Mario Kart-like racing game, complete with a selection of different playable cars, eight tracks and a collection of powerups players can use against the competition. For a single AI agent, generating a game from scratch, with all the needed visual assets, would be a tough ask, but Codex was able to complete the task because it could delegate the work of making the game to different models with complementary capabilities. For example, it turned to GPT Image for the visual assets, while a separate model simultaneously coded the web game. \"It took on the roles of designer, game developer and QA tester to validate its work by actually playing the game,\" OpenAI says of the process. If that sounds complicated, OpenAI has tried to make it more approachable with a section of the app titled Skills. The feature bundles “instructions, resources, and scripts so Codex can reliably connect to tools, run workflows, and complete tasks according to your team’s preferences,\" the company explains. \"The Codex app includes a dedicated interface to create and manage skills. You can explicitly ask Codex to use specific skills, or let it automatically use them based on the task at hand.\"As you might imagine, Codex can also automate repetitive tasks. A dedicated Automations section of the app allows you to schedule tasks, which the software will complete in the background. \"At OpenAI, we’ve been using Automations to handle the repetitive but important tasks, like daily issue triage, finding and summarizing CI failures, generating daily release briefs, checking for bugs, and more,\" the company said. The release of the Codex macOS app comes as AI startups explore what a group of AI agents working in parallel can accomplish. At the start of the year, Anysphere, the company behind Cursor, found it was possible to build a working web browser from scratch using such an approach, though it did encounter problems along the way. For a limited time, OpenAI is making Codex available to ChatGPT Free and Go users so they can see what's possible with this new software. At the same time, the company is doubling rates for Plus and Pro subscribers. This article originally appeared on Engadget at https://www.engadget.com/ai/openai-brings-its-codex-coding-app-to-mac-with-new-multi-agent-abilities-included-183103262.html?src=rss",
          "content": "Since last spring, OpenAI has offered Codex. What started life as the company's response to Claude Code is becoming something more sophisticated with the release of a new dedicated macOS app. At its most basic form, Codex is a programming agent capable of writing code for users, but now it can also manage multiple AI assistants that can work together to complete more complex tasks.OpenAI gives an example of how this could work in practice. The company used Codex to create a Mario Kart-like racing game, complete with a selection of different playable cars, eight tracks and a collection of powerups players can use against the competition. For a single AI agent, generating a game from scratch, with all the needed visual assets, would be a tough ask, but Codex was able to complete the task because it could delegate the work of making the game to different models with complementary capabilities. For example, it turned to GPT Image for the visual assets, while a separate model simultaneously coded the web game. \"It took on the roles of designer, game developer and QA tester to validate its work by actually playing the game,\" OpenAI says of the process. If that sounds complicated, OpenAI has tried to make it more approachable with a section of the app titled Skills. The feature bundles “instructions, resources, and scripts so Codex can reliably connect to tools, run workflows, and complete tasks according to your team’s preferences,\" the company explains. \"The Codex app includes a dedicated interface to create and manage skills. You can explicitly ask Codex to use specific skills, or let it automatically use them based on the task at hand.\"As you might imagine, Codex can also automate repetitive tasks. A dedicated Automations section of the app allows you to schedule tasks, which the software will complete in the background. \"At OpenAI, we’ve been using Automations to handle the repetitive but important tasks, like daily issue triage, finding and summarizing CI failures, generating daily release briefs, checking for bugs, and more,\" the company said. The release of the Codex macOS app comes as AI startups explore what a group of AI agents working in parallel can accomplish. At the start of the year, Anysphere, the company behind Cursor, found it was possible to build a working web browser from scratch using such an approach, though it did encounter problems along the way. For a limited time, OpenAI is making Codex available to ChatGPT Free and Go users so they can see what's possible with this new software. At the same time, the company is doubling rates for Plus and Pro subscribers. This article originally appeared on Engadget at https://www.engadget.com/ai/openai-brings-its-codex-coding-app-to-mac-with-new-multi-agent-abilities-included-183103262.html?src=rss",
          "feed_position": 9
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/openai-launches-a-codex-desktop-app-for-macos-to-run-multiple-ai-coding",
          "published_at": "Mon, 02 Feb 2026 18:00:00 GMT",
          "title": "OpenAI launches a Codex desktop app for macOS to run multiple AI coding agents in parallel",
          "standfirst": "OpenAI on Monday released a new desktop application for its Codex artificial intelligence coding system, a tool the company says transforms software development from a collaborative exercise with a single AI assistant into something more akin to managing a team of autonomous workers.The Codex app for macOS functions as what OpenAI executives describe as a \"command center for agents,\" allowing developers to delegate multiple coding tasks simultaneously, automate repetitive work, and supervise AI systems that can run for up to 30 minutes independently before returning completed code.\"This is the most loved internal product we&#x27;ve ever had,\" Sam Altman, OpenAI&#x27;s chief executive, told VentureBeat in a press briefing ahead of Monday&#x27;s launch. \"It&#x27;s been totally an amazing thing for us to be using recently at OpenAI.\"The release arrives at a pivotal moment for the enterprise AI market. According to a survey of 100 Global 2000 companies published last week by venture capital firm Andreessen Horowitz, 78% of enterprise CIOs now use OpenAI models in production, though competitors Anthropic and Google are gaining ground rapidly. Anthropic posted the largest share increase of any frontier lab since May 2025, growing 25% in enterprise penetration, with 44% of enterprises now using Anthropic in production.The timing of OpenAI&#x27;s Codex app launch — with its focus on professional software engineering workflows — appears designed to defend the company&#x27;s position in what has become the most contested segment of the AI market: coding tools.Why developers are abandoning their IDEs for AI agent managementThe Codex app introduces a fundamentally different approach to AI-assisted coding. While previous tools like GitHub Copilot focused on autocompleting lines of code in real-time, the new application enables developers to \"effortlessly manage multiple agents at once, run work in parallel, and collaborate with agents over long-running tasks.\"Alexander Embiricos, the product lead for Codex, explained the evolution during the press briefing by tracing the product&#x27;s lineage back to 2021, when OpenAI first introduced a model called Codex that powered GitHub Copilot.\"Back then, people were using AI to write small chunks of code in their IDEs,\" Embiricos said. \"GPT-5 in August last year was a big jump, and then 5.2 in December was another massive jump, where people started doing longer and longer tasks, asking models to do work end to end. So what we saw is that developers, instead of working closely with the model, pair coding, they started delegating entire features.\"The shift has been so profound that Altman said he recently completed a substantial coding project without ever opening a traditional integrated development environment.\"I was astonished by this…I did this fairly big project in a few days earlier this week and over the weekend. I did not open an IDE during the process. Not a single time,\" Altman said. \"I did look at some code, but I was not doing it the old-fashioned way, and I did not think that was going to be happening by now.\"How skills and automations extend AI coding beyond simple code generationThe Codex app introduces several new capabilities designed to extend AI coding beyond writing lines of code. Chief among these are \"Skills,\" which bundle instructions, resources, and scripts so that Codex can \"reliably connect to tools, run workflows, and complete tasks according to your team&#x27;s preferences.\"The app includes a dedicated interface for creating and managing skills, and users can explicitly invoke specific skills or allow the system to automatically select them based on the task at hand. OpenAI has published a library of skills for common workflows, including tools to fetch design context from Figma, manage projects in Linear, deploy web applications to cloud hosts like Cloudflare and Vercel, generate images using GPT Image, and create professional documents in PDF, spreadsheet, and Word formats.To demonstrate the system&#x27;s capabilities, OpenAI asked Codex to build a racing game from a single prompt. Using an image generation skill and a web game development skill, Codex built the game by working independently using more than 7 million tokens with just one initial user prompt, taking on \"the roles of designer, game developer, and QA tester to validate its work by actually playing the game.\"The company has also introduced \"Automations,\" which allow developers to schedule Codex to work in the background on an automatic schedule. \"When an Automation finishes, the results land in a review queue so you can jump back in and continue working if needed.\"Thibault Sottiaux, who leads the Codex team at OpenAI, described how the company uses these automations internally: \"We&#x27;ve been using Automations to handle the repetitive but important tasks, like daily issue triage, finding and summarizing CI failures, generating daily release briefs, checking for bugs, and more.\"The app also includes built-in support for \"worktrees,\" allowing multiple agents to work on the same repository without conflicts. \"Each agent works on an isolated copy of your code, allowing you to explore different paths without needing to track how they impact your codebase.\"OpenAI battles Anthropic and Google for control of enterprise AI spendingThe launch comes as enterprise spending on AI coding tools accelerates dramatically. According to the Andreessen Horowitz survey, average enterprise AI spend on large language models has risen from approximately $4.5 million to $7 million over the last two years, with enterprises expecting growth of another 65% this year to approximately $11.6 million.Leadership in the enterprise AI market varies significantly by use case. OpenAI dominates \"early, horizontal use cases like general purpose chatbots, enterprise knowledge management and customer support,\" while Anthropic leads in \"software development and data analysis, where CIOs consistently cite rapid capability gains since the second half of 2024.\"When asked during the press briefing how Codex differentiates from Anthropic&#x27;s Claude Code, which has been described as having its \"ChatGPT moment,\" Sottiaux emphasized OpenAI&#x27;s focus on model capability for long-running tasks.\"One of the things that our models are extremely good at—they really sit at the frontier of intelligence and doing reliable work for long periods of time,\" Sottiaux said. \"This is also what we&#x27;re optimizing this new surface to be very good at, so that you can start many parallel agents and coordinate them over long periods of time and not get lost.\"Altman added that while many tools can handle \"vibe coding front ends,\" OpenAI&#x27;s 5.2 model remains \"the strongest model by far\" for sophisticated work on complex systems.\"Taking that level of model capability and putting it in an interface where you can do what Thibault was saying, we think is going to matter quite a bit,\" Altman said. \"That&#x27;s probably the, at least listening to users and sort of looking at the chatter on social that&#x27;s that&#x27;s the single biggest differentiator.\"The surprising satisfies on AI progress: how fast humans can typeThe philosophical underpinning of the Codex app reflects a view that OpenAI executives have been articulating for months: that human limitations — not AI capabilities — now constitute the primary constraint on productivity.In a December appearance on Lenny’s Podcast, Embiricos described human typing speed as \"the current underappreciated limiting factor\" to achieving artificial general intelligence. The logic: if AI can perform complex coding tasks but humans can&#x27;t write prompts or review outputs fast enough, progress stalls.The Codex app attempts to address this by enabling what the team calls an \"abundance mindset\" — running multiple tasks in parallel rather than perfecting single requests. During the briefing, Embiricos described how power users at OpenAI work with the tool.\"Last night, I was working on the app, and I was making a few changes, and all of these changes are able to run in parallel together. And I was just sort of going between them, managing them,\" Embiricos said. \"Behind the scenes, all these tasks are running on something called gate work trees, which means that the agents are running independently, and you don&#x27;t have to manage them.\"In the Sequoia Capital podcast \"Training Data,\" Embiricos elaborated on this mindset shift: \"The mindset that works really well for Codex is, like, kind of like this abundance mindset and, like, hey, let&#x27;s try anything. Let&#x27;s try anything even multiple times and see what works.\" He noted that when users run 20 or more tasks in a day or an hour, \"they&#x27;ve probably understood basically how to use the tool.\"Building trust through sandboxes: how OpenAI secures autonomous coding agentsOpenAI has built security measures into the Codex architecture from the ground up. The app uses \"native, open-source and configurable system-level sandboxing,\" and by default, \"Codex agents are limited to editing files in the folder or branch where they&#x27;re working and using cached web search, then asking for permission to run commands that require elevated permissions like network access.\"Embiricos elaborated on the security approach during the briefing, noting that OpenAI has open-sourced its sandbox technology.\"Codex has this sandbox that we&#x27;re actually incredibly proud of, and it&#x27;s open source, so you can go check it out,\" Embiricos said. The sandbox \"basically ensures that when the agent is working on your computer, it can only make writes in a specific folder that you want it to make rights into, and it doesn&#x27;t access network without information.\"The system also includes a granular permission model that allows users to configure persistent approvals for specific actions, avoiding the need to repeatedly authorize routine operations. \"If the agent wants to do something and you find yourself annoyed that you&#x27;re constantly having to approve it, instead of just saying, &#x27;All right, you can do everything,&#x27; you can just say, &#x27;Hey, remember this one thing — I&#x27;m actually okay with you doing this going forward,&#x27;\" Embiricos explained.Altman emphasized that the permission architecture signals a broader philosophy about AI safety in agentic systems.\"I think this is going to be really important. I mean, it&#x27;s been so clear to us using this, how much you want it to have control of your computer, and how much you need it,\" Altman said. \"And the way the team built Codex such that you can sensibly limit what&#x27;s happening and also pick the level of control you&#x27;re comfortable with is important.\"He also acknowledged the dual-use nature of the technology. \"We do expect to get to our internal cybersecurity high moment of our models very soon. We&#x27;ve been preparing for this. We&#x27;ve talked about our mitigation plan,\" Altman said. \"A real thing for the world to contend with is going to be defending against a lot of capable cybersecurity threats using these models very quickly.\"The same capabilities that make Codex valuable for fixing bugs and refactoring code could, in the wrong hands, be used to discover vulnerabilities or write malicious software—a tension that will only intensify as AI coding agents become more capable.From Android apps to research breakthroughs: how Codex transformed OpenAI&#x27;s own operationsPerhaps the most compelling evidence for Codex&#x27;s capabilities comes from OpenAI&#x27;s own use of the tool. Sottiaux described how the system has accelerated internal development.\"A Sora Android app is an example of that where four engineers shipped in only 18 days internally, and then within the month we give access to the world,\" Sottiaux said. \"I had never noticed such speed at this scale before.\"Beyond product development, Sottiaux described how Codex has become integral to OpenAI&#x27;s research operations.\"Codex is really involved in all parts of the research — making new data sets, investigating its own screening runs,\" he said. \"When I sit in meetings with researchers, they all send Codex off to do an investigation while we&#x27;re having a chat, and then it will come back with useful information, and we&#x27;re able to debug much faster.\"The tool has also begun contributing to its own development. \"Codex also is starting to build itself,\" Sottiaux noted. \"There&#x27;s no screen within the Codex engineering team that doesn&#x27;t have Codex running on multiple, six, eight, ten, tasks at a time.\"When asked whether this constitutes evidence of \"recursive self-improvement\" — a concept that has long concerned AI safety researchers — Sottiaux was measured in his response.\"There is a human in the loop at all times,\" he said. \"I wouldn&#x27;t necessarily call it recursive self-improvement, a glimpse into the future there.\"Altman offered a more expansive view of the research implications.\"There&#x27;s two parts of what people talk about when they talk about automating research to a degree where you can imagine that happening,\" Altman said. \"One is, can you write software, extremely complex infrastructure, software to run training jobs across hundreds of thousands of GPUs and babysit them. And the second is, can you come up with the new scientific ideas that make algorithms more efficient.\"He noted that OpenAI is \"seeing early but promising signs on both of those.\"The end of technical debt? AI agents take on the work engineers hate mostOne of the more unexpected applications of Codex has been addressing technical debt — the accumulated maintenance burden that plagues most software projects.Altman described how AI coding agents excel at the unglamorous work that human engineers typically avoid.\"The kind of work that human engineers hate to do — go refactor this, clean up this code base, rewrite this, write this test — this is where the model doesn&#x27;t care. The model will do anything, whether it&#x27;s fun or not,\" Altman said.He reported that some infrastructure teams at OpenAI that \"had sort of like, given up hope that you were ever really going to long term win the war against tech debt, are now like, we&#x27;re going to win this, because the model is going to constantly be working behind us, making sure we have great test coverage, making sure that we refactor when we&#x27;re supposed to.\"The observation speaks to a broader theme that emerged repeatedly during the briefing: AI coding agents don&#x27;t experience the motivational fluctuations that affect human programmers. As Altman noted, a team member recently observed that \"the hardest mental adjustment to make about working with these sort of like aI coding teammates, unlike a human, is the models just don&#x27;t run out of dopamine. They keep trying. They don&#x27;t run out of motivation. They don&#x27;t get, you know, they don&#x27;t lose energy when something&#x27;s not working. They just keep going and, you know, they figure out how to get it done.\"What the Codex app costs and who can use it starting todayThe Codex app launches today on macOS and is available to anyone with a ChatGPT Plus, Pro, Business, Enterprise, or Edu subscription. Usage is included in ChatGPT subscriptions, with the option to purchase additional credits if needed.In a promotional push, OpenAI is temporarily making Codex available to ChatGPT Free and Go users \"to help more people try agentic workflows.\" The company is also doubling rate limits for existing Codex users across all paid plans during this promotional period.The pricing strategy reflects OpenAI&#x27;s determination to establish Codex as the default tool for AI-assisted development before competitors can gain further traction. More than a million developers have used Codex in the past month, and usage has nearly doubled since the launch of GPT-5.2-Codex in mid-December, building on more than 20x usage growth since August 2025.Customers using Codex include large enterprises like Cisco, Ramp, Virgin Atlantic, Vanta, Duolingo, and Gap, as well as startups like Harvey, Sierra, and Wonderful. Individual developers have also embraced the tool: Peter Steinberger, creator of OpenClaw, built the project entirely with Codex and reports that since fully switching to the tool, his productivity has roughly doubled across more than 82,000 GitHub contributions.OpenAI&#x27;s ambitious roadmap: Windows support, cloud triggers, and continuous background agentsOpenAI outlined an aggressive development roadmap for Codex. The company plans to make the app available on Windows, continue pushing \"the frontier of model capabilities,\" and roll out faster inference.Within the app, OpenAI will \"keep refining multi-agent workflows based on real-world feedback\" and is \"building out Automations with support for cloud-based triggers, so Codex can run continuously in the background—not just when your computer is open.\"The company also announced a new \"plan mode\" feature that allows Codex to read through complex changes in read-only mode, then discuss with the user before executing. \"This means that it lets you build a lot of confidence before, again, sending it to do a lot of work by itself, independently, in parallel to you,\" Embiricos explained.Additionally, OpenAI is introducing customizable personalities for Codex. \"The default personality for Codex has been quite terse. A lot of people love it, but some people want something more engaging,\" Embiricos said. Users can access the new personalities using the /personality command.Altman also hinted at future integration with ChatGPT&#x27;s broader ecosystem.\"There will be all kinds of cool things we can do over time to connect people&#x27;s ChatGPT accounts and leverage sort of all the history they&#x27;ve built up there,\" Altman said.Microsoft still dominates enterprise AI, but the window for disruption is openThe Codex app launch occurs as most enterprises have moved beyond single-vendor strategies. According to the Andreessen Horowitz survey, \"81% now use three or more model families in testing or production, up from 68% less than a year ago.\"Despite the proliferation of AI coding tools, Microsoft continues to dominate enterprise adoption through its existing relationships. \"Microsoft 365 Copilot leads enterprise chat though ChatGPT has closed the gap meaningfully,\" and \"Github Copilot is still the coding leader for enterprises.\" The survey found that \"65% of enterprises noted they preferred to go with incumbent solutions when available,\" citing trust, integration, and procurement simplicity.However, the survey also suggests significant opportunity for challengers: \"Enterprises consistently say they value faster innovation, deeper AI focus, and greater flexibility paired with cutting edge capabilities that AI native startups bring.\"OpenAI appears to be positioning Codex as a bridge between these worlds. \"Codex is built on a simple premise: everything is controlled by code,\" the company stated. \"The better an agent is at reasoning about and producing code, the more capable it becomes across all forms of technical and knowledge work.\"The company&#x27;s ambition extends beyond coding. \"We&#x27;ve focused on making Codex the best coding agent, which has also laid the foundation for it to become a strong agent for a broad range of knowledge work tasks that extend beyond writing code.\"When asked whether AI coding tools could eventually move beyond early adopters to become mainstream, Altman suggested the transition may be closer than many expect.\"Can it go from vibe coding to serious software engineering? That&#x27;s what this is about,\" Altman said. \"I think we are over the bar on that. I think this will be the way that most serious coders do their job — and very rapidly from now.\"He then pivoted to an even bolder prediction: that code itself could become the universal interface for all computer-based work.\"Code is a universal language to get computers to do what you want. And it&#x27;s gotten so good that I think, very quickly, we can go not just from vibe coding silly apps but to doing all the non-coding knowledge work,\" Altman said.At the close of the briefing, Altman urged journalists to try the product themselves: \"Please try the app. There&#x27;s no way to get this across just by talking about it. It&#x27;s a crazy amount of power.\"For developers who have spent careers learning to write code, the message was clear: the future belongs to those who learn to manage the machines that write it for them.",
          "content": "OpenAI on Monday released a new desktop application for its Codex artificial intelligence coding system, a tool the company says transforms software development from a collaborative exercise with a single AI assistant into something more akin to managing a team of autonomous workers.The Codex app for macOS functions as what OpenAI executives describe as a \"command center for agents,\" allowing developers to delegate multiple coding tasks simultaneously, automate repetitive work, and supervise AI systems that can run for up to 30 minutes independently before returning completed code.\"This is the most loved internal product we&#x27;ve ever had,\" Sam Altman, OpenAI&#x27;s chief executive, told VentureBeat in a press briefing ahead of Monday&#x27;s launch. \"It&#x27;s been totally an amazing thing for us to be using recently at OpenAI.\"The release arrives at a pivotal moment for the enterprise AI market. According to a survey of 100 Global 2000 companies published last week by venture capital firm Andreessen Horowitz, 78% of enterprise CIOs now use OpenAI models in production, though competitors Anthropic and Google are gaining ground rapidly. Anthropic posted the largest share increase of any frontier lab since May 2025, growing 25% in enterprise penetration, with 44% of enterprises now using Anthropic in production.The timing of OpenAI&#x27;s Codex app launch — with its focus on professional software engineering workflows — appears designed to defend the company&#x27;s position in what has become the most contested segment of the AI market: coding tools.Why developers are abandoning their IDEs for AI agent managementThe Codex app introduces a fundamentally different approach to AI-assisted coding. While previous tools like GitHub Copilot focused on autocompleting lines of code in real-time, the new application enables developers to \"effortlessly manage multiple agents at once, run work in parallel, and collaborate with agents over long-running tasks.\"Alexander Embiricos, the product lead for Codex, explained the evolution during the press briefing by tracing the product&#x27;s lineage back to 2021, when OpenAI first introduced a model called Codex that powered GitHub Copilot.\"Back then, people were using AI to write small chunks of code in their IDEs,\" Embiricos said. \"GPT-5 in August last year was a big jump, and then 5.2 in December was another massive jump, where people started doing longer and longer tasks, asking models to do work end to end. So what we saw is that developers, instead of working closely with the model, pair coding, they started delegating entire features.\"The shift has been so profound that Altman said he recently completed a substantial coding project without ever opening a traditional integrated development environment.\"I was astonished by this…I did this fairly big project in a few days earlier this week and over the weekend. I did not open an IDE during the process. Not a single time,\" Altman said. \"I did look at some code, but I was not doing it the old-fashioned way, and I did not think that was going to be happening by now.\"How skills and automations extend AI coding beyond simple code generationThe Codex app introduces several new capabilities designed to extend AI coding beyond writing lines of code. Chief among these are \"Skills,\" which bundle instructions, resources, and scripts so that Codex can \"reliably connect to tools, run workflows, and complete tasks according to your team&#x27;s preferences.\"The app includes a dedicated interface for creating and managing skills, and users can explicitly invoke specific skills or allow the system to automatically select them based on the task at hand. OpenAI has published a library of skills for common workflows, including tools to fetch design context from Figma, manage projects in Linear, deploy web applications to cloud hosts like Cloudflare and Vercel, generate images using GPT Image, and create professional documents in PDF, spreadsheet, and Word formats.To demonstrate the system&#x27;s capabilities, OpenAI asked Codex to build a racing game from a single prompt. Using an image generation skill and a web game development skill, Codex built the game by working independently using more than 7 million tokens with just one initial user prompt, taking on \"the roles of designer, game developer, and QA tester to validate its work by actually playing the game.\"The company has also introduced \"Automations,\" which allow developers to schedule Codex to work in the background on an automatic schedule. \"When an Automation finishes, the results land in a review queue so you can jump back in and continue working if needed.\"Thibault Sottiaux, who leads the Codex team at OpenAI, described how the company uses these automations internally: \"We&#x27;ve been using Automations to handle the repetitive but important tasks, like daily issue triage, finding and summarizing CI failures, generating daily release briefs, checking for bugs, and more.\"The app also includes built-in support for \"worktrees,\" allowing multiple agents to work on the same repository without conflicts. \"Each agent works on an isolated copy of your code, allowing you to explore different paths without needing to track how they impact your codebase.\"OpenAI battles Anthropic and Google for control of enterprise AI spendingThe launch comes as enterprise spending on AI coding tools accelerates dramatically. According to the Andreessen Horowitz survey, average enterprise AI spend on large language models has risen from approximately $4.5 million to $7 million over the last two years, with enterprises expecting growth of another 65% this year to approximately $11.6 million.Leadership in the enterprise AI market varies significantly by use case. OpenAI dominates \"early, horizontal use cases like general purpose chatbots, enterprise knowledge management and customer support,\" while Anthropic leads in \"software development and data analysis, where CIOs consistently cite rapid capability gains since the second half of 2024.\"When asked during the press briefing how Codex differentiates from Anthropic&#x27;s Claude Code, which has been described as having its \"ChatGPT moment,\" Sottiaux emphasized OpenAI&#x27;s focus on model capability for long-running tasks.\"One of the things that our models are extremely good at—they really sit at the frontier of intelligence and doing reliable work for long periods of time,\" Sottiaux said. \"This is also what we&#x27;re optimizing this new surface to be very good at, so that you can start many parallel agents and coordinate them over long periods of time and not get lost.\"Altman added that while many tools can handle \"vibe coding front ends,\" OpenAI&#x27;s 5.2 model remains \"the strongest model by far\" for sophisticated work on complex systems.\"Taking that level of model capability and putting it in an interface where you can do what Thibault was saying, we think is going to matter quite a bit,\" Altman said. \"That&#x27;s probably the, at least listening to users and sort of looking at the chatter on social that&#x27;s that&#x27;s the single biggest differentiator.\"The surprising satisfies on AI progress: how fast humans can typeThe philosophical underpinning of the Codex app reflects a view that OpenAI executives have been articulating for months: that human limitations — not AI capabilities — now constitute the primary constraint on productivity.In a December appearance on Lenny’s Podcast, Embiricos described human typing speed as \"the current underappreciated limiting factor\" to achieving artificial general intelligence. The logic: if AI can perform complex coding tasks but humans can&#x27;t write prompts or review outputs fast enough, progress stalls.The Codex app attempts to address this by enabling what the team calls an \"abundance mindset\" — running multiple tasks in parallel rather than perfecting single requests. During the briefing, Embiricos described how power users at OpenAI work with the tool.\"Last night, I was working on the app, and I was making a few changes, and all of these changes are able to run in parallel together. And I was just sort of going between them, managing them,\" Embiricos said. \"Behind the scenes, all these tasks are running on something called gate work trees, which means that the agents are running independently, and you don&#x27;t have to manage them.\"In the Sequoia Capital podcast \"Training Data,\" Embiricos elaborated on this mindset shift: \"The mindset that works really well for Codex is, like, kind of like this abundance mindset and, like, hey, let&#x27;s try anything. Let&#x27;s try anything even multiple times and see what works.\" He noted that when users run 20 or more tasks in a day or an hour, \"they&#x27;ve probably understood basically how to use the tool.\"Building trust through sandboxes: how OpenAI secures autonomous coding agentsOpenAI has built security measures into the Codex architecture from the ground up. The app uses \"native, open-source and configurable system-level sandboxing,\" and by default, \"Codex agents are limited to editing files in the folder or branch where they&#x27;re working and using cached web search, then asking for permission to run commands that require elevated permissions like network access.\"Embiricos elaborated on the security approach during the briefing, noting that OpenAI has open-sourced its sandbox technology.\"Codex has this sandbox that we&#x27;re actually incredibly proud of, and it&#x27;s open source, so you can go check it out,\" Embiricos said. The sandbox \"basically ensures that when the agent is working on your computer, it can only make writes in a specific folder that you want it to make rights into, and it doesn&#x27;t access network without information.\"The system also includes a granular permission model that allows users to configure persistent approvals for specific actions, avoiding the need to repeatedly authorize routine operations. \"If the agent wants to do something and you find yourself annoyed that you&#x27;re constantly having to approve it, instead of just saying, &#x27;All right, you can do everything,&#x27; you can just say, &#x27;Hey, remember this one thing — I&#x27;m actually okay with you doing this going forward,&#x27;\" Embiricos explained.Altman emphasized that the permission architecture signals a broader philosophy about AI safety in agentic systems.\"I think this is going to be really important. I mean, it&#x27;s been so clear to us using this, how much you want it to have control of your computer, and how much you need it,\" Altman said. \"And the way the team built Codex such that you can sensibly limit what&#x27;s happening and also pick the level of control you&#x27;re comfortable with is important.\"He also acknowledged the dual-use nature of the technology. \"We do expect to get to our internal cybersecurity high moment of our models very soon. We&#x27;ve been preparing for this. We&#x27;ve talked about our mitigation plan,\" Altman said. \"A real thing for the world to contend with is going to be defending against a lot of capable cybersecurity threats using these models very quickly.\"The same capabilities that make Codex valuable for fixing bugs and refactoring code could, in the wrong hands, be used to discover vulnerabilities or write malicious software—a tension that will only intensify as AI coding agents become more capable.From Android apps to research breakthroughs: how Codex transformed OpenAI&#x27;s own operationsPerhaps the most compelling evidence for Codex&#x27;s capabilities comes from OpenAI&#x27;s own use of the tool. Sottiaux described how the system has accelerated internal development.\"A Sora Android app is an example of that where four engineers shipped in only 18 days internally, and then within the month we give access to the world,\" Sottiaux said. \"I had never noticed such speed at this scale before.\"Beyond product development, Sottiaux described how Codex has become integral to OpenAI&#x27;s research operations.\"Codex is really involved in all parts of the research — making new data sets, investigating its own screening runs,\" he said. \"When I sit in meetings with researchers, they all send Codex off to do an investigation while we&#x27;re having a chat, and then it will come back with useful information, and we&#x27;re able to debug much faster.\"The tool has also begun contributing to its own development. \"Codex also is starting to build itself,\" Sottiaux noted. \"There&#x27;s no screen within the Codex engineering team that doesn&#x27;t have Codex running on multiple, six, eight, ten, tasks at a time.\"When asked whether this constitutes evidence of \"recursive self-improvement\" — a concept that has long concerned AI safety researchers — Sottiaux was measured in his response.\"There is a human in the loop at all times,\" he said. \"I wouldn&#x27;t necessarily call it recursive self-improvement, a glimpse into the future there.\"Altman offered a more expansive view of the research implications.\"There&#x27;s two parts of what people talk about when they talk about automating research to a degree where you can imagine that happening,\" Altman said. \"One is, can you write software, extremely complex infrastructure, software to run training jobs across hundreds of thousands of GPUs and babysit them. And the second is, can you come up with the new scientific ideas that make algorithms more efficient.\"He noted that OpenAI is \"seeing early but promising signs on both of those.\"The end of technical debt? AI agents take on the work engineers hate mostOne of the more unexpected applications of Codex has been addressing technical debt — the accumulated maintenance burden that plagues most software projects.Altman described how AI coding agents excel at the unglamorous work that human engineers typically avoid.\"The kind of work that human engineers hate to do — go refactor this, clean up this code base, rewrite this, write this test — this is where the model doesn&#x27;t care. The model will do anything, whether it&#x27;s fun or not,\" Altman said.He reported that some infrastructure teams at OpenAI that \"had sort of like, given up hope that you were ever really going to long term win the war against tech debt, are now like, we&#x27;re going to win this, because the model is going to constantly be working behind us, making sure we have great test coverage, making sure that we refactor when we&#x27;re supposed to.\"The observation speaks to a broader theme that emerged repeatedly during the briefing: AI coding agents don&#x27;t experience the motivational fluctuations that affect human programmers. As Altman noted, a team member recently observed that \"the hardest mental adjustment to make about working with these sort of like aI coding teammates, unlike a human, is the models just don&#x27;t run out of dopamine. They keep trying. They don&#x27;t run out of motivation. They don&#x27;t get, you know, they don&#x27;t lose energy when something&#x27;s not working. They just keep going and, you know, they figure out how to get it done.\"What the Codex app costs and who can use it starting todayThe Codex app launches today on macOS and is available to anyone with a ChatGPT Plus, Pro, Business, Enterprise, or Edu subscription. Usage is included in ChatGPT subscriptions, with the option to purchase additional credits if needed.In a promotional push, OpenAI is temporarily making Codex available to ChatGPT Free and Go users \"to help more people try agentic workflows.\" The company is also doubling rate limits for existing Codex users across all paid plans during this promotional period.The pricing strategy reflects OpenAI&#x27;s determination to establish Codex as the default tool for AI-assisted development before competitors can gain further traction. More than a million developers have used Codex in the past month, and usage has nearly doubled since the launch of GPT-5.2-Codex in mid-December, building on more than 20x usage growth since August 2025.Customers using Codex include large enterprises like Cisco, Ramp, Virgin Atlantic, Vanta, Duolingo, and Gap, as well as startups like Harvey, Sierra, and Wonderful. Individual developers have also embraced the tool: Peter Steinberger, creator of OpenClaw, built the project entirely with Codex and reports that since fully switching to the tool, his productivity has roughly doubled across more than 82,000 GitHub contributions.OpenAI&#x27;s ambitious roadmap: Windows support, cloud triggers, and continuous background agentsOpenAI outlined an aggressive development roadmap for Codex. The company plans to make the app available on Windows, continue pushing \"the frontier of model capabilities,\" and roll out faster inference.Within the app, OpenAI will \"keep refining multi-agent workflows based on real-world feedback\" and is \"building out Automations with support for cloud-based triggers, so Codex can run continuously in the background—not just when your computer is open.\"The company also announced a new \"plan mode\" feature that allows Codex to read through complex changes in read-only mode, then discuss with the user before executing. \"This means that it lets you build a lot of confidence before, again, sending it to do a lot of work by itself, independently, in parallel to you,\" Embiricos explained.Additionally, OpenAI is introducing customizable personalities for Codex. \"The default personality for Codex has been quite terse. A lot of people love it, but some people want something more engaging,\" Embiricos said. Users can access the new personalities using the /personality command.Altman also hinted at future integration with ChatGPT&#x27;s broader ecosystem.\"There will be all kinds of cool things we can do over time to connect people&#x27;s ChatGPT accounts and leverage sort of all the history they&#x27;ve built up there,\" Altman said.Microsoft still dominates enterprise AI, but the window for disruption is openThe Codex app launch occurs as most enterprises have moved beyond single-vendor strategies. According to the Andreessen Horowitz survey, \"81% now use three or more model families in testing or production, up from 68% less than a year ago.\"Despite the proliferation of AI coding tools, Microsoft continues to dominate enterprise adoption through its existing relationships. \"Microsoft 365 Copilot leads enterprise chat though ChatGPT has closed the gap meaningfully,\" and \"Github Copilot is still the coding leader for enterprises.\" The survey found that \"65% of enterprises noted they preferred to go with incumbent solutions when available,\" citing trust, integration, and procurement simplicity.However, the survey also suggests significant opportunity for challengers: \"Enterprises consistently say they value faster innovation, deeper AI focus, and greater flexibility paired with cutting edge capabilities that AI native startups bring.\"OpenAI appears to be positioning Codex as a bridge between these worlds. \"Codex is built on a simple premise: everything is controlled by code,\" the company stated. \"The better an agent is at reasoning about and producing code, the more capable it becomes across all forms of technical and knowledge work.\"The company&#x27;s ambition extends beyond coding. \"We&#x27;ve focused on making Codex the best coding agent, which has also laid the foundation for it to become a strong agent for a broad range of knowledge work tasks that extend beyond writing code.\"When asked whether AI coding tools could eventually move beyond early adopters to become mainstream, Altman suggested the transition may be closer than many expect.\"Can it go from vibe coding to serious software engineering? That&#x27;s what this is about,\" Altman said. \"I think we are over the bar on that. I think this will be the way that most serious coders do their job — and very rapidly from now.\"He then pivoted to an even bolder prediction: that code itself could become the universal interface for all computer-based work.\"Code is a universal language to get computers to do what you want. And it&#x27;s gotten so good that I think, very quickly, we can go not just from vibe coding silly apps but to doing all the non-coding knowledge work,\" Altman said.At the close of the briefing, Altman urged journalists to try the product themselves: \"Please try the app. There&#x27;s no way to get this across just by talking about it. It&#x27;s a crazy amount of power.\"For developers who have spent careers learning to write code, the message was clear: the future belongs to those who learn to manage the machines that write it for them.",
          "feed_position": 1,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/5ixq6lS6l5yrO3RJxCtr5w/c11ddd394c8969826452a5a30312234b/nuneybits_Vector_art_of_an_Apple_iMac_monitor_displaying_cascad_ecce1621-251d-41d9-ac6e-72eb25b2fd35.webp?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/mobile/smartphones/samsung-galaxy-unpacked-2026-the-galaxy-s26-lineup-and-everything-else-we-expect-130000999.html",
          "published_at": "Mon, 02 Feb 2026 16:29:55 +0000",
          "title": "Samsung Galaxy Unpacked 2026: The Galaxy S26 lineup and everything else we expect",
          "standfirst": "Samsung’s 2025 was filled with new foldables, an ultra-thin new form factor and the launch of Google's XR platform. After making some announcements at CES 2026, the company is expected to host its first Galaxy Unpacked of the year in February to introduce the Galaxy S26 lineup.Engadget will be covering Galaxy Unpacked live, and we'll most likely have hands-on coverage of Samsung's new smartphones soon after they're announced. While we wait for an official invite, here's everything we expect Samsung will introduce at the first Galaxy Unpacked event of 2026.What is Unpacked 2026 taking place?But first, when is Unpacked going to happen? A recent image shared by leakster Evan Blass indicated Unpacked should be taking place on “February 25 2026.” Blass has a long history of credible leaks, which means this date is all but confirmed, and the main questions remaining would be — what time and in what timezone? We’re still waiting on Samsung for the official details, which should include answers to those questions.Galaxy S26, S26+ and S26 UltraSamsung Galaxy S25 Ultra hands-on photoPhoto by Sam Rutherford/EngadgetSamsung's restrained approach to updating its phones will likely continue with the Galaxy S26. Based on leaked images of the new lineup, the company is not expected to radically reinvent the look of the Galaxy S26, Galaxy S26+ or Galaxy S26 Ultra, and instead will stick with a similar design to what it used on the Galaxy S25. The phones will have a flat front screen and frame, with rounded corners and cameras housed in a vertical pill-shaped plateau on the back. Unlike Apple's move from the iPhone 16 Pro to the iPhone 17 Pro, the biggest difference here will likely be internal components like the screens, chips and camera sensors Samsung uses.Qualcomm's new Snapdragon 8 Elite Gen 5 chip is expected to be in all Samsung Galaxy S26 phones, though Korean news site Yonhap News reports Samsung's relatively new Exynos 2600 chip could be used in some phones in the lineup depending on the region, a strategy Samsung has deployed in the past. Either way the new phones should be more performant than the previous generation, and in the case of the models with the Snapdragon 8 Elite Gen 5, particularly good at on-device AI processing.I have compiled the most accurate comprehensive parameter comparison of Galaxy S25, S25+ and Galaxy S26、 S26+. Which one do you want to buy? pic.twitter.com/aQpoSvYjOz— Ice Universe (@UniverseIce) November 29, 2025One notable difference between the Galaxy S26 and the Galaxy S25 could be the phone's screen. The new phone will reportedly feature a 6.3-inch FHD+ display according to specs shared by leaker Ice Universe, which makes it ever so slightly larger than the 6.2-inch display used on the Galaxy S25. The S26 will also allegedly come with 12GB of RAM, either 256GB or 512GB of storage and a slightly larger 4,300mAh battery. Samsung isn't changing the cameras on the entry-level phone, though: leaks suggest it'll feature the same 50-megapixel main camera, 12-megapixel ultrawide, 10-megapixel 3x telephoto and 12-megapixel selfie camera as the previous generation. Changes appear to be even more minor on the Galaxy S26+. Other than the new Snapdragon chip, the phone will reportedly feature the same 6.7-inch FHD+ screen, 4,900mAh battery, 12GB of RAM and the same camera array used on the base Galaxy S26.The difference between the Galaxy S26 Ultra and Galaxy S25 Ultra is reportedly a bit clearer. According to Android Headlines, the new phone's cameras will be slightly more raised, and stand out thanks to a new metallic finish. Samsung may also switch back to using an aluminum frame on the Galaxy S26 Ultra, after using titanium frames on both the Galaxy S24 and S25 Ultras. Most importantly, to make the phone actually support Qi2 rather than only technically work with the standard when a case is attached, rumors suggest Samsung will remove the S Pen digitizer layer in the phone and adopt a new method for accepting stylus input. It's not clear what that new method will actually be, but it could let the Galaxy S26 Ultra more easily work with Qi2 accessories without losing its stylus.Android Headlines also recently shared what appear to be full image renders of the S26 series, and they generally line up with what has already been rumored, leaked and reported so far. If these pictures are accurate, they give us a clearer look at the camera bump and two color variants of the S26 Ultra.Galaxy Buds 4Galaxy Buds 3 Pro in case.EngadgetSamsung released the Galaxy Buds 3 and 3 Pro in 2024, with a major redesign that brought them much more in line with Apple's AirPods. The Galaxy Buds 4 and Buds 4 Pro Samsung is rumored to be announcing soon won't necessarily change that, though they will feature a more compact case and less angular stems, according to leaked images from the Samsung Tips app.Support for head gestures to accept and decline calls, a feature Apple includes on the AirPods Pro 3 and AirPods 4, is also rumored to work on both versions of the new Galaxy Buds. SamMobile reports the Galaxy Buds 4 and 4 Pro may also ship with a new Ultra Wideband chip that will make them easier to find with Google's Find Hub network.Galaxy Z TrifoldYes, the TriFold has a crease, two in fact. But they still don't ruin the experience. Sam Rutherford for EngadgetSamsung announced the Galaxy Z TriFold in late 2025 without firm details of when the new smartphone-that-folds-into-a-tablet would be available in North America. That info came on January 27, when the company announced the TriFold would be available in the US on January 30, for a whopping $2,900. Considering we’ve already seen the device in person at CES 2026 and people are most likely to have had a chance to look at, if not buy the foldable for themselves by the time Unpacked rolls around, we don’t expect Samsung to spend too much time dwelling on it, if at all.Galaxy S26 EdgeAt just 5.8mm thick, the Samsung Galaxy S25 Edge is one of the thinnest smartphones ever made. Sam Rutherford for EngadgetWhen the Galaxy S25 Edge was announced in 2025, it seemed possible that Samsung could replace its \"Plus\" smartphone with a unique form factor, just like Apple has opted to do with the iPhone Air. There have been conflicting reports on the matter, but it seems like Samsung will not be doing that with the Galaxy S26 Edge.Instead, the smartphone will reportedly remain another option, much like foldables are for customers not swayed by Samsung's traditional smartphones. The Galaxy S26 Edge is rumored to feature a slightly different design than last year's model, according to Android Headlines, with a large rectangular camera plateau that's reminiscent of Google's Pixel phones, and the raised oval Apple used on the iPhone Air. Beyond that, the phone is also expected to be ever so slightly thinner at 5.5mm than the 5.8mm Galaxy S25 Edge.Bixby and other AI featuresSamsung already acts as a first place Google can show off new AI features for Android, but the company is reportedly exploring other AI partnerships, too. In June 2025, Bloomberg reported that Samsung was nearing a deal with Perplexity to integrate its AI-powered search engine across OneUI and its homegrown mobile browser. Perplexity already has a deal with Motorola on its Razr phones, so the only thing that would make a deal with Samsung unusual is the close relationship the company already has with Google.The company also accidentally announced a new version of its Bixby AI assistant, which will likely also be integrated with Perplexity and could serve as an alternative to Google Gemini. Both a new Bixby and a deeper integration with Perplexity seem like natural new software features to show off at Galaxy Unpacked.Update, January 27 2026, 11:55AM ET: This story has been updated to reflect the latest news around the Galaxy Z TriFold’s price and availability in the US.Update, January 30 2026, 12:45PM ET: This story has been updated to include the latest leaks on the possible dates for Unpacked 2026.Update, February 02 2026, 11:30AM ET: This story has been updated to include the latest leaks with full image renders of the S26 trio of devices.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/samsung-galaxy-unpacked-2026-the-galaxy-s26-lineup-and-everything-else-we-expect-130000999.html?src=rss",
          "content": "Samsung’s 2025 was filled with new foldables, an ultra-thin new form factor and the launch of Google's XR platform. After making some announcements at CES 2026, the company is expected to host its first Galaxy Unpacked of the year in February to introduce the Galaxy S26 lineup.Engadget will be covering Galaxy Unpacked live, and we'll most likely have hands-on coverage of Samsung's new smartphones soon after they're announced. While we wait for an official invite, here's everything we expect Samsung will introduce at the first Galaxy Unpacked event of 2026.What is Unpacked 2026 taking place?But first, when is Unpacked going to happen? A recent image shared by leakster Evan Blass indicated Unpacked should be taking place on “February 25 2026.” Blass has a long history of credible leaks, which means this date is all but confirmed, and the main questions remaining would be — what time and in what timezone? We’re still waiting on Samsung for the official details, which should include answers to those questions.Galaxy S26, S26+ and S26 UltraSamsung Galaxy S25 Ultra hands-on photoPhoto by Sam Rutherford/EngadgetSamsung's restrained approach to updating its phones will likely continue with the Galaxy S26. Based on leaked images of the new lineup, the company is not expected to radically reinvent the look of the Galaxy S26, Galaxy S26+ or Galaxy S26 Ultra, and instead will stick with a similar design to what it used on the Galaxy S25. The phones will have a flat front screen and frame, with rounded corners and cameras housed in a vertical pill-shaped plateau on the back. Unlike Apple's move from the iPhone 16 Pro to the iPhone 17 Pro, the biggest difference here will likely be internal components like the screens, chips and camera sensors Samsung uses.Qualcomm's new Snapdragon 8 Elite Gen 5 chip is expected to be in all Samsung Galaxy S26 phones, though Korean news site Yonhap News reports Samsung's relatively new Exynos 2600 chip could be used in some phones in the lineup depending on the region, a strategy Samsung has deployed in the past. Either way the new phones should be more performant than the previous generation, and in the case of the models with the Snapdragon 8 Elite Gen 5, particularly good at on-device AI processing.I have compiled the most accurate comprehensive parameter comparison of Galaxy S25, S25+ and Galaxy S26、 S26+. Which one do you want to buy? pic.twitter.com/aQpoSvYjOz— Ice Universe (@UniverseIce) November 29, 2025One notable difference between the Galaxy S26 and the Galaxy S25 could be the phone's screen. The new phone will reportedly feature a 6.3-inch FHD+ display according to specs shared by leaker Ice Universe, which makes it ever so slightly larger than the 6.2-inch display used on the Galaxy S25. The S26 will also allegedly come with 12GB of RAM, either 256GB or 512GB of storage and a slightly larger 4,300mAh battery. Samsung isn't changing the cameras on the entry-level phone, though: leaks suggest it'll feature the same 50-megapixel main camera, 12-megapixel ultrawide, 10-megapixel 3x telephoto and 12-megapixel selfie camera as the previous generation. Changes appear to be even more minor on the Galaxy S26+. Other than the new Snapdragon chip, the phone will reportedly feature the same 6.7-inch FHD+ screen, 4,900mAh battery, 12GB of RAM and the same camera array used on the base Galaxy S26.The difference between the Galaxy S26 Ultra and Galaxy S25 Ultra is reportedly a bit clearer. According to Android Headlines, the new phone's cameras will be slightly more raised, and stand out thanks to a new metallic finish. Samsung may also switch back to using an aluminum frame on the Galaxy S26 Ultra, after using titanium frames on both the Galaxy S24 and S25 Ultras. Most importantly, to make the phone actually support Qi2 rather than only technically work with the standard when a case is attached, rumors suggest Samsung will remove the S Pen digitizer layer in the phone and adopt a new method for accepting stylus input. It's not clear what that new method will actually be, but it could let the Galaxy S26 Ultra more easily work with Qi2 accessories without losing its stylus.Android Headlines also recently shared what appear to be full image renders of the S26 series, and they generally line up with what has already been rumored, leaked and reported so far. If these pictures are accurate, they give us a clearer look at the camera bump and two color variants of the S26 Ultra.Galaxy Buds 4Galaxy Buds 3 Pro in case.EngadgetSamsung released the Galaxy Buds 3 and 3 Pro in 2024, with a major redesign that brought them much more in line with Apple's AirPods. The Galaxy Buds 4 and Buds 4 Pro Samsung is rumored to be announcing soon won't necessarily change that, though they will feature a more compact case and less angular stems, according to leaked images from the Samsung Tips app.Support for head gestures to accept and decline calls, a feature Apple includes on the AirPods Pro 3 and AirPods 4, is also rumored to work on both versions of the new Galaxy Buds. SamMobile reports the Galaxy Buds 4 and 4 Pro may also ship with a new Ultra Wideband chip that will make them easier to find with Google's Find Hub network.Galaxy Z TrifoldYes, the TriFold has a crease, two in fact. But they still don't ruin the experience. Sam Rutherford for EngadgetSamsung announced the Galaxy Z TriFold in late 2025 without firm details of when the new smartphone-that-folds-into-a-tablet would be available in North America. That info came on January 27, when the company announced the TriFold would be available in the US on January 30, for a whopping $2,900. Considering we’ve already seen the device in person at CES 2026 and people are most likely to have had a chance to look at, if not buy the foldable for themselves by the time Unpacked rolls around, we don’t expect Samsung to spend too much time dwelling on it, if at all.Galaxy S26 EdgeAt just 5.8mm thick, the Samsung Galaxy S25 Edge is one of the thinnest smartphones ever made. Sam Rutherford for EngadgetWhen the Galaxy S25 Edge was announced in 2025, it seemed possible that Samsung could replace its \"Plus\" smartphone with a unique form factor, just like Apple has opted to do with the iPhone Air. There have been conflicting reports on the matter, but it seems like Samsung will not be doing that with the Galaxy S26 Edge.Instead, the smartphone will reportedly remain another option, much like foldables are for customers not swayed by Samsung's traditional smartphones. The Galaxy S26 Edge is rumored to feature a slightly different design than last year's model, according to Android Headlines, with a large rectangular camera plateau that's reminiscent of Google's Pixel phones, and the raised oval Apple used on the iPhone Air. Beyond that, the phone is also expected to be ever so slightly thinner at 5.5mm than the 5.8mm Galaxy S25 Edge.Bixby and other AI featuresSamsung already acts as a first place Google can show off new AI features for Android, but the company is reportedly exploring other AI partnerships, too. In June 2025, Bloomberg reported that Samsung was nearing a deal with Perplexity to integrate its AI-powered search engine across OneUI and its homegrown mobile browser. Perplexity already has a deal with Motorola on its Razr phones, so the only thing that would make a deal with Samsung unusual is the close relationship the company already has with Google.The company also accidentally announced a new version of its Bixby AI assistant, which will likely also be integrated with Perplexity and could serve as an alternative to Google Gemini. Both a new Bixby and a deeper integration with Perplexity seem like natural new software features to show off at Galaxy Unpacked.Update, January 27 2026, 11:55AM ET: This story has been updated to reflect the latest news around the Galaxy Z TriFold’s price and availability in the US.Update, January 30 2026, 12:45PM ET: This story has been updated to include the latest leaks on the possible dates for Unpacked 2026.Update, February 02 2026, 11:30AM ET: This story has been updated to include the latest leaks with full image renders of the S26 trio of devices.This article originally appeared on Engadget at https://www.engadget.com/mobile/smartphones/samsung-galaxy-unpacked-2026-the-galaxy-s26-lineup-and-everything-else-we-expect-130000999.html?src=rss",
          "feed_position": 14,
          "image_url": "https://media-mbst-pub-ue1.s3.amazonaws.com/creatr-uploaded-images/2025-01/59db82d0-d8d0-11ef-babd-deb856accfc5"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/audio/headphones/best-noise-canceling-earbuds-150026857.html",
          "published_at": "Mon, 02 Feb 2026 10:00:35 +0000",
          "title": "The best noise-canceling earbuds for 2026",
          "standfirst": "Noise-canceling earbuds have become an everyday essential for a lot of people, whether you’re trying to survive a noisy commute, concentrate in a shared workspace or just carve out a little quiet time. Advances in active noise cancellation and audio processing mean today’s best earbuds do a much better job of cutting through background noise, without forcing you to move up to bulky over-ear headphones.The latest models also balance sound quality with convenience, offering stable Bluetooth connections, comfortable fits and battery life that can last through a full day with help from their charging cases. From premium options with the strongest ANC to more affordable picks that still get the basics right, there’s no shortage of solid choices depending on what you value most. Best noise-cancelling earbuds for 2026 How to choose the best noise-canceling earbuds for you Design Most true wireless earbuds these days have a “traditional” design that’s a round bud that fits in your ear canals. However, there are some variations on the formula in terms of shape, size and additional fitting elements. Some companies include fins or fit wings to help hold their in-ear earbuds in place while others opt for an over-the-ear hook on more sporty models. You’ll want to pay attention to these things to make sure they align with how you plan to use them. Also consider overall size and weight since those two factors can impact the fit. A less-than-ideal seal due to a weird fit will affect the performance of active noise-canceling earbuds. Type of noise cancellation Next, you’ll want to look at the type of ANC a set of earbuds offer. You’ll see terms like “hybrid active noise cancellation” or “hybrid adaptive active noise cancellation,” and there are key differences between the two. A hybrid ANC setup uses microphones on the inside and the outside of the device to detect ambient noise. By analyzing input from both mics, a hybrid system can combat more sounds than “regular” ANC, but it’s at a constant level that doesn’t change. Adaptive ANC takes the hybrid configuration a step further by continuously adjusting the noise cancellation for changes in your environment and any leakage around the padding of the ear cups or ear tips. Adaptive ANC is also better at combating wind noise, which can really kill your vibe while using earbuds outdoors. For this top pick list of the best noise-canceling earbuds, I’m only considering products with hybrid ANC or adaptive ANC setups because those are the most effective at blocking noise in noisy environments. Customization You’ll also want to check to see if the ANC system on a prospective set of earbuds offers presets or adjustable levels of noise reduction. These can help you dial in the amount of ANC you need for various environments, but it can also help save battery life. Master & Dynamic, for example, has ANC presets that either provide maximum noise-blocking or prioritize energy efficiency. Other companies may include a slider in their companion apps that let you adjust the ANC level. How we test noise-canceling earbuds The primary way we test earbuds is to wear them as much as possible. I prefer to do this over a one-to-two-week period, but sometimes deadlines don’t allow it. During this time, I listen to a mix of music and podcasts, while also using the earbuds to take both voice and video calls. Since battery life for ANC earbuds is typically 6-10 hours, I drain the battery with looping music and the volume set at a comfortable level (usually around 75 percent). When necessary, I’ll power the headphones off during a review without putting them back in the case. This simulates real-world use and keeps me from having to wear them for an entire day. To test ANC performance specifically, I use the earbuds in a variety of environments, from noisy coffee shops to quiet home offices. When my schedule allows, I also use them during air travel, since plane noise is a massive distraction to both work and relaxation. Even if I’m not slated to hop on a flight, I simulate a constant roar with white noise machines, bathroom fans, vacuums and more. I also make note of how well earbuds block human voices, which are a key stumbling block for a lot of ANC setups. I also do a thorough review of companion apps, testing each feature as I work through the software. Any holdovers from previous models are double-checked for improvements or regression. If the earbuds I’m testing are an updated version of a previous model, I’ll spend time getting reacquainted with the older set, and revisit the closest competition as well.This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/best-noise-canceling-earbuds-150026857.html?src=rss",
          "content": "Noise-canceling earbuds have become an everyday essential for a lot of people, whether you’re trying to survive a noisy commute, concentrate in a shared workspace or just carve out a little quiet time. Advances in active noise cancellation and audio processing mean today’s best earbuds do a much better job of cutting through background noise, without forcing you to move up to bulky over-ear headphones.The latest models also balance sound quality with convenience, offering stable Bluetooth connections, comfortable fits and battery life that can last through a full day with help from their charging cases. From premium options with the strongest ANC to more affordable picks that still get the basics right, there’s no shortage of solid choices depending on what you value most. Best noise-cancelling earbuds for 2026 How to choose the best noise-canceling earbuds for you Design Most true wireless earbuds these days have a “traditional” design that’s a round bud that fits in your ear canals. However, there are some variations on the formula in terms of shape, size and additional fitting elements. Some companies include fins or fit wings to help hold their in-ear earbuds in place while others opt for an over-the-ear hook on more sporty models. You’ll want to pay attention to these things to make sure they align with how you plan to use them. Also consider overall size and weight since those two factors can impact the fit. A less-than-ideal seal due to a weird fit will affect the performance of active noise-canceling earbuds. Type of noise cancellation Next, you’ll want to look at the type of ANC a set of earbuds offer. You’ll see terms like “hybrid active noise cancellation” or “hybrid adaptive active noise cancellation,” and there are key differences between the two. A hybrid ANC setup uses microphones on the inside and the outside of the device to detect ambient noise. By analyzing input from both mics, a hybrid system can combat more sounds than “regular” ANC, but it’s at a constant level that doesn’t change. Adaptive ANC takes the hybrid configuration a step further by continuously adjusting the noise cancellation for changes in your environment and any leakage around the padding of the ear cups or ear tips. Adaptive ANC is also better at combating wind noise, which can really kill your vibe while using earbuds outdoors. For this top pick list of the best noise-canceling earbuds, I’m only considering products with hybrid ANC or adaptive ANC setups because those are the most effective at blocking noise in noisy environments. Customization You’ll also want to check to see if the ANC system on a prospective set of earbuds offers presets or adjustable levels of noise reduction. These can help you dial in the amount of ANC you need for various environments, but it can also help save battery life. Master & Dynamic, for example, has ANC presets that either provide maximum noise-blocking or prioritize energy efficiency. Other companies may include a slider in their companion apps that let you adjust the ANC level. How we test noise-canceling earbuds The primary way we test earbuds is to wear them as much as possible. I prefer to do this over a one-to-two-week period, but sometimes deadlines don’t allow it. During this time, I listen to a mix of music and podcasts, while also using the earbuds to take both voice and video calls. Since battery life for ANC earbuds is typically 6-10 hours, I drain the battery with looping music and the volume set at a comfortable level (usually around 75 percent). When necessary, I’ll power the headphones off during a review without putting them back in the case. This simulates real-world use and keeps me from having to wear them for an entire day. To test ANC performance specifically, I use the earbuds in a variety of environments, from noisy coffee shops to quiet home offices. When my schedule allows, I also use them during air travel, since plane noise is a massive distraction to both work and relaxation. Even if I’m not slated to hop on a flight, I simulate a constant roar with white noise machines, bathroom fans, vacuums and more. I also make note of how well earbuds block human voices, which are a key stumbling block for a lot of ANC setups. I also do a thorough review of companion apps, testing each feature as I work through the software. Any holdovers from previous models are double-checked for improvements or regression. If the earbuds I’m testing are an updated version of a previous model, I’ll spend time getting reacquainted with the older set, and revisit the closest competition as well.This article originally appeared on Engadget at https://www.engadget.com/audio/headphones/best-noise-canceling-earbuds-150026857.html?src=rss",
          "feed_position": 25
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/home/home-theater/best-projectors-123004354.html",
          "published_at": "Mon, 02 Feb 2026 08:00:35 +0000",
          "title": "The best projector for a home theater in 2026",
          "standfirst": "To see a film the way the creators intended, you really need a projector. A good one can show a bright, sharp image up to 250 inches in size for an immersive experience that no TV can match — and usually at a much lower price. Plus, they’re great for immersive gaming with consoles and PCs.Thanks to companies like Anker and Valerion, projectors are starting to be seen as a must-have item for cinephiles and outdoor party screenings alike. That means there are a wide variety of choices, ranging from classic ceiling-mounted models to battery-powered projectors you can take on a camping trick. You can also choose from dozens of ultra short throw (UST) models for a more TV-like installation.But compared to TVs, projectors remain a bit more confusing for a majority of buyers. This guide will fill you in on important details to consider like brightness, type (classic, portable and ultra short throw) and other factors to help you choose the best model for your setup. Best projectors for 2026 Some projectors are for serious cinephiles, projecting sharp 4K video with HDR brightness and hyper realistic colors to a large screen. Others are bright enough to replace your TV for sports or gaming, and some low-cost portable models can be set up for camping or outdoor fun. That’s why we’ve divided this guide into several categories to help you find the right one. What to consider when buying a projector For a deep dive on projector technology check my previous explainer, but there are few key things to keep in mind. What will the projector mainly be used for? What type of room will it be used in? And how big of an image do you want? You’ll also see a variety of specifications that may be confusing, so here are a few to consider and what they mean. Brightness and contrast Brightness is measured in ANSI lumens; the brighter the projector, typically the more expensive it will be. 1,500-2,500 lumens is good for darkened rooms, 3,000-4,000 lumens allows you to see with some ambient light and 4,000+ lumens is bright enough to use in direct sunlight. High contrast is important for detail, because projectors are more sensitive to things like ambient light and reflections. Laser projectors offer the most brightness and they are entering the mainstream with models costing well under $2,000. Below that, you’re looking at projectors with bulbs. Aside from brightness, laser projectors have an advantage in that the light source lasts 10,000 hours or more, compared to 2,000 hours maximum for bulb projectors. DLP vs LCD Digital light processing units (DLPs) used by Optoma, BenQ, LG and others allow bright 4K images. The negative is that they can produce a “rainbow” effect, or red/blue/green artifacts that affect some viewers more than others. LCDs are used mainly by Epson, but also Sony and Sanyo. Those are often brighter, more color accurate and don’t produce rainbow effects, but are also more expensive and susceptible to image degradation over time. Resolution If you want a true 4K projector, beware: only expensive models have native 4K resolution (many movie theaters still use 2K projectors for various reasons). However, most DLP projectors and some LCD models can use pixel-shifting to attain 4K resolution. HDR and color accuracy Projectors can’t produce anywhere close to the amount of light required to qualify as true HDR. Rather, they use a technique called tone mapping to fit the entire HDR gamut into a lower brightness range. That said, many projectors can display millions of colors, with some models surpassing the color accuracy of TVs and monitors. UST vs. classic Classic projectors and screens can be mounted on the ceiling so they’re great if you have no floor space. They can also project a larger video for a truly cinematic experience. UST projectors mount on the floor right next to the screen so they can take the place of a TV. They don’t beam as big an image but are generally brighter, sharper and more expensive. For best results, they require special screens. Elite Starling Mounting and fan noise Ceiling mounting requires some work and don’t forget to budget for a bracket and any necessary long cables, including extra power for a Google Chromecast or other streaming device. UST projectors require less labor, but getting the image perfectly square can still be surprisingly time-consuming. As for fan noise, some projectors (usually cheaper DLP models) generate more than others. Optics For more flexibility with location and image size, ceiling mounted projectors need a good zoom range. Lens shift, meanwhile, is used if the projector is mounted higher or lower relative to the screen than recommended by the manufacturer. Otherwise, you might have to use a \"keystone correction\" to digitally stretch part of the image, resulting in distortion or artifacts. Also, keystore correction may not work in gaming modes for some models. Gaming and streaming If you’re interested in a projector for gaming, look up the refresh rate and input lag figures. Some projectors offer good numbers in that regard (240Hz and <20 ms, respectively), but others designed for home entertainment have very poor input lag and refresh rates at just 60 Hz. If it’s streaming you want, be sure to pick a model either with built-in Google TV or a bundled streaming dongle. Screens Should you project onto a wall, roll-down screen, fixed screen or ambient light rejecting (ALR) screen? The choice depends largely on the room and what kind of projector you have. Roll down screens take up no space as they’re ceiling mounted, fixed screens can be moved easily and ALR models are perfect in rooms with a lot of ambient light. Best projector FAQs Are 4K projectors better? Yes, because higher resolution is more noticeable on larger screens, so 4K is particularly useful with projectors since they beam images up to 200 inches in size. That being said, brightness and contrast are more important. Is a projector better than a TV? Projectors can provide a more immersive experience thanks to the large screen, but they’re not necessarily “better.” Since you usually have to dim the lights with a projector, TVs are superior for everyday use. Is 2000 lumens bright enough for a projector? Yes, 2000 lumens is easily bright enough, even with some ambient light in the room. However, the image will still be hard to see with the windows open on a bright day. Should I get a 4K or 1080p projector? That depends on your budget and needs. If your budget is below $1,000, look for a 1080p projector with the best brightness and contrast. Between $1,000-$2,000, you’ll need to weigh whether brightness or 4K resolution is most important. Above that, choose the brightest 4K projector you can afford. What are the best projectors in daylight? The best projectors in daylight are ultra short throw (UST) models, as they have the brightest and sharpest image. However, they generally cost more than $2,000. Do you need a screen for a better projector experience? Technically, you don’t need a screen to use a projector — any light-colored, smooth wall can work in a pinch. But if you want to get the most out of your projector, a screen can make a difference. Projector screens are designed to reflect light evenly and enhance contrast, so colors look more vibrant and the picture appears sharper. With a screen, you’ll notice darker blacks and brighter colors, which can give a real boost to your movie nights or gaming sessions. So while you can absolutely enjoy a projector without one, a screen can make the experience feel a bit more like your own personal theater. Should I buy a portable or home projector? It depends on how and where you plan to use it. If you want a projector you can easily move around, bring to friends’ houses or set up indoors or outdoors easily, a portable projector is a great choice. They’re usually smaller, lightweight and often have built-in speakers and batteries, making them convenient for on-the-go use. On the other hand, if you’re looking for a more permanent setup for a home theater or living room, a home projector might be the way to go. Home projectors tend to be more powerful, with higher resolution and brightness, which gives you that crisp, cinema-quality experience. They’re ideal if you have a dedicated space and don’t mind leaving it set up in one spot.This article originally appeared on Engadget at https://www.engadget.com/home/home-theater/best-projectors-123004354.html?src=rss",
          "content": "To see a film the way the creators intended, you really need a projector. A good one can show a bright, sharp image up to 250 inches in size for an immersive experience that no TV can match — and usually at a much lower price. Plus, they’re great for immersive gaming with consoles and PCs.Thanks to companies like Anker and Valerion, projectors are starting to be seen as a must-have item for cinephiles and outdoor party screenings alike. That means there are a wide variety of choices, ranging from classic ceiling-mounted models to battery-powered projectors you can take on a camping trick. You can also choose from dozens of ultra short throw (UST) models for a more TV-like installation.But compared to TVs, projectors remain a bit more confusing for a majority of buyers. This guide will fill you in on important details to consider like brightness, type (classic, portable and ultra short throw) and other factors to help you choose the best model for your setup. Best projectors for 2026 Some projectors are for serious cinephiles, projecting sharp 4K video with HDR brightness and hyper realistic colors to a large screen. Others are bright enough to replace your TV for sports or gaming, and some low-cost portable models can be set up for camping or outdoor fun. That’s why we’ve divided this guide into several categories to help you find the right one. What to consider when buying a projector For a deep dive on projector technology check my previous explainer, but there are few key things to keep in mind. What will the projector mainly be used for? What type of room will it be used in? And how big of an image do you want? You’ll also see a variety of specifications that may be confusing, so here are a few to consider and what they mean. Brightness and contrast Brightness is measured in ANSI lumens; the brighter the projector, typically the more expensive it will be. 1,500-2,500 lumens is good for darkened rooms, 3,000-4,000 lumens allows you to see with some ambient light and 4,000+ lumens is bright enough to use in direct sunlight. High contrast is important for detail, because projectors are more sensitive to things like ambient light and reflections. Laser projectors offer the most brightness and they are entering the mainstream with models costing well under $2,000. Below that, you’re looking at projectors with bulbs. Aside from brightness, laser projectors have an advantage in that the light source lasts 10,000 hours or more, compared to 2,000 hours maximum for bulb projectors. DLP vs LCD Digital light processing units (DLPs) used by Optoma, BenQ, LG and others allow bright 4K images. The negative is that they can produce a “rainbow” effect, or red/blue/green artifacts that affect some viewers more than others. LCDs are used mainly by Epson, but also Sony and Sanyo. Those are often brighter, more color accurate and don’t produce rainbow effects, but are also more expensive and susceptible to image degradation over time. Resolution If you want a true 4K projector, beware: only expensive models have native 4K resolution (many movie theaters still use 2K projectors for various reasons). However, most DLP projectors and some LCD models can use pixel-shifting to attain 4K resolution. HDR and color accuracy Projectors can’t produce anywhere close to the amount of light required to qualify as true HDR. Rather, they use a technique called tone mapping to fit the entire HDR gamut into a lower brightness range. That said, many projectors can display millions of colors, with some models surpassing the color accuracy of TVs and monitors. UST vs. classic Classic projectors and screens can be mounted on the ceiling so they’re great if you have no floor space. They can also project a larger video for a truly cinematic experience. UST projectors mount on the floor right next to the screen so they can take the place of a TV. They don’t beam as big an image but are generally brighter, sharper and more expensive. For best results, they require special screens. Elite Starling Mounting and fan noise Ceiling mounting requires some work and don’t forget to budget for a bracket and any necessary long cables, including extra power for a Google Chromecast or other streaming device. UST projectors require less labor, but getting the image perfectly square can still be surprisingly time-consuming. As for fan noise, some projectors (usually cheaper DLP models) generate more than others. Optics For more flexibility with location and image size, ceiling mounted projectors need a good zoom range. Lens shift, meanwhile, is used if the projector is mounted higher or lower relative to the screen than recommended by the manufacturer. Otherwise, you might have to use a \"keystone correction\" to digitally stretch part of the image, resulting in distortion or artifacts. Also, keystore correction may not work in gaming modes for some models. Gaming and streaming If you’re interested in a projector for gaming, look up the refresh rate and input lag figures. Some projectors offer good numbers in that regard (240Hz and <20 ms, respectively), but others designed for home entertainment have very poor input lag and refresh rates at just 60 Hz. If it’s streaming you want, be sure to pick a model either with built-in Google TV or a bundled streaming dongle. Screens Should you project onto a wall, roll-down screen, fixed screen or ambient light rejecting (ALR) screen? The choice depends largely on the room and what kind of projector you have. Roll down screens take up no space as they’re ceiling mounted, fixed screens can be moved easily and ALR models are perfect in rooms with a lot of ambient light. Best projector FAQs Are 4K projectors better? Yes, because higher resolution is more noticeable on larger screens, so 4K is particularly useful with projectors since they beam images up to 200 inches in size. That being said, brightness and contrast are more important. Is a projector better than a TV? Projectors can provide a more immersive experience thanks to the large screen, but they’re not necessarily “better.” Since you usually have to dim the lights with a projector, TVs are superior for everyday use. Is 2000 lumens bright enough for a projector? Yes, 2000 lumens is easily bright enough, even with some ambient light in the room. However, the image will still be hard to see with the windows open on a bright day. Should I get a 4K or 1080p projector? That depends on your budget and needs. If your budget is below $1,000, look for a 1080p projector with the best brightness and contrast. Between $1,000-$2,000, you’ll need to weigh whether brightness or 4K resolution is most important. Above that, choose the brightest 4K projector you can afford. What are the best projectors in daylight? The best projectors in daylight are ultra short throw (UST) models, as they have the brightest and sharpest image. However, they generally cost more than $2,000. Do you need a screen for a better projector experience? Technically, you don’t need a screen to use a projector — any light-colored, smooth wall can work in a pinch. But if you want to get the most out of your projector, a screen can make a difference. Projector screens are designed to reflect light evenly and enhance contrast, so colors look more vibrant and the picture appears sharper. With a screen, you’ll notice darker blacks and brighter colors, which can give a real boost to your movie nights or gaming sessions. So while you can absolutely enjoy a projector without one, a screen can make the experience feel a bit more like your own personal theater. Should I buy a portable or home projector? It depends on how and where you plan to use it. If you want a projector you can easily move around, bring to friends’ houses or set up indoors or outdoors easily, a portable projector is a great choice. They’re usually smaller, lightweight and often have built-in speakers and batteries, making them convenient for on-the-go use. On the other hand, if you’re looking for a more permanent setup for a home theater or living room, a home projector might be the way to go. Home projectors tend to be more powerful, with higher resolution and brightness, which gives you that crisp, cinema-quality experience. They’re ideal if you have a dedicated space and don’t mind leaving it set up in one spot.This article originally appeared on Engadget at https://www.engadget.com/home/home-theater/best-projectors-123004354.html?src=rss",
          "feed_position": 26,
          "image_url": "https://s.yimg.com/os/creatr-uploaded-images/2021-04/34181c50-92ea-11eb-99db-e05de4751f8f"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/orchestration/enterprises-are-measuring-the-wrong-part-of-rag",
          "published_at": "Sun, 01 Feb 2026 19:00:00 GMT",
          "title": "Enterprises are measuring the wrong part of RAG",
          "standfirst": "Enterprises have moved quickly to adopt RAG to ground LLMs in proprietary data. In practice, however, many organizations are discovering that retrieval is no longer a feature bolted onto model inference — it has become a foundational system dependency.Once AI systems are deployed to support decision-making, automate workflows or operate semi-autonomously, failures in retrieval propagate directly into business risk. Stale context, ungoverned access paths and poorly evaluated retrieval pipelines do not merely degrade answer quality; they undermine trust, compliance and operational reliability.This article reframes retrieval as infrastructure rather than application logic. It introduces a system-level model for designing retrieval platforms that support freshness, governance and evaluation as first-class architectural concerns. The goal is to help enterprise architects, AI platform leaders, and data infrastructure teams reason about retrieval systems with the same rigor historically applied to compute, networking and storage.Retrieval as infrastructure — A reference architecture illustrating how freshness, governance, and evaluation function as first-class system planes rather than embedded application logic. Conceptual diagram created by the author.Why RAG breaks down at enterprise scaleEarly RAG implementations were designed for narrow use cases: document search, internal Q&A and copilots operating within tightly scoped domains. These designs assumed relatively static corpora, predictable access patterns and human-in-the-loop oversight. Those assumptions no longer hold.Modern enterprise AI systems increasingly rely on:Continuously changing data sourcesMulti-step reasoning across domainsAgent-driven workflows that retrieve context autonomouslyRegulatory and audit requirements tied to data usageIn these environments, retrieval failures compound quickly. A single outdated index or mis-scoped access policy can cascade across multiple downstream decisions. Treating retrieval as a lightweight enhancement to inference logic obscures its growing role as a systemic risk surface.Retrieval freshness is a systems problem, not a tuning problemFreshness failures rarely originate in embedding models. They originate in the surrounding system.Most enterprise retrieval stacks struggle to answer basic operational questions:How quickly do source changes propagate into indexes?Which consumers are still querying outdated representations?What guarantees exist when data changes mid-session?In mature platforms, freshness is enforced through explicit architectural mechanisms rather than periodic rebuilds. These include event-driven reindexing, versioned embeddings and retrieval-time awareness of data staleness.Across enterprise deployments, the recurring pattern is that freshness failures rarely come from embedding quality; they emerge when source systems change continuously while indexing and embedding pipelines update asynchronously, leaving retrieval consumers unknowingly operating on stale context. Because the system still produces fluent, plausible answers, these gaps often go unnoticed until autonomous workflows depend on retrieval continuously and reliability issues surface at scale.Governance must extend into the retrieval layerMost enterprise governance models were designed for data access and model usage independently. Retrieval systems sit uncomfortably between the two.Ungoverned retrieval introduces several risks:Models accessing data outside their intended scopeSensitive fields leaking through embeddingsAgents retrieving information they are not authorized to act uponInability to reconstruct which data influenced a decisionIn retrieval-centric architectures, governance must operate at semantic boundaries rather than only at storage or API layers. This requires policy enforcement tied to queries, embeddings and downstream consumers — not just datasets.Effective retrieval governance typically includes:Domain-scoped indexes with explicit ownershipPolicy-aware retrieval APIsAudit trails linking queries to retrieved artifactsControls on cross-domain retrieval by autonomous agentsWithout these controls, retrieval systems quietly bypass safeguards that organizations assume are in place.Evaluation cannot stop at answer qualityTraditional RAG evaluation focuses on whether responses appear correct. This is insufficient for enterprise systems.Retrieval failures often manifest upstream of the final answer:Irrelevant but plausible documents retrievedMissing critical contextOverrepresentation of outdated sourcesSilent exclusion of authoritative dataAs AI systems become more autonomous, teams must evaluate retrieval as an independent subsystem. This includes measuring recall under policy constraints, monitoring freshness drift and detecting bias introduced by retrieval pathways.In production environments, evaluation tends to break once retrieval becomes autonomous rather than human-triggered. Teams continue to score answer quality on sampled prompts, but lack visibility into what was retrieved, what was missed or whether stale or unauthorized context influenced decisions. As retrieval pathways evolve dynamically in production, silent drift accumulates upstream, and by the time issues surface, failures are often misattributed to model behavior rather than the retrieval system itself.Evaluation that ignores retrieval behavior leaves organizations blind to the true causes of system failure.Control planes governing retrieval behaviorControl-plane model for enterprise retrieval systems, separating execution from governance to enable policy enforcement, auditability, and continuous evaluation. Conceptual diagram created by the author.A reference architecture: Retrieval as infrastructureA retrieval system designed for enterprise AI typically consists of five interdependent layers:Source ingestion layer: Handles structured, unstructured and streaming data with provenance tracking.Embedding and indexing layer: Supports versioning, domain isolation and controlled update propagation.Policy and governance layer: Enforces access controls, semantic boundaries, and auditability at retrieval time.Evaluation and monitoring layer: Measures freshness, recall and policy adherence independently of model output.Consumption layer: Serves humans, applications and autonomous agents with contextual constraints.This architecture treats retrieval as shared infrastructure rather than application-specific logic, enabling consistent behavior across use cases.Why retrieval determines AI reliabilityAs enterprises move toward agentic systems and long-running AI workflows, retrieval becomes the substrate on which reasoning depends. Models can only be as reliable as the context they are given.Organizations that continue to treat retrieval as a secondary concern will struggle with:Unexplained model behaviorCompliance gapsInconsistent system performanceErosion of stakeholder trustThose that elevate retrieval to an infrastructure discipline — governed, evaluated and engineered for change — gain a foundation that scales with both autonomy and risk.ConclusionRetrieval is no longer a supporting feature of enterprise AI systems. It is infrastructure.Freshness, governance and evaluation are not optional optimizations; they are prerequisites for deploying AI systems that operate reliably in real-world environments. As organizations push beyond experimental RAG deployments toward autonomous and decision-support systems, the architectural treatment of retrieval will increasingly determine success or failure.Enterprises that recognize this shift early will be better positioned to scale AI responsibly, withstand regulatory scrutiny and maintain trust as systems grow more capable — and more consequential.Varun Raj is a cloud and AI engineering executive specializing in enterprise-scale cloud modernization, AI-native architectures, and large-scale distributed systems.",
          "content": "Enterprises have moved quickly to adopt RAG to ground LLMs in proprietary data. In practice, however, many organizations are discovering that retrieval is no longer a feature bolted onto model inference — it has become a foundational system dependency.Once AI systems are deployed to support decision-making, automate workflows or operate semi-autonomously, failures in retrieval propagate directly into business risk. Stale context, ungoverned access paths and poorly evaluated retrieval pipelines do not merely degrade answer quality; they undermine trust, compliance and operational reliability.This article reframes retrieval as infrastructure rather than application logic. It introduces a system-level model for designing retrieval platforms that support freshness, governance and evaluation as first-class architectural concerns. The goal is to help enterprise architects, AI platform leaders, and data infrastructure teams reason about retrieval systems with the same rigor historically applied to compute, networking and storage.Retrieval as infrastructure — A reference architecture illustrating how freshness, governance, and evaluation function as first-class system planes rather than embedded application logic. Conceptual diagram created by the author.Why RAG breaks down at enterprise scaleEarly RAG implementations were designed for narrow use cases: document search, internal Q&A and copilots operating within tightly scoped domains. These designs assumed relatively static corpora, predictable access patterns and human-in-the-loop oversight. Those assumptions no longer hold.Modern enterprise AI systems increasingly rely on:Continuously changing data sourcesMulti-step reasoning across domainsAgent-driven workflows that retrieve context autonomouslyRegulatory and audit requirements tied to data usageIn these environments, retrieval failures compound quickly. A single outdated index or mis-scoped access policy can cascade across multiple downstream decisions. Treating retrieval as a lightweight enhancement to inference logic obscures its growing role as a systemic risk surface.Retrieval freshness is a systems problem, not a tuning problemFreshness failures rarely originate in embedding models. They originate in the surrounding system.Most enterprise retrieval stacks struggle to answer basic operational questions:How quickly do source changes propagate into indexes?Which consumers are still querying outdated representations?What guarantees exist when data changes mid-session?In mature platforms, freshness is enforced through explicit architectural mechanisms rather than periodic rebuilds. These include event-driven reindexing, versioned embeddings and retrieval-time awareness of data staleness.Across enterprise deployments, the recurring pattern is that freshness failures rarely come from embedding quality; they emerge when source systems change continuously while indexing and embedding pipelines update asynchronously, leaving retrieval consumers unknowingly operating on stale context. Because the system still produces fluent, plausible answers, these gaps often go unnoticed until autonomous workflows depend on retrieval continuously and reliability issues surface at scale.Governance must extend into the retrieval layerMost enterprise governance models were designed for data access and model usage independently. Retrieval systems sit uncomfortably between the two.Ungoverned retrieval introduces several risks:Models accessing data outside their intended scopeSensitive fields leaking through embeddingsAgents retrieving information they are not authorized to act uponInability to reconstruct which data influenced a decisionIn retrieval-centric architectures, governance must operate at semantic boundaries rather than only at storage or API layers. This requires policy enforcement tied to queries, embeddings and downstream consumers — not just datasets.Effective retrieval governance typically includes:Domain-scoped indexes with explicit ownershipPolicy-aware retrieval APIsAudit trails linking queries to retrieved artifactsControls on cross-domain retrieval by autonomous agentsWithout these controls, retrieval systems quietly bypass safeguards that organizations assume are in place.Evaluation cannot stop at answer qualityTraditional RAG evaluation focuses on whether responses appear correct. This is insufficient for enterprise systems.Retrieval failures often manifest upstream of the final answer:Irrelevant but plausible documents retrievedMissing critical contextOverrepresentation of outdated sourcesSilent exclusion of authoritative dataAs AI systems become more autonomous, teams must evaluate retrieval as an independent subsystem. This includes measuring recall under policy constraints, monitoring freshness drift and detecting bias introduced by retrieval pathways.In production environments, evaluation tends to break once retrieval becomes autonomous rather than human-triggered. Teams continue to score answer quality on sampled prompts, but lack visibility into what was retrieved, what was missed or whether stale or unauthorized context influenced decisions. As retrieval pathways evolve dynamically in production, silent drift accumulates upstream, and by the time issues surface, failures are often misattributed to model behavior rather than the retrieval system itself.Evaluation that ignores retrieval behavior leaves organizations blind to the true causes of system failure.Control planes governing retrieval behaviorControl-plane model for enterprise retrieval systems, separating execution from governance to enable policy enforcement, auditability, and continuous evaluation. Conceptual diagram created by the author.A reference architecture: Retrieval as infrastructureA retrieval system designed for enterprise AI typically consists of five interdependent layers:Source ingestion layer: Handles structured, unstructured and streaming data with provenance tracking.Embedding and indexing layer: Supports versioning, domain isolation and controlled update propagation.Policy and governance layer: Enforces access controls, semantic boundaries, and auditability at retrieval time.Evaluation and monitoring layer: Measures freshness, recall and policy adherence independently of model output.Consumption layer: Serves humans, applications and autonomous agents with contextual constraints.This architecture treats retrieval as shared infrastructure rather than application-specific logic, enabling consistent behavior across use cases.Why retrieval determines AI reliabilityAs enterprises move toward agentic systems and long-running AI workflows, retrieval becomes the substrate on which reasoning depends. Models can only be as reliable as the context they are given.Organizations that continue to treat retrieval as a secondary concern will struggle with:Unexplained model behaviorCompliance gapsInconsistent system performanceErosion of stakeholder trustThose that elevate retrieval to an infrastructure discipline — governed, evaluated and engineered for change — gain a foundation that scales with both autonomy and risk.ConclusionRetrieval is no longer a supporting feature of enterprise AI systems. It is infrastructure.Freshness, governance and evaluation are not optional optimizations; they are prerequisites for deploying AI systems that operate reliably in real-world environments. As organizations push beyond experimental RAG deployments toward autonomous and decision-support systems, the architectural treatment of retrieval will increasingly determine success or failure.Enterprises that recognize this shift early will be better positioned to scale AI responsibly, withstand regulatory scrutiny and maintain trust as systems grow more capable — and more consequential.Varun Raj is a cloud and AI engineering executive specializing in enterprise-scale cloud modernization, AI-native architectures, and large-scale distributed systems.",
          "feed_position": 2,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/2RWRKDlAYxJdWbClQsJBLv/9cfd607f68f0a4c521f84322b94ca0ce/DDM_2.png?w=300&q=30"
        },
        {
          "source": "Engadget",
          "url": "https://www.engadget.com/computing/accessories/how-to-replace-your-airtag-battery-130000463.html",
          "published_at": "Sun, 01 Feb 2026 13:00:00 +0000",
          "title": "How to replace your AirTag battery",
          "standfirst": "Apple’s AirTag is designed to run quietly in the background, helping you keep track of everyday items like keys, bags and luggage. Unlike many small trackers, an AirTag doesn’t need to be charged. Instead, it uses a standard replaceable coin cell battery that typically lasts around a year, depending on usage.When the battery runs low, your iPhone will alert you. Replacing it is a simple process that takes just a few minutes and doesn’t require any tools. This guide explains how to tell when your AirTag battery needs replacing, which battery to use and how to swap it safely.How to replace the battery in your AirTagReplacing the battery only takes a few steps.Hold the AirTag with the polished stainless steel side facing up. Press down firmly on the metal battery cover and rotate it counterclockwise. Continue turning until the cover stops moving.Lift off the cover and remove the old battery.Insert a new CR2032 battery with the positive (+) side facing up. Once the battery is seated correctly, the AirTag will emit a brief chime, confirming that power has been restored.Place the battery cover back onto the AirTag. Align the three small tabs on the cover with the matching slots on the AirTag body.Press down gently and rotate the cover clockwise until it stops. The cover should sit flush with the AirTag and feel secure once locked into place.No pairing or setup steps are required after replacing the battery. Your AirTag will automatically reconnect to your Apple ID.When to replace your AirTag batteryYour iPhone will automatically notify you when an AirTag battery is running low. The alert appears as a notification and doesn’t interrupt tracking, but it’s a good idea to replace the battery quickly to avoid losing location updates.If you’re unsure whether your AirTag battery needs replacing, open the Find My app, tap the Items tab and select your AirTag. If a message appears under the AirTag name stating “Low Battery”, you’ll know it needs replacing. If no message appears, it’s safe to assume the battery level is fine for now. AirTags don’t have a screen or any other battery indicator, but Apple does show a battery percentage for AirTags in the FindMy app. The low battery warning is the only signal Apple provides before replacement becomes necessary.What to do if your AirTag doesn’t make a soundIf you don’t hear a sound after inserting the new battery, remove it and check that it’s oriented correctly with the positive side facing up. You should also secure the back cover onto the AirTag as well, to see if the chime sounds after that.If the battery is oriented properly and still doesn’t trigger a sound, try a different CR2032 battery. AirTag uses a CR2032 lithium 3V coin battery, a common type available at most electronics stores, supermarkets and pharmacies. Some batteries, particularly those with thick coatings, may not make consistent contact. Apple suggests looking for packaging that states “Compatible with AirTag.” Once a working battery is installed, the AirTag should resume normal operation immediately.How often should you replace your AirTag batteryMost AirTag batteries last about a year under typical use. Frequent use of Precision Finding, sound playback or location updates may reduce battery life. iOS will notify you before the battery is fully depleted, so there’s no need to replace it preemptively unless you’re preparing for long-term travel or storage.Used coin batteries should not be thrown in household trash. Many retailers and recycling centers accept lithium batteries for proper disposal. Check local recycling guidelines for battery drop-off locations. Storing used batteries in a secure container until they can be recycled helps reduce the risk of accidental contact or ingestion.Replacing an AirTag battery is one of the simplest maintenance tasks Apple devices require. With a readily available battery and no tools involved, most users can complete the process in under a minute. As long as you pay attention to low battery notifications and follow basic safety precautions, your AirTag should continue tracking your belongings reliably with minimal effort.This article originally appeared on Engadget at https://www.engadget.com/computing/accessories/how-to-replace-your-airtag-battery-130000463.html?src=rss",
          "content": "Apple’s AirTag is designed to run quietly in the background, helping you keep track of everyday items like keys, bags and luggage. Unlike many small trackers, an AirTag doesn’t need to be charged. Instead, it uses a standard replaceable coin cell battery that typically lasts around a year, depending on usage.When the battery runs low, your iPhone will alert you. Replacing it is a simple process that takes just a few minutes and doesn’t require any tools. This guide explains how to tell when your AirTag battery needs replacing, which battery to use and how to swap it safely.How to replace the battery in your AirTagReplacing the battery only takes a few steps.Hold the AirTag with the polished stainless steel side facing up. Press down firmly on the metal battery cover and rotate it counterclockwise. Continue turning until the cover stops moving.Lift off the cover and remove the old battery.Insert a new CR2032 battery with the positive (+) side facing up. Once the battery is seated correctly, the AirTag will emit a brief chime, confirming that power has been restored.Place the battery cover back onto the AirTag. Align the three small tabs on the cover with the matching slots on the AirTag body.Press down gently and rotate the cover clockwise until it stops. The cover should sit flush with the AirTag and feel secure once locked into place.No pairing or setup steps are required after replacing the battery. Your AirTag will automatically reconnect to your Apple ID.When to replace your AirTag batteryYour iPhone will automatically notify you when an AirTag battery is running low. The alert appears as a notification and doesn’t interrupt tracking, but it’s a good idea to replace the battery quickly to avoid losing location updates.If you’re unsure whether your AirTag battery needs replacing, open the Find My app, tap the Items tab and select your AirTag. If a message appears under the AirTag name stating “Low Battery”, you’ll know it needs replacing. If no message appears, it’s safe to assume the battery level is fine for now. AirTags don’t have a screen or any other battery indicator, but Apple does show a battery percentage for AirTags in the FindMy app. The low battery warning is the only signal Apple provides before replacement becomes necessary.What to do if your AirTag doesn’t make a soundIf you don’t hear a sound after inserting the new battery, remove it and check that it’s oriented correctly with the positive side facing up. You should also secure the back cover onto the AirTag as well, to see if the chime sounds after that.If the battery is oriented properly and still doesn’t trigger a sound, try a different CR2032 battery. AirTag uses a CR2032 lithium 3V coin battery, a common type available at most electronics stores, supermarkets and pharmacies. Some batteries, particularly those with thick coatings, may not make consistent contact. Apple suggests looking for packaging that states “Compatible with AirTag.” Once a working battery is installed, the AirTag should resume normal operation immediately.How often should you replace your AirTag batteryMost AirTag batteries last about a year under typical use. Frequent use of Precision Finding, sound playback or location updates may reduce battery life. iOS will notify you before the battery is fully depleted, so there’s no need to replace it preemptively unless you’re preparing for long-term travel or storage.Used coin batteries should not be thrown in household trash. Many retailers and recycling centers accept lithium batteries for proper disposal. Check local recycling guidelines for battery drop-off locations. Storing used batteries in a secure container until they can be recycled helps reduce the risk of accidental contact or ingestion.Replacing an AirTag battery is one of the simplest maintenance tasks Apple devices require. With a readily available battery and no tools involved, most users can complete the process in under a minute. As long as you pay attention to low battery notifications and follow basic safety precautions, your AirTag should continue tracking your belongings reliably with minimal effort.This article originally appeared on Engadget at https://www.engadget.com/computing/accessories/how-to-replace-your-airtag-battery-130000463.html?src=rss",
          "feed_position": 31
        }
      ],
      "featured_image": "https://images.ctfassets.net/jdtwqhzvc2n1/hgdgcVYh6eTScx5sg3xmL/51a2bb25a7e65cb132358db07dcc2315/Connecting_data.png?w=300&q=30",
      "popularity_score": 2008.9371963888889
    },
    {
      "id": "cluster_36",
      "coverage": 1,
      "updated_at": "Mon, 02 Feb 2026 22:31:46 +0000",
      "title": "Streaming service Crunchyroll raises prices weeks after killing its free tier",
      "neutral_headline": "Streaming service Crunchyroll raises prices weeks after killing its free tier",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/02/streaming-service-crunchyroll-raises-prices-weeks-after-killing-its-free-tier/",
          "published_at": "Mon, 02 Feb 2026 22:31:46 +0000",
          "title": "Streaming service Crunchyroll raises prices weeks after killing its free tier",
          "standfirst": "Sony has made streaming anime pricier since buying Crunchyroll.",
          "content": "Crunchyroll is one of the most popular streaming platforms for anime viewers. Over the past six years, the service has raised prices for fans, and today, it announced that it's increasing monthly subscription prices by up to 20 percent. Sony bought Crunchyroll from AT&T in 2020. At the time, Crunchyroll had 3 million paid subscribers and an additional 197 million users with free accounts, which let people watch a limited number of titles with commercials. At the time, Crunchyroll monthly subscription tiers cost $8, $10, or $15. After its acquisition by Sony, like many large technology companies that buy a smaller, beloved product, the company made controversial changes. The Tokyo-based company folded rival Funimation into Crunchyroll; Sony shut down Funimation, which it bought in 2017, in April 2024.Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-2258531948-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-2258531948-1024x648.jpg",
      "popularity_score": 348.89997416666665
    },
    {
      "id": "cluster_42",
      "coverage": 1,
      "updated_at": "Mon, 02 Feb 2026 21:55:44 +0000",
      "title": "SpaceX acquires xAI, plans to launch a massive satellite constellation to power it",
      "neutral_headline": "SpaceX acquires xAI, plans to launch a massive satellite constellation to power it",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2026/02/spacex-acquires-xai-plans-1-million-satellite-constellation-to-power-it/",
          "published_at": "Mon, 02 Feb 2026 21:55:44 +0000",
          "title": "SpaceX acquires xAI, plans to launch a massive satellite constellation to power it",
          "standfirst": "\"This marks not just the next chapter, but the next book in SpaceX and xAI's mission.\"",
          "content": "SpaceX has formally acquired another one of Elon Musk's companies, xAi, the space company announced on Monday afternoon. \"SpaceX has acquired xAI to form the most ambitious, vertically-integrated innovation engine on (and off) Earth, with AI, rockets, space-based internet, direct-to-mobile device communications and the world’s foremost real-time information and free speech platform,\" the company said. \"This marks not just the next chapter, but the next book in SpaceX and xAI's mission: scaling to make a sentient sun to understand the Universe and extend the light of consciousness to the stars!\" The merging of what is arguably Musk's most successful company, SpaceX, with the more speculative xAI venture is a risk. Founded in 2023, xAI's main products are the generative AI chatbot, Grok, and the social media site X, formerly known as Twitter. The company aims to compete with OpenAI and other artificial intelligence firms. However, Grok has been controversial, including the sexualization of women and children through AI-generated images, as has Musk's management of Twitter.Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/starship_march2025-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/starship_march2025-1152x648.jpg",
      "popularity_score": 346.2994186111111
    },
    {
      "id": "cluster_34",
      "coverage": 1,
      "updated_at": "Mon, 02 Feb 2026 22:57:56 +0000",
      "title": "Looking back at Catacomb 3D, the game that led to Wolfenstein 3D",
      "neutral_headline": "Looking back at Catacomb 3D, the game that led to Wolfenstein 3D",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2026/02/looking-back-at-catacomb-3d-the-game-that-led-to-wolfenstein-3d/",
          "published_at": "Mon, 02 Feb 2026 22:57:56 +0000",
          "title": "Looking back at Catacomb 3D, the game that led to Wolfenstein 3D",
          "standfirst": "Romero, Carmack, and colleagues discuss an oft-forgotten piece of PC gaming history",
          "content": "If you know anything about the history of id Software, you know how 1992's Wolfenstein 3D helped establish the company's leadership in the burgeoning first-person shooter genre, leading directly to subsequent hits like Doom and Quake. But only the serious id Software nerds remember Catacomb 3D, id's first-person adventure game that directly preceded and inspired work on Wolfenstein 3D. Now, nearly 35 years after Catacomb 3D's initial release, id co-founder John Romero brought the company's founding members together for an informative retrospective video on the creation of the oft-forgotten game. But the pioneering game—which included mouse support, color-coded keys, and shooting walls to find secrets—almost ended up being a gimmicky dead end for the company. id Software's founders look back at an oft-forgotten piece of gaming history Texture maps and \"undo\" animation Catacomb 3D was a follow-up to id's earlier Catacomb, which was a simplified clone of the popular arcade hit Gauntlet. As such, the 3D game still has some of that \"quarter eater\" mentality that was not very fashionable in PC gaming at the time, as John Carmack remembered.Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/c3d-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/c3d-1152x648.jpg",
      "popularity_score": 344.3360852777778
    },
    {
      "id": "cluster_45",
      "coverage": 1,
      "updated_at": "Mon, 02 Feb 2026 21:32:18 +0000",
      "title": "Russian drones use Starlink, but Ukraine has plan to block their Internet access",
      "neutral_headline": "Russian drones use Starlink, but Ukraine has plan to block their Internet access",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/02/russian-drones-use-starlink-but-ukraine-has-plan-to-block-their-internet-access/",
          "published_at": "Mon, 02 Feb 2026 21:32:18 +0000",
          "title": "Russian drones use Starlink, but Ukraine has plan to block their Internet access",
          "standfirst": "Defense chief: \"No Ukrainians have been killed by Russian drones using Starlink.\"",
          "content": "Ukraine and SpaceX say they recently collaborated to stop strikes by Russian drones using Starlink and will soon block all unregistered use of Starlink terminals in an attempt to stop Russia's military from using the satellite broadband network over Ukraine territory. Ukrainians will soon be required to register their Starlink terminals to get on a whitelist. After that, \"only verified and registered terminals will be allowed to operate in the country. All others will be disconnected,\" the Ukraine Ministry of Defense said in a press release today. Ukraine Minister of Defense Mykhailo Fedorov \"emphasized that the only technical solution to counter this threat is to introduce a 'whitelist' and authorize all terminals,\" according to the ministry. \"This is a necessary step by the Government to save Ukrainian lives and protect critical energy infrastructure,\" Fedorov said.Read full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2023/02/getty-ukraine-starlink-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2023/02/getty-ukraine-starlink-1152x648.jpg",
      "popularity_score": 327.90886305555557
    },
    {
      "id": "cluster_50",
      "coverage": 1,
      "updated_at": "Mon, 02 Feb 2026 20:43:31 +0000",
      "title": "Court orders restart of all US offshore wind construction",
      "neutral_headline": "Court orders restart of all US offshore wind construction",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/02/court-orders-restart-of-all-us-offshore-wind-construction/",
          "published_at": "Mon, 02 Feb 2026 20:43:31 +0000",
          "title": "Court orders restart of all US offshore wind construction",
          "standfirst": "Trump admin's \"it's classified\" ploy put on hold in five different cases.",
          "content": "The Trump administration is no fan of renewable energy, but it reserves special ire for wind power. Trump himself has repeatedly made false statements about the cost of wind power, its use around the world, and its environmental impacts. That animosity was paired with an executive order that blocked all permitting for offshore wind and some land-based projects, an order that has since been thrown out by a court that ruled it arbitrary and capricious. Not content to block all future developments, the administration has also gone after the five offshore wind projects currently under construction. After temporarily blocking two of them for reasons that were never fully elaborated, the Department of the Interior settled on a single justification for blocking turbine installation: a classified national security risk. The response to that late-December announcement has been uniform: The companies building each of the projects sued the administration. As of Monday, every single one of them has achieved the same result: a temporary injunction that allows them to continue construction. This, despite the fact that the suits were filed in three different courts and heard by four different judges.Read full article Comments",
          "feed_position": 4,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-1623091024.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-1623091024.jpg",
      "popularity_score": 302.0958075
    },
    {
      "id": "cluster_56",
      "coverage": 1,
      "updated_at": "Mon, 02 Feb 2026 20:30:56 +0000",
      "title": "Notepad++ users take note: It's time to check if you're hacked",
      "neutral_headline": "Notepad++ users take note: It's time to check if you're hacked",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/security/2026/02/notepad-updater-was-compromised-for-6-months-in-supply-chain-attack/",
          "published_at": "Mon, 02 Feb 2026 20:30:56 +0000",
          "title": "Notepad++ users take note: It's time to check if you're hacked",
          "standfirst": "Suspected China-state hackers used update infrastructure to deliver backdoored version.",
          "content": "Infrastructure delivering updates for Notepad++—a widely used text editor for Windows—was compromised for six months by suspected China-state hackers who used their control to deliver backdoored versions of the app to select targets, developers said Monday. “I deeply apologize to all users affected by this hijacking,” the author of a post published to the official notepad-plus-plus.org site wrote Monday. The post said that the attack began last June with an “infrastructure-level compromise that allowed malicious actors to intercept and redirect update traffic destined for notepad-plus-plus.org.” The attackers, whom multiple investigators tied to the Chinese government, then selectively redirected certain targeted users to malicious update servers where they received backdoored updates. Notepad++ didn’t regain control of its infrastructure until December. The attackers used their access to install a never-before-seen payload that has been dubbed Chrysalis. Security firm Rapid 7 descrbed it as a \"custom, feature-rich backdoor.\"Read full article Comments",
          "feed_position": 5,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2023/07/exploit-vulnerability-security.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2023/07/exploit-vulnerability-security.jpg",
      "popularity_score": 301.8860852777778
    },
    {
      "id": "cluster_60",
      "coverage": 1,
      "updated_at": "Mon, 02 Feb 2026 20:00:35 +0000",
      "title": "A century of hair samples proves leaded gas ban worked",
      "neutral_headline": "A century of hair samples proves leaded gas ban worked",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/02/a-century-of-hair-samples-proves-leaded-gas-ban-worked/",
          "published_at": "Mon, 02 Feb 2026 20:00:35 +0000",
          "title": "A century of hair samples proves leaded gas ban worked",
          "standfirst": "“We should not forget the lessons of history. And the lesson is those regulations have been very important.”",
          "content": "The Environmental Protection Agency (EPA) cracked down on lead-based products—including lead paint and leaded gasoline—in the 1970s because of its toxic effects on human health. Scientists at the University of Utah have analyzed human hair samples spanning nearly 100 years and found a 100-fold decrease in lead concentrations, concluding that this regulatory action was highly effective in achieving its stated objectives. They described their findings in a new paper published in the Proceedings of the National Academy of Sciences. We've known about the dangers of lead exposure for a very long time—arguably since the second century BCE—so why conduct this research now? Per the authors, it's because there are growing concerns over the Trump administration's move last year to deregulate many key elements of the EPA's mission. Lead specifically has not yet been deregulated, but there are hints that there could be a loosening of enforcement of the 2024 Lead and Cooper rule requiring water systems to replace old lead pipes. “We should not forget the lessons of history. And the lesson is those regulations have been very important,” said co-author Thure Cerling. “Sometimes they seem onerous and mean that industry can't do exactly what they'd like to do when they want to do it or as quickly as they want to do it. But it's had really, really positive effects.”Read full article Comments",
          "feed_position": 6,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/lead2-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/lead2-1152x648.jpg",
      "popularity_score": 296.38025194444447
    },
    {
      "id": "cluster_61",
      "coverage": 1,
      "updated_at": "Mon, 02 Feb 2026 19:52:32 +0000",
      "title": "Ongoing RAM crisis prompts Raspberry Pi's second price hike in two months",
      "neutral_headline": "Ongoing RAM crisis prompts Raspberry Pi's second price hike in two months",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/02/ongoing-ram-crisis-prompts-raspberry-pis-second-price-hike-in-two-months/",
          "published_at": "Mon, 02 Feb 2026 19:52:32 +0000",
          "title": "Ongoing RAM crisis prompts Raspberry Pi's second price hike in two months",
          "standfirst": "The more RAM the Pi board has, the more its price is increasing.",
          "content": "The ongoing AI-fueled shortages of memory and storage chips has hit RAM kits and SSDs for PC builders the fastest and hardest, meaning it's likely that, for other products that use these chips, we'll be seeing price hikes for the entire rest of the year, if not for longer. The latest price hike news comes courtesy of Raspberry Pi CEO Eben Upton, who announced today that the company would be raising prices on most of its single-board computers for the second time in two months. Prices are going up for all Raspberry Pi 4 and Raspberry Pi 5 boards with 2GB of more of LPDDR4 RAM, including the Compute Module 4 and 5 and the Raspberry Pi 500 computer-inside-a-keyboard. The 2GB boards' pricing will go up by $10, 4GB boards will go up by $15, 8GB boards will go up by $30, and 16GB boards will increase by a whopping $60.Read full article Comments",
          "feed_position": 7,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/IMG_0625-1152x648.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/IMG_0625-1152x648.jpeg",
      "popularity_score": 271.24608527777775
    },
    {
      "id": "cluster_64",
      "coverage": 1,
      "updated_at": "Mon, 02 Feb 2026 19:40:40 +0000",
      "title": "Judge rules Department of Energy's climate working group was illegal",
      "neutral_headline": "Judge rules Department of Energy's climate working group was illegal",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/02/us-forced-to-disclose-its-climate-working-groups-communications/",
          "published_at": "Mon, 02 Feb 2026 19:40:40 +0000",
          "title": "Judge rules Department of Energy's climate working group was illegal",
          "standfirst": "Meant to undercut EPA regulations, the group tried to work in secret.",
          "content": "On Friday, a judge ruled that the Trump administration violated the law in forming its Climate Working Group, which released a report that was intended to undercut the rationale behind greenhouse gas regulations. The judge overseeing the case determined that the government tried to treat the Climate Working Group as a formal advisory body, while not having it obey many of the statutory requirements that govern such bodies. While the Department of Energy (DOE) later disbanded the Climate Working Group in the hopes of avoiding legal scrutiny, documents obtained during the proceedings have now revealed the group's electronic communications. As such, the judge ruled that the trial itself had essentially overcome the government's illegal attempts to hide those communications. Legal and scientific flaws The whole saga derives from a Supreme Court Ruling that compelled the Environmental Protection Agency (EPA) to evaluate the risks posed to the US public by greenhouse gases. During the Obama administration, this resulted in an endangerment finding that created the foundation for the EPA to regulate carbon emissions under the Clean Air Act. The science underlying the endangerment finding was so solid that it was left unchallenged during the first Trump administration.Read full article Comments",
          "feed_position": 8,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-1804069599-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-1804069599-1152x648.jpg",
      "popularity_score": 269.0483075
    },
    {
      "id": "cluster_67",
      "coverage": 1,
      "updated_at": "Mon, 02 Feb 2026 18:58:10 +0000",
      "title": "DOJ released Epstein files with dozens of nudes and victims' names, reports say",
      "neutral_headline": "DOJ released Epstein files with dozens of nudes and victims' names, reports say",
      "bullet_summary": [
        "DOJ reportedly failed to redact nearly 40 nude photos and 43 victims' names",
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2026/02/doj-released-epstein-files-with-dozens-of-nudes-and-victims-names-reports-say/",
          "published_at": "Mon, 02 Feb 2026 18:58:10 +0000",
          "title": "DOJ released Epstein files with dozens of nudes and victims' names, reports say",
          "standfirst": "DOJ reportedly failed to redact nearly 40 nude photos and 43 victims' names.",
          "content": "The Epstein files released by the Department of Justice on Friday included at least a few dozen unredacted nude photos and names of at least 43 victims, according to news reports. The DOJ missed a December 19 deadline set by the Epstein Files Transparency Act by more than a month, but still released the files without fully redacting nude photos and names of Jeffrey Epstein's victims. The New York Times reported yesterday that it found \"nearly 40 unredacted images that appeared to be part of a personal photo collection, showing both nude bodies and the faces of the people portrayed.\" While the people in the photos were young, \"it was unclear whether they were minors,\" the article said. \"Some of the images seemed to show Mr. Epstein’s private island, including a beach. Others were taken in bedrooms and other private spaces.\" The photos \"appeared to show at least seven different people,\" the article said.Read full article Comments",
          "feed_position": 9,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/epstein-files-1152x648-1770057497.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/epstein-files-1152x648-1770057497.jpg",
      "popularity_score": 250.33997416666668
    },
    {
      "id": "cluster_75",
      "coverage": 1,
      "updated_at": "Mon, 02 Feb 2026 18:00:20 +0000",
      "title": "OpenAI picks up pace against Claude Code with new Codex desktop app",
      "neutral_headline": "OpenAI picks up pace against Claude Code with new Codex desktop app",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2026/02/openai-picks-up-pace-against-claude-code-with-new-codex-desktop-app/",
          "published_at": "Mon, 02 Feb 2026 18:00:20 +0000",
          "title": "OpenAI picks up pace against Claude Code with new Codex desktop app",
          "standfirst": "The macOS app does everything the CLI, IDE, and web interfaces do.",
          "content": "Today, OpenAI launched a macOS desktop app for Codex, its large language model-based coding tool that was previously used through a command line interface (CLI) on the web or inside an integrated development environment (IDE) via extensions. By launching a desktop app, OpenAI is catching up to Anthropic's popular Claude Code, which already offered a macOS version. Whether the desktop app makes sense compared to the existing interfaces depends a little bit on who you are and how you intend to use it. The Codex macOS app aims to make it easier to manage multiple coding agents in tandem, sometimes with parallel tasks running over several hours—the company argues that neither the CLI nor the IDE extensions are ideal interfaces for that.Read full article Comments",
          "feed_position": 12,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/Codex-dark-1152x648-1770052639.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/Codex-dark-1152x648-1770052639.jpg",
      "popularity_score": 154.37608527777778
    },
    {
      "id": "cluster_71",
      "coverage": 1,
      "updated_at": "Mon, 02 Feb 2026 18:23:56 +0000",
      "title": "Intel Panther Lake Core Ultra review: Intel's best laptop CPU in a very long time",
      "neutral_headline": "Intel Panther Lake Core Ultra review: Intel's best laptop CPU in a very long time",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2026/02/intel-panther-lake-core-ultra-review-intels-best-laptop-cpu-in-a-very-long-time/",
          "published_at": "Mon, 02 Feb 2026 18:23:56 +0000",
          "title": "Intel Panther Lake Core Ultra review: Intel's best laptop CPU in a very long time",
          "standfirst": "Intel manages big boosts to CPU and GPU speed without blowing up battery life.",
          "content": "Intel's Core Ultra lineup of desktop and laptop processors has been frustrating to review. None of them has been across-the-board awful or totally without redeeming qualities. But Intel has struggled mightily this decade to produce new processors that are straightforward, easy-to-recommend improvements over their predecessors. The company's 12th- and 13th-generation Core chips offered big boosts to CPU performance over the 11th-generation CPUs, for example, but they also usually came with a significant hit to battery life, and they only minimally improved the GPU. The first-generation Core Ultra chips, codenamed Meteor Lake, improved the GPU but couldn't beat the CPU performance of older chips. Last year's Core Ultra 200V series, codenamed Lunar Lake, boasted good battery life and solid graphics performance but weaker CPU performance; better-performing Core Ultra 200H chips (codenamed Arrow Lake) improved CPU performance but came with lesser GPUs and some other missing features. The Core Ultra Series 3 processors, codenamed Panther Lake, finally put an end to the years of uneven zig-zagging advancement we've seen in the last half-decade.Read full article Comments",
          "feed_position": 10,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/IMG_3607-1152x648.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/IMG_3607-1152x648.jpeg",
      "popularity_score": 150.76941861111112
    },
    {
      "id": "cluster_78",
      "coverage": 1,
      "updated_at": "Mon, 02 Feb 2026 17:00:49 +0000",
      "title": "Why Civilization VII is the way it is, and how its devs plan to win critics back",
      "neutral_headline": "Why Civilization VII is the way it is, and how its devs plan to win critics back",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2026/02/interview-civilization-viis-devs-on-the-big-update-meant-to-win-critics-back/",
          "published_at": "Mon, 02 Feb 2026 17:00:49 +0000",
          "title": "Why Civilization VII is the way it is, and how its devs plan to win critics back",
          "standfirst": "Firaxis' Ed Beach and Dennis Shirk talk major overhauls in \"Test of Time\" update.",
          "content": "It has been difficult at times for new mainline releases in the Civilization series of games to win over new players right out of the gate. For Civilization VII—which launched just shy of one year ago—the struggles seemed to go deeper, with some players saying it didn't feel like a Civilization game. Civ VII’s developer, Firaxis Games, announced today it is planning an update this spring called \"Test of Time\" that rethinks a few unpopular changes, in some cases replacing key mechanics from the original release. I spoke with Ed Beach, the Civilization franchise's creative director, as well as Dennis Shirk, its executive producer, about what's changing, the team's interpretation of the player backlash to the choices in the initial release, and Firaxis and 2K's plans for the future of the Civilization model.Read full article Comments",
          "feed_position": 13,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/yields-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/yields-1152x648.jpg",
      "popularity_score": 144.38414083333333
    },
    {
      "id": "cluster_80",
      "coverage": 1,
      "updated_at": "Mon, 02 Feb 2026 16:32:52 +0000",
      "title": "Here's what Cities: Skylines 2’s new developer is updating first",
      "neutral_headline": "Here's what Cities: Skylines 2’s new developer is updating first",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2026/02/heres-what-cities-skylines-2s-new-developer-is-updating-first/",
          "published_at": "Mon, 02 Feb 2026 16:32:52 +0000",
          "title": "Here's what Cities: Skylines 2’s new developer is updating first",
          "standfirst": "Visual upgrades include new UI, realistic snow cover, better lighting.",
          "content": "Back in November, Cities: Skylines 2 publisher Paradox made the surprising announcement that longtime series developer Colossal Order would be ceasing work on the series as part of a \"mutual\" breakup. Now, we're getting our first glimpse into the kinds of patches and upgrades new developer Iceflake (Surviving the Aftermath) is prioritizing for the popular city-builder going forward. In a City Corner Developer Diary posted late last week, Iceflake focuses mainly on the visual improvements it's planning for its first major Cities: Skylines 2 patch. Chief among these is improvements to the game's user interface that Iceflake admits can \"sometimes be a bit confusing when it comes to communicating things.\" The new patch will include a \"streamlined\" onboarding process for new cities, more expressive and context-aware icons, and toolbars with clearer colors and visual style. A new in-game Encyclopedia will also let players search through information about different gameplay topics, though that feature likely won't be ready for Iceflake's first patch.Read full article Comments",
          "feed_position": 14,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/citiessnow-1152x648.png"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/citiessnow-1152x648.png",
      "popularity_score": 143.9183072222222
    },
    {
      "id": "cluster_92",
      "coverage": 1,
      "updated_at": "Mon, 02 Feb 2026 13:41:54 +0000",
      "title": "NASA gears up for one more key test before launching Artemis II to the Moon",
      "neutral_headline": "NASA gears up for one more key test before launching Artemis II to the Moon",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2026/02/nasa-gears-up-for-one-more-key-test-before-launching-artemis-ii-to-the-moon/",
          "published_at": "Mon, 02 Feb 2026 13:41:54 +0000",
          "title": "NASA gears up for one more key test before launching Artemis II to the Moon",
          "standfirst": "A good test would clear the way for launch of Artemis II as soon as next Sunday, February 8.",
          "content": "If all goes according to plan Monday, NASA's launch team at Kennedy Space Center in Florida will load more than 700,000 gallons of super-cold propellants into the rocket built to send the Artemis II mission toward the Moon. The fuel loading is part of a simulated countdown for the Space Launch System rocket, a final opportunity for engineers to rehearse for the day NASA will send four astronauts on a nearly 10-day voyage around the far side of the Moon and back to Earth. The Artemis II mission will send humans farther from Earth than ever before. The astronauts will be the first to launch on NASA's SLS rocket and the first people to travel to the vicinity of the Moon in more than 53 years. Charlie Blackwell-Thompson, NASA's launch director for the Artemis II mission, will supervise the practice countdown from a firing room inside the Launch Control Center a few miles away from the SLS rocket at Kennedy Space Center. In a recent briefing with reporters, she called the Wet Dress Rehearsal—\"wet\" refers to the loading of liquid propellants—the \"best risk reduction test\" for verifying all is ready to proceed into the real countdown.Read full article Comments",
          "feed_position": 16,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/55050650260_2530fea74e_k-1152x648-1770023686.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/55050650260_2530fea74e_k-1152x648-1770023686.jpg",
      "popularity_score": 140.06886277777778
    },
    {
      "id": "cluster_74",
      "coverage": 1,
      "updated_at": "Mon, 02 Feb 2026 18:08:54 +0000",
      "title": "Guinea worm on track to be 2nd eradicated human disease; only 10 cases in 2025",
      "neutral_headline": "Guinea worm on track to be 2nd eradicated human disease; only 10 cases in 2025",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2026/02/guinea-worm-on-track-to-be-2nd-eradicated-human-disease-only-10-cases-in-2025/",
          "published_at": "Mon, 02 Feb 2026 18:08:54 +0000",
          "title": "Guinea worm on track to be 2nd eradicated human disease; only 10 cases in 2025",
          "standfirst": "When the eradication program began in 1986, there were a 3.5 million cases.",
          "content": "A debilitating infection from the parasitic Guinea worm is inching closer to global eradication, with an all-time low of only 10 human cases reported worldwide in 2025, the Carter Center announced. If health workers can fully wipe out the worms, it will be only the second human disease to be eradicated, after smallpox. Guinea worm (Dracunculus medinensis) is a parasitic nematode transmitted in water. More specifically, it's found in waters that contain small crustacean copepods, which harbor the worm's larvae. If a person consumes water contaminated with Guinea worm, the parasites burrow through the intestinal tract and migrate through the body. About a year later, a spaghetti noodle-length worm emerges from a painful blister, usually in the feet or legs. It can take up to eight weeks for the adult worm to fully emerge. To ease the searing pain, infected people may put their blistered limbs in water, allowing the parasite to release more larvae and continue the cycle.Read full article Comments",
          "feed_position": 11,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-594370432-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-594370432-1152x648.jpg",
      "popularity_score": 139.51886305555556
    },
    {
      "id": "cluster_88",
      "coverage": 1,
      "updated_at": "Mon, 02 Feb 2026 14:43:30 +0000",
      "title": "Narwhals become quieter as the Arctic Ocean grows louder",
      "neutral_headline": "Narwhals become quieter as the Arctic Ocean grows louder",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/02/narwhals-become-quieter-as-the-arctic-ocean-grows-louder/",
          "published_at": "Mon, 02 Feb 2026 14:43:30 +0000",
          "title": "Narwhals become quieter as the Arctic Ocean grows louder",
          "standfirst": "Increasing shipping traffic is interfering with the whales’ ability to hunt and communicate.",
          "content": "For most of their evolutionary history, narwhals have relied more on sound than sight to survive in the Arctic’s dark icy waters. The speckled toothed whales—sometimes referred to as “unicorns of the sea” for the long, spiral tusks that protrude from the heads of males—navigate, hunt, and communicate using echolocation. By emitting a series of calls, whistles, and high frequency clicks—as many as a thousand per second—and listening for the echoes that bounce back, they are able to locate prey hundreds to thousands of feet deep and detect narrow cracks in sea ice where they can surface to breathe. But as global temperatures continue to rise, the acoustic world narwhals depend on is rapidly shifting throughout their range, from northeastern Canada and Greenland to Norway’s Svalbard archipelago and Arctic waters in Russia. It’s getting louder.Read full article Comments",
          "feed_position": 15,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/narwhal-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/narwhal-1152x648.jpg",
      "popularity_score": 136.09552944444445
    },
    {
      "id": "cluster_116",
      "coverage": 1,
      "updated_at": "Sun, 01 Feb 2026 12:15:50 +0000",
      "title": "At NIH, a power struggle over institute directorships deepens",
      "neutral_headline": "At NIH, a power struggle over institute directorships deepens",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/02/at-nih-a-power-struggle-over-institute-directorships-deepens/",
          "published_at": "Sun, 01 Feb 2026 12:15:50 +0000",
          "title": "At NIH, a power struggle over institute directorships deepens",
          "standfirst": "The research agency has 27 institute and center directors. Will those roles become politicized?",
          "content": "When a new presidential administration comes in, it is responsible for filling around 4,000 jobs sprinkled across the federal government’s vast bureaucracy. These political appointees help carry out the president’s agenda, and, at least in theory, make government agencies responsive to elected officials. Some of these roles—the secretary of state, for example—are well-known. Others, such as the deputy assistant secretary for textiles, consumer goods, materials, critical minerals & metals industry & analysis, are more obscure. Historically, science agencies like NASA or the National Institutes of Health tend to have fewer political appointees than many other parts of the federal government. Sometimes, very senior roles—with authority over billions of dollars of spending, and the power to shape entire fields of research—are filled without any direct input from the White House or Congress. The arrangement reflects a long-running argument that scientists should oversee the work of funding and conducting research with very little interference from political leaders.Read full article Comments",
          "feed_position": 17,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/05/GettyImages-1291108057-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/05/GettyImages-1291108057-1152x648.jpg",
      "popularity_score": 133
    },
    {
      "id": "cluster_118",
      "coverage": 1,
      "updated_at": "Sun, 01 Feb 2026 12:00:13 +0000",
      "title": "Fungus could be the insecticide of the future",
      "neutral_headline": "Fungus could be the insecticide of the future",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2026/02/fungus-could-be-the-insecticide-of-the-future/",
          "published_at": "Sun, 01 Feb 2026 12:00:13 +0000",
          "title": "Fungus could be the insecticide of the future",
          "standfirst": "Plant chemicals made more potent by insect pests are detoxified by the fungus.",
          "content": "Exterminators keep getting calls for a reason. Wood-devouring insects, such as beetles, termites, and carpenter ants, are constantly chewing through walls or infecting trees and breaking them down. The fight against these insects usually involved noxious insecticides; but now, at least some of them can be eliminated using a certain species of fungus. Infestations of bark beetles are the bane of spruce trees. Eurasian spruce bark beetles (Ips typographus) ingest bark high in phenolic compounds, organic molecules that often act as antioxidants and antimicrobials. They protect spruce bark from pathogenic fungi—and the beetles take advantage. Their bodies boost the antimicrobial power of these compounds by turning them into substances that are even more toxic to fungi. This would seem to make the beetles invulnerable to fungi. There is a way to get past the beetles’ borrowed defenses, though. Led by biochemist Ruo Sun, a team of researchers from the Max Planck Institute for Chemical Ecology in Jena, Germany, found that some strains of the fungus Beauveria bassiana are capable of infecting and killing the pests.Read full article Comments",
          "feed_position": 18,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-1541622283-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-1541622283-1024x648.jpg",
      "popularity_score": 130
    }
  ]
}