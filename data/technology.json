{
  "updated_at": "2025-12-02T23:13:08.097Z",
  "clusters": [
    {
      "id": "cluster_0",
      "coverage": 2,
      "updated_at": "Tue, 02 Dec 2025 23:05:51 GMT",
      "title": "Cyber Monday streaming deals are still live: Don't miss Peacock, Paramount+ & more",
      "neutral_headline": "Cyber Monday Deals Still Available at Multiple Retailers",
      "bullet_summary": [
        "Prevent cavities and keep your budget in check with the best deals we've found on electric toothbrushes",
        "Here are the best deals WIRED has found",
        "We found a handful of Pokémon Cyber Monday deals that’ll make perfect gifts for enthusiasts of all ages"
      ],
      "items": [
        {
          "source": "ZDNet",
          "url": "https://www.zdnet.com/article/cyber-monday-streaming-deals-hulu-youtube-tv-peacock-still-live/",
          "published_at": "Tue, 02 Dec 2025 23:05:51 GMT",
          "title": "Cyber Monday streaming deals are still live: Don't miss Peacock, Paramount+ & more",
          "standfirst": "I'm still tracking deals on the most popular streaming services still live for Cyber Monday, at the lowest prices of the year - but hurry, most of these offers will end soon.",
          "content": "I'm still tracking deals on the most popular streaming services still live for Cyber Monday, at the lowest prices of the year - but hurry, most of these offers will end soon.",
          "feed_position": 0
        },
        {
          "source": "ZDNet",
          "url": "https://www.zdnet.com/article/cyber-monday-walmart-deals-tvs-tablets-smartwatches-still-live/",
          "published_at": "Tue, 02 Dec 2025 22:52:36 GMT",
          "title": "The best Walmart Cyber Monday deals are still live: Shop the top 35 sales while you can",
          "standfirst": "Cyber Monday is over, but many of Walmart's best deals are still live -- including on the Nintendo Switch 2, PS5, and Apple products.",
          "content": "Cyber Monday is over, but many of Walmart's best deals are still live -- including on the Nintendo Switch 2, PS5, and Apple products.",
          "feed_position": 1
        },
        {
          "source": "ZDNet",
          "url": "https://www.zdnet.com/article/cyber-monday-ipad-deals-amazon-walmart-best-buy-still-live/",
          "published_at": "Tue, 02 Dec 2025 22:34:01 GMT",
          "title": "The best Cyber Monday iPad deals still live include sales up to $100 off",
          "standfirst": "Gifting an iPad this holiday season? Some Cyber Monday sales are still available, so take advantage of discounts on an iPad while supplies last.",
          "content": "Gifting an iPad this holiday season? Some Cyber Monday sales are still available, so take advantage of discounts on an iPad while supplies last.",
          "feed_position": 2
        },
        {
          "source": "ZDNet",
          "url": "https://www.zdnet.com/article/cyber-monday-tv-deals-live-amazon-best-buy-lg-last-chance/",
          "published_at": "Tue, 02 Dec 2025 22:22:39 GMT",
          "title": "These Cyber Monday TV deals are still live: Save up to $2,500 off LG, Samsung, Sony, TCL, & more",
          "standfirst": "Cyber Monday is over, but if you're in the market for a new TV, lots of deals are still live.",
          "content": "Cyber Monday is over, but if you're in the market for a new TV, lots of deals are still live.",
          "feed_position": 3
        },
        {
          "source": "ZDNet",
          "url": "https://www.zdnet.com/article/black-friday-power-station-deals-amazon-and-wellbots-last-chance/",
          "published_at": "Tue, 02 Dec 2025 21:53:55 GMT",
          "title": "My favorite Cyber Monday power station deals from EcoFlow, Jackery, & more are still live",
          "standfirst": "Black Friday and Cyber Monday may be over, but we've got our eyes on some excellent deals on power stations from top brands still available now.",
          "content": "Black Friday and Cyber Monday may be over, but we've got our eyes on some excellent deals on power stations from top brands still available now.",
          "feed_position": 4
        },
        {
          "source": "ZDNet",
          "url": "https://www.zdnet.com/article/cyber-monday-tablet-deals-oneplus-best-buy-amazon-still-live/",
          "published_at": "Tue, 02 Dec 2025 21:43:00 GMT",
          "title": "Best Cyber Monday tablet deals 2025: I'm tracking 15+ of the top sales still live today",
          "standfirst": "These lingering Cyber Monday tablet deals from Apple, Samsung, Microsoft, and more are ending soon.",
          "content": "These lingering Cyber Monday tablet deals from Apple, Samsung, Microsoft, and more are ending soon.",
          "feed_position": 6
        },
        {
          "source": "ZDNet",
          "url": "https://www.zdnet.com/article/cyber-monday-deals-2025-amazon-best-buy-hulu-still-live/",
          "published_at": "Tue, 02 Dec 2025 21:30:41 GMT",
          "title": "Our favorite Cyber Monday deals are still live: Shop Amazon, Best Buy, Lowe's sales now",
          "standfirst": "Black Friday and Cyber Monday are over, but major retailers are still offering big sales on items from Apple, Samsung, LG, Roku, and more.",
          "content": "Black Friday and Cyber Monday are over, but major retailers are still offering big sales on items from Apple, Samsung, LG, Roku, and more.",
          "feed_position": 8
        },
        {
          "source": "ZDNet",
          "url": "https://www.zdnet.com/article/cyber-monday-amazon-deals-ps5-earbuds-tvs-still-live/",
          "published_at": "Tue, 02 Dec 2025 21:11:58 GMT",
          "title": "Cyber Monday is over, but you can still shop my favorite Amazon sales on Hisense, Oura, and Apple",
          "standfirst": "Amazon has lingering Cyber Monday deals that are too good to miss, like the Hisense Canvas TV for $350 off.",
          "content": "Amazon has lingering Cyber Monday deals that are too good to miss, like the Hisense Canvas TV for $350 off.",
          "feed_position": 9
        },
        {
          "source": "ZDNet",
          "url": "https://www.zdnet.com/article/cyber-monday-best-buy-deals-meta-glasses-tvs-apple-watches-still-live/",
          "published_at": "Tue, 02 Dec 2025 21:09:23 GMT",
          "title": "Cyber Monday is over, but you can still shop my favorite deals on Apple, Sony, Bose and more",
          "standfirst": "Cyber Monday has ended, but Best Buy is still selling top tech at a discount. Shop my favorites.",
          "content": "Cyber Monday has ended, but Best Buy is still selling top tech at a discount. Shop my favorites.",
          "feed_position": 10
        },
        {
          "source": "ZDNet",
          "url": "https://www.zdnet.com/article/cyber-monday-smartwatch-deals-amazon-and-walmart-still-available/",
          "published_at": "Tue, 02 Dec 2025 20:38:39 GMT",
          "title": "My favorite Cyber Monday smartwatch deals still live: Apple Watch, Whoop, and more",
          "standfirst": "Cyber Monday is over, but you can still shop these available deals on smartwatches, smart rings, and more.",
          "content": "Cyber Monday is over, but you can still shop these available deals on smartwatches, smart rings, and more.",
          "feed_position": 11
        },
        {
          "source": "ZDNet",
          "url": "https://www.zdnet.com/article/cyber-monday-apple-watch-deals-amazon-best-buy-walmart-still-live/",
          "published_at": "Tue, 02 Dec 2025 20:37:16 GMT",
          "title": "I found the best Cyber Monday Apple Watch deals still available today",
          "standfirst": "Shop these Cyber Monday deals still available on Apple Watches, including the new Series 11, Ultra 2, and SE 3, before they're gone.",
          "content": "Shop these Cyber Monday deals still available on Apple Watches, including the new Series 11, Ultra 2, and SE 3, before they're gone.",
          "feed_position": 12
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/cyber-monday-deals-2025-1/",
          "published_at": "Tue, 02 Dec 2025 19:46:09 +0000",
          "title": "The 157 Best Cyber Week Deals—Save up to 57% Off Gear We Love",
          "standfirst": "Cyber Monday is over, but many deals are still available, at least for now. These are the absolute best discounts on gear we've tested ourselves.",
          "content": "Cyber Monday is over, but many deals are still available, at least for now. These are the absolute best discounts on gear we've tested ourselves.",
          "feed_position": 2,
          "image_url": "https://media.wired.com/photos/692f415882a0f4fe6c166da2/master/pass/Wired%20-%20Cyber%20week%20deals.jpg"
        },
        {
          "source": "ZDNet",
          "url": "https://www.zdnet.com/article/cyber-monday-laptop-deals-amazon-best-buy-walmart-still-available/",
          "published_at": "Tue, 02 Dec 2025 19:27:00 GMT",
          "title": "Best Cyber Monday laptop deals still live: Grab 20 sales on MacBooks, Lenovo, HP, & more",
          "standfirst": "We've gathered the best Cyber Monday deals on laptops still live now, including the new MacBook Air M4 for 25% off.",
          "content": "We've gathered the best Cyber Monday deals on laptops still live now, including the new MacBook Air M4 for 25% off.",
          "feed_position": 15
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/cyber-monday-best-buy-deals/",
          "published_at": "Tue, 02 Dec 2025 01:36:52 +0000",
          "title": "22 Best Cyber Monday Deals at Best Buy (2025) on Hot Tech",
          "standfirst": "Best Buy is rolling out really great deals on some of our favorite tech that we've tested this year.",
          "content": "Best Buy is rolling out really great deals on some of our favorite tech that we've tested this year.",
          "feed_position": 15,
          "image_url": "https://media.wired.com/photos/691ebbbfaaec53d0d5d9437c/master/pass/The%20Best%20Early%20Black%20Friday%20Tech%20Deals%20From%20Best%20Buy.png"
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/amazon-device-kindle-cyber-monday-deals-2025/",
          "published_at": "Mon, 01 Dec 2025 22:07:43 +0000",
          "title": "The Best Amazon Device and Kindle Cyber Monday Deals (2025): Paperwhite, Scribe, Echo Dot Max",
          "standfirst": "Amazon's Cyber Monday sales are live. Here are the best deals on Echo speakers, Fire TVs, and Kindles.",
          "content": "Amazon's Cyber Monday sales are live. Here are the best deals on Echo speakers, Fire TVs, and Kindles.",
          "feed_position": 17,
          "image_url": "https://media.wired.com/photos/6923deca7b8cd84c7d271add/master/pass/The%20Best%20Kindle%20and%20Amazon%20Device%20Black%20Friday%20Deals.png"
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/best-cyber-monday-laptop-deals-2025/",
          "published_at": "Mon, 01 Dec 2025 21:56:02 +0000",
          "title": "14 Best Cyber Monday Laptop Deals (2025): MacBooks, Gaming Laptops, and More",
          "standfirst": "Some of the best MacBooks, Chromebooks, and gaming laptops I've reviewed this year have steep discounts for Cyber Monday.",
          "content": "Some of the best MacBooks, Chromebooks, and gaming laptops I've reviewed this year have steep discounts for Cyber Monday.",
          "feed_position": 18,
          "image_url": "https://media.wired.com/photos/692402a28006ba74bce6f97f/master/pass/Best%20Laptop%20Deals%20for%20Black%20Friday%202025.png"
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/cyber-monday-soundbar-deals-2025/",
          "published_at": "Mon, 01 Dec 2025 20:42:38 +0000",
          "title": "The Best Cyber Monday Soundbar Deals",
          "standfirst": "Scoop up savings on our favorite soundbars from brands like Sony, Vizio, and Samsung.",
          "content": "Scoop up savings on our favorite soundbars from brands like Sony, Vizio, and Samsung.",
          "feed_position": 22,
          "image_url": "https://media.wired.com/photos/692e055647a0022efecfae9d/master/pass/The-Best-Cyber-Monday-Soundbar-Deals.jpg"
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/best-cyber-monday-electric-toothbrush-deals-2025/",
          "published_at": "Mon, 01 Dec 2025 20:31:03 +0000",
          "title": "Cyber Monday Electric Toothbrush Deals (2025)",
          "standfirst": "Prevent cavities and keep your budget in check with the best deals we've found on electric toothbrushes.",
          "content": "Prevent cavities and keep your budget in check with the best deals we've found on electric toothbrushes.",
          "feed_position": 25,
          "image_url": "https://media.wired.com/photos/692df31f2a39d9894f47ea57/master/pass/Best%20Cyber%20Monday%20Electric%20Toothbrush%20Deals.png"
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/best-cyber-monday-coffee-subscription-deals-2025/",
          "published_at": "Mon, 01 Dec 2025 20:10:00 +0000",
          "title": "Best Cyber Monday Coffee Subscription Deals (2025): Atlas, Trade",
          "standfirst": "Coffee subscriptions offer their steepest discounts around Cyber Monday and Black Friday. Here are the best deals WIRED has found.",
          "content": "Coffee subscriptions offer their steepest discounts around Cyber Monday and Black Friday. Here are the best deals WIRED has found.",
          "feed_position": 26,
          "image_url": "https://media.wired.com/photos/5dbca743dea30b00096c6c2e/master/pass/Gear-Atlas-Coffee-Subscription-SOURCE-Atlas-Coffee.jpg"
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/cyber-monday-phone-deals-2025/",
          "published_at": "Mon, 01 Dec 2025 19:37:55 +0000",
          "title": "15 Best Cyber Monday Phone Deals (2025)",
          "standfirst": "Now is a great time to upgrade your phone. This Cyber Monday has discounts ranging from the Google Pixel 9a to Samsung's Galaxy Z Fold7.",
          "content": "Now is a great time to upgrade your phone. This Cyber Monday has discounts ranging from the Google Pixel 9a to Samsung's Galaxy Z Fold7.",
          "feed_position": 27,
          "image_url": "https://media.wired.com/photos/69266c30e44d5ed7c3809f07/master/pass/The%20Best%20Black%20Friday%20Smartphone%20Deals.png"
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/best-cyber-monday-mattress-deals-2025/",
          "published_at": "Mon, 01 Dec 2025 19:10:42 +0000",
          "title": "The Best Cyber Monday Mattress and Bedding Deals (2025)",
          "standfirst": "Some of the best sales of the year on mattresses, mattress toppers, and pillows are happening right now.",
          "content": "Some of the best sales of the year on mattresses, mattress toppers, and pillows are happening right now.",
          "feed_position": 29,
          "image_url": "https://media.wired.com/photos/6925f93abc7f8203325acf6c/master/pass/The%20Best%20Black%20Friday%20Mattress%20Deals%202025.png"
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/cyber-monday-therabody-deals-2025/",
          "published_at": "Mon, 01 Dec 2025 18:39:44 +0000",
          "title": "The Best Therabody and Theragun Cyber Monday Deals (2025)",
          "standfirst": "Therabody's Cyber Monday sale is live—and it's good.",
          "content": "Therabody's Cyber Monday sale is live—and it's good.",
          "feed_position": 30,
          "image_url": "https://media.wired.com/photos/69240a3bc7154b4f80a5f96c/master/pass/The%20Best%20Black%20Friday%20Therabody%20Deals.png"
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/best-cyber-monday-deals-under-100-2025/",
          "published_at": "Mon, 01 Dec 2025 18:32:55 +0000",
          "title": "48 Best Cyber Monday Deals Under $100 (2025)",
          "standfirst": "These Cyber Monday deals won't break your budget, proving that you don't need to spend a lot to save on WIRED-approved gear.",
          "content": "These Cyber Monday deals won't break your budget, proving that you don't need to spend a lot to save on WIRED-approved gear.",
          "feed_position": 31,
          "image_url": "https://media.wired.com/photos/6925527fe444184cf49e477c/master/pass/Best%20Black%20Friday%20Deals%20Under%20$100.png"
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/hyperice-cyber-monday-deals-2025/",
          "published_at": "Mon, 01 Dec 2025 18:30:00 +0000",
          "title": "Best Hyperice Cyber Monday Deals (2025)",
          "standfirst": "Here are the Hyperice deals worth your money this Cyber Monday.",
          "content": "Here are the Hyperice deals worth your money this Cyber Monday.",
          "feed_position": 32,
          "image_url": "https://media.wired.com/photos/69266a1559de112f2dd1e3dc/master/pass/The%20Best%20Hyperice%20Black%20Friday%20Deals.png"
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/digital-notebook-cyber-monday-sales/",
          "published_at": "Mon, 01 Dec 2025 17:45:38 +0000",
          "title": "Best Digital Notebook Cyber Monday Sales (2025): ReMarkable, Kobo, Kindle",
          "standfirst": "These handy e-paper devices let you write notes, sketch ideas, and even read books—and they're on sale for Cyber Monday.",
          "content": "These handy e-paper devices let you write notes, sketch ideas, and even read books—and they're on sale for Cyber Monday.",
          "feed_position": 33,
          "image_url": "https://media.wired.com/photos/6923ce96a616c99b3b5d5966/master/pass/Our%20Favorite%20Digital%20Notebooks%20Are%20On%20Sale%20for%20Black%20Friday.png"
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/best-rei-cyber-week-outdoor-deals-2025/",
          "published_at": "Mon, 01 Dec 2025 17:02:34 +0000",
          "title": "The 74 Best REI Cyber Monday Outdoor Deals (2025)",
          "standfirst": "Gear up for next year with these great deals on tents, packs, sleeping bags, and merino wool.",
          "content": "Gear up for next year with these great deals on tents, packs, sleeping bags, and merino wool.",
          "feed_position": 36,
          "image_url": "https://media.wired.com/photos/69266f0385902b21de6d45ab/master/pass/The%2049%20Best%20Black%20Friday%20Outdoor%20Deals.png"
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/cyber-monday-grill-deals-2025/",
          "published_at": "Mon, 01 Dec 2025 16:44:51 +0000",
          "title": "Cyber Monday Grill Deals: A Bunch of Favorites Are on Sale Today (2025)",
          "standfirst": "It's the end of the season for outdoor living, which means you can save big on Cyber Monday grill deals.",
          "content": "It's the end of the season for outdoor living, which means you can save big on Cyber Monday grill deals.",
          "feed_position": 37,
          "image_url": "https://media.wired.com/photos/691e4c4c8ac5d19ad334a51e/master/pass/An%20AI-Enabled%20Pellet%20Grill%20Is%20a%20Dumb%20Idea.%20Buy%20This%20One%20Anyway.png"
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/best-pokemon-black-friday-deals-2025/",
          "published_at": "Mon, 01 Dec 2025 16:20:28 +0000",
          "title": "The Best Pokémon Cyber Monday Deals That Make Great Gifts (2025)",
          "standfirst": "We found a handful of Pokémon Cyber Monday deals that’ll make perfect gifts for enthusiasts of all ages.",
          "content": "We found a handful of Pokémon Cyber Monday deals that’ll make perfect gifts for enthusiasts of all ages.",
          "feed_position": 38,
          "image_url": "https://media.wired.com/photos/692a4c807a136ff60f6dbb7d/master/pass/Best%20Pokemon%20Black%20Friday%20Deals.png"
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/cyber-monday-home-security-deals-2025/",
          "published_at": "Mon, 01 Dec 2025 15:56:01 +0000",
          "title": "12 Best Cyber Monday Home Security Deals 2025",
          "standfirst": "If you want to secure your property, these Cyber Monday security camera deals are worth a look.",
          "content": "If you want to secure your property, these Cyber Monday security camera deals are worth a look.",
          "feed_position": 39,
          "image_url": "https://media.wired.com/photos/69254ff8e444184cf49e477a/master/pass/Arlo%20Pro%205S%20Black%20Friday%20Deal.png"
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/cyber-monday-tech-deals-2025/",
          "published_at": "Mon, 01 Dec 2025 14:14:32 +0000",
          "title": "39 Best Cyber Monday Tech Deals (2025)",
          "standfirst": "Behold the best Cyber Monday tech deals this weekend on WIRED-tested and approved gadgetry of all kinds.",
          "content": "Behold the best Cyber Monday tech deals this weekend on WIRED-tested and approved gadgetry of all kinds.",
          "feed_position": 40,
          "image_url": "https://media.wired.com/photos/69254e313babfea407a3eeff/master/pass/The%20Best%20Black%20Friday%20Tech%20Deals.png"
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/cyber-monday-camera-deals-2025/",
          "published_at": "Mon, 01 Dec 2025 14:02:33 +0000",
          "title": "23 Best GoPro and Camera Deals for Cyber Monday (2025)",
          "standfirst": "Score a great deal on our favorite action cameras, 360 cameras, and more with these Cyber Monday sales.",
          "content": "Score a great deal on our favorite action cameras, 360 cameras, and more with these Cyber Monday sales.",
          "feed_position": 41,
          "image_url": "https://media.wired.com/photos/68f941cd8917864e5606190f/master/pass/GoPro%20Max%202%20front%20SOURCE%20Scott%20Gilbertson.png"
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/best-cyber-monday-google-pixel-deals-2025/",
          "published_at": "Mon, 01 Dec 2025 13:31:14 +0000",
          "title": "Best Cyber Monday Google Pixel Deals (2025)",
          "standfirst": "This Cyber Monday, score hundreds off the new Pixel 10 range, or snag a discounted Pixel Watch 4 or Pixel Buds.",
          "content": "This Cyber Monday, score hundreds off the new Pixel 10 range, or snag a discounted Pixel Watch 4 or Pixel Buds.",
          "feed_position": 44,
          "image_url": "https://media.wired.com/photos/691eb5b2d121d26c390d65a4/master/pass/Google's%20Black%20Friday%20Sale%20Starts%20Today%20on%20Pixel%20Phones_.png"
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/cyber-monday-beauty-deals-2025/",
          "published_at": "Mon, 01 Dec 2025 13:04:05 +0000",
          "title": "The Best Cyber Monday Beauty Deals, WIRED Approved (2025)",
          "standfirst": "Name a better time to stock up on beauty bargains—I'll wait.",
          "content": "Name a better time to stock up on beauty bargains—I'll wait.",
          "feed_position": 45,
          "image_url": "https://media.wired.com/photos/6923fb9dc68e1875e6bc3d1b/master/pass/The%20Best%20Black%20Friday%20Beauty%20Deals.png"
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/costco-cyber-monday-2025/",
          "published_at": "Mon, 01 Dec 2025 11:41:13 +0000",
          "title": "Best Costco Cyber Monday Deals 2025",
          "standfirst": "Some of our favorite purchases are in stock at Costco, with savings just for members.",
          "content": "Some of our favorite purchases are in stock at Costco, with savings just for members.",
          "feed_position": 48,
          "image_url": "https://media.wired.com/photos/5fb2cc575c9914713ead03de/master/pass/Gear-Apple-MacBook-Air-top-down-SOURCE-Apple.jpg"
        },
        {
          "source": "Wired Tech",
          "url": "https://www.wired.com/story/nintendo-switch-2-cyber-monday-deals/",
          "published_at": "Mon, 01 Dec 2025 11:39:50 +0000",
          "title": "Nintendo Switch 2 Cyber Monday Deals: Bundles, Controllers, Earbuds",
          "standfirst": "While the Switch 2 itself isn't on sale, you can still find good prices on bundles and accessories.",
          "content": "While the Switch 2 itself isn't on sale, you can still find good prices on bundles and accessories.",
          "feed_position": 49,
          "image_url": "https://media.wired.com/photos/67ed725356eda31fe204a393/master/pass/Everything-You-Need-To-Know-Culture-NintendoSwitch2_HW_33.jpg"
        }
      ],
      "featured_image": "https://media.wired.com/photos/692f415882a0f4fe6c166da2/master/pass/Wired%20-%20Cyber%20week%20deals.jpg",
      "popularity_score": 2019.8785841666668,
      "ai_summary": [
        "Many Cyber Monday deals are still available from various retailers.",
        "Deals include discounts on streaming services like Peacock and Paramount+.",
        "Walmart is still offering deals on items like the Nintendo Switch 2.",
        "Amazon is still offering deals on items like the Hisense Canvas TV.",
        "Best Buy is still selling top tech at a discount."
      ]
    },
    {
      "id": "cluster_43",
      "coverage": 2,
      "updated_at": "Tue, 02 Dec 2025 13:25:02 -0500",
      "title": "Apptopia: ChatGPT referrals to retailer mobile apps increased 28% YoY during the Black Friday weekend in 2025; Amazon's share of ChatGPT referrals grew to 54% (Sarah Perez/TechCrunch)",
      "neutral_headline": "ChatGPT Referrals to Retailer Apps Increased on Black Friday",
      "bullet_summary": [
        "Reported by TechMeme, TechCrunch"
      ],
      "items": [
        {
          "source": "TechMeme",
          "url": "http://www.techmeme.com/251202/p47#a251202p47",
          "published_at": "Tue, 02 Dec 2025 13:25:02 -0500",
          "title": "Apptopia: ChatGPT referrals to retailer mobile apps increased 28% YoY during the Black Friday weekend in 2025; Amazon's share of ChatGPT referrals grew to 54% (Sarah Perez/TechCrunch)",
          "standfirst": "Sarah Perez / TechCrunch: Apptopia: ChatGPT referrals to retailer mobile apps increased 28% YoY during the Black Friday weekend in 2025; Amazon's share of ChatGPT referrals grew to 54% &mdash; New data shows ChatGPT's growing influence as a referrer to e-commerce websites, but also how small its slice of this market is currently.",
          "content": "Sarah Perez / TechCrunch: Apptopia: ChatGPT referrals to retailer mobile apps increased 28% YoY during the Black Friday weekend in 2025; Amazon's share of ChatGPT referrals grew to 54% &mdash; New data shows ChatGPT's growing influence as a referrer to e-commerce websites, but also how small its slice of this market is currently.",
          "feed_position": 7,
          "image_url": "http://www.techmeme.com/251202/i47.jpg"
        },
        {
          "source": "TechCrunch",
          "url": "https://techcrunch.com/2025/12/02/chatgpt-referrals-to-retailers-apps-increased-28-year-over-year-says-report/",
          "published_at": "Tue, 02 Dec 2025 17:56:16 +0000",
          "title": "ChatGPT referrals to retailers&#8217; apps increased 28% year-over-year, says report",
          "standfirst": "ChatGPT referrals to retailers' apps were up on Black Friday year-over-year, with Walmart and Amazon benefiting the most.",
          "content": "ChatGPT referrals to retailers' apps were up on Black Friday year-over-year, with Walmart and Amazon benefiting the most.",
          "feed_position": 9
        }
      ],
      "featured_image": "http://www.techmeme.com/251202/i47.jpg",
      "popularity_score": 2015.1983063888888,
      "ai_summary": [
        "ChatGPT referrals to retailer mobile apps increased 28% year-over-year.",
        "The increase occurred during the Black Friday weekend in 2025.",
        "Amazon's share of ChatGPT referrals grew to 54%.",
        "The data shows ChatGPT's growing influence in e-commerce.",
        "Walmart and Amazon benefited the most from the referrals."
      ]
    },
    {
      "id": "cluster_51",
      "coverage": 2,
      "updated_at": "Tue, 02 Dec 2025 17:30:00 GMT",
      "title": "Amazon's new AI can code for days without human help. What does that mean for software engineers?",
      "neutral_headline": "Amazon's AI Can Code Without Human Intervention",
      "bullet_summary": [
        "\"We see frontier agents as a completely new class of agents,\" said Deepak Singh, vice president of developer agents and experiences at Amazon, in an interview ahead of the announcement",
        "\"A frontier agent can decide to spin up 10 versions of itself, all working on different parts of the problem at once,\" Singh said",
        "\"AWS Security Agent helped catch a business logic bug that no existing tools would have caught, exposing information improperly,\" said Andres Ruiz, staff software engineer at the company",
        "\"You can go in and even redact that from its knowledge like, &#x27;No, we don&#x27;t want you to ever use this knowledge,&#x27;\" Singh said"
      ],
      "items": [
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/amazons-new-ai-can-code-for-days-without-human-help-what-does-that-mean-for",
          "published_at": "Tue, 02 Dec 2025 17:30:00 GMT",
          "title": "Amazon's new AI can code for days without human help. What does that mean for software engineers?",
          "standfirst": "Amazon Web Services on Tuesday announced a new class of artificial intelligence systems called \"frontier agents\" that can work autonomously for hours or even days without human intervention, representing one of the most ambitious attempts yet to automate the full software development lifecycle.The announcement, made during AWS CEO Matt Garman&#x27;s keynote address at the company&#x27;s annual re:Invent conference, introduces three specialized AI agents designed to act as virtual team members: Kiro autonomous agent for software development, AWS Security Agent for application security, and AWS DevOps Agent for IT operations.The move signals Amazon&#x27;s intent to leap ahead in the intensifying competition to build AI systems capable of performing complex, multi-step tasks that currently require teams of skilled engineers.\"We see frontier agents as a completely new class of agents,\" said Deepak Singh, vice president of developer agents and experiences at Amazon, in an interview ahead of the announcement. \"They&#x27;re fundamentally designed to work for hours and days. You&#x27;re not giving them a problem that you want finished in the next five minutes. You&#x27;re giving them complex challenges that they may have to think about, try different solutions, and get to the right conclusion — and they should do that without intervention.\"Why Amazon believes its new agents leave existing AI coding tools behindThe frontier agents differ from existing AI coding assistants like GitHub Copilot or Amazon&#x27;s own CodeWhisperer in several fundamental ways.Current AI coding tools, while powerful, require engineers to drive every interaction. Developers must write prompts, provide context, and manually coordinate work across different code repositories. When switching between tasks, the AI loses context and must start fresh.The new frontier agents, by contrast, maintain persistent memory across sessions and continuously learn from an organization&#x27;s codebase, documentation, and team communications. They can independently determine which code repositories require changes, work on multiple files simultaneously, and coordinate complex transformations spanning dozens of microservices.\"With a current agent, you would go microservice by microservice, making changes one at a time, and each change would be a different session with no shared context,\" Singh explained. \"With a frontier agent, you say, &#x27;I need to solve this broad problem.&#x27; You point it to the right application, and it decides which repos need changes.\"The agents exhibit three defining characteristics that AWS believes set them apart: autonomy in decision-making, the ability to scale by spawning multiple agents to work on different aspects of a problem simultaneously, and the capacity to operate independently for extended periods.\"A frontier agent can decide to spin up 10 versions of itself, all working on different parts of the problem at once,\" Singh said.How each of the three frontier agents tackles a different phase of developmentKiro autonomous agent serves as a virtual developer that maintains context across coding sessions and learns from an organization&#x27;s pull requests, code reviews, and technical discussions. Teams can connect it to GitHub, Jira, Slack, and internal documentation systems. The agent then acts like a teammate, accepting task assignments and working independently until it either completes the work or requires human guidance.AWS Security Agent embeds security expertise throughout the development process, automatically reviewing design documents and scanning pull requests against organizational security requirements. Perhaps most significantly, it transforms penetration testing from a weeks-long manual process into an on-demand capability that completes in hours.SmugMug, a photo hosting platform, has already deployed the security agent. \"AWS Security Agent helped catch a business logic bug that no existing tools would have caught, exposing information improperly,\" said Andres Ruiz, staff software engineer at the company. \"To any other tool, this would have been invisible. But the ability for Security Agent to contextualize the information, parse the API response, and find the unexpected information there represents a leap forward in automated security testing.\"AWS DevOps Agent functions as an always-on operations team member, responding instantly to incidents and using its accumulated knowledge to identify root causes. It connects to observability tools including Amazon CloudWatch, Datadog, Dynatrace, New Relic, and Splunk, along with runbooks and deployment pipelines.Commonwealth Bank of Australia tested the DevOps agent by replicating a complex network and identity management issue that typically requires hours for experienced engineers to diagnose. The agent identified the root cause in under 15 minutes.\"AWS DevOps Agent thinks and acts like a seasoned DevOps engineer, helping our engineers build a banking infrastructure that&#x27;s faster, more resilient, and designed to deliver better experiences for our customers,\" said Jason Sandry, head of cloud services at Commonwealth Bank.Amazon makes its case against Google and Microsoft in the AI coding warsThe announcement arrives amid a fierce battle among technology giants to dominate the emerging market for AI-powered development tools. Google has made significant noise in recent weeks with its own AI coding capabilities, while Microsoft continues to advance GitHub Copilot and its broader AI development toolkit.Singh argued that AWS holds distinct advantages rooted in the company&#x27;s 20-year history operating cloud infrastructure and Amazon&#x27;s own massive software engineering organization.\"AWS has been the cloud of choice for 20 years, so we have two decades of knowledge building and running it, and working with customers who&#x27;ve been building and running applications on it,\" Singh said. \"The learnings from operating AWS, the knowledge our customers have, the experience we&#x27;ve built using these tools ourselves every day to build real-world applications—all of that is embodied in these frontier agents.\"He drew a distinction between tools suitable for prototypes versus production systems. \"There&#x27;s a lot of things out there that you can use to build your prototype or your toy application. But if you want to build production applications, there&#x27;s a lot of knowledge that we bring in as AWS that apply here.\"The safeguards Amazon built to keep autonomous agents from going rogueThe prospect of AI systems operating autonomously for days raises immediate questions about what happens when they go off track. Singh described multiple safeguards built into the system.All learnings accumulated by the agents are logged and visible, allowing engineers to understand what knowledge influences the agent&#x27;s decisions. Teams can even remove specific learnings if they discover the agent has absorbed incorrect information from team communications.\"You can go in and even redact that from its knowledge like, &#x27;No, we don&#x27;t want you to ever use this knowledge,&#x27;\" Singh said. \"You can look at the knowledge like it&#x27;s almost—it&#x27;s like looking at your neurons inside your brain. You can disconnect some.\"Engineers can also monitor agent activity in real-time and intervene when necessary, either redirecting the agent or taking over entirely. Most critically, the agents never commit code directly to production systems. That responsibility remains with human engineers.\"These agents are never going to check the code into production. That is still the human&#x27;s responsibility,\" Singh emphasized. \"You are still, as an engineer, responsible for the code you&#x27;re checking in, whether it&#x27;s generated by you or by an agent working autonomously.\"What frontier agents mean for the future of software engineering jobsThe announcement inevitably raises concerns about the impact on software engineering jobs. Singh pushed back against the notion that frontier agents will replace developers, framing them instead as tools that amplify human capabilities.\"Software engineering is craft. What&#x27;s changing is not, &#x27;Hey, agents are doing all the work.&#x27; The craft of software engineering is changing—how you use agents, how do you set up your code base, how do you set up your prompts, how do you set up your rules, how do you set up your knowledge bases so that agents can be effective,\" he said.Singh noted that senior engineers who had drifted away from hands-on coding are now writing more code than ever. \"It&#x27;s actually easier for them to become software engineers,\" he said.He pointed to an internal example where a team completed a project in 78 days that would have taken 18 months using traditional practices. \"Because they were able to use AI. And the thing that made it work was not just the fact that they were using AI, but how they organized and set up their practices of how they built that software were maximized around that.\"How Amazon plans to make AI-generated code more trustworthy over timeSingh outlined several areas where frontier agents will evolve over the coming years. Multi-agent architectures, where systems of specialized agents coordinate to solve complex problems, represent a major frontier. So does the integration of formal verification techniques to increase confidence in AI-generated code.AWS recently introduced property-based testing in Kiro, which uses automated reasoning to extract testable properties from specifications and generate thousands of test scenarios automatically.\"If you have a shopping cart application, every way an order can be canceled, and how it might be canceled, and the way refunds are handled in Germany versus the US—if you&#x27;re writing a unit test, maybe two, Germany and US, but now, because you have this property-based testing approach, your agent can create a scenario for every country you operate in and test all of them automatically for you,\" Singh explained.Building trust in autonomous systems remains the central challenge. \"Right now you still require tons of human guardrails at every step to make sure that the right thing happens. And as we get better at these techniques, you will use less and less, and you&#x27;ll be able to trust the agents a lot more,\" he said.Amazon&#x27;s bigger bet on autonomous AI stretches far beyond writing codeThe frontier agents announcement arrived alongside a cascade of other news at re:Invent 2025. AWS kicked off the conference with major announcements on agentic AI capabilities, customer service innovations, and multicloud networking.Amazon expanded its Nova portfolio with four new models delivering industry-leading price-performance across reasoning, multimodal processing, conversational AI, code generation, and agentic tasks. Nova Forge pioneers \"open training,\" giving organizations access to pre-trained model checkpoints and the ability to blend proprietary data with Amazon Nova-curated datasets.AWS also added 18 new open weight models to Amazon Bedrock, reinforcing its commitment to offering a broad selection of fully managed models from leading AI providers. The launch includes new models from Mistral AI, Google&#x27;s Gemma 3, MiniMax&#x27;s M2, NVIDIA&#x27;s Nemotron, and OpenAI&#x27;s GPT OSS Safeguard.On the infrastructure side, Amazon EC2 Trn3 UltraServers, powered by AWS&#x27;s first 3nm AI chip, pack up to 144 Trainium3 chips into a single integrated system, delivering up to 4.4x more compute performance and 4x greater energy efficiency than the previous generation. AWS AI Factories provides enterprises and government organizations with dedicated AWS AI infrastructure deployed in their own data centers, combining NVIDIA GPUs, Trainium chips, AWS networking, and AI services like Amazon Bedrock and SageMaker AI.All three frontier agents launched in preview on Tuesday. Pricing will be announced when the services reach general availability.Singh made clear the company sees applications far beyond coding. \"These are the first frontier agents we are releasing, and they&#x27;re in the software development lifecycle,\" he said. \"The problems and use cases for frontier agents—these agents that are long running, capable of autonomy, thinking, always learning and improving—can be applied to many, many domains.\"Amazon, after all, operates satellite networks, runs robotics warehouses, and manages one of the world&#x27;s largest e-commerce platforms. If autonomous agents can learn to write code on their own, the company is betting they can eventually learn to do just about anything else.",
          "content": "Amazon Web Services on Tuesday announced a new class of artificial intelligence systems called \"frontier agents\" that can work autonomously for hours or even days without human intervention, representing one of the most ambitious attempts yet to automate the full software development lifecycle.The announcement, made during AWS CEO Matt Garman&#x27;s keynote address at the company&#x27;s annual re:Invent conference, introduces three specialized AI agents designed to act as virtual team members: Kiro autonomous agent for software development, AWS Security Agent for application security, and AWS DevOps Agent for IT operations.The move signals Amazon&#x27;s intent to leap ahead in the intensifying competition to build AI systems capable of performing complex, multi-step tasks that currently require teams of skilled engineers.\"We see frontier agents as a completely new class of agents,\" said Deepak Singh, vice president of developer agents and experiences at Amazon, in an interview ahead of the announcement. \"They&#x27;re fundamentally designed to work for hours and days. You&#x27;re not giving them a problem that you want finished in the next five minutes. You&#x27;re giving them complex challenges that they may have to think about, try different solutions, and get to the right conclusion — and they should do that without intervention.\"Why Amazon believes its new agents leave existing AI coding tools behindThe frontier agents differ from existing AI coding assistants like GitHub Copilot or Amazon&#x27;s own CodeWhisperer in several fundamental ways.Current AI coding tools, while powerful, require engineers to drive every interaction. Developers must write prompts, provide context, and manually coordinate work across different code repositories. When switching between tasks, the AI loses context and must start fresh.The new frontier agents, by contrast, maintain persistent memory across sessions and continuously learn from an organization&#x27;s codebase, documentation, and team communications. They can independently determine which code repositories require changes, work on multiple files simultaneously, and coordinate complex transformations spanning dozens of microservices.\"With a current agent, you would go microservice by microservice, making changes one at a time, and each change would be a different session with no shared context,\" Singh explained. \"With a frontier agent, you say, &#x27;I need to solve this broad problem.&#x27; You point it to the right application, and it decides which repos need changes.\"The agents exhibit three defining characteristics that AWS believes set them apart: autonomy in decision-making, the ability to scale by spawning multiple agents to work on different aspects of a problem simultaneously, and the capacity to operate independently for extended periods.\"A frontier agent can decide to spin up 10 versions of itself, all working on different parts of the problem at once,\" Singh said.How each of the three frontier agents tackles a different phase of developmentKiro autonomous agent serves as a virtual developer that maintains context across coding sessions and learns from an organization&#x27;s pull requests, code reviews, and technical discussions. Teams can connect it to GitHub, Jira, Slack, and internal documentation systems. The agent then acts like a teammate, accepting task assignments and working independently until it either completes the work or requires human guidance.AWS Security Agent embeds security expertise throughout the development process, automatically reviewing design documents and scanning pull requests against organizational security requirements. Perhaps most significantly, it transforms penetration testing from a weeks-long manual process into an on-demand capability that completes in hours.SmugMug, a photo hosting platform, has already deployed the security agent. \"AWS Security Agent helped catch a business logic bug that no existing tools would have caught, exposing information improperly,\" said Andres Ruiz, staff software engineer at the company. \"To any other tool, this would have been invisible. But the ability for Security Agent to contextualize the information, parse the API response, and find the unexpected information there represents a leap forward in automated security testing.\"AWS DevOps Agent functions as an always-on operations team member, responding instantly to incidents and using its accumulated knowledge to identify root causes. It connects to observability tools including Amazon CloudWatch, Datadog, Dynatrace, New Relic, and Splunk, along with runbooks and deployment pipelines.Commonwealth Bank of Australia tested the DevOps agent by replicating a complex network and identity management issue that typically requires hours for experienced engineers to diagnose. The agent identified the root cause in under 15 minutes.\"AWS DevOps Agent thinks and acts like a seasoned DevOps engineer, helping our engineers build a banking infrastructure that&#x27;s faster, more resilient, and designed to deliver better experiences for our customers,\" said Jason Sandry, head of cloud services at Commonwealth Bank.Amazon makes its case against Google and Microsoft in the AI coding warsThe announcement arrives amid a fierce battle among technology giants to dominate the emerging market for AI-powered development tools. Google has made significant noise in recent weeks with its own AI coding capabilities, while Microsoft continues to advance GitHub Copilot and its broader AI development toolkit.Singh argued that AWS holds distinct advantages rooted in the company&#x27;s 20-year history operating cloud infrastructure and Amazon&#x27;s own massive software engineering organization.\"AWS has been the cloud of choice for 20 years, so we have two decades of knowledge building and running it, and working with customers who&#x27;ve been building and running applications on it,\" Singh said. \"The learnings from operating AWS, the knowledge our customers have, the experience we&#x27;ve built using these tools ourselves every day to build real-world applications—all of that is embodied in these frontier agents.\"He drew a distinction between tools suitable for prototypes versus production systems. \"There&#x27;s a lot of things out there that you can use to build your prototype or your toy application. But if you want to build production applications, there&#x27;s a lot of knowledge that we bring in as AWS that apply here.\"The safeguards Amazon built to keep autonomous agents from going rogueThe prospect of AI systems operating autonomously for days raises immediate questions about what happens when they go off track. Singh described multiple safeguards built into the system.All learnings accumulated by the agents are logged and visible, allowing engineers to understand what knowledge influences the agent&#x27;s decisions. Teams can even remove specific learnings if they discover the agent has absorbed incorrect information from team communications.\"You can go in and even redact that from its knowledge like, &#x27;No, we don&#x27;t want you to ever use this knowledge,&#x27;\" Singh said. \"You can look at the knowledge like it&#x27;s almost—it&#x27;s like looking at your neurons inside your brain. You can disconnect some.\"Engineers can also monitor agent activity in real-time and intervene when necessary, either redirecting the agent or taking over entirely. Most critically, the agents never commit code directly to production systems. That responsibility remains with human engineers.\"These agents are never going to check the code into production. That is still the human&#x27;s responsibility,\" Singh emphasized. \"You are still, as an engineer, responsible for the code you&#x27;re checking in, whether it&#x27;s generated by you or by an agent working autonomously.\"What frontier agents mean for the future of software engineering jobsThe announcement inevitably raises concerns about the impact on software engineering jobs. Singh pushed back against the notion that frontier agents will replace developers, framing them instead as tools that amplify human capabilities.\"Software engineering is craft. What&#x27;s changing is not, &#x27;Hey, agents are doing all the work.&#x27; The craft of software engineering is changing—how you use agents, how do you set up your code base, how do you set up your prompts, how do you set up your rules, how do you set up your knowledge bases so that agents can be effective,\" he said.Singh noted that senior engineers who had drifted away from hands-on coding are now writing more code than ever. \"It&#x27;s actually easier for them to become software engineers,\" he said.He pointed to an internal example where a team completed a project in 78 days that would have taken 18 months using traditional practices. \"Because they were able to use AI. And the thing that made it work was not just the fact that they were using AI, but how they organized and set up their practices of how they built that software were maximized around that.\"How Amazon plans to make AI-generated code more trustworthy over timeSingh outlined several areas where frontier agents will evolve over the coming years. Multi-agent architectures, where systems of specialized agents coordinate to solve complex problems, represent a major frontier. So does the integration of formal verification techniques to increase confidence in AI-generated code.AWS recently introduced property-based testing in Kiro, which uses automated reasoning to extract testable properties from specifications and generate thousands of test scenarios automatically.\"If you have a shopping cart application, every way an order can be canceled, and how it might be canceled, and the way refunds are handled in Germany versus the US—if you&#x27;re writing a unit test, maybe two, Germany and US, but now, because you have this property-based testing approach, your agent can create a scenario for every country you operate in and test all of them automatically for you,\" Singh explained.Building trust in autonomous systems remains the central challenge. \"Right now you still require tons of human guardrails at every step to make sure that the right thing happens. And as we get better at these techniques, you will use less and less, and you&#x27;ll be able to trust the agents a lot more,\" he said.Amazon&#x27;s bigger bet on autonomous AI stretches far beyond writing codeThe frontier agents announcement arrived alongside a cascade of other news at re:Invent 2025. AWS kicked off the conference with major announcements on agentic AI capabilities, customer service innovations, and multicloud networking.Amazon expanded its Nova portfolio with four new models delivering industry-leading price-performance across reasoning, multimodal processing, conversational AI, code generation, and agentic tasks. Nova Forge pioneers \"open training,\" giving organizations access to pre-trained model checkpoints and the ability to blend proprietary data with Amazon Nova-curated datasets.AWS also added 18 new open weight models to Amazon Bedrock, reinforcing its commitment to offering a broad selection of fully managed models from leading AI providers. The launch includes new models from Mistral AI, Google&#x27;s Gemma 3, MiniMax&#x27;s M2, NVIDIA&#x27;s Nemotron, and OpenAI&#x27;s GPT OSS Safeguard.On the infrastructure side, Amazon EC2 Trn3 UltraServers, powered by AWS&#x27;s first 3nm AI chip, pack up to 144 Trainium3 chips into a single integrated system, delivering up to 4.4x more compute performance and 4x greater energy efficiency than the previous generation. AWS AI Factories provides enterprises and government organizations with dedicated AWS AI infrastructure deployed in their own data centers, combining NVIDIA GPUs, Trainium chips, AWS networking, and AI services like Amazon Bedrock and SageMaker AI.All three frontier agents launched in preview on Tuesday. Pricing will be announced when the services reach general availability.Singh made clear the company sees applications far beyond coding. \"These are the first frontier agents we are releasing, and they&#x27;re in the software development lifecycle,\" he said. \"The problems and use cases for frontier agents—these agents that are long running, capable of autonomy, thinking, always learning and improving—can be applied to many, many domains.\"Amazon, after all, operates satellite networks, runs robotics warehouses, and manages one of the world&#x27;s largest e-commerce platforms. If autonomous agents can learn to write code on their own, the company is betting they can eventually learn to do just about anything else.",
          "feed_position": 0,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/4DAwyP4OahDixwCOgmDRK0/8c301172d603674eb96b8f67008faf53/nuneybits_Vector_art_of_glowing-code_cloud_4880d34c-2130-4612-92b4-ff55b2bb0255.webp?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/mistral-launches-mistral-3-a-family-of-open-models-designed-to-run-on",
          "published_at": "Tue, 02 Dec 2025 15:00:00 GMT",
          "title": "Mistral launches Mistral 3, a family of open models designed to run on laptops, drones, and edge devices",
          "standfirst": "Mistral AI, Europe&#x27;s most prominent artificial intelligence startup, is releasing its most ambitious product suite to date: a family of 10 open-source models designed to run everywhere from smartphones and autonomous drones to enterprise cloud systems, marking a major escalation in the company&#x27;s challenge to both U.S. tech giants and surging Chinese competitors.The Mistral 3 family, launching today, includes a new flagship model called Mistral Large 3 and a suite of smaller \"Ministral 3\" models optimized for edge computing applications. All models will be released under the permissive Apache 2.0 license, allowing unrestricted commercial use — a sharp contrast to the closed systems offered by OpenAI, Google, and Anthropic.The release is a pointed bet by Mistral that the future of artificial intelligence lies not in building ever-larger proprietary systems, but in offering businesses maximum flexibility to customize and deploy AI tailored to their specific needs, often using smaller models that can run without cloud connectivity.\"The gap between closed and open source is getting smaller, because more and more people are contributing to open source, which is great,\" Guillaume Lample, Mistral&#x27;s chief scientist and co-founder, said in an exclusive interview with VentureBeat. \"We are catching up fast.\"Why Mistral is choosing flexibility over frontier performance in the AI raceThe strategic calculus behind Mistral 3 diverges sharply from recent model releases by industry leaders. While OpenAI, Google, and Anthropic have focused recent launches on increasingly capable \"agentic\" systems — AI that can autonomously execute complex multi-step tasks — Mistral is prioritizing breadth, efficiency, and what Lample calls \"distributed intelligence.\"Mistral Large 3, the flagship model, employs a Mixture of Experts architecture with 41 billion active parameters drawn from a total pool of 675 billion parameters. The model can process both text and images, handles context windows up to 256,000 tokens, and was trained with particular emphasis on non-English languages — a rarity among frontier AI systems.\"Most AI labs focus on their native language, but Mistral Large 3 was trained on a wide variety of languages, making advanced AI useful for billions who speak different native languages,\" the company said in a statement reviewed ahead of the announcement.But the more significant departure lies in the Ministral 3 lineup: nine compact models across three sizes (14 billion, 8 billion, and 3 billion parameters) and three variants tailored for different use cases. Each variant serves a distinct purpose: base models for extensive customization, instruction-tuned models for general chat and task completion, and reasoning-optimized models for complex logic requiring step-by-step deliberation.The smallest Ministral 3 models can run on devices with as little as 4 gigabytes of video memory using 4-bit quantization — making frontier AI capabilities accessible on standard laptops, smartphones, and embedded systems without requiring expensive cloud infrastructure or even internet connectivity. This approach reflects Mistral&#x27;s belief that AI&#x27;s next evolution will be defined not by sheer scale, but by ubiquity: models small enough to run on drones, in vehicles, in robots, and on consumer devices.How fine-tuned small models beat expensive large models for enterprise customersLample&#x27;s comments reveal a business model fundamentally different from that of closed-source competitors. Rather than competing primarily on benchmark performance, Mistral is targeting enterprise customers frustrated by the cost and inflexibility of proprietary systems.\"Sometimes customers say, &#x27;Is there a use case where the best closed-source model isn&#x27;t working?&#x27; If that&#x27;s the case, then they&#x27;re essentially stuck,\" Lample explained. \"There&#x27;s nothing they can do. It&#x27;s the best model available, and it&#x27;s not working out of the box.\"This is where Mistral&#x27;s approach diverges. When a generic model fails, the company deploys engineering teams to work directly with customers, analyzing specific problems, creating synthetic training data, and fine-tuning smaller models to outperform larger general-purpose systems on narrow tasks.\"In more than 90% of cases, a small model can do the job, especially if it&#x27;s fine-tuned. It doesn&#x27;t have to be a model with hundreds of billions of parameters, just a 14-billion or 24-billion parameter model,\" Lample said. \"So it&#x27;s not only much cheaper, but also faster, plus you have all the benefits: you don&#x27;t need to worry about privacy, latency, reliability, and so on.\"The economic argument is compelling. Multiple enterprise customers have approached Mistral after building prototypes with expensive closed-source models, only to find deployment costs prohibitive at scale, according to Lample.\"They come back to us a couple of months later because they realize, &#x27;We built this prototype, but it&#x27;s way too slow and way too expensive,&#x27;\" he said.Where Mistral 3 fits in the increasingly crowded open-source AI marketMistral&#x27;s release comes amid fierce competition on multiple fronts. OpenAI recently released GPT-5.1 with enhanced agentic capabilities. Google launched Gemini 3 with improved multimodal understanding. Anthropic released Opus 4.5 on the same day as this interview, with similar agent-focused features.But Lample argues those comparisons miss the point. \"It&#x27;s a little bit behind. But I think what matters is that we are catching up fast,\" he acknowledged regarding performance against closed models. \"I think we are maybe playing a strategic long game.\"That long game involves a different competitive set: primarily open-source models from Chinese companies like DeepSeek and Alibaba&#x27;s Qwen series, which have made remarkable strides in recent months.Mistral differentiates itself through multilingual capabilities that extend far beyond English or Chinese, multimodal integration handling both text and images in a unified model, and what the company characterizes as superior customization through easier fine-tuning.\"One key difference with the models themselves is that we focused much more on multilinguality,\" Lample said. \"If you look at all the top models from [Chinese competitors], they&#x27;re all text-only. They have visual models as well, but as separate systems. We wanted to integrate everything into a single model.\"The multilingual emphasis aligns with Mistral&#x27;s broader positioning as a European AI champion focused on digital sovereignty — the principle that organizations and nations should maintain control over their AI infrastructure and data.Building beyond models: Mistral&#x27;s full-stack enterprise AI platform strategyMistral 3&#x27;s release builds on an increasingly comprehensive enterprise AI platform that extends well beyond model development. The company has assembled a full-stack offering that differentiates it from pure model providers.Recent product launches include Mistral Agents API, which combines language models with built-in connectors for code execution, web search, image generation, and persistent memory across conversations; Magistral, the company&#x27;s reasoning model designed for domain-specific, transparent, and multilingual reasoning; and Mistral Code, an AI-powered coding assistant bundling models, an in-IDE assistant, and local deployment options with enterprise tooling.The consumer-facing Le Chat assistant has been enhanced with Deep Research mode for structured research reports, voice capabilities, and Projects for organizing conversations into context-rich folders. More recently, Le Chat gained a connector directory with 20+ enterprise integrations powered by the Model Context Protocol (MCP), spanning tools like Databricks, Snowflake, GitHub, Atlassian, Asana, and Stripe.In October, Mistral unveiled AI Studio, a production AI platform providing observability, agent runtime, and AI registry capabilities to help enterprises track output changes, monitor usage, run evaluations, and fine-tune models using proprietary data.Mistral now positions itself as a full-stack, global enterprise AI company, offering not just models but an application-building layer through AI Studio, compute infrastructure, and forward-deployed engineers to help businesses realize return on investment.Why open source AI matters for customization, transparency and sovereigntyMistral&#x27;s commitment to open-source development under permissive licenses is both an ideological stance and a competitive strategy in an AI landscape increasingly dominated by closed systems.Lample elaborated on the practical benefits: \"I think something that people don&#x27;t realize — but our customers know this very well — is how much better any model can actually improve if you fine tune it on the task of interest. There&#x27;s a huge gap between a base model and one that&#x27;s fine-tuned for a specific task, and in many cases, it outperforms the closed-source model.\"The approach enables capabilities impossible with closed systems: organizations can fine-tune models on proprietary data that never leaves their infrastructure, customize architectures for specific workflows, and maintain complete transparency into how AI systems make decisions — critical for regulated industries like finance, healthcare, and defense.This positioning has attracted government and public sector partnerships. The company launched \"AI for Citizens\" in July 2025, an initiative to \"help States and public institutions strategically harness AI for their people by transforming public services\" and has secured strategic partnerships with France&#x27;s army and job agency, Luxembourg&#x27;s government, and various European public sector organizations.Mistral&#x27;s transatlantic AI collaboration goes beyond European bordersWhile Mistral is frequently characterized as Europe&#x27;s answer to OpenAI, the company views itself as a transatlantic collaboration rather than a purely European venture. The company has teams across both continents, with co-founders spending significant time with customers and partners in the United States, and these models are being trained in partnerships with U.S.-based teams and infrastructure providers.This transatlantic positioning may prove strategically important as geopolitical tensions around AI development intensify. The recent ASML investment, a €1.7 billion ($1.5 billion) funding round led by the Dutch semiconductor equipment manufacturer, signals deepening collaboration across the Western semiconductor and AI value chain at a moment when both Europe and the United States are seeking to reduce dependence on Chinese technology.Mistral&#x27;s investor base reflects this dynamic: the Series C round included participation from U.S. firms Andreessen Horowitz, General Catalyst, Lightspeed, and Index Ventures alongside European investors like France&#x27;s state-backed Bpifrance and global players like DST Global and Nvidia.Founded in May 2023 by former Google DeepMind and Meta researchers, Mistral has raised roughly $1.05 billion (€1 billion) in funding. The company was valued at $6 billion in a June 2024 Series B, then more than doubled its valuation in a September Series C.Can customization and efficiency beat raw performance in enterprise AI?The Mistral 3 release crystallizes a fundamental question facing the AI industry: Will enterprises ultimately prioritize the absolute cutting-edge capabilities of proprietary systems, or will they choose open, customizable alternatives that offer greater control, lower costs, and independence from big tech platforms?Mistral&#x27;s answer is unambiguous. The company is betting that as AI moves from prototype to production, the factors that matter most shift dramatically. Raw benchmark scores matter less than total cost of ownership. Slight performance edges matter less than the ability to fine-tune for specific workflows. Cloud-based convenience matters less than data sovereignty and edge deployment.It&#x27;s a wager with significant risks. Despite Lample&#x27;s optimism about closing the performance gap, Mistral&#x27;s models still trail the absolute frontier. The company&#x27;s revenue, while growing, reportedly remains modest relative to its nearly $14 billion valuation. And competition intensifies from both well-funded Chinese rivals making remarkable open-source progress and U.S. tech giants increasingly offering their own smaller, more efficient models.But if Mistral is right — if the future of AI looks less like a handful of cloud-based oracles and more like millions of specialized systems running everywhere from factory floors to smartphones — then the company has positioned itself at the center of that transformation.The release of Mistral 3 is the most comprehensive expression yet of that vision: 10 models, spanning every size category, optimized for every deployment scenario, available to anyone who wants to build with them.Whether \"distributed intelligence\" becomes the industry&#x27;s dominant paradigm or remains a compelling alternative serving a narrower market will determine not just Mistral&#x27;s fate, but the broader question of who controls the AI future — and whether that future will be open.For now, the race is on. And Mistral is betting it can win not by building the biggest model, but by building everywhere else.",
          "content": "Mistral AI, Europe&#x27;s most prominent artificial intelligence startup, is releasing its most ambitious product suite to date: a family of 10 open-source models designed to run everywhere from smartphones and autonomous drones to enterprise cloud systems, marking a major escalation in the company&#x27;s challenge to both U.S. tech giants and surging Chinese competitors.The Mistral 3 family, launching today, includes a new flagship model called Mistral Large 3 and a suite of smaller \"Ministral 3\" models optimized for edge computing applications. All models will be released under the permissive Apache 2.0 license, allowing unrestricted commercial use — a sharp contrast to the closed systems offered by OpenAI, Google, and Anthropic.The release is a pointed bet by Mistral that the future of artificial intelligence lies not in building ever-larger proprietary systems, but in offering businesses maximum flexibility to customize and deploy AI tailored to their specific needs, often using smaller models that can run without cloud connectivity.\"The gap between closed and open source is getting smaller, because more and more people are contributing to open source, which is great,\" Guillaume Lample, Mistral&#x27;s chief scientist and co-founder, said in an exclusive interview with VentureBeat. \"We are catching up fast.\"Why Mistral is choosing flexibility over frontier performance in the AI raceThe strategic calculus behind Mistral 3 diverges sharply from recent model releases by industry leaders. While OpenAI, Google, and Anthropic have focused recent launches on increasingly capable \"agentic\" systems — AI that can autonomously execute complex multi-step tasks — Mistral is prioritizing breadth, efficiency, and what Lample calls \"distributed intelligence.\"Mistral Large 3, the flagship model, employs a Mixture of Experts architecture with 41 billion active parameters drawn from a total pool of 675 billion parameters. The model can process both text and images, handles context windows up to 256,000 tokens, and was trained with particular emphasis on non-English languages — a rarity among frontier AI systems.\"Most AI labs focus on their native language, but Mistral Large 3 was trained on a wide variety of languages, making advanced AI useful for billions who speak different native languages,\" the company said in a statement reviewed ahead of the announcement.But the more significant departure lies in the Ministral 3 lineup: nine compact models across three sizes (14 billion, 8 billion, and 3 billion parameters) and three variants tailored for different use cases. Each variant serves a distinct purpose: base models for extensive customization, instruction-tuned models for general chat and task completion, and reasoning-optimized models for complex logic requiring step-by-step deliberation.The smallest Ministral 3 models can run on devices with as little as 4 gigabytes of video memory using 4-bit quantization — making frontier AI capabilities accessible on standard laptops, smartphones, and embedded systems without requiring expensive cloud infrastructure or even internet connectivity. This approach reflects Mistral&#x27;s belief that AI&#x27;s next evolution will be defined not by sheer scale, but by ubiquity: models small enough to run on drones, in vehicles, in robots, and on consumer devices.How fine-tuned small models beat expensive large models for enterprise customersLample&#x27;s comments reveal a business model fundamentally different from that of closed-source competitors. Rather than competing primarily on benchmark performance, Mistral is targeting enterprise customers frustrated by the cost and inflexibility of proprietary systems.\"Sometimes customers say, &#x27;Is there a use case where the best closed-source model isn&#x27;t working?&#x27; If that&#x27;s the case, then they&#x27;re essentially stuck,\" Lample explained. \"There&#x27;s nothing they can do. It&#x27;s the best model available, and it&#x27;s not working out of the box.\"This is where Mistral&#x27;s approach diverges. When a generic model fails, the company deploys engineering teams to work directly with customers, analyzing specific problems, creating synthetic training data, and fine-tuning smaller models to outperform larger general-purpose systems on narrow tasks.\"In more than 90% of cases, a small model can do the job, especially if it&#x27;s fine-tuned. It doesn&#x27;t have to be a model with hundreds of billions of parameters, just a 14-billion or 24-billion parameter model,\" Lample said. \"So it&#x27;s not only much cheaper, but also faster, plus you have all the benefits: you don&#x27;t need to worry about privacy, latency, reliability, and so on.\"The economic argument is compelling. Multiple enterprise customers have approached Mistral after building prototypes with expensive closed-source models, only to find deployment costs prohibitive at scale, according to Lample.\"They come back to us a couple of months later because they realize, &#x27;We built this prototype, but it&#x27;s way too slow and way too expensive,&#x27;\" he said.Where Mistral 3 fits in the increasingly crowded open-source AI marketMistral&#x27;s release comes amid fierce competition on multiple fronts. OpenAI recently released GPT-5.1 with enhanced agentic capabilities. Google launched Gemini 3 with improved multimodal understanding. Anthropic released Opus 4.5 on the same day as this interview, with similar agent-focused features.But Lample argues those comparisons miss the point. \"It&#x27;s a little bit behind. But I think what matters is that we are catching up fast,\" he acknowledged regarding performance against closed models. \"I think we are maybe playing a strategic long game.\"That long game involves a different competitive set: primarily open-source models from Chinese companies like DeepSeek and Alibaba&#x27;s Qwen series, which have made remarkable strides in recent months.Mistral differentiates itself through multilingual capabilities that extend far beyond English or Chinese, multimodal integration handling both text and images in a unified model, and what the company characterizes as superior customization through easier fine-tuning.\"One key difference with the models themselves is that we focused much more on multilinguality,\" Lample said. \"If you look at all the top models from [Chinese competitors], they&#x27;re all text-only. They have visual models as well, but as separate systems. We wanted to integrate everything into a single model.\"The multilingual emphasis aligns with Mistral&#x27;s broader positioning as a European AI champion focused on digital sovereignty — the principle that organizations and nations should maintain control over their AI infrastructure and data.Building beyond models: Mistral&#x27;s full-stack enterprise AI platform strategyMistral 3&#x27;s release builds on an increasingly comprehensive enterprise AI platform that extends well beyond model development. The company has assembled a full-stack offering that differentiates it from pure model providers.Recent product launches include Mistral Agents API, which combines language models with built-in connectors for code execution, web search, image generation, and persistent memory across conversations; Magistral, the company&#x27;s reasoning model designed for domain-specific, transparent, and multilingual reasoning; and Mistral Code, an AI-powered coding assistant bundling models, an in-IDE assistant, and local deployment options with enterprise tooling.The consumer-facing Le Chat assistant has been enhanced with Deep Research mode for structured research reports, voice capabilities, and Projects for organizing conversations into context-rich folders. More recently, Le Chat gained a connector directory with 20+ enterprise integrations powered by the Model Context Protocol (MCP), spanning tools like Databricks, Snowflake, GitHub, Atlassian, Asana, and Stripe.In October, Mistral unveiled AI Studio, a production AI platform providing observability, agent runtime, and AI registry capabilities to help enterprises track output changes, monitor usage, run evaluations, and fine-tune models using proprietary data.Mistral now positions itself as a full-stack, global enterprise AI company, offering not just models but an application-building layer through AI Studio, compute infrastructure, and forward-deployed engineers to help businesses realize return on investment.Why open source AI matters for customization, transparency and sovereigntyMistral&#x27;s commitment to open-source development under permissive licenses is both an ideological stance and a competitive strategy in an AI landscape increasingly dominated by closed systems.Lample elaborated on the practical benefits: \"I think something that people don&#x27;t realize — but our customers know this very well — is how much better any model can actually improve if you fine tune it on the task of interest. There&#x27;s a huge gap between a base model and one that&#x27;s fine-tuned for a specific task, and in many cases, it outperforms the closed-source model.\"The approach enables capabilities impossible with closed systems: organizations can fine-tune models on proprietary data that never leaves their infrastructure, customize architectures for specific workflows, and maintain complete transparency into how AI systems make decisions — critical for regulated industries like finance, healthcare, and defense.This positioning has attracted government and public sector partnerships. The company launched \"AI for Citizens\" in July 2025, an initiative to \"help States and public institutions strategically harness AI for their people by transforming public services\" and has secured strategic partnerships with France&#x27;s army and job agency, Luxembourg&#x27;s government, and various European public sector organizations.Mistral&#x27;s transatlantic AI collaboration goes beyond European bordersWhile Mistral is frequently characterized as Europe&#x27;s answer to OpenAI, the company views itself as a transatlantic collaboration rather than a purely European venture. The company has teams across both continents, with co-founders spending significant time with customers and partners in the United States, and these models are being trained in partnerships with U.S.-based teams and infrastructure providers.This transatlantic positioning may prove strategically important as geopolitical tensions around AI development intensify. The recent ASML investment, a €1.7 billion ($1.5 billion) funding round led by the Dutch semiconductor equipment manufacturer, signals deepening collaboration across the Western semiconductor and AI value chain at a moment when both Europe and the United States are seeking to reduce dependence on Chinese technology.Mistral&#x27;s investor base reflects this dynamic: the Series C round included participation from U.S. firms Andreessen Horowitz, General Catalyst, Lightspeed, and Index Ventures alongside European investors like France&#x27;s state-backed Bpifrance and global players like DST Global and Nvidia.Founded in May 2023 by former Google DeepMind and Meta researchers, Mistral has raised roughly $1.05 billion (€1 billion) in funding. The company was valued at $6 billion in a June 2024 Series B, then more than doubled its valuation in a September Series C.Can customization and efficiency beat raw performance in enterprise AI?The Mistral 3 release crystallizes a fundamental question facing the AI industry: Will enterprises ultimately prioritize the absolute cutting-edge capabilities of proprietary systems, or will they choose open, customizable alternatives that offer greater control, lower costs, and independence from big tech platforms?Mistral&#x27;s answer is unambiguous. The company is betting that as AI moves from prototype to production, the factors that matter most shift dramatically. Raw benchmark scores matter less than total cost of ownership. Slight performance edges matter less than the ability to fine-tune for specific workflows. Cloud-based convenience matters less than data sovereignty and edge deployment.It&#x27;s a wager with significant risks. Despite Lample&#x27;s optimism about closing the performance gap, Mistral&#x27;s models still trail the absolute frontier. The company&#x27;s revenue, while growing, reportedly remains modest relative to its nearly $14 billion valuation. And competition intensifies from both well-funded Chinese rivals making remarkable open-source progress and U.S. tech giants increasingly offering their own smaller, more efficient models.But if Mistral is right — if the future of AI looks less like a handful of cloud-based oracles and more like millions of specialized systems running everywhere from factory floors to smartphones — then the company has positioned itself at the center of that transformation.The release of Mistral 3 is the most comprehensive expression yet of that vision: 10 models, spanning every size category, optimized for every deployment scenario, available to anyone who wants to build with them.Whether \"distributed intelligence\" becomes the industry&#x27;s dominant paradigm or remains a compelling alternative serving a narrower market will determine not just Mistral&#x27;s fate, but the broader question of who controls the AI future — and whether that future will be open.For now, the race is on. And Mistral is betting it can win not by building the biggest model, but by building everywhere else.",
          "feed_position": 1,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/4Yxx8rUYmqPtp65edDIllA/0966fbacbe24440180ec28d1a3fce518/nuneybits_Retro_computer_with_an_M_on_the_screen_c962f72c-f352-412f-b782-dd91c03696b6.webp?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/ascentra-labs-raises-usd2-million-to-help-consultants-use-ai-instead-of-all",
          "published_at": "Tue, 02 Dec 2025 14:00:00 GMT",
          "title": "Ascentra Labs raises $2 million to help consultants use AI instead of all-night Excel marathons",
          "standfirst": "While artificial intelligence has stormed into law firms and accounting practices with billion-dollar startups like Harvey leading the charge, the global consulting industry—a $250 billion behemoth—has remained stubbornly analog. A London-based startup founded by former McKinsey consultants is betting $2 million that it can crack open this resistant market, one Excel spreadsheet at a time.Ascentra Labs announced Tuesday that it has closed a $2 million seed round led by NAP, a Berlin-based venture capital firm formerly known as Cavalry Ventures. The funding comes with participation from notable founder-angels including Alan Chang, chief executive of Fuse and former chief revenue officer at Revolut, and Fredrik Hjelm, chief executive of European e-scooter company Voi.The investment is modest by the standards of enterprise AI — a sector that has seen funding rounds routinely reach into the hundreds of millions. But Ascentra&#x27;s founders argue that their focused approach to a narrow but painful problem could give them an edge in a market where broad AI solutions have repeatedly failed to gain traction.Consultants spend countless hours on Excel survey analysis that even top firms haven&#x27;t automatedParitosh Devbhandari, Ascentra&#x27;s co-founder and chief executive, spent years at McKinsey & Company, including a stint at QuantumBlack, the firm&#x27;s AI and advanced analytics division. He knows intimately the late nights consultants spend wrestling with survey data—the kind of quantitative research that forms the backbone of private equity due diligence.\"Before starting the company, I was working at McKinsey, specifically on the private equity team,\" Devbhandari explained in an exclusive interview with VentureBeat. The work, he said, involves analyzing encoded survey responses from customers, suppliers, and market participants during potential acquisitions.\"Consultants typically spend a lot of time doing this in Excel,\" he said. \"One of the things that surprised me, having worked at a couple of different places, is that the workflow — even at the best firms — really isn&#x27;t that different from some of the boutiques. I always expected there would be some smarter way of doing things, and often there just isn&#x27;t.\"That gap between expectation and reality became the foundation for Ascentra. The company&#x27;s platform ingests raw survey data files and outputs formatted Excel workbooks complete with traceable formulas — the kind of deliverable a junior associate would spend hours constructing manually.AI has transformed legal work but consulting presents unique technical challenges that have blocked adoptionThe disparity between AI adoption in law versus consulting raises an obvious question: if the consulting market is so large and the workflows so manual, why hasn&#x27;t venture capital flooded the space the way it has legal tech?Devbhandari offered a frank assessment. \"It&#x27;s not like people haven&#x27;t tried,\" he said. \"The top of the funnel in our space is crowded. When we speak to our consulting clients, the partners say they get another pitch deck in their LinkedIn inbox or email every week—sometimes several. There are plenty of people trying.\"The barriers, he argued, are structural. Professional services firms move slowly on technology adoption, demanding extensive security credentials and customer references before granting even a pilot opportunity. \"I think that&#x27;s where 90% of startups in professional services, writ large, fall down,\" he said.But consulting presents unique technical challenges beyond the sales cycle. Unlike legal work, which largely involves text documents that modern large language models handle well, consulting spans multiple data modalities — PowerPoint presentations, Excel spreadsheets, Word documents — with information that can be tabular, graphical, or textual.\"You can have multiple formats of Excel in itself,\" Devbhandari noted. \"And that&#x27;s a big contrast to the legal space, where you could have a multi-purpose AI agent, or collection of agents, which can actually do a lot of the tasks that lawyers do day to day. Consulting is the opposite of that.\"Ascentra&#x27;s private equity focus reflects a calculated bet on repeatable workflowsAscentra&#x27;s strategy hinges on extreme specificity. Rather than attempting to automate the full spectrum of consulting work, the company focuses exclusively on survey analysis within private equity due diligence — a niche within a niche.The logic is both technical and commercial. Private equity work tends to be more standardized than other consulting engagements, with similar analyses recurring across deals. That repeatability makes automation feasible. It also positions Ascentra against a less formidable competitive set: even the largest consulting firms, Devbhandari claimed, lack dedicated internal tools for this particular workflow.\"Survey analysis automation is so specific that even the biggest and best firms haven&#x27;t developed anything in-house for it,\" he said.The company claims that three of the world&#x27;s top five consulting firms now use its platform, with early adopters reporting time savings of 60 to 80 percent on active due diligence projects. But there&#x27;s a notable caveat: Ascentra cannot publicly name any of these clients.\"It&#x27;s a very private industry, so at the moment, we can&#x27;t announce any clients publicly,\" Devbhandari acknowledged. \"What I can say is that we&#x27;re working with three of the top five consulting firms. We&#x27;ve passed pilots at multiple organizations and have submitted business cases for enterprise rollouts.\"Eliminating AI hallucinations becomes critical when billion-dollar deals hang in the balanceFor an AI company selling into quantitative workflows, accuracy is existential. Consultants delivering analysis to private equity clients face enormous pressure to be precise—a single error in a financial model can undermine credibility and, potentially, billion-dollar investment decisions.Devbhandari described this as Ascentra&#x27;s central design challenge. \"Consultants require a very, very high degree of fidelity when they&#x27;re doing their analysis,\" he said. \"So with quantitative data, even if it&#x27;s 95% accurate, they will revert to Excel because they know it, they trust it, and they don&#x27;t want there to be any margin for error.\"Ascentra&#x27;s technical approach attempts to address this by limiting where AI models operate within the workflow. The company uses GPT-based models from OpenAI to interpret and ingest incoming data, but the actual analysis relies on deterministic Python scripts that produce consistent, verifiable outputs.\"What&#x27;s different is the steps that follow are deterministic,\" Devbhandari explained. \"There&#x27;s no room for error. There&#x27;s no hallucinations, and the Excel writer that we&#x27;ve connected to the product on the back end converts this analysis into Excel formula, which are live and traceable, so consultants can get that assurance that they can follow along with the maths.\"Whether this hybrid approach delivers on its promise of eliminating hallucinations while maintaining useful AI capabilities will be tested as the platform scales across more complex use cases and client environments.Enterprise security certifications give Ascentra an edge over less prepared competitorsSelling software to major consulting firms requires clearing an unusually high security bar. These organizations handle sensitive client data across industries, and their vendor security assessments can take months to complete.Ascentra invested early in obtaining enterprise-grade certifications, a strategic choice that Devbhandari framed as essential table stakes. The company has achieved SOC 2 Type II and ISO 27001 certifications and claims to be under audit for ISO 42001, an emerging standard for AI management systems.Data handling policies also reflect the sensitivity of the target market. Client data is deleted within 30 to 45 days, depending on contractual terms, and Ascentra does not use customer data to train its models.There&#x27;s also an argument that survey data carries somewhat lower sensitivity than other consulting materials. \"Survey data is unique in consulting data because it&#x27;s collected during the course of a project, and it is market data,\" Devbhandari noted. \"You interview people in the market, and you collect a bunch of data in an Excel, as opposed to—you look at Rogo or some of the other finance AI startups—they use client data, so financials, which is confidential and strictly non-public.\"Per-project pricing aligns with how consulting firms actually spend moneyAscentra&#x27;s pricing model departs from the subscription-based approach that dominates enterprise software. The company charges on a per-project basis, a structure Devbhandari said aligns with how consulting firms allocate budgets.\"Project budgets are in consulting set on a per project basis,\" he explained. \"You&#x27;ll have central budgets which are for things like Microsoft, right, very central things that every team will use all of the time. And then you have project budgets which are for the teams that are using specific resources, teams or products nowadays.\"This approach may ease initial adoption by avoiding the need for central IT procurement approval, but it also introduces revenue unpredictability. The company&#x27;s success will depend on converting project-level usage into broader enterprise relationships—a path Devbhandari suggested is already underway through submitted business cases for enterprise rollouts.AI may not eliminate consulting jobs, but it will fundamentally transform what consultants doPerhaps the most interesting tension in Devbhandari&#x27;s vision concerns what AI ultimately means for consulting employment. He pushed back on predictions that AI will eliminate consulting jobs while simultaneously describing an industry on the cusp of fundamental transformation.\"People love to talk about how AI is going to remove the need for consultants, and I disagree,\" he said. \"Yes, the role will change, but I don&#x27;t think the industry goes away. I think the best solutions will come from people within the industry building products around the work they know.\"Yet he also painted a picture of dramatic change. \"At the moment, you have a big intake of graduates who just do—for the most part, you know, they have the strategic work as part of what they do, but they also have a lot of work in Excel and PowerPoint. I think in a few years&#x27; time, we&#x27;ll look back at these times and think, you know, very, very different.\"The honest answer, he acknowledged, is that no one truly knows how this plays out. \"I don&#x27;t think even AI leaders truly know what that looks like yet,\" he said of whether productivity gains will translate to more work or fewer workers.Ascentra plans to use seed funding to expand its U.S. presence and go-to-market teamThe $2 million will primarily fund Ascentra&#x27;s expansion into the United States, where more than 80 percent of its customers are already based. Devbhandari plans to relocate there personally as the company builds out go-to-market capabilities.\"One of the things that we&#x27;ve really noticed is that with consulting being an American industry, and I think America being a great place for innovation and trying new things, we&#x27;ve definitely drawn ourselves to the U.S.,\" he said. \"American hires are very expensive, and I&#x27;m sure that a lot of the raise will go towards that.\"The seed round represents a bet by NAP on what its co-founder Stefan Walter called an overdue disruption. \"While most knowledge work has been reshaped by new technology, consulting has remained stubbornly manual,\" Walter said. \"AI won&#x27;t replace consultants, but consultants using Ascentra might.\"The startup now faces the hard work of converting pilot wins into lasting enterprise contractsAscentra enters 2026 with momentum but no guarantee of success. The company must transform pilot programs at elite firms into sticky enterprise contracts — all while fending off the inevitable well-funded competitors who will flood into the space once the opportunity becomes undeniable. Its deliberately narrow focus on survey analysis provides a defensible beachhead, but expanding into adjacent workflows will require building entirely new products without sacrificing the domain expertise that Devbhandari argues is the company&#x27;s core advantage.Oliver Thurston, Ascentra&#x27;s co-founder and chief technology officer, who previously led machine learning at Mathison AI, offered a clear-eyed assessment of the challenge. \"Consulting workflows are uniquely complex and difficult to build products around,\" he said in a statement. \"It&#x27;s not surprising the space hasn&#x27;t changed yet. This will change though, and there&#x27;s no doubt that the industry is going to look completely different in five years&#x27; time.\"For now, Ascentra is placing a focused wager: that the consultants who once spent their nights formatting spreadsheets will be the ones who finally bring AI into an industry that has long resisted it. The irony is hard to miss. After years of advising Fortune 500 companies on digital transformation, consulting may finally have to take its own medicine.",
          "content": "While artificial intelligence has stormed into law firms and accounting practices with billion-dollar startups like Harvey leading the charge, the global consulting industry—a $250 billion behemoth—has remained stubbornly analog. A London-based startup founded by former McKinsey consultants is betting $2 million that it can crack open this resistant market, one Excel spreadsheet at a time.Ascentra Labs announced Tuesday that it has closed a $2 million seed round led by NAP, a Berlin-based venture capital firm formerly known as Cavalry Ventures. The funding comes with participation from notable founder-angels including Alan Chang, chief executive of Fuse and former chief revenue officer at Revolut, and Fredrik Hjelm, chief executive of European e-scooter company Voi.The investment is modest by the standards of enterprise AI — a sector that has seen funding rounds routinely reach into the hundreds of millions. But Ascentra&#x27;s founders argue that their focused approach to a narrow but painful problem could give them an edge in a market where broad AI solutions have repeatedly failed to gain traction.Consultants spend countless hours on Excel survey analysis that even top firms haven&#x27;t automatedParitosh Devbhandari, Ascentra&#x27;s co-founder and chief executive, spent years at McKinsey & Company, including a stint at QuantumBlack, the firm&#x27;s AI and advanced analytics division. He knows intimately the late nights consultants spend wrestling with survey data—the kind of quantitative research that forms the backbone of private equity due diligence.\"Before starting the company, I was working at McKinsey, specifically on the private equity team,\" Devbhandari explained in an exclusive interview with VentureBeat. The work, he said, involves analyzing encoded survey responses from customers, suppliers, and market participants during potential acquisitions.\"Consultants typically spend a lot of time doing this in Excel,\" he said. \"One of the things that surprised me, having worked at a couple of different places, is that the workflow — even at the best firms — really isn&#x27;t that different from some of the boutiques. I always expected there would be some smarter way of doing things, and often there just isn&#x27;t.\"That gap between expectation and reality became the foundation for Ascentra. The company&#x27;s platform ingests raw survey data files and outputs formatted Excel workbooks complete with traceable formulas — the kind of deliverable a junior associate would spend hours constructing manually.AI has transformed legal work but consulting presents unique technical challenges that have blocked adoptionThe disparity between AI adoption in law versus consulting raises an obvious question: if the consulting market is so large and the workflows so manual, why hasn&#x27;t venture capital flooded the space the way it has legal tech?Devbhandari offered a frank assessment. \"It&#x27;s not like people haven&#x27;t tried,\" he said. \"The top of the funnel in our space is crowded. When we speak to our consulting clients, the partners say they get another pitch deck in their LinkedIn inbox or email every week—sometimes several. There are plenty of people trying.\"The barriers, he argued, are structural. Professional services firms move slowly on technology adoption, demanding extensive security credentials and customer references before granting even a pilot opportunity. \"I think that&#x27;s where 90% of startups in professional services, writ large, fall down,\" he said.But consulting presents unique technical challenges beyond the sales cycle. Unlike legal work, which largely involves text documents that modern large language models handle well, consulting spans multiple data modalities — PowerPoint presentations, Excel spreadsheets, Word documents — with information that can be tabular, graphical, or textual.\"You can have multiple formats of Excel in itself,\" Devbhandari noted. \"And that&#x27;s a big contrast to the legal space, where you could have a multi-purpose AI agent, or collection of agents, which can actually do a lot of the tasks that lawyers do day to day. Consulting is the opposite of that.\"Ascentra&#x27;s private equity focus reflects a calculated bet on repeatable workflowsAscentra&#x27;s strategy hinges on extreme specificity. Rather than attempting to automate the full spectrum of consulting work, the company focuses exclusively on survey analysis within private equity due diligence — a niche within a niche.The logic is both technical and commercial. Private equity work tends to be more standardized than other consulting engagements, with similar analyses recurring across deals. That repeatability makes automation feasible. It also positions Ascentra against a less formidable competitive set: even the largest consulting firms, Devbhandari claimed, lack dedicated internal tools for this particular workflow.\"Survey analysis automation is so specific that even the biggest and best firms haven&#x27;t developed anything in-house for it,\" he said.The company claims that three of the world&#x27;s top five consulting firms now use its platform, with early adopters reporting time savings of 60 to 80 percent on active due diligence projects. But there&#x27;s a notable caveat: Ascentra cannot publicly name any of these clients.\"It&#x27;s a very private industry, so at the moment, we can&#x27;t announce any clients publicly,\" Devbhandari acknowledged. \"What I can say is that we&#x27;re working with three of the top five consulting firms. We&#x27;ve passed pilots at multiple organizations and have submitted business cases for enterprise rollouts.\"Eliminating AI hallucinations becomes critical when billion-dollar deals hang in the balanceFor an AI company selling into quantitative workflows, accuracy is existential. Consultants delivering analysis to private equity clients face enormous pressure to be precise—a single error in a financial model can undermine credibility and, potentially, billion-dollar investment decisions.Devbhandari described this as Ascentra&#x27;s central design challenge. \"Consultants require a very, very high degree of fidelity when they&#x27;re doing their analysis,\" he said. \"So with quantitative data, even if it&#x27;s 95% accurate, they will revert to Excel because they know it, they trust it, and they don&#x27;t want there to be any margin for error.\"Ascentra&#x27;s technical approach attempts to address this by limiting where AI models operate within the workflow. The company uses GPT-based models from OpenAI to interpret and ingest incoming data, but the actual analysis relies on deterministic Python scripts that produce consistent, verifiable outputs.\"What&#x27;s different is the steps that follow are deterministic,\" Devbhandari explained. \"There&#x27;s no room for error. There&#x27;s no hallucinations, and the Excel writer that we&#x27;ve connected to the product on the back end converts this analysis into Excel formula, which are live and traceable, so consultants can get that assurance that they can follow along with the maths.\"Whether this hybrid approach delivers on its promise of eliminating hallucinations while maintaining useful AI capabilities will be tested as the platform scales across more complex use cases and client environments.Enterprise security certifications give Ascentra an edge over less prepared competitorsSelling software to major consulting firms requires clearing an unusually high security bar. These organizations handle sensitive client data across industries, and their vendor security assessments can take months to complete.Ascentra invested early in obtaining enterprise-grade certifications, a strategic choice that Devbhandari framed as essential table stakes. The company has achieved SOC 2 Type II and ISO 27001 certifications and claims to be under audit for ISO 42001, an emerging standard for AI management systems.Data handling policies also reflect the sensitivity of the target market. Client data is deleted within 30 to 45 days, depending on contractual terms, and Ascentra does not use customer data to train its models.There&#x27;s also an argument that survey data carries somewhat lower sensitivity than other consulting materials. \"Survey data is unique in consulting data because it&#x27;s collected during the course of a project, and it is market data,\" Devbhandari noted. \"You interview people in the market, and you collect a bunch of data in an Excel, as opposed to—you look at Rogo or some of the other finance AI startups—they use client data, so financials, which is confidential and strictly non-public.\"Per-project pricing aligns with how consulting firms actually spend moneyAscentra&#x27;s pricing model departs from the subscription-based approach that dominates enterprise software. The company charges on a per-project basis, a structure Devbhandari said aligns with how consulting firms allocate budgets.\"Project budgets are in consulting set on a per project basis,\" he explained. \"You&#x27;ll have central budgets which are for things like Microsoft, right, very central things that every team will use all of the time. And then you have project budgets which are for the teams that are using specific resources, teams or products nowadays.\"This approach may ease initial adoption by avoiding the need for central IT procurement approval, but it also introduces revenue unpredictability. The company&#x27;s success will depend on converting project-level usage into broader enterprise relationships—a path Devbhandari suggested is already underway through submitted business cases for enterprise rollouts.AI may not eliminate consulting jobs, but it will fundamentally transform what consultants doPerhaps the most interesting tension in Devbhandari&#x27;s vision concerns what AI ultimately means for consulting employment. He pushed back on predictions that AI will eliminate consulting jobs while simultaneously describing an industry on the cusp of fundamental transformation.\"People love to talk about how AI is going to remove the need for consultants, and I disagree,\" he said. \"Yes, the role will change, but I don&#x27;t think the industry goes away. I think the best solutions will come from people within the industry building products around the work they know.\"Yet he also painted a picture of dramatic change. \"At the moment, you have a big intake of graduates who just do—for the most part, you know, they have the strategic work as part of what they do, but they also have a lot of work in Excel and PowerPoint. I think in a few years&#x27; time, we&#x27;ll look back at these times and think, you know, very, very different.\"The honest answer, he acknowledged, is that no one truly knows how this plays out. \"I don&#x27;t think even AI leaders truly know what that looks like yet,\" he said of whether productivity gains will translate to more work or fewer workers.Ascentra plans to use seed funding to expand its U.S. presence and go-to-market teamThe $2 million will primarily fund Ascentra&#x27;s expansion into the United States, where more than 80 percent of its customers are already based. Devbhandari plans to relocate there personally as the company builds out go-to-market capabilities.\"One of the things that we&#x27;ve really noticed is that with consulting being an American industry, and I think America being a great place for innovation and trying new things, we&#x27;ve definitely drawn ourselves to the U.S.,\" he said. \"American hires are very expensive, and I&#x27;m sure that a lot of the raise will go towards that.\"The seed round represents a bet by NAP on what its co-founder Stefan Walter called an overdue disruption. \"While most knowledge work has been reshaped by new technology, consulting has remained stubbornly manual,\" Walter said. \"AI won&#x27;t replace consultants, but consultants using Ascentra might.\"The startup now faces the hard work of converting pilot wins into lasting enterprise contractsAscentra enters 2026 with momentum but no guarantee of success. The company must transform pilot programs at elite firms into sticky enterprise contracts — all while fending off the inevitable well-funded competitors who will flood into the space once the opportunity becomes undeniable. Its deliberately narrow focus on survey analysis provides a defensible beachhead, but expanding into adjacent workflows will require building entirely new products without sacrificing the domain expertise that Devbhandari argues is the company&#x27;s core advantage.Oliver Thurston, Ascentra&#x27;s co-founder and chief technology officer, who previously led machine learning at Mathison AI, offered a clear-eyed assessment of the challenge. \"Consulting workflows are uniquely complex and difficult to build products around,\" he said in a statement. \"It&#x27;s not surprising the space hasn&#x27;t changed yet. This will change though, and there&#x27;s no doubt that the industry is going to look completely different in five years&#x27; time.\"For now, Ascentra is placing a focused wager: that the consultants who once spent their nights formatting spreadsheets will be the ones who finally bring AI into an industry that has long resisted it. The irony is hard to miss. After years of advising Fortune 500 companies on digital transformation, consulting may finally have to take its own medicine.",
          "feed_position": 2,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/3dciXMn96xuLKTtsZ90F0T/c956c93546100054ffbc0380bc0f0826/Ascentra_Labs_-_team.png?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/aws-goes-beyond-prompt-level-safety-with-automated-reasoning-in-agentcore",
          "published_at": "Tue, 02 Dec 2025 05:00:00 GMT",
          "title": "AWS goes beyond prompt-level safety with automated reasoning in AgentCore",
          "standfirst": "AWS is leveraging automated reasoning, which uses math-based verification, to build out new capabilities in its Amazon Bedrock AgentCore platform as the company digs deeper into the agentic AI ecosystem. Announced during its annual re: Invent conference in Las Vegas, AWS is adding three new capabilities to AgentCore: \"policy,\" \"evaluations\" and \"episodic memory.\" The new features aim to give enterprises more control over agent behavior and performance. AWS also revealed what it calls “a new class of agents,\" or \"frontier agents,\" that are autonomous, scalable and independent. Swami Sivasubramanian, AWS VP for Agentic AI, told VentureBeat that many of AWS’s new features represent a shift in who becomes a builder. “We are actually on the cusp of a major tectonic transformation with AI, but agentic AI is truly starting to transform what is the art of the possible, and it is going to make this one of the most truly transforming technologies,” Sivasubramanian said. Policy agentsThe new policy capability helps enterprises reinforce guidelines even after the agent has already reasoned its response. AWS VP for AgentCore David Richardson told VentureBeat that the policy tool sits between the agent and the tools it calls, rather than being baked into the agent, as fine-tuning often is. The idea is to prevent an agent from violating enterprise rules and redirect it to re-evaluate its reasoning. Richardson gave the example of a customer service agent: A company would write a policy stating that the agent can grant a refund of up to $100, but for anything higher, the agent would need to bounce the customer to a human. He noted that it remains easy to subvert an agent&#x27;s reasoning loop through, for instance, prompt injection or poisoned data, leading agents to ignore guardrails. “There are always these prompt injection attacks where people try to subvert the reasoning of the agent to get the agent to do things it shouldn’t do,” Richardson said. “That’s why we implemented the policy outside of the agent, and it works using the automated reasoning capabilities that we’ve spent years building up to help customer define their capabilities.”AWS unveiled Automated Reasoning Checks on Bedrock at last year’s re: Invent. These use neurosymbolic AI, or math-based validation, to prove correctness. The tool applies mathematical proofs to models to confirm that it hasn’t hallucinated. AWS has been leaning heavily into neurosymbolic AI and automated reasoning, pushing for enterprise-grade security and safety in ways that differ from other AI model providers.Episodic memories and evaluationsThe two other new updates to AgentCore, \"evaluations\" and \"episodic memory,\" also give enterprises a better view of agent performance and give agents episodic memory.An enhancement of AgentCore memory, episodic memory refers to knowledge that agents tap into only occasionally, unlike longer-running preferences, which they have to refer back to constantly. Context window limits hamper some agents, so they sometimes forget information or conversations they haven’t tapped into for a while. “The idea is to help capture information that a user really would wish the agent remembered when they came back,\" said Richardson. \"For example, &#x27;what is their preferred seat on an airplane for family trips?&#x27; Or &#x27;what is the sort of price range they&#x27;re looking for?&#x27;\"Episodic memory differs from the previously shipped AgentCore memory because, instead of relying on maintaining short- and long-term memory, agents built on AgentCore can recall certain information based on triggers. This can eliminate the need for custom instructions.With AgentCore evaluations, organizations can use 13 pre-built evaluators or write their own. Developers can set alerts to warn them if agents begin to fail quality monitoring.Frontier agentsBut perhaps AWS&#x27;s strongest push into enterprise agentic AI is the release of frontier agents, or fully automated and independent agents that the company says can act as teammates with little direction. The concept is similar, if not identical, to those of more asynchronous agents from competitors like Google and OpenAI. However, AWS seems to be releasing more than just autonomous coding agents. Sivasubramanian called them a \"new class\" of agents, \"not only a step function change in what you can do today; they move from assisting with individual tasks to complex projects.\"The first is Kiro, an autonomous coding agent that has been in public preview since July. At the time, Kiro was billed as an alternative to vibe coding platforms like OpenAI’s Codex or Windsurf. Similar to Codex and Google’s myriad asynchronous coding agents, including Jules, Kiro can code, undertake reviews, fix bugs independently and determine the tasks it needs to accomplish. AWS security agent, meanwhile, embeds deep security expertise into applications from the start. The company said in a press release that users “define security standards once and AWS security agent automatically validates them across your applications during its review — helping teams address the risks that matter to their business, not generic checklists.”The AWS DevOps agent will help developers, especially those on call, proactively find system breaks or bugs. It can respond to incidents using its knowledge of the application or service. It also acknowledges the relationships between the application and the tools it taps, such as Amazon CloudWatch, Datadog and Splunk, to trace the root cause of the issue. Enterprises are interested in deploying agents and, eventually, bringing more autonomous agents into their workflows. And, while companies like AWS continue to bolster these agents with security and control, organizations are slowly figuring out how to connect them all.",
          "content": "AWS is leveraging automated reasoning, which uses math-based verification, to build out new capabilities in its Amazon Bedrock AgentCore platform as the company digs deeper into the agentic AI ecosystem. Announced during its annual re: Invent conference in Las Vegas, AWS is adding three new capabilities to AgentCore: \"policy,\" \"evaluations\" and \"episodic memory.\" The new features aim to give enterprises more control over agent behavior and performance. AWS also revealed what it calls “a new class of agents,\" or \"frontier agents,\" that are autonomous, scalable and independent. Swami Sivasubramanian, AWS VP for Agentic AI, told VentureBeat that many of AWS’s new features represent a shift in who becomes a builder. “We are actually on the cusp of a major tectonic transformation with AI, but agentic AI is truly starting to transform what is the art of the possible, and it is going to make this one of the most truly transforming technologies,” Sivasubramanian said. Policy agentsThe new policy capability helps enterprises reinforce guidelines even after the agent has already reasoned its response. AWS VP for AgentCore David Richardson told VentureBeat that the policy tool sits between the agent and the tools it calls, rather than being baked into the agent, as fine-tuning often is. The idea is to prevent an agent from violating enterprise rules and redirect it to re-evaluate its reasoning. Richardson gave the example of a customer service agent: A company would write a policy stating that the agent can grant a refund of up to $100, but for anything higher, the agent would need to bounce the customer to a human. He noted that it remains easy to subvert an agent&#x27;s reasoning loop through, for instance, prompt injection or poisoned data, leading agents to ignore guardrails. “There are always these prompt injection attacks where people try to subvert the reasoning of the agent to get the agent to do things it shouldn’t do,” Richardson said. “That’s why we implemented the policy outside of the agent, and it works using the automated reasoning capabilities that we’ve spent years building up to help customer define their capabilities.”AWS unveiled Automated Reasoning Checks on Bedrock at last year’s re: Invent. These use neurosymbolic AI, or math-based validation, to prove correctness. The tool applies mathematical proofs to models to confirm that it hasn’t hallucinated. AWS has been leaning heavily into neurosymbolic AI and automated reasoning, pushing for enterprise-grade security and safety in ways that differ from other AI model providers.Episodic memories and evaluationsThe two other new updates to AgentCore, \"evaluations\" and \"episodic memory,\" also give enterprises a better view of agent performance and give agents episodic memory.An enhancement of AgentCore memory, episodic memory refers to knowledge that agents tap into only occasionally, unlike longer-running preferences, which they have to refer back to constantly. Context window limits hamper some agents, so they sometimes forget information or conversations they haven’t tapped into for a while. “The idea is to help capture information that a user really would wish the agent remembered when they came back,\" said Richardson. \"For example, &#x27;what is their preferred seat on an airplane for family trips?&#x27; Or &#x27;what is the sort of price range they&#x27;re looking for?&#x27;\"Episodic memory differs from the previously shipped AgentCore memory because, instead of relying on maintaining short- and long-term memory, agents built on AgentCore can recall certain information based on triggers. This can eliminate the need for custom instructions.With AgentCore evaluations, organizations can use 13 pre-built evaluators or write their own. Developers can set alerts to warn them if agents begin to fail quality monitoring.Frontier agentsBut perhaps AWS&#x27;s strongest push into enterprise agentic AI is the release of frontier agents, or fully automated and independent agents that the company says can act as teammates with little direction. The concept is similar, if not identical, to those of more asynchronous agents from competitors like Google and OpenAI. However, AWS seems to be releasing more than just autonomous coding agents. Sivasubramanian called them a \"new class\" of agents, \"not only a step function change in what you can do today; they move from assisting with individual tasks to complex projects.\"The first is Kiro, an autonomous coding agent that has been in public preview since July. At the time, Kiro was billed as an alternative to vibe coding platforms like OpenAI’s Codex or Windsurf. Similar to Codex and Google’s myriad asynchronous coding agents, including Jules, Kiro can code, undertake reviews, fix bugs independently and determine the tasks it needs to accomplish. AWS security agent, meanwhile, embeds deep security expertise into applications from the start. The company said in a press release that users “define security standards once and AWS security agent automatically validates them across your applications during its review — helping teams address the risks that matter to their business, not generic checklists.”The AWS DevOps agent will help developers, especially those on call, proactively find system breaks or bugs. It can respond to incidents using its knowledge of the application or service. It also acknowledges the relationships between the application and the tools it taps, such as Amazon CloudWatch, Datadog and Splunk, to trace the root cause of the issue. Enterprises are interested in deploying agents and, eventually, bringing more autonomous agents into their workflows. And, while companies like AWS continue to bolster these agents with security and control, organizations are slowly figuring out how to connect them all.",
          "feed_position": 3,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/4P7dxndG2uP4r14FVxrdBV/9e194ade83471023c872b410f5a95b9a/crimedy7_illustration_of_a_robot_judge_in_a_courtroom_--ar_16_bd4821d0-5f6a-4492-aa30-d2092fd27ce0_0.png?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/with-ai-browsers-creating-fresh-security-and-privacy-concerns-norton-neo-is",
          "published_at": "Tue, 02 Dec 2025 05:00:00 GMT",
          "title": "With AI browsers creating fresh security and privacy concerns, Norton Neo is the first to enter with a safety-first approach",
          "standfirst": "The AI browser wars are heating up. OpenAI and other AI companies like Perplexity have gotten a lot of attention with their new AI-first and agentic browsers. They&#x27;re being positioned as direct competition to Google, which currently holds a 70% share of the market with its Chrome browser. As the incumbent, Google has been slower to respond to the shift toward AI search — integrating Gemini into Chrome, is widely seen as playing catch-up to competitors that were AI-first from day one.It&#x27;s understandable, as a $100 billion business is an enormous, unwieldy beast to pivot. That leaves space for the new guys to maneuver, who are essentially starting with blank slates, and free reign for innovation.Enter Neo, released for worldwide general availability today — the next step in Norton’s AI innovation journey, building on its leadership in cyber safety and its bid to deliver the world’s first safe, zero-prompt AI browser. From the beginning, the minds behind Neo made a deliberate choice to focus on a proactive AI assistant rather than chase today’s agentic trends. Even enthusiasts willing to tolerate the risks face too much unpredictability, along with new safety and privacy concerns.Howie Xu, chief AI & innovation officer at Gen, describes Neo as a browser built to help before you ask — delivering on-page, in-flow support through summaries, reminders, and context-aware suggestions without prompts or extra steps.\"It&#x27;s like having a highly intelligent assistant sitting next to me, helping me absorb and process information much more broadly, much faster, much deeper,\" Xu says. \"That assistant is there when you&#x27;re reading, when you&#x27;re researching, when you&#x27;re working on an online project. And based on your interests and browsing, your assistant can help you at every step.\"Borrowing from Norton&#x27;s unique consumer security expertise, privacy and safety has also been integrated from the ground up.\"What makes us unique is that we&#x27;re giving people both peace of mind and AI functionality at the same time,\" Xu explains. \"Norton’s roots are in security. We’re the only game in town that built an AI native browser from the ground up with safety and privacy at its core —one that won’t exploit or use your data for training.The zero-prompt differenceComet (Perplexity) and Atlas (OpenAI) were built by chat-first companies that assume users will actively ask questions. But getting value from AI takes cognitive effort: you need to know what to ask, shift into “question mode,” and understand what the model can actually do. Asking a question isn’t the hard part; realizing what to ask requires meta-cognition — awareness of what you don’t know — which makes turning to ChatGPT in the middle of browsing feel harder than it should.Neo takes the opposite approach. Instead of waiting for you to prompt it, it acts first — offering summaries, reminders, relevant news, and even questions you’re likely to explore. \"Based on my browsing interests, Neo reminds me of events I might want to attend, surfaces personalized news, and presents pre-generated questions that I actually want to explore,\" Xu explains. \"In other words, I’ve never had to formulate a single prompt — I’m simply clicking on insights the AI has already anticipated for me as if I had been prompting.”Because most people don’t know the boundaries of AI technology or how to phrase effective prompts, expecting them to drive the interaction is unrealistic for many people.\"We decided to shift the burden away from people. You can still ask questions, of course, but we’re designing for those who want less cognitive load and prefer AI to take the first step,\" he says. Much like the recommendations that surface on any news or retail site, Neo leverages browsing context to surface the right content at the right moment.Neo can summarize a page and anticipate questions based on your interests and behaviors. With permission, it can also create detailed reminders — for example, noticing repeat visits to Formula 1 websites and prompting you about upcoming races. Control stays with the person using Neo: if an interest fades, they can remove it from Neo’s Configurable Memory.Because Neo’s browsing history and preferences are stored locally and securely, it can customize prompts, insights, and suggestions — from calendar nudges to news recommendations to suggested questions in the Neo Chat interface. The result is an AI-powered browser that gives people the benefits of AI without typing prompts. Inline actions like “Summary,” “Add to calendar?,” “Resume where you left off,” and “Price dropped” make browsing feel faster and lighter, without extra steps.A calm-by-design experience grounded in security“Calm by design” has guided Neo’s development, and for Xu that comes down to three things: control, privacy, and security, all within a clean, streamlined experience that makes browsing faster and easier.Rooted in Norton’s decades of security expertise, Neo’s calm experience starts with privacy and protection. Xu views it as the bedrock of Neo’s approach: the company never knows what you’re doing, because all personal data stays on the device unless explicitly permitted otherwise. Norton-backed security practices suppress prompt-injection risks common in other AI browsers, local processing keeps sensitive information contained, and scoped sync ensures only user-approved context carries across devices.Norton also brings deep web intelligence: decades of scanning the vast majority of the internet and evolving antivirus capabilities that now understand both static and runtime web content. That real-time insight allows Neo’s built in antivirus, anti-phishing, and anti-scam technology to detect and shut down malicious behavior and content the moment it appears.\"When we think about calm, what we really mean is delivering value in a consistent way, in a reliable way, in a way that people can predict, so people have peace of mind,\" Xu says. \"This is very different from the design of the agentic browsers out there where the result is simply unpredictable, not to mention the associated latency and overhead. I believe consistency is a necessity for us to push an AI browser to a mass population. We have some flashy capabilities too, but our primary goal is that people can just use it in their daily lives without ever having to worry about all the vulnerabilities that most agentic browsers introduce. Since we&#x27;re calm, reliable and safe by design, we believe we’ll win the hearts of a mass audience.\"For anyone watching the rapid shift toward AI-powered browsing, Neo shows how Norton is fusing assistance, security, and zero-prompt design into a single experience. See it in action at neobrowser.ai.Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "content": "The AI browser wars are heating up. OpenAI and other AI companies like Perplexity have gotten a lot of attention with their new AI-first and agentic browsers. They&#x27;re being positioned as direct competition to Google, which currently holds a 70% share of the market with its Chrome browser. As the incumbent, Google has been slower to respond to the shift toward AI search — integrating Gemini into Chrome, is widely seen as playing catch-up to competitors that were AI-first from day one.It&#x27;s understandable, as a $100 billion business is an enormous, unwieldy beast to pivot. That leaves space for the new guys to maneuver, who are essentially starting with blank slates, and free reign for innovation.Enter Neo, released for worldwide general availability today — the next step in Norton’s AI innovation journey, building on its leadership in cyber safety and its bid to deliver the world’s first safe, zero-prompt AI browser. From the beginning, the minds behind Neo made a deliberate choice to focus on a proactive AI assistant rather than chase today’s agentic trends. Even enthusiasts willing to tolerate the risks face too much unpredictability, along with new safety and privacy concerns.Howie Xu, chief AI & innovation officer at Gen, describes Neo as a browser built to help before you ask — delivering on-page, in-flow support through summaries, reminders, and context-aware suggestions without prompts or extra steps.\"It&#x27;s like having a highly intelligent assistant sitting next to me, helping me absorb and process information much more broadly, much faster, much deeper,\" Xu says. \"That assistant is there when you&#x27;re reading, when you&#x27;re researching, when you&#x27;re working on an online project. And based on your interests and browsing, your assistant can help you at every step.\"Borrowing from Norton&#x27;s unique consumer security expertise, privacy and safety has also been integrated from the ground up.\"What makes us unique is that we&#x27;re giving people both peace of mind and AI functionality at the same time,\" Xu explains. \"Norton’s roots are in security. We’re the only game in town that built an AI native browser from the ground up with safety and privacy at its core —one that won’t exploit or use your data for training.The zero-prompt differenceComet (Perplexity) and Atlas (OpenAI) were built by chat-first companies that assume users will actively ask questions. But getting value from AI takes cognitive effort: you need to know what to ask, shift into “question mode,” and understand what the model can actually do. Asking a question isn’t the hard part; realizing what to ask requires meta-cognition — awareness of what you don’t know — which makes turning to ChatGPT in the middle of browsing feel harder than it should.Neo takes the opposite approach. Instead of waiting for you to prompt it, it acts first — offering summaries, reminders, relevant news, and even questions you’re likely to explore. \"Based on my browsing interests, Neo reminds me of events I might want to attend, surfaces personalized news, and presents pre-generated questions that I actually want to explore,\" Xu explains. \"In other words, I’ve never had to formulate a single prompt — I’m simply clicking on insights the AI has already anticipated for me as if I had been prompting.”Because most people don’t know the boundaries of AI technology or how to phrase effective prompts, expecting them to drive the interaction is unrealistic for many people.\"We decided to shift the burden away from people. You can still ask questions, of course, but we’re designing for those who want less cognitive load and prefer AI to take the first step,\" he says. Much like the recommendations that surface on any news or retail site, Neo leverages browsing context to surface the right content at the right moment.Neo can summarize a page and anticipate questions based on your interests and behaviors. With permission, it can also create detailed reminders — for example, noticing repeat visits to Formula 1 websites and prompting you about upcoming races. Control stays with the person using Neo: if an interest fades, they can remove it from Neo’s Configurable Memory.Because Neo’s browsing history and preferences are stored locally and securely, it can customize prompts, insights, and suggestions — from calendar nudges to news recommendations to suggested questions in the Neo Chat interface. The result is an AI-powered browser that gives people the benefits of AI without typing prompts. Inline actions like “Summary,” “Add to calendar?,” “Resume where you left off,” and “Price dropped” make browsing feel faster and lighter, without extra steps.A calm-by-design experience grounded in security“Calm by design” has guided Neo’s development, and for Xu that comes down to three things: control, privacy, and security, all within a clean, streamlined experience that makes browsing faster and easier.Rooted in Norton’s decades of security expertise, Neo’s calm experience starts with privacy and protection. Xu views it as the bedrock of Neo’s approach: the company never knows what you’re doing, because all personal data stays on the device unless explicitly permitted otherwise. Norton-backed security practices suppress prompt-injection risks common in other AI browsers, local processing keeps sensitive information contained, and scoped sync ensures only user-approved context carries across devices.Norton also brings deep web intelligence: decades of scanning the vast majority of the internet and evolving antivirus capabilities that now understand both static and runtime web content. That real-time insight allows Neo’s built in antivirus, anti-phishing, and anti-scam technology to detect and shut down malicious behavior and content the moment it appears.\"When we think about calm, what we really mean is delivering value in a consistent way, in a reliable way, in a way that people can predict, so people have peace of mind,\" Xu says. \"This is very different from the design of the agentic browsers out there where the result is simply unpredictable, not to mention the associated latency and overhead. I believe consistency is a necessity for us to push an AI browser to a mass population. We have some flashy capabilities too, but our primary goal is that people can just use it in their daily lives without ever having to worry about all the vulnerabilities that most agentic browsers introduce. Since we&#x27;re calm, reliable and safe by design, we believe we’ll win the hearts of a mass audience.\"For anyone watching the rapid shift toward AI-powered browsing, Neo shows how Norton is fusing assistance, security, and zero-prompt design into a single experience. See it in action at neobrowser.ai.Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.",
          "feed_position": 4,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/6bg1UyCoivNSgAKjhIspX5/551ac0fa54122ad6230dd1007626e22f/Neo_Light_Mode_with_logo.png?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/with-nova-forge-aws-gives-companies-a-path-to-build-foundation-class-models",
          "published_at": "Tue, 02 Dec 2025 04:00:00 GMT",
          "title": "With Nova Forge, AWS gives companies a path to build foundation-class models without GPUs",
          "standfirst": "Amazon Web Services (AWS) is leaning into the growing trend toward custom models with a new service that it says will let enterprises bring more personalization and internal knowledge. The move comes alongside the release of AWS&#x27;s new models as part of its Nova family, which expands the capabilities of its reasoning models.Nova 2 Lite, Nova 2 Pro, Nova 2 Sonic and Nova 2 Omni update the first Nova models AWS announced last year.Nova 2 Lite is a fast, cost-effective reasoning model optimized for everyday tasks that can process text, images and videos to generate text. Nova 2 Pro, which AWS said is its most intelligent reasoning model, can handle complex tasks such as coding agents, long-range planning and problem-solving. It can act as a “teacher” model for distillation projects. Nova 2 Sonic is a speech-to-speech model, while Nova 2 Omni enables organizations to generate both text and images from text, image and video inputs. Nova Act, AWS&#x27;s browser agent — announced as an experimental development kit in April — is also powered by the Nova 2 models and now available to customers. However, it is the custom model service, Nova Forge, that AWS is most excited about. The service gives customers the ability to introduce proprietary data to a pre-trained model without fear that the model will forget its previous training. Nova Forge allows enterprises to create custom, optimized versions of Nova models, which it calls “Novellas,” and bring them directly to its Amazon Bedrock platform. Custom model creation Enterprises are increasingly turning to model distillation or custom models, especially with many industries choosing to create foundation models with domain-specific knowledge. But these can often be out of reach for many companies, as not everyone can afford several Nvidia GPU H100s to build models from scratch. As a result, they turn to heavily fine-tuned open-source off-the-shelf models. “You just don&#x27;t have a great way to get a frontier model that deeply understands your data and your domain,\" AWS CEO Matt Garman said during his keynote speech at AWS’s annual re: Invent conference. \"But what if it was possible? What if you could integrate your data at the right time during the training of a frontier model, then create a proprietary model that was just for you?” Nova Forge employs what AWS calls “open training,” which allows developers to blend their proprietary data with an Amazon-curated dataset at every step of model development, with checkpoints during training. AWS said this means models will not regress on foundational capabilities, such as instruction following, while learning company-specific knowledge and instructions. Each “Novella” could be a custom version of Nova 2 Lite, with Nova’s full knowledge and reasoning power, but with domain-specificity. Right now, enterprises can only make Novellas from Nova 2 Lite, but many will expand to other Nova 2 models soon. Nova Forge also offers enterprises “reinforcement learning gyms.\" This allows them to train AI systems through their own environments with simulated scenarios to create smaller, faster models and access responsible AI toolkits. Once companies create their Novellas, they can bring them to Bedrock to build more applications and agents. One customer currently using Nova Forge is Reddit, which integrated its own data and community-specific knowledge into a model to build a moderation program. Nova Forge only works with Nova models, and AWS does not plan to bring in third-party open-source models hosted on Bedrock (for now).Nova 2 models in detailAWS said tens of thousands of companies now use its Nova models and the company expects the Nova 2 models to see the same adoption. “Nova 2 Lite delivers incredible price performance for many workloads that we actually see our customers wanting to deliver in production,” Garman said. “We think Nova 2 Lite will be the workhorse for many companies, while Pro will be for more complex tasks and for when you need your agents to be great.”In a press release, AWS said evaluations showed Nova 2 Lite performed “equal or better on 13 out of 15 benchmarks compared to Claude Haiku 4.5, equal or better on 11 out of 17 benchmarks compared to GPT-5 Mini and equal or better on 14 out of 18 benchmarks compared to Gemini Flash 2.5.”Users can adjust how much Nova 2 Lite shows its step-by-step thinking to balance costs with depth. Nova Pro 2 also performed well in benchmark testing compared to Claude Sonnet 4.5, GPT-5.1 and Gemini 2.5 Pro. This model works best for multi-document analysis, video reasoning, advanced math and agentic engineering tasks. AWS said in its press release that both Nova 2 Lite and Pro “have built-in grounding and code execution capabilities.”Nova 2 Sonic, the speech-to-speech model, generates human-like conversations and now supports multiple languages. The updated model has a 1-million-token context window, with more expressive voices and higher accuracy. The company said Sonic can even switch topics mid-conversation.Nova 2 Omni handles “up to 750,000 words, hours of audio, long videos and hundred-page documents, simultaneously analyzing entire product catalogs, testimonials, brand guidelines and video libraries at once.” “While there are no comparable models in the industry to Nova 2 Omni, it demonstrates strengths in public benchmarks of multimodal reasoning on documents, images, videos and audio, and can generate high-quality images similar to other leading image-generation models,” AWS said in its release.",
          "content": "Amazon Web Services (AWS) is leaning into the growing trend toward custom models with a new service that it says will let enterprises bring more personalization and internal knowledge. The move comes alongside the release of AWS&#x27;s new models as part of its Nova family, which expands the capabilities of its reasoning models.Nova 2 Lite, Nova 2 Pro, Nova 2 Sonic and Nova 2 Omni update the first Nova models AWS announced last year.Nova 2 Lite is a fast, cost-effective reasoning model optimized for everyday tasks that can process text, images and videos to generate text. Nova 2 Pro, which AWS said is its most intelligent reasoning model, can handle complex tasks such as coding agents, long-range planning and problem-solving. It can act as a “teacher” model for distillation projects. Nova 2 Sonic is a speech-to-speech model, while Nova 2 Omni enables organizations to generate both text and images from text, image and video inputs. Nova Act, AWS&#x27;s browser agent — announced as an experimental development kit in April — is also powered by the Nova 2 models and now available to customers. However, it is the custom model service, Nova Forge, that AWS is most excited about. The service gives customers the ability to introduce proprietary data to a pre-trained model without fear that the model will forget its previous training. Nova Forge allows enterprises to create custom, optimized versions of Nova models, which it calls “Novellas,” and bring them directly to its Amazon Bedrock platform. Custom model creation Enterprises are increasingly turning to model distillation or custom models, especially with many industries choosing to create foundation models with domain-specific knowledge. But these can often be out of reach for many companies, as not everyone can afford several Nvidia GPU H100s to build models from scratch. As a result, they turn to heavily fine-tuned open-source off-the-shelf models. “You just don&#x27;t have a great way to get a frontier model that deeply understands your data and your domain,\" AWS CEO Matt Garman said during his keynote speech at AWS’s annual re: Invent conference. \"But what if it was possible? What if you could integrate your data at the right time during the training of a frontier model, then create a proprietary model that was just for you?” Nova Forge employs what AWS calls “open training,” which allows developers to blend their proprietary data with an Amazon-curated dataset at every step of model development, with checkpoints during training. AWS said this means models will not regress on foundational capabilities, such as instruction following, while learning company-specific knowledge and instructions. Each “Novella” could be a custom version of Nova 2 Lite, with Nova’s full knowledge and reasoning power, but with domain-specificity. Right now, enterprises can only make Novellas from Nova 2 Lite, but many will expand to other Nova 2 models soon. Nova Forge also offers enterprises “reinforcement learning gyms.\" This allows them to train AI systems through their own environments with simulated scenarios to create smaller, faster models and access responsible AI toolkits. Once companies create their Novellas, they can bring them to Bedrock to build more applications and agents. One customer currently using Nova Forge is Reddit, which integrated its own data and community-specific knowledge into a model to build a moderation program. Nova Forge only works with Nova models, and AWS does not plan to bring in third-party open-source models hosted on Bedrock (for now).Nova 2 models in detailAWS said tens of thousands of companies now use its Nova models and the company expects the Nova 2 models to see the same adoption. “Nova 2 Lite delivers incredible price performance for many workloads that we actually see our customers wanting to deliver in production,” Garman said. “We think Nova 2 Lite will be the workhorse for many companies, while Pro will be for more complex tasks and for when you need your agents to be great.”In a press release, AWS said evaluations showed Nova 2 Lite performed “equal or better on 13 out of 15 benchmarks compared to Claude Haiku 4.5, equal or better on 11 out of 17 benchmarks compared to GPT-5 Mini and equal or better on 14 out of 18 benchmarks compared to Gemini Flash 2.5.”Users can adjust how much Nova 2 Lite shows its step-by-step thinking to balance costs with depth. Nova Pro 2 also performed well in benchmark testing compared to Claude Sonnet 4.5, GPT-5.1 and Gemini 2.5 Pro. This model works best for multi-document analysis, video reasoning, advanced math and agentic engineering tasks. AWS said in its press release that both Nova 2 Lite and Pro “have built-in grounding and code execution capabilities.”Nova 2 Sonic, the speech-to-speech model, generates human-like conversations and now supports multiple languages. The updated model has a 1-million-token context window, with more expressive voices and higher accuracy. The company said Sonic can even switch topics mid-conversation.Nova 2 Omni handles “up to 750,000 words, hours of audio, long videos and hundred-page documents, simultaneously analyzing entire product catalogs, testimonials, brand guidelines and video libraries at once.” “While there are no comparable models in the industry to Nova 2 Omni, it demonstrates strengths in public benchmarks of multimodal reasoning on documents, images, videos and audio, and can generate high-quality images similar to other leading image-generation models,” AWS said in its release.",
          "feed_position": 5,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/1GG1fDQ0xQTs9lrG0f4S7V/9682524eed92fdf4fbd8c23b0e787326/Garman_Keynote.jpg?w=300&q=30"
        },
        {
          "source": "VentureBeat",
          "url": "https://venturebeat.com/ai/arcee-aims-to-reboot-u-s-open-source-ai-with-new-trinity-models-released",
          "published_at": "Tue, 02 Dec 2025 03:53:00 GMT",
          "title": "Arcee aims to reboot U.S. open source AI with new Trinity models released under Apache 2.0",
          "standfirst": "For much of 2025, the frontier of open-weight language models has been defined not in Silicon Valley or New York City, but in Beijing and Hangzhou.Chinese research labs including Alibaba&#x27;s Qwen, DeepSeek, Moonshot and Baidu have rapidly set the pace in developing large-scale, open Mixture-of-Experts (MoE) models — often with permissive licenses and leading benchmark performance. While OpenAI fielded its own open source, general purpose LLM this summer as well — gpt-oss-20B and 120B — the uptake has been slowed by so many equally or better performing alternatives. Now, one small U.S. company is pushing back.Today, Arcee AI announced the release of Trinity Mini and Trinity Nano Preview, the first two models in its new “Trinity” family—an open-weight MoE model suite fully trained in the United States. Users can try the former directly for themselves in a chatbot format on Acree&#x27;s new website, chat.arcee.ai, and developers can download the code for both models on Hugging Face and run it themselves, as well as modify them/fine-tune to their liking — all for free under an enterprise-friendly Apache 2.0 license. While small compared to the largest frontier models, these releases represent a rare attempt by a U.S. startup to build end-to-end open-weight models at scale—trained from scratch, on American infrastructure, using a U.S.-curated dataset pipeline.\"I&#x27;m experiencing a combination of extreme pride in my team and crippling exhaustion, so I&#x27;m struggling to put into words just how excited I am to have these models out,\" wrote Arcee Chief Technology Officer (CTO) Lucas Atkins in a post on the social network X (formerly Twitter). \"Especially Mini.\"A third model, Trinity Large, is already in training: a 420B parameter model with 13B active parameters per token, scheduled to launch in January 2026.“We want to add something that has been missing in that picture,” Atkins wrote in the Trinity launch manifesto published on Arcee&#x27;s website. “A serious open weight model family trained end to end in America… that businesses and developers can actually own.”From Small Models to Scaled AmbitionThe Trinity project marks a turning point for Arcee AI, which until now has been known for its compact, enterprise-focused models. The company has raised $29.5 million in funding to date, including a $24 million Series A in 2024 led by Emergence Capital, and its previous releases include AFM-4.5B, a compact instruct-tuned model released in mid-2025, and SuperNova, an earlier 70B-parameter instruction-following model designed for in-VPC enterprise deployment. Both were aimed at solving regulatory and cost issues plaguing proprietary LLM adoption in the enterprise.With Trinity, Arcee is aiming higher: not just instruction tuning or post-training, but full-stack pretraining of open-weight foundation models—built for long-context reasoning, synthetic data adaptation, and future integration with live retraining systems.Originally conceived as a stepping stone to Trinity Large, both Mini and Nano emerged from early experimentation with sparse modeling and quickly became production targets themselves.Technical HighlightsTrinity Mini is a 26B parameter model with 3B active per token, designed for high-throughput reasoning, function calling, and tool use. Trinity Nano Preview is a 6B parameter model with roughly 800M active non-embedding parameters—a more experimental, chat-focused model with a stronger personality, but lower reasoning robustness. Both models use Arcee’s new Attention-First Mixture-of-Experts (AFMoE) architecture, a custom MoE design blending global sparsity, local/global attention, and gated attention techniques.Inspired by recent advances from DeepSeek and Qwen, AFMoE departs from traditional MoE by tightly integrating sparse expert routing with an enhanced attention stack — including grouped-query attention, gated attention, and a local/global pattern that improves long-context reasoning. Think of a typical MoE model like a call center with 128 specialized agents (called “experts”) — but only a few are consulted for each call, depending on the question. This saves time and energy, since not every expert needs to weigh in.What makes AFMoE different is how it decides which agents to call and how it blends their answers. Most MoE models use a standard approach that picks experts based on a simple ranking. AFMoE, by contrast, uses a smoother method (called sigmoid routing) that’s more like adjusting a volume dial than flipping a switch — letting the model blend multiple perspectives more gracefully.The “attention-first” part means the model focuses heavily on how it pays attention to different parts of the conversation. Imagine reading a novel and remembering some parts more clearly than others based on importance, recency, or emotional impact — that’s attention. AFMoE improves this by combining local attention (focusing on what was just said) with global attention (remembering key points from earlier), using a rhythm that keeps things balanced.Finally, AFMoE introduces something called gated attention, which acts like a volume control on each attention output — helping the model emphasize or dampen different pieces of information as needed, like adjusting how much you care about each voice in a group discussion.All of this is designed to make the model more stable during training and more efficient at scale — so it can understand longer conversations, reason more clearly, and run faster without needing massive computing resources.Unlike many existing MoE implementations, AFMoE emphasizes stability at depth and training efficiency, using techniques like sigmoid-based routing without auxiliary loss, and depth-scaled normalization to support scaling without divergence.Model CapabilitiesTrinity Mini adopts an MoE architecture with 128 experts, 8 active per token, and 1 always-on shared expert. Context windows reach up to 131,072 tokens, depending on provider. Benchmarks show Trinity Mini performing competitively with larger models across reasoning tasks, including outperforming gpt-oss on the SimpleQA benchmark (tests factual recall and whether the model admits uncertainty), MMLU (Zero shot, measuring broad academic knowledge and reasoning across many subjects without examples), and BFCL V3 (evaluates multi-step function calling and real-world tool use):MMLU (zero-shot): 84.95Math-500: 92.10GPQA-Diamond: 58.55BFCL V3: 59.67Latency and throughput numbers across providers like Together and Clarifai show 200+ tokens per second throughput with sub-three-second E2E latency—making Trinity Mini viable for interactive applications and agent pipelines.Trinity Nano, while smaller and not as stable on edge cases, demonstrates sparse MoE architecture viability at under 1B active parameters per token. Access, Pricing, and Ecosystem IntegrationBoth Trinity models are released under the permissive, enterprise-friendly, Apache 2.0 license, allowing unrestricted commercial and research use. Trinity Mini is available via:Hugging FaceOpenRouterchat.arcee.aiAPI pricing for Trinity Mini via OpenRouter:$0.045 per million input tokens$0.15 per million output tokensA free tier is available for a limited time on OpenRouterThe model is already integrated into apps including Benchable.ai, Open WebUI, and SillyTavern. It&#x27;s supported in Hugging Face Transformers, VLLM, LM Studio, and llama.cpp.Data Without Compromise: DatologyAI’s RoleCentral to Arcee’s approach is control over training data—a sharp contrast to many open models trained on web-scraped or legally ambiguous datasets. That’s where DatologyAI, a data curation startup co-founded by former Meta and DeepMind researcher Ari Morcos, plays a critical role.DatologyAI’s platform automates data filtering, deduplication, and quality enhancement across modalities, ensuring Arcee’s training corpus avoids the pitfalls of noisy, biased, or copyright-risk content. For Trinity, DatologyAI helped construct a 10 trillion token curriculum organized into three phases: 7T general data, 1.8T high-quality text, and 1.2T STEM-heavy material, including math and code.This is the same partnership that powered Arcee’s AFM-4.5B—but scaled significantly in both size and complexity. According to Arcee, it was Datology’s filtering and data-ranking tools that allowed Trinity to scale cleanly while improving performance on tasks like mathematics, QA, and agent tool use.Datology’s contribution also extends into synthetic data generation. For Trinity Large, the company has produced over 10 trillion synthetic tokens—paired with 10T curated web tokens—to form a 20T-token training corpus for the full-scale model now in progress.Building the Infrastructure to Compete: Prime IntellectArcee’s ability to execute full-scale training in the U.S. is also thanks to its infrastructure partner, Prime Intellect. The startup, founded in early 2024, began with a mission to democratize access to AI compute by building a decentralized GPU marketplace and training stack.While Prime Intellect made headlines with its distributed training of INTELLECT-1—a 10B parameter model trained across contributors in five countries—its more recent work, including the 106B INTELLECT-3, acknowledges the tradeoffs of scale: distributed training works, but for 100B+ models, centralized infrastructure is still more efficient.For Trinity Mini and Nano, Prime Intellect supplied the orchestration stack, modified TorchTitan runtime, and physical compute environment: 512 H200 GPUs in a custom bf16 pipeline, running high-efficiency HSDP parallelism. It is also hosting the 2048 B300 GPU cluster used to train Trinity Large.The collaboration shows the difference between branding and execution. While Prime Intellect’s long-term goal remains decentralized compute, its short-term value for Arcee lies in efficient, transparent training infrastructure—infrastructure that remains under U.S. jurisdiction, with known provenance and security controls.A Strategic Bet on Model SovereigntyArcee&#x27;s push into full pretraining reflects a broader thesis: that the future of enterprise AI will depend on owning the training loop—not just fine-tuning. As systems evolve to adapt from live usage and interact with tools autonomously, compliance and control over training objectives will matter as much as performance.“As applications get more ambitious, the boundary between ‘model’ and ‘product’ keeps moving,” Atkins noted in Arcee&#x27;s Trinity manifesto. “To build that kind of software you need to control the weights and the training pipeline, not only the instruction layer.”This framing sets Trinity apart from other open-weight efforts. Rather than patching someone else’s base model, Arcee has built its own—from data to deployment, infrastructure to optimizer—alongside partners who share that vision of openness and sovereignty.Looking Ahead: Trinity LargeTraining is currently underway for Trinity Large, Arcee’s 420B parameter MoE model, using the same afmoe architecture scaled to a larger expert set. The dataset includes 20T tokens, split evenly between synthetic data from DatologyAI and curated wb data.The model is expected to launch next month in January 2026, with a full technical report to follow shortly thereafter.If successful, it would make Trinity Large one of the only fully open-weight, U.S.-trained frontier-scale models—positioning Arcee as a serious player in the open ecosystem at a time when most American LLM efforts are either closed or based on non-U.S. foundations.A recommitment to U.S. open sourceIn a landscape where the most ambitious open-weight models are increasingly shaped by Chinese research labs, Arcee’s Trinity launch signals a rare shift in direction: an attempt to reclaim ground for transparent, U.S.-controlled model development. Backed by specialized partners in data and infrastructure, and built from scratch for long-term adaptability, Trinity is a bold statement about the future of U.S. AI development, showing that small, lesser-known companies can still push the boundaries and innovate in an open fashion even as the industry is increasingly productized and commodtized. What remains to be seen is whether Trinity Large can match the capabilities of its better-funded peers. But with Mini and Nano already in use, and a strong architectural foundation in place, Arcee may already be proving its central thesis: that model sovereignty, not just model size, will define the next era of AI.",
          "content": "For much of 2025, the frontier of open-weight language models has been defined not in Silicon Valley or New York City, but in Beijing and Hangzhou.Chinese research labs including Alibaba&#x27;s Qwen, DeepSeek, Moonshot and Baidu have rapidly set the pace in developing large-scale, open Mixture-of-Experts (MoE) models — often with permissive licenses and leading benchmark performance. While OpenAI fielded its own open source, general purpose LLM this summer as well — gpt-oss-20B and 120B — the uptake has been slowed by so many equally or better performing alternatives. Now, one small U.S. company is pushing back.Today, Arcee AI announced the release of Trinity Mini and Trinity Nano Preview, the first two models in its new “Trinity” family—an open-weight MoE model suite fully trained in the United States. Users can try the former directly for themselves in a chatbot format on Acree&#x27;s new website, chat.arcee.ai, and developers can download the code for both models on Hugging Face and run it themselves, as well as modify them/fine-tune to their liking — all for free under an enterprise-friendly Apache 2.0 license. While small compared to the largest frontier models, these releases represent a rare attempt by a U.S. startup to build end-to-end open-weight models at scale—trained from scratch, on American infrastructure, using a U.S.-curated dataset pipeline.\"I&#x27;m experiencing a combination of extreme pride in my team and crippling exhaustion, so I&#x27;m struggling to put into words just how excited I am to have these models out,\" wrote Arcee Chief Technology Officer (CTO) Lucas Atkins in a post on the social network X (formerly Twitter). \"Especially Mini.\"A third model, Trinity Large, is already in training: a 420B parameter model with 13B active parameters per token, scheduled to launch in January 2026.“We want to add something that has been missing in that picture,” Atkins wrote in the Trinity launch manifesto published on Arcee&#x27;s website. “A serious open weight model family trained end to end in America… that businesses and developers can actually own.”From Small Models to Scaled AmbitionThe Trinity project marks a turning point for Arcee AI, which until now has been known for its compact, enterprise-focused models. The company has raised $29.5 million in funding to date, including a $24 million Series A in 2024 led by Emergence Capital, and its previous releases include AFM-4.5B, a compact instruct-tuned model released in mid-2025, and SuperNova, an earlier 70B-parameter instruction-following model designed for in-VPC enterprise deployment. Both were aimed at solving regulatory and cost issues plaguing proprietary LLM adoption in the enterprise.With Trinity, Arcee is aiming higher: not just instruction tuning or post-training, but full-stack pretraining of open-weight foundation models—built for long-context reasoning, synthetic data adaptation, and future integration with live retraining systems.Originally conceived as a stepping stone to Trinity Large, both Mini and Nano emerged from early experimentation with sparse modeling and quickly became production targets themselves.Technical HighlightsTrinity Mini is a 26B parameter model with 3B active per token, designed for high-throughput reasoning, function calling, and tool use. Trinity Nano Preview is a 6B parameter model with roughly 800M active non-embedding parameters—a more experimental, chat-focused model with a stronger personality, but lower reasoning robustness. Both models use Arcee’s new Attention-First Mixture-of-Experts (AFMoE) architecture, a custom MoE design blending global sparsity, local/global attention, and gated attention techniques.Inspired by recent advances from DeepSeek and Qwen, AFMoE departs from traditional MoE by tightly integrating sparse expert routing with an enhanced attention stack — including grouped-query attention, gated attention, and a local/global pattern that improves long-context reasoning. Think of a typical MoE model like a call center with 128 specialized agents (called “experts”) — but only a few are consulted for each call, depending on the question. This saves time and energy, since not every expert needs to weigh in.What makes AFMoE different is how it decides which agents to call and how it blends their answers. Most MoE models use a standard approach that picks experts based on a simple ranking. AFMoE, by contrast, uses a smoother method (called sigmoid routing) that’s more like adjusting a volume dial than flipping a switch — letting the model blend multiple perspectives more gracefully.The “attention-first” part means the model focuses heavily on how it pays attention to different parts of the conversation. Imagine reading a novel and remembering some parts more clearly than others based on importance, recency, or emotional impact — that’s attention. AFMoE improves this by combining local attention (focusing on what was just said) with global attention (remembering key points from earlier), using a rhythm that keeps things balanced.Finally, AFMoE introduces something called gated attention, which acts like a volume control on each attention output — helping the model emphasize or dampen different pieces of information as needed, like adjusting how much you care about each voice in a group discussion.All of this is designed to make the model more stable during training and more efficient at scale — so it can understand longer conversations, reason more clearly, and run faster without needing massive computing resources.Unlike many existing MoE implementations, AFMoE emphasizes stability at depth and training efficiency, using techniques like sigmoid-based routing without auxiliary loss, and depth-scaled normalization to support scaling without divergence.Model CapabilitiesTrinity Mini adopts an MoE architecture with 128 experts, 8 active per token, and 1 always-on shared expert. Context windows reach up to 131,072 tokens, depending on provider. Benchmarks show Trinity Mini performing competitively with larger models across reasoning tasks, including outperforming gpt-oss on the SimpleQA benchmark (tests factual recall and whether the model admits uncertainty), MMLU (Zero shot, measuring broad academic knowledge and reasoning across many subjects without examples), and BFCL V3 (evaluates multi-step function calling and real-world tool use):MMLU (zero-shot): 84.95Math-500: 92.10GPQA-Diamond: 58.55BFCL V3: 59.67Latency and throughput numbers across providers like Together and Clarifai show 200+ tokens per second throughput with sub-three-second E2E latency—making Trinity Mini viable for interactive applications and agent pipelines.Trinity Nano, while smaller and not as stable on edge cases, demonstrates sparse MoE architecture viability at under 1B active parameters per token. Access, Pricing, and Ecosystem IntegrationBoth Trinity models are released under the permissive, enterprise-friendly, Apache 2.0 license, allowing unrestricted commercial and research use. Trinity Mini is available via:Hugging FaceOpenRouterchat.arcee.aiAPI pricing for Trinity Mini via OpenRouter:$0.045 per million input tokens$0.15 per million output tokensA free tier is available for a limited time on OpenRouterThe model is already integrated into apps including Benchable.ai, Open WebUI, and SillyTavern. It&#x27;s supported in Hugging Face Transformers, VLLM, LM Studio, and llama.cpp.Data Without Compromise: DatologyAI’s RoleCentral to Arcee’s approach is control over training data—a sharp contrast to many open models trained on web-scraped or legally ambiguous datasets. That’s where DatologyAI, a data curation startup co-founded by former Meta and DeepMind researcher Ari Morcos, plays a critical role.DatologyAI’s platform automates data filtering, deduplication, and quality enhancement across modalities, ensuring Arcee’s training corpus avoids the pitfalls of noisy, biased, or copyright-risk content. For Trinity, DatologyAI helped construct a 10 trillion token curriculum organized into three phases: 7T general data, 1.8T high-quality text, and 1.2T STEM-heavy material, including math and code.This is the same partnership that powered Arcee’s AFM-4.5B—but scaled significantly in both size and complexity. According to Arcee, it was Datology’s filtering and data-ranking tools that allowed Trinity to scale cleanly while improving performance on tasks like mathematics, QA, and agent tool use.Datology’s contribution also extends into synthetic data generation. For Trinity Large, the company has produced over 10 trillion synthetic tokens—paired with 10T curated web tokens—to form a 20T-token training corpus for the full-scale model now in progress.Building the Infrastructure to Compete: Prime IntellectArcee’s ability to execute full-scale training in the U.S. is also thanks to its infrastructure partner, Prime Intellect. The startup, founded in early 2024, began with a mission to democratize access to AI compute by building a decentralized GPU marketplace and training stack.While Prime Intellect made headlines with its distributed training of INTELLECT-1—a 10B parameter model trained across contributors in five countries—its more recent work, including the 106B INTELLECT-3, acknowledges the tradeoffs of scale: distributed training works, but for 100B+ models, centralized infrastructure is still more efficient.For Trinity Mini and Nano, Prime Intellect supplied the orchestration stack, modified TorchTitan runtime, and physical compute environment: 512 H200 GPUs in a custom bf16 pipeline, running high-efficiency HSDP parallelism. It is also hosting the 2048 B300 GPU cluster used to train Trinity Large.The collaboration shows the difference between branding and execution. While Prime Intellect’s long-term goal remains decentralized compute, its short-term value for Arcee lies in efficient, transparent training infrastructure—infrastructure that remains under U.S. jurisdiction, with known provenance and security controls.A Strategic Bet on Model SovereigntyArcee&#x27;s push into full pretraining reflects a broader thesis: that the future of enterprise AI will depend on owning the training loop—not just fine-tuning. As systems evolve to adapt from live usage and interact with tools autonomously, compliance and control over training objectives will matter as much as performance.“As applications get more ambitious, the boundary between ‘model’ and ‘product’ keeps moving,” Atkins noted in Arcee&#x27;s Trinity manifesto. “To build that kind of software you need to control the weights and the training pipeline, not only the instruction layer.”This framing sets Trinity apart from other open-weight efforts. Rather than patching someone else’s base model, Arcee has built its own—from data to deployment, infrastructure to optimizer—alongside partners who share that vision of openness and sovereignty.Looking Ahead: Trinity LargeTraining is currently underway for Trinity Large, Arcee’s 420B parameter MoE model, using the same afmoe architecture scaled to a larger expert set. The dataset includes 20T tokens, split evenly between synthetic data from DatologyAI and curated wb data.The model is expected to launch next month in January 2026, with a full technical report to follow shortly thereafter.If successful, it would make Trinity Large one of the only fully open-weight, U.S.-trained frontier-scale models—positioning Arcee as a serious player in the open ecosystem at a time when most American LLM efforts are either closed or based on non-U.S. foundations.A recommitment to U.S. open sourceIn a landscape where the most ambitious open-weight models are increasingly shaped by Chinese research labs, Arcee’s Trinity launch signals a rare shift in direction: an attempt to reclaim ground for transparent, U.S.-controlled model development. Backed by specialized partners in data and infrastructure, and built from scratch for long-term adaptability, Trinity is a bold statement about the future of U.S. AI development, showing that small, lesser-known companies can still push the boundaries and innovate in an open fashion even as the industry is increasingly productized and commodtized. What remains to be seen is whether Trinity Large can match the capabilities of its better-funded peers. But with Mini and Nano already in use, and a strong architectural foundation in place, Arcee may already be proving its central thesis: that model sovereignty, not just model size, will define the next era of AI.",
          "feed_position": 6,
          "image_url": "https://images.ctfassets.net/jdtwqhzvc2n1/5eaxHEnHdxoMHz7f1nqoI3/5f5ae76e1d9082742a5ed0c82d818fd4/JIw2KAqLv9DVkYKstOJ2Q.jpg?w=300&q=30"
        },
        {
          "source": "TechMeme",
          "url": "https://news.techmeme.com/251201/contact",
          "published_at": "Mon, 01 Dec 2025 14:16:44 -0500",
          "title": "SITE NEWS: How to contact Techmeme about news",
          "standfirst": "Given that our contact points have evolved over the years, here's a general update on how best to tip us, advise us, or complain to us about news. This post is organized around several scenarios, which I'll list in bold. You want to send an announcement just as an FYI to Techmeme: In the typical scenario, in which you think Techmeme is unlikely to feature the news, or you're not familiar with our criteria for posting, it's best not to do anything. Techmeme only posts about 50 headlines per day and any given announcement is very unlikely to be featured. So save us both time and focus on more fruitful channels than Techmeme. You want to send news to Techmeme that you think there's a good chance we'll want to post: If you're familiar with Techmeme and anticipate we'll be interested in the story, you can tip the link using this online form. This form integrates into editors' workflow so human editors will see the link in real time. As a bonus, the form requests an email address, enabling us to notify you if we do post the link. For the (hopefully rare) bad actor out there, I need to stress that all submissions are fully vetted by human editors, so any spamming attempt will silently fail. You want to add a social link underneath news that is already featured on Techmeme: We often feature related blog posts and social posts from LinkedIn, X, Bluesky, Threads, and Mastodon beneath our headlines, and you are encouraged to contribute these links. Just hover over the headline on our desktop page and click the \"Add Link Here\" button that appears. (For an example, see the image below.) As long as the link you submit adds value in some way, we will add it, and you'll get an email confirming this once we do. Feel free to tip your own links or links from your company, clients, or friends. As long as the link makes Techmeme better, it's a win/win for you and us. (Once again, I must stress that for the rare bad actor, all submissions are fully vetted, and spammy links will not make it to Techmeme.) You are briefing publications on embargoed news and want to let Techmeme know: Larger companies often give us a heads-up on major announcements, because it helps us post as soon as possible after the embargo and arrange more comprehensive coverage. Because embargoed news isn't public yet, there's no link for it, so you can't submit via our online form. So instead, you can submit details via this special email address. To ease the process for both companies and Techmeme, our policy is to automatically accept embargoed information sent to this email address, meaning we won't publish any information sent to us until it's public. So please don't start off by asking if we accept. Yes, we accept, and have handled embargoes from the biggest tech companies for over a decade without incident. When you email, please include as much detail as you can, including the embargo time, any blog posts or press releases, and specifics on the publications you've briefed. Note that this email address will reach a person who then routes the news to a limited set of editors. (It is not an alias that simply forwards to all editors.) Because of this we request you email 12 or more hours before the embargo time if possible. Techmeme posted something erroneous or misleading and you want to let us know: Occasionally we flub a headline, or mention a detail from a story that was later corrected unbeknownst to us. In scenarios like this, we definitely want to know so we can fix our headline, or, less commonly, remove or replace our headline, so please use this email address to reach us. Note that you can also use this email address for sending other information or even news tips that can't easily be conveyed by a single URL (making it hard to use this form.) Please note that while we always read these emails, in many cases, we don't have time to reply. As a bonus, here are a few non-editorial scenarios for contacting us: to place ads on Techmeme, email us here, to inquire about our media monitoring and summary services, email us here, and for matters unrelated to all of the above, use this email address. (function() { var emails = { embargo: ['embargo', 'techmeme', 'com'], editorial: ['editorial', 'techmeme', 'com'], sponsor: ['sponsor', 'techmeme', 'com'], service: ['service', 'techmeme', 'com'] }; function createMailto(parts) { return 'mailto:' + parts[0] + '@' + parts[1] + '.' + parts[2]; } document.getElementById('embargo-link').href = createMailto(emails.embargo); document.getElementById('editorial-link').href = createMailto(emails.editorial); document.getElementById('sponsor-link').href = createMailto(emails.sponsor); document.getElementById('service1-link').href = createMailto(emails.service); document.getElementById('service2-link').href = createMailto(emails.service); })();",
          "content": "Given that our contact points have evolved over the years, here's a general update on how best to tip us, advise us, or complain to us about news. This post is organized around several scenarios, which I'll list in bold. You want to send an announcement just as an FYI to Techmeme: In the typical scenario, in which you think Techmeme is unlikely to feature the news, or you're not familiar with our criteria for posting, it's best not to do anything. Techmeme only posts about 50 headlines per day and any given announcement is very unlikely to be featured. So save us both time and focus on more fruitful channels than Techmeme. You want to send news to Techmeme that you think there's a good chance we'll want to post: If you're familiar with Techmeme and anticipate we'll be interested in the story, you can tip the link using this online form. This form integrates into editors' workflow so human editors will see the link in real time. As a bonus, the form requests an email address, enabling us to notify you if we do post the link. For the (hopefully rare) bad actor out there, I need to stress that all submissions are fully vetted by human editors, so any spamming attempt will silently fail. You want to add a social link underneath news that is already featured on Techmeme: We often feature related blog posts and social posts from LinkedIn, X, Bluesky, Threads, and Mastodon beneath our headlines, and you are encouraged to contribute these links. Just hover over the headline on our desktop page and click the \"Add Link Here\" button that appears. (For an example, see the image below.) As long as the link you submit adds value in some way, we will add it, and you'll get an email confirming this once we do. Feel free to tip your own links or links from your company, clients, or friends. As long as the link makes Techmeme better, it's a win/win for you and us. (Once again, I must stress that for the rare bad actor, all submissions are fully vetted, and spammy links will not make it to Techmeme.) You are briefing publications on embargoed news and want to let Techmeme know: Larger companies often give us a heads-up on major announcements, because it helps us post as soon as possible after the embargo and arrange more comprehensive coverage. Because embargoed news isn't public yet, there's no link for it, so you can't submit via our online form. So instead, you can submit details via this special email address. To ease the process for both companies and Techmeme, our policy is to automatically accept embargoed information sent to this email address, meaning we won't publish any information sent to us until it's public. So please don't start off by asking if we accept. Yes, we accept, and have handled embargoes from the biggest tech companies for over a decade without incident. When you email, please include as much detail as you can, including the embargo time, any blog posts or press releases, and specifics on the publications you've briefed. Note that this email address will reach a person who then routes the news to a limited set of editors. (It is not an alias that simply forwards to all editors.) Because of this we request you email 12 or more hours before the embargo time if possible. Techmeme posted something erroneous or misleading and you want to let us know: Occasionally we flub a headline, or mention a detail from a story that was later corrected unbeknownst to us. In scenarios like this, we definitely want to know so we can fix our headline, or, less commonly, remove or replace our headline, so please use this email address to reach us. Note that you can also use this email address for sending other information or even news tips that can't easily be conveyed by a single URL (making it hard to use this form.) Please note that while we always read these emails, in many cases, we don't have time to reply. As a bonus, here are a few non-editorial scenarios for contacting us: to place ads on Techmeme, email us here, to inquire about our media monitoring and summary services, email us here, and for matters unrelated to all of the above, use this email address. (function() { var emails = { embargo: ['embargo', 'techmeme', 'com'], editorial: ['editorial', 'techmeme', 'com'], sponsor: ['sponsor', 'techmeme', 'com'], service: ['service', 'techmeme', 'com'] }; function createMailto(parts) { return 'mailto:' + parts[0] + '@' + parts[1] + '.' + parts[2]; } document.getElementById('embargo-link').href = createMailto(emails.embargo); document.getElementById('editorial-link').href = createMailto(emails.editorial); document.getElementById('sponsor-link').href = createMailto(emails.sponsor); document.getElementById('service1-link').href = createMailto(emails.service); document.getElementById('service2-link').href = createMailto(emails.service); })();",
          "feed_position": 15,
          "image_url": "https://news.techmeme.com/images/add_link_here.png"
        }
      ],
      "featured_image": "https://images.ctfassets.net/jdtwqhzvc2n1/4DAwyP4OahDixwCOgmDRK0/8c301172d603674eb96b8f67008faf53/nuneybits_Vector_art_of_glowing-code_cloud_4880d34c-2130-4612-92b4-ff55b2bb0255.webp?w=300&q=30",
      "popularity_score": 2014.2810841666667,
      "ai_summary": [
        "Amazon announced new AI systems called \"frontier agents\".",
        "These agents can work autonomously for hours or days.",
        "The agents are designed to automate software development.",
        "Three specialized AI agents are introduced by Amazon.",
        "The agents include Kiro, AWS Security Agent, and AWS DevOps Agent."
      ]
    },
    {
      "id": "cluster_5",
      "coverage": 1,
      "updated_at": "Tue, 02 Dec 2025 22:42:09 +0000",
      "title": "OpenAI CEO declares “code red” as Gemini gains 200 million users in 3 months",
      "neutral_headline": "OpenAI CEO Declares \"Code Red\" Amidst Gemini Growth",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2025/12/openai-ceo-declares-code-red-as-gemini-gains-200-million-users-in-3-months/",
          "published_at": "Tue, 02 Dec 2025 22:42:09 +0000",
          "title": "OpenAI CEO declares “code red” as Gemini gains 200 million users in 3 months",
          "standfirst": "Three years after Google sounded alarm bells over ChatGPT, the tables have turned.",
          "content": "The shoe is most certainly on the other foot. On Monday, OpenAI CEO Sam Altman reportedly declared a “code red” at the company to improve ChatGPT, delaying advertising plans and other products in the process, The Information reported based on a leaked internal memo. The move follows Google’s release of its Gemini 3 model last month, which has outperformed ChatGPT on some industry benchmark tests and sparked high-profile praise on social media. In the memo, Altman wrote, “We are at a critical time for ChatGPT.” The company will push back work on advertising integration, AI agents for health and shopping, and a personal assistant feature called Pulse. Altman encouraged temporary team transfers and established daily calls for employees responsible for enhancing the chatbot. The directive creates an odd symmetry with events from December 2022, when Google management declared its own “code red” internal emergency after ChatGPT launched and rapidly gained in popularity. At the time, Google CEO Sundar Pichai reassigned teams across the company to develop AI prototypes and products to compete with OpenAI’s chatbot. Now, three years later, the AI industry is in a very different place.Read full article Comments",
          "feed_position": 1,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/aaltman_crop-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/aaltman_crop-1152x648.jpg",
      "popularity_score": 357.4835841666667,
      "ai_summary": [
        "OpenAI's CEO has declared a \"code red\" situation.",
        "The declaration is due to Gemini's rapid user growth.",
        "Gemini has gained 200 million users in three months.",
        "The situation marks a shift in the AI landscape.",
        "Google previously expressed concerns about ChatGPT."
      ]
    },
    {
      "id": "cluster_1",
      "coverage": 1,
      "updated_at": "Tue, 02 Dec 2025 23:04:37 +0000",
      "title": "This Chinese company could become the country’s first to land a reusable rocket",
      "neutral_headline": "Chinese Company Aims to Launch Reusable Rocket",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2025/12/this-chinese-company-could-become-the-countrys-first-to-land-a-reusable-rocket/",
          "published_at": "Tue, 02 Dec 2025 23:04:37 +0000",
          "title": "This Chinese company could become the country’s first to land a reusable rocket",
          "standfirst": "From the outside, China's Zhuque-3 rocket looks like a clone of SpaceX's Falcon 9.",
          "content": "There’s a race in China among several companies vying to become the next to launch and land an orbital-class rocket, and the starting gun could go off as soon as tonight. LandSpace, one of several maturing Chinese rocket startups, is about to launch the first flight of its medium-lift Zhuque-3 rocket. Liftoff could happen around 11 pm EST tonight (04:00 UTC Wednesday), or noon local time at the Jiuquan Satellite Launch Center in northwestern China. Airspace warning notices advising pilots to steer clear of the rocket’s flight path suggest LandSpace has a launch window of about two hours. When it lifts off, the Zhuque-3 (Vermillion Bird-3) rocket will become the largest commercial launch vehicle ever flown in China. What’s more, LandSpace will become the first Chinese launch provider to attempt a landing of its first stage booster, using the same tried-and-true return method pioneered by SpaceX and, more recently, Blue Origin in the United States.Read full article Comments",
          "feed_position": 0,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/zq3hangar-1152x648-1764713841.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/zq3hangar-1152x648-1764713841.jpg",
      "popularity_score": 352.85802861111114,
      "ai_summary": [
        "A Chinese company is working on a reusable rocket.",
        "The rocket is called Zhuque-3.",
        "The rocket's design resembles SpaceX's Falcon 9.",
        "The company aims to achieve reusable rocket technology.",
        "This could be the first for a Chinese company."
      ]
    },
    {
      "id": "cluster_16",
      "coverage": 1,
      "updated_at": "Tue, 02 Dec 2025 21:36:50 +0000",
      "title": "India orders device makers to put government-run security app on all phones",
      "neutral_headline": "India Mandates Government Security App on All Devices",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/12/apple-will-refuse-to-preload-state-run-snooping-app-on-iphones-report-says/",
          "published_at": "Tue, 02 Dec 2025 21:36:50 +0000",
          "title": "India orders device makers to put government-run security app on all phones",
          "standfirst": "Apple will refuse to preload state-run “snooping” app on iPhones, report says.",
          "content": "Apple reportedly won’t comply with a government order in India to preload iPhones with a state-run app that can track and block lost or stolen phones via a device’s International Mobile Equipment Identity (IMEI) code. While the government describes it as a tool to help consumers, privacy advocates say it could easily be repurposed for surveillance. Reuters reported today, citing three anonymous sources, that “Apple does not plan to comply with a mandate to preload its smartphones with a state-owned cyber safety app and will convey its concerns to New Delhi.” Reuters noted that the government mandate has “sparked surveillance concerns and a political uproar.” The government’s Sanchar Saathi (“Communication Partner”) app is billed as a consumer tool for reporting suspected fraud communications, verifying the genuineness of a phone, and blocking lost or stolen handsets. The app can already be installed by users as it is available on the Apple and Google Play app stores, but the government wants device makers such as Apple, Google, Samsung, and Xiaomi to load phones with the app before they are shipped.Read full article Comments",
          "feed_position": 3,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/apple-store-india-1152x648-1764709977.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/apple-store-india-1152x648-1764709977.jpg",
      "popularity_score": 337.39497305555557,
      "ai_summary": [
        "India is ordering device makers to include a security app.",
        "The app is government-run and for security purposes.",
        "Apple will refuse to preload the state-run app on iPhones.",
        "The report indicates Apple's refusal to comply.",
        "The app is described as a \"snooping\" app."
      ]
    },
    {
      "id": "cluster_12",
      "coverage": 1,
      "updated_at": "Tue, 02 Dec 2025 21:52:10 +0000",
      "title": "Mad Men’s 4K debut botched by HBO Max streaming episode with visible crewmembers",
      "neutral_headline": "Mad Men 4K Debut Features Visible Crew Members",
      "bullet_summary": [
        "Producer Lionsgate reportedly contributed to the gaffe",
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/12/mad-mens-4k-debut-botched-by-hbo-max-streaming-episode-with-visible-crewmembers/",
          "published_at": "Tue, 02 Dec 2025 21:52:10 +0000",
          "title": "Mad Men’s 4K debut botched by HBO Max streaming episode with visible crewmembers",
          "standfirst": "Producer Lionsgate reportedly contributed to the gaffe.",
          "content": "Streaming services have a way of reviving love for old shows, and HBO Max is looking to entice old and new fans with this month’s addition of Mad Men. Instead, viewers have been laughing at the problems with the show’s 4K premiere. Mad Men ran on the AMC channel for seven seasons from 2007 to 2015. The show had a vintage aesthetic, depicting the 1960s advertising industry in New York City. Last month, HBO Max announced it would modernize the show by debuting a 4K version. The show originally aired in SD and HD resolutions and had not been previously made available in 4K through other means, such as Blu-ray.Read full article Comments",
          "feed_position": 2,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/mad-men-season-6-jon-hamm-2-770x470-1.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/mad-men-season-6-jon-hamm-2-770x470-1.jpg",
      "popularity_score": 331.6505286111111,
      "ai_summary": [
        "The 4K debut of Mad Men was marred by a technical issue.",
        "An episode on HBO Max showed visible crew members.",
        "The issue occurred during the streaming of the episode.",
        "Lionsgate reportedly contributed to the gaffe.",
        "The error impacted the viewing experience."
      ]
    },
    {
      "id": "cluster_34",
      "coverage": 1,
      "updated_at": "Tue, 02 Dec 2025 19:26:26 +0000",
      "title": "Testing shows why the Steam Machine’s 8GB of graphics RAM could be a problem",
      "neutral_headline": "Steam Machine Graphics RAM Could Be a Problem",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/12/steamos-has-problems-with-8gb-gpus-but-valve-is-working-on-it/",
          "published_at": "Tue, 02 Dec 2025 19:26:26 +0000",
          "title": "Testing shows why the Steam Machine’s 8GB of graphics RAM could be a problem",
          "standfirst": "Valve has work to do on the software side—but some fixes are coming.",
          "content": "By Valve’s admission, its upcoming Steam Machine desktop isn’t swinging for the fences with its graphical performance. The specs promise decent 1080p-to-1440p performance in most games, with 4K occasionally reachable with assistance from FSR upscaling—about what you’d expect from a box with a modern midrange graphics card in it. But there’s one spec that has caused some concern among Ars staffers and others with their eyes on the Steam Machine: The GPU comes with just 8GB of dedicated graphics RAM, an amount that is steadily becoming more of a bottleneck for midrange GPUs like AMD’s Radeon RX 7060 and 9060, or Nvidia’s GeForce RTX 4060 or 5060. In our reviews of these GPUs, we’ve already run into some games where the RAM ceiling limits performance in Windows, especially at 1440p. But we’ve been doing more extensive testing of various GPUs with SteamOS, and we can confirm that in current betas, 8GB GPUs struggle even more on SteamOS than they do running the same games at the same settings in Windows 11.Read full article Comments",
          "feed_position": 4,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/IMG_1114-1152x648.jpeg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/IMG_1114-1152x648.jpeg",
      "popularity_score": 314.2216397222222,
      "ai_summary": [
        "Testing reveals potential issues with the Steam Machine.",
        "The issue relates to the 8GB of graphics RAM.",
        "Valve needs to address the problem on the software side.",
        "Some fixes are reportedly in development.",
        "The graphics RAM limitation could affect performance."
      ]
    },
    {
      "id": "cluster_35",
      "coverage": 1,
      "updated_at": "Tue, 02 Dec 2025 19:11:47 +0000",
      "title": "Google announces second Android 16 release of 2025 is heading to Pixels",
      "neutral_headline": "Google Announces Second Android 16 Release for Pixels",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/google/2025/12/google-announces-second-android-16-release-of-2025-is-heading-to-pixels/",
          "published_at": "Tue, 02 Dec 2025 19:11:47 +0000",
          "title": "Google announces second Android 16 release of 2025 is heading to Pixels",
          "standfirst": "The update is rolling out to Pixels starting today.",
          "content": "Google is following through on its pledge to split Android versions into more frequent updates. We already had one Android 16 release this year, and now it’s time for the second. The new version is rolling out first on Google’s Pixel phones, featuring more icon customization, easier parental controls, and AI-powered notifications. Don’t be bummed if you aren’t first in line for the new Android 16—Google also has a raft of general improvements coming to the wider Android ecosystem. Android 16, part 2 Since rolling out the first version of Android in 2008, Google has largely stuck to one major release per year. Android 16 changes things, moving from one monolithic release to two. Today’s OS update is the second part of the Android 16 era, but don’t expect major changes. As expected, the first release in June made more changes. Most of what we’ll see in the second update is geared toward Google’s Pixel phones, plus some less notable changes for developers. Google’s new AI features for notifications are probably the most important change. Android 16 will use AI for two notification tasks: summarizing and organizing. The OS will take long chat conversations and summarize the notifications with AI. Notification data is processed locally on the device and won’t be uploaded anywhere. In the notification shade, the collapsed notification line will feature a summary of the conversation rather than a snippet of one message. Expanding the notification will display the full text.Read full article Comments",
          "feed_position": 5,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/06/Android-16-1-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/06/Android-16-1-1152x648.jpg",
      "popularity_score": 310.97747305555555,
      "ai_summary": [
        "Google is releasing a second Android 16 update.",
        "The update is for Pixel devices.",
        "The update is rolling out starting today.",
        "The update is the second release of 2025.",
        "The update will include new features and fixes."
      ]
    },
    {
      "id": "cluster_47",
      "coverage": 1,
      "updated_at": "Tue, 02 Dec 2025 17:57:42 +0000",
      "title": "Meet CDC’s new lead vaccine advisor who thinks shots cause heart disease",
      "neutral_headline": "CDC's New Vaccine Advisor Has Controversial Views",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/health/2025/12/meet-cdcs-new-lead-vaccine-advisor-who-thinks-shots-cause-heart-disease/",
          "published_at": "Tue, 02 Dec 2025 17:57:42 +0000",
          "title": "Meet CDC’s new lead vaccine advisor who thinks shots cause heart disease",
          "standfirst": "Milhoan has a history of touting unproven COVID cures while disparaging vaccines.",
          "content": "When the federal vaccine committee hand-picked by anti-vaccine Health Secretary Robert F. Kennedy Jr. meets again this week, it will have yet another new chairperson to lead its ongoing work of dismantling the evidence-based vaccine recommendations set by the Centers for Disease Control and Prevention. On Monday, the Department of Health and Human Services announced that the chairperson who has been in place since June—when Kennedy fired all 17 expert advisors on the committee and replaced them with questionably qualified allies—is moving to a senior role in the department. Biostatistician Martin Kulldorff will now be the chief science officer for the Office of the Assistant Secretary for Planning and Evaluation (ASPE), HHS said. As such, he’s stepping down from the vaccine committee, the Advisory Committee on Immunization Practices (ACIP). Kulldorff gained prominence amid the COVID-19 pandemic, criticizing public health responses to the crisis, particularly lockdowns and COVID-19 vaccines. He was a co-author of the Great Barrington Declaration that advocated for letting the deadly virus spread unchecked through the population, which was called unethical by health experts.Read full article Comments",
          "feed_position": 6,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2235571142-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2235571142-1152x648.jpg",
      "popularity_score": 287.74275083333333,
      "ai_summary": [
        "The CDC has a new lead vaccine advisor.",
        "The advisor has expressed controversial views.",
        "The advisor thinks shots cause heart disease.",
        "The advisor has touted unproven COVID cures.",
        "The advisor has disparaged vaccines in the past."
      ]
    },
    {
      "id": "cluster_55",
      "coverage": 1,
      "updated_at": "Tue, 02 Dec 2025 16:47:10 +0000",
      "title": "Samsung reveals Galaxy Z TriFold with 10-inch foldable screen, astronomical price",
      "neutral_headline": "Samsung Unveils Galaxy Z TriFold with Large Foldable Screen",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/12/samsungs-galaxy-z-trifold-is-a-10-inch-tablet-that-fits-in-your-pocket/",
          "published_at": "Tue, 02 Dec 2025 16:47:10 +0000",
          "title": "Samsung reveals Galaxy Z TriFold with 10-inch foldable screen, astronomical price",
          "standfirst": "Samsung's long-awaited tri-fold phone is launching in Korea this month, with a US launch early next year.",
          "content": "Samsung has a new foldable smartphone, and it’s not just another Z Flip or Z Fold. The Galaxy Z TriFold has three articulating sections that house a massive 10-inch tablet-style screen, along with a traditional smartphone screen on the outside. The lavish new smartphone is launching this month in South Korea with a hefty price tag, and it will eventually make its way to the US in early 2026. Samsung says it refined its Armor FlexHinge design for the TriFold. The device’s two hinges are slightly different sizes because the phone’s three panels have distinct shapes. The center panel is the thickest at 4.2 mm, and the other two are fractions of a millimeter thinner. The phone has apparently been designed to account for the varying sizes and weights, allowing the frame to fold up tight in a pocketable form factor. Huawei’s impressive Mate XT tri-fold phones have been making the rounds online, but they’re not available in Western markets. Samsung’s new foldable looks similar at a glance, but the way the three panels fit together is different. The Mate XT folds in a Z-shaped configuration, using part of the main screen as the cover display. On Samsung’s phone, the left and right segments fold inward behind the separate cover screen. Samsung claims it has tested the design extensively to verify that the hinges will hold up to daily use for years.Read full article Comments",
          "feed_position": 7,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/Samsung-Mobile-Galaxy-Z-TriFold-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/Samsung-Mobile-Galaxy-Z-TriFold-1152x648.jpg",
      "popularity_score": 282.5671952777778,
      "ai_summary": [
        "Samsung will launch its tri-fold phone in Korea this month.",
        "The United States launch is planned for early next year.",
        "The phone features a ten-inch foldable screen.",
        "The device is expected to have a high price point.",
        "The Galaxy Z TriFold is a long-awaited product."
      ]
    },
    {
      "id": "cluster_61",
      "coverage": 1,
      "updated_at": "Tue, 02 Dec 2025 16:23:24 +0000",
      "title": "3D model shows small clans created Easter Island statues",
      "neutral_headline": "Study Reveals How Easter Island Statues Were Created",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/12/explore-the-statues-of-easter-island-with-this-fly-through-3d-model/",
          "published_at": "Tue, 02 Dec 2025 16:23:24 +0000",
          "title": "3D model shows small clans created Easter Island statues",
          "standfirst": "Study: Moai were created by small, decentralized working groups, not managed by one central \"chieftain.\"",
          "content": "Credit: ArcGIS Easter Island is famous for its giant monumental statues, called moai, built some 800 years ago. The volcanic rock used for the moai came from a quarry site called Rano Raraku. Archaeologists have created a high-resolution interactive 3D model of the quarry site to learn more about the processes used to create the moai. (You can explore the full interactive model here.) According to a paper published in the journal PLoS ONE, the model shows that there were numerous independent groups, probably family clans, that created the moai, rather than a centralized management system. “You can see things that you couldn’t actually see on the ground. You can see tops and sides and all kinds of areas that just would never be able to walk to,” said co-author Carl Lipo of Binghamton University. “We can say, ‘Here, go look at it.’ If you want to see the different kinds of carving, fly around and see stuff there. We’re documenting something that really has needed to be documented, but in a way that’s really comprehensive and shareable.” Lipo is one of the foremost experts on the Easter Island moai. In October, we reported on Lipo’s experimental confirmation—based on 3D modeling of the physics and new field tests to re-create that motion—that Easter Island’s people transported the statues in a vertical position, with workers using ropes to essentially “walk” the moai onto their platforms. To explain the presence of so many moai, the assumption has been that the island was once home to tens of thousands of people. Read full article Comments",
          "feed_position": 8,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/easterTOP-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/11/easterTOP-1152x648.jpg",
      "popularity_score": 266.1710841666667,
      "ai_summary": [
        "Researchers created a 3D model of the statue creation process.",
        "The Moai statues were created by small working groups.",
        "These groups were decentralized in their organization.",
        "The groups were not managed by a central leader.",
        "The study challenges previous assumptions about the statues."
      ]
    },
    {
      "id": "cluster_63",
      "coverage": 1,
      "updated_at": "Tue, 02 Dec 2025 16:01:03 +0000",
      "title": "“Renewable” no more: Trump admin renames the National Renewable Energy Laboratory",
      "neutral_headline": "Trump Administration Renames Renewable Energy Laboratory",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/12/renewable-no-more-trump-admin-renames-the-national-renewable-energy-laboratory/",
          "published_at": "Tue, 02 Dec 2025 16:01:03 +0000",
          "title": "“Renewable” no more: Trump admin renames the National Renewable Energy Laboratory",
          "standfirst": "A key driver of US renewable energy research is now the National Laboratory of the Rockies.",
          "content": "The Trump administration has renamed the National Renewable Energy Laboratory, now calling it the National Laboratory of the Rockies, marking an identity shift for the Colorado institution that has been a global leader in wind, solar and other renewable energy research. “The new name reflects the Trump administration’s broader vision for the lab’s applied energy research, which historically emphasized alternative and renewable sources of generation, and honors the natural splendor of the lab’s surroundings in Golden, Colorado,” said Jud Virden, laboratory director, in a statement. He did not specify what this “broader vision” would mean for the lab’s programs or its staff of about 4,000.Read full article Comments",
          "feed_position": 9,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/98079-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/98079-1152x648.jpg",
      "popularity_score": 255.79858416666667,
      "ai_summary": [
        "The National Renewable Energy Laboratory has been renamed.",
        "The new name is the National Laboratory of the Rockies.",
        "This change was made by the Trump administration.",
        "The laboratory is a key driver of renewable energy research.",
        "The renaming may signal a shift in priorities."
      ]
    },
    {
      "id": "cluster_76",
      "coverage": 1,
      "updated_at": "Tue, 02 Dec 2025 12:15:55 +0000",
      "title": "Syntax hacking: Researchers discover sentence structure can bypass AI safety rules",
      "neutral_headline": "Researchers Discover AI Safety Rule Bypass Through Sentence Structure",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/ai/2025/12/syntax-hacking-researchers-discover-sentence-structure-can-bypass-ai-safety-rules/",
          "published_at": "Tue, 02 Dec 2025 12:15:55 +0000",
          "title": "Syntax hacking: Researchers discover sentence structure can bypass AI safety rules",
          "standfirst": "New research offers clues about why some prompt injection attacks may succeed.",
          "content": "Researchers from MIT, Northeastern University, and Meta recently released a paper suggesting that large language models (LLMs) similar to those that power ChatGPT may sometimes prioritize sentence structure over meaning when answering questions. The findings reveal a weakness in how these models process instructions that may shed light on why some prompt injection or jailbreaking approaches work, though the researchers caution their analysis of some production models remains speculative since training data details of prominent commercial AI models are not publicly available. The team, led by Chantal Shaib and Vinith M. Suriyakumar, tested this by asking models questions with preserved grammatical patterns but nonsensical words. For example, when prompted with “Quickly sit Paris clouded?” (mimicking the structure of “Where is Paris located?”), models still answered “France.” This suggests models absorb both meaning and syntactic patterns, but can overrely on structural shortcuts when they strongly correlate with specific domains in training data, which sometimes allows patterns to override semantic understanding in edge cases. The team plans to present these findings at NeurIPS later this month.Read full article Comments",
          "feed_position": 12,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/BOOK_PAGES_FLYING-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/BOOK_PAGES_FLYING-1152x648.jpg",
      "popularity_score": 167.04636194444444,
      "ai_summary": [
        "Researchers found sentence structure can bypass AI safety rules.",
        "The research offers clues about prompt injection attacks.",
        "Some prompt injection attacks may succeed due to this.",
        "The findings highlight vulnerabilities in AI systems.",
        "The study focuses on how AI models interpret language."
      ]
    },
    {
      "id": "cluster_104",
      "coverage": 1,
      "updated_at": "Mon, 01 Dec 2025 17:40:14 +0000",
      "title": "Space CEO explains why he believes private space stations are a viable business",
      "neutral_headline": "Space CEO Discusses Private Space Station Viability",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2025/12/space-ceo-explains-why-he-believes-private-space-stations-are-a-viable-business/",
          "published_at": "Mon, 01 Dec 2025 17:40:14 +0000",
          "title": "Space CEO explains why he believes private space stations are a viable business",
          "standfirst": "Voyager Technologies Chairman Dylan Taylor checks in with Ars from the space station frontier.",
          "content": "It’s a critical time for companies competing to develop a commercial successor to the International Space Station. NASA is working with several companies, including Axiom Space, Voyager Technologies, Blue Origin, and Vast, to develop concepts for private stations where it can lease time for its astronauts. The space agency awarded Phase One contracts several years ago and is now in the final stages of writing requirements for Phase Two after asking for feedback from industry partners in September. This program is known as Commercial LEO Destinations, or CLDs in industry parlance. Time is running out for NASA if it wants to establish continuity from the International Space Station, which will reach its end of life in 2030, with a follow-on station ready to go before then.Read full article Comments",
          "feed_position": 19,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2219047538-1024x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2219047538-1024x648.jpg",
      "popularity_score": 162,
      "ai_summary": [
        "Voyager Technologies Chairman Dylan Taylor discussed space stations.",
        "He believes private space stations are a viable business.",
        "Taylor spoke with Ars Technica about the topic.",
        "The interview took place on the space station frontier.",
        "The discussion covered the future of space commercialization."
      ]
    },
    {
      "id": "cluster_101",
      "coverage": 1,
      "updated_at": "Mon, 01 Dec 2025 19:43:05 +0000",
      "title": "Even Microsoft’s retro holiday sweaters are having Copilot forced upon them",
      "neutral_headline": "Microsoft's Holiday Sweaters Feature Copilot Integration",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gadgets/2025/12/even-microsofts-retro-holiday-sweaters-are-having-copilot-forced-upon-them/",
          "published_at": "Mon, 01 Dec 2025 19:43:05 +0000",
          "title": "Even Microsoft’s retro holiday sweaters are having Copilot forced upon them",
          "standfirst": "Microsoft has not one, not two, but three new sweaters available for $60 to $80.",
          "content": "I can take or leave some of the things that Microsoft is doing with Windows 11 these days, but I do usually enjoy the company’s yearly limited-time holiday sweater releases. Usually crafted around a specific image or product from the company’s ’90s-and-early-2000s heyday—2022’s sweater was Clippy themed, and 2023’s was just the Windows XP Bliss wallpaper in sweater form—the sweaters usually hit the exact combination of dorky/cute/recognizable that makes for a good holiday party conversation starter. Microsoft is reviving the tradition for 2025 after taking a year off, and the design for this year’s flagship $80 sweater is mostly in line with what the company has done in past years. The 2025 “Artifact Holiday Sweater” revives multiple pixelated icons that Windows 3.1-to-XP users will recognize, including Notepad, Reversi, Paint, MS-DOS, Internet Explorer, and even the MSN butterfly logo. Clippy is, once again, front and center, looking happy to be included. Not all of the icons are from Microsoft’s past; a sunglasses-wearing emoji, a “50” in the style of the old flying Windows icon (for Microsoft’s 50th anniversary), and a Minecraft Creeper face all nod to the company’s more modern products. But the only one I really take issue with is on the right sleeve, where Microsoft has stuck a pixelated monochrome icon for its Copilot AI assistant.Read full article Comments",
          "feed_position": 18,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/MIC060639_2-xl-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/MIC060639_2-xl-1152x648.jpg",
      "popularity_score": 151,
      "ai_summary": [
        "Microsoft is selling new holiday sweaters.",
        "The sweaters are priced between sixty and eighty dollars.",
        "The sweaters feature Copilot integration.",
        "Microsoft is offering three different sweater designs.",
        "The sweaters are a part of Microsoft's holiday marketing."
      ]
    },
    {
      "id": "cluster_90",
      "coverage": 1,
      "updated_at": "Mon, 01 Dec 2025 23:36:50 +0000",
      "title": "The missile meant to strike fear in Russia’s enemies fails once again",
      "neutral_headline": "Russian Missile Fails to Impress Once Again",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2025/12/the-missile-meant-to-strike-fear-in-russias-enemies-fails-once-again/",
          "published_at": "Mon, 01 Dec 2025 23:36:50 +0000",
          "title": "The missile meant to strike fear in Russia’s enemies fails once again",
          "standfirst": "One of Vladimir Putin's favorite sabres to rattle seems to have lost its edge.",
          "content": "A Russian intercontinental ballistic missile (ICBM) fired from an underground silo on the country’s southern steppe Friday on a scheduled test to deliver a dummy warhead to a remote impact zone nearly 4,000 miles away. The missile didn’t even make it 4,000 feet. Russia’s military has been silent on the accident, but the missile’s crash was seen and heard for miles around the Dombarovsky air base in Orenburg Oblast near the Russian-Kazakh border. A video posted by the Russian blog site MilitaryRussia.ru on Telegram and widely shared on other social media platforms showed the missile veering off course immediately after launch before cartwheeling upside down, losing power, and then crashing a short distance from the launch site. The missile ejected a component before it hit the ground, perhaps as part of a payload salvage sequence, according to Pavel Podvig, a senior researcher at the United Nations Institute for Disarmament Research in Geneva.Read full article Comments",
          "feed_position": 13,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/icbmfailure1.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/icbmfailure1.jpg",
      "popularity_score": 148,
      "ai_summary": [
        "A missile meant to strike fear has failed.",
        "The missile is one of Vladimir Putin's favorites.",
        "The missile's effectiveness seems to be diminished.",
        "The missile's failures have been noted.",
        "The missile's performance is under scrutiny."
      ]
    },
    {
      "id": "cluster_92",
      "coverage": 1,
      "updated_at": "Mon, 01 Dec 2025 22:16:28 +0000",
      "title": "OpenAI desperate to avoid explaining why it deleted pirated book datasets",
      "neutral_headline": "OpenAI Deletes Pirated Book Datasets, Risks Fines",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/12/openai-desperate-to-avoid-explaining-why-it-deleted-pirated-book-datasets/",
          "published_at": "Mon, 01 Dec 2025 22:16:28 +0000",
          "title": "OpenAI desperate to avoid explaining why it deleted pirated book datasets",
          "standfirst": "OpenAI risks increased fines after deleting pirated books datasets.",
          "content": "OpenAI may soon be forced to explain why it deleted a pair of controversial datasets composed of pirated books, and the stakes could not be higher. At the heart of a class-action lawsuit from authors alleging that ChatGPT was illegally trained on their works, OpenAI’s decision to delete the datasets could end up being a deciding factor that gives the authors the win. It’s undisputed that OpenAI deleted the datasets, known as “Books 1” and “Books 2,” prior to ChatGPT’s release in 2022. Created by former OpenAI employees in 2021, the datasets were built by scraping the open web and seizing the bulk of its data from a shadow library called Library Genesis (LibGen).Read full article Comments",
          "feed_position": 15,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-1227510667-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-1227510667-1152x648.jpg",
      "popularity_score": 148,
      "ai_summary": [
        "OpenAI deleted pirated book datasets.",
        "The company risks increased fines as a result.",
        "The deletion followed scrutiny of the datasets.",
        "The datasets were used for training AI models.",
        "The situation raises questions about data sourcing."
      ]
    },
    {
      "id": "cluster_71",
      "coverage": 1,
      "updated_at": "Tue, 02 Dec 2025 15:30:00 +0000",
      "title": "NASA seeks a “warm backup” option as key decision on lunar rover nears",
      "neutral_headline": "NASA Seeks Backup Option for Lunar Rover Decision",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/space/2025/12/wary-of-picking-just-one-nasa-nears-important-decision-on-a-lunar-rover-selection/",
          "published_at": "Tue, 02 Dec 2025 15:30:00 +0000",
          "title": "NASA seeks a “warm backup” option as key decision on lunar rover nears",
          "standfirst": "\"This would be a cheap insurance policy.\"",
          "content": "By the time the second group of NASA astronauts reach the Moon later this decade, the space agency would like to have a lunar rover waiting for them. But as the space agency nears a key selection, some government officials are seeking an insurance policy of sorts to increase the program’s chance of success. At issue is the agency’s “Lunar Terrain Vehicle” (LTV) contract. In April 2024, the space agency awarded a few tens of millions of dollars to three companies—Intuitive Machines, Lunar Outpost, and Astrolab—to complete preliminary design work on vehicle concepts. NASA then planned to down-select to one company to construct one or more rovers, land on the Moon, and provide rover services for a decade beginning in 2029. Over the lifetime of the fixed-price services contract, there was a combined maximum potential value of $4.6 billion. The companies have since completed their design work, including the construction of prototypes, and submitted their final bids for the much larger services contract in August. According to two sources, NASA has since been weighing those bids and is prepared to announce a final selection before the end of this month.Read full article Comments",
          "feed_position": 10,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2020/07/LTV1-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2020/07/LTV1-1152x648.jpg",
      "popularity_score": 145.28108416666666,
      "ai_summary": [
        "NASA is seeking a \"warm backup\" option.",
        "A key decision on the lunar rover is nearing.",
        "The backup option is described as a cheap insurance policy.",
        "The decision involves the future of lunar exploration.",
        "The backup plan aims to mitigate risks."
      ]
    },
    {
      "id": "cluster_72",
      "coverage": 1,
      "updated_at": "Tue, 02 Dec 2025 15:04:53 +0000",
      "title": "“Players are selfish”: Fallout 2’s Chris Avellone describes his game design philosophy",
      "neutral_headline": "Fallout 2 Designer Describes Game Design Philosophy",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2025/12/fallout-2-designer-chris-avellone-recalls-his-first-forays-into-game-development/",
          "published_at": "Tue, 02 Dec 2025 15:04:53 +0000",
          "title": "“Players are selfish”: Fallout 2’s Chris Avellone describes his game design philosophy",
          "standfirst": "Avellone recaps his journey from learning on a TRS-80 to today.",
          "content": "Chris Avellone wants you to have a good time. People often ask creatives—especially those in careers some dream of entering—”how did you get started?” Video game designers are no exception, and Avellone says that one of the most important keys to his success was one he learned early in his origin story. “Players are selfish,” Avellone said, reflecting on his time designing the seminal computer roleplaying game Planescape: Torment. “The more you can make the experience all about them, the better. So Torment became that. Almost every single thing in the game is about you, the player.”Read full article Comments",
          "feed_position": 11,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/Variant_4-rotated-1152x648-1762375363.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/10/Variant_4-rotated-1152x648-1762375363.jpg",
      "popularity_score": 144.86247305555557,
      "ai_summary": [
        "Chris Avellone discussed his game design philosophy.",
        "He described his journey from early computing to today.",
        "Avellone worked on Fallout 2.",
        "He believes players are selfish in their gameplay.",
        "The discussion covered his approach to game development."
      ]
    },
    {
      "id": "cluster_91",
      "coverage": 1,
      "updated_at": "Mon, 01 Dec 2025 22:33:25 +0000",
      "title": "Supreme Court hears case that could trigger big crackdown on Internet piracy",
      "neutral_headline": "Supreme Court Hears Internet Piracy Crackdown Case",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/tech-policy/2025/12/supreme-court-debates-whether-isps-must-kick-pirates-off-the-internet/",
          "published_at": "Mon, 01 Dec 2025 22:33:25 +0000",
          "title": "Supreme Court hears case that could trigger big crackdown on Internet piracy",
          "standfirst": "Justices want Cox to crack down on piracy, but question Sony's strict demands.",
          "content": "Supreme Court justices expressed numerous concerns today in a case that could determine whether Internet service providers must terminate the accounts of broadband users accused of copyright infringement. Oral arguments were held in the case between cable Internet provider Cox Communications and record labels led by Sony. Some justices were skeptical of arguments that ISPs should have no legal obligation under the Digital Millennium Copyright Act (DMCA) to terminate an account when a user’s IP address has been repeatedly flagged for downloading pirated music. But justices also seemed hesitant to rule in favor of record labels, with some of the debate focusing on how ISPs should handle large accounts like universities where there could be tens of thousands of users. Justice Sonia Sotomayor chided Cox for not doing more to fight infringement.Read full article Comments",
          "feed_position": 14,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/online-piracy-1152x648-1764625886.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/online-piracy-1152x648-1764625886.jpg",
      "popularity_score": 133,
      "ai_summary": [
        "The Supreme Court is hearing a case on internet piracy.",
        "The case could trigger a crackdown on piracy.",
        "Justices are questioning Sony's demands.",
        "The justices want Cox to crack down on piracy.",
        "The case involves copyright infringement issues."
      ]
    },
    {
      "id": "cluster_95",
      "coverage": 1,
      "updated_at": "Mon, 01 Dec 2025 21:23:29 +0000",
      "title": "In Myanmar, illicit rare-earth mining is taking a heavy toll",
      "neutral_headline": "Illicit Rare-Earth Mining Impacts Myanmar",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/science/2025/12/in-myanmar-illicit-rare-earth-mining-is-taking-a-heavy-toll/",
          "published_at": "Mon, 01 Dec 2025 21:23:29 +0000",
          "title": "In Myanmar, illicit rare-earth mining is taking a heavy toll",
          "standfirst": "Uncontrolled mining in areas of Myanmar ruled by powerful ethnic armies has boomed.",
          "content": "In early 2025, Sian traveled deep into the mountains of Shan State, on Myanmar’s eastern border with China, in search of work. He had heard from a friend that Chinese companies were recruiting at new rare-earth mining sites in territory administered by the United Wa State Army, Myanmar’s most powerful ethnic armed group, and that workers could earn upwards of $1,400 a month. It was an opportunity too good to pass up in a country where the formal economy has collapsed since the 2021 military coup, and nearly half of the population lives on less than $2 a day. So Sian set off by car for the town of Mong Pawk, then rode a motorbike for hours through the thick forest. Hired for daily wages of approximately $21, he now digs boreholes and installs pipes. It is the first step in a process called in situ leaching, which involves injecting acidic solutions into mountainsides, then collecting the drained solution in plastic-lined pools where solids, like dysprosium and terbium, two of the world’s most sought-after heavy rare-earth metals, settle out. The resulting sediment sludge is then transported to furnaces and burned, producing dry rare earth oxides.Read full article Comments",
          "feed_position": 16,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2218000971-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2218000971-1152x648.jpg",
      "popularity_score": 133,
      "ai_summary": [
        "Illicit rare-earth mining is taking a toll in Myanmar.",
        "Uncontrolled mining has boomed in certain areas.",
        "These areas are ruled by powerful ethnic armies.",
        "The mining is causing environmental damage.",
        "The situation highlights issues of resource exploitation."
      ]
    },
    {
      "id": "cluster_100",
      "coverage": 1,
      "updated_at": "Mon, 01 Dec 2025 19:54:09 +0000",
      "title": "After a Witcher-free decade, CDPR still promises three sequels in six years",
      "neutral_headline": "CD Projekt Red Promises Three Witcher Sequels",
      "bullet_summary": [
        "Reported by Ars Technica"
      ],
      "items": [
        {
          "source": "Ars Technica",
          "url": "https://arstechnica.com/gaming/2025/12/after-a-witcher-free-decade-cdpr-still-promises-three-sequels-in-six-years/",
          "published_at": "Mon, 01 Dec 2025 19:54:09 +0000",
          "title": "After a Witcher-free decade, CDPR still promises three sequels in six years",
          "standfirst": "CD Projekt Red says shift to Unreal Engine allows for more rapid development.",
          "content": "It’s been over 10 years since the launch of the excellent The Witcher 3: Wild Hunt, and nearly four years since the announcement of “the next installment in The Witcher series of video games.” Despite those long waits, developer CD Projekt Red is still insisting it will deliver the next three complete Witcher games in a short six-year window. In a recent earnings call, CDPR VP of Business Development Michał Nowakowski suggested that a rapid release schedule would be enabled in no small part by the team’s transition away from its proprietary REDEngine to the popular Unreal Engine in 2022. At the time, CDPR said the transition to Unreal Engine would “elevate development predictability and efficiency, while simultaneously granting us access to cutting-edge game development tools.” Those considerations seemed especially important in the wake of widespread technical issues with the console versions of Cyberpunk 2077, which CDPR later blamed on REDEngine’s “in-game streaming system.” “We’re happy with how [Unreal Engine] is evolving through the Epic team’s efforts, and how we are learning how to make it work within a huge open-world game, as [The Witcher 4] is meant to be,” Nowakowski said in the recent earnings call. “In a way, yes, I do believe that further games should be delivered in a shorter period of time—as we had stated before, our plan still is to launch the whole trilogy within a six-year period, so yes, that would mean we would plan to have a shorter development time between TW4 and TW5, between TW5 and TW6 and so on.”Read full article Comments",
          "feed_position": 17,
          "image_url": "https://cdn.arstechnica.net/wp-content/uploads/2022/03/witcher-logo-1152x648.jpg"
        }
      ],
      "featured_image": "https://cdn.arstechnica.net/wp-content/uploads/2022/03/witcher-logo-1152x648.jpg",
      "popularity_score": 133,
      "ai_summary": [
        "CD Projekt Red plans three Witcher sequels.",
        "The sequels will be released within six years.",
        "The company is shifting to Unreal Engine.",
        "The new engine allows for faster development.",
        "The announcement follows a decade without new games."
      ]
    }
  ]
}